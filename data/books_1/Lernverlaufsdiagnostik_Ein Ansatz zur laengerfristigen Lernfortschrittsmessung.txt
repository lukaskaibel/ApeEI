111 Lernverlaufsdiagnostik Lernverlaufsdiagnostik: Ein Ansatz zur längerfristigen Lernfortschrittsmessung Alfons M. Strathmann und Karl Josef Klauer Universität zu Köln und RWTH AachenSonderdruck aus: Zeitschrift für Entwicklungspsychologie und Pädagogische Psychologie, 42 (2), 111–122 © Hogrefe Verlag Göttingen 2010 DOI: 10.1026/0049-8637/a000011Zusammenfassung.  Am Beispiel des Rechnens in der Grundschule wird eine Weiterentwicklung des amerikanischen „Curriculum – based measurement“ demonstriert. Ein ganzes Jahr lang erhalten 190 Kinder aus sieben Grundschulklassen und dreiSonderschulklassen alle zwei Wochen einen Rechentest. Bei den Tests handelt es sich um Zufallsstichproben aus Grundgesamt-heiten von Aufgaben, die dem Lehrziel für jedes der Schuljahre entsprechend definiert sind. Für jedes Kind und jeden Terminwird eine eigene neue Zufallsstichprobe generiert, so dass kein Test zweimal gegeben wird, ein jeder aber die geforderteFertigkeit kontentvalide erfasst. Solche Tests lassen sich als kriteriumsorientierte Binomialtests darstellen. Im vorliegendenBeitrag wird (1) das ursprüngliche Konzept und seine Weiterentwicklung kurz vorgestellt, (2) empirisch getestet, ob das neueVerfahren geeignet ist, von Klassenlehrern vertretbar eingesetzt zu werden, und (3) werden Ausblicke auf dringend erwünschteweiterführende Forschungen geboten. Die vorgelegten Daten erlauben, das Spektrum von Verläufen auf Klassenwie Individu-alebene zu dokumentieren, aber auch, die Probleme und vielversprechenden Möglichkeiten des Ansatzes kritisch offen zulegen.Schlüsselwörter: Le rnverlaufsdiagnostik, Lernfortschrittsmessung, Entwicklungsverlauf, Arithmetik  in der Grundschule, kriteriumsorientierte Tests Diagnosing the trajectory of learning: An approach to long term measuring of learning progress Abstract.  This paper describes a further development of the American Curriculum Based Measurement (CBM) using arithmetic tests in elementary schools. For a whole year 190 children from seven classes of elementary schools and three classes ofa special school are administered math tests every second week. The tests are randomly taken from the sets of arithmetic tasksappropriately defined for the respective grades. At each test administration each child received a new sample of test itemsgenerated by a random procedure. This way no test was given twice but every test measured the same objective or skill. Sucha test can be referred to as a criterion referenced binomial test. In this contribution, (1) the CBM procedure is explained andfurther developed; (2) it is empirically tested whether the new diagnostic procedure can be adequately applied by teachers intheir classes; and (3) suggestions are given concerning theoretically important research projects. Based upon the datapresented the range of trajectories of whole classes as well as of children are demonstrated and the problems as well as thepromising possiblities of the test procedure are critically discussed.Key words: curriculum based measurement, measuring the development of learning, aritmetic in elementary school, criterionreferenced tests. Wie entwickelt sich die Lernleistung einzelner Kinder oder ganzer Schulklassen mittelund langfristig? Stellt sich dieLeistungsentwicklung als linearer Zuwachs dar? Oder gibt es typische Lernverläufe, nach denen sich Kinder oder ganze Klassen unterscheiden? Wie oft  begegnet mannichtlinearen Verläufen, etwa positiv oder negativ beschleunigten Kurven oder gar Lernplateaus, bei denen zeitweise kein Lernen erkennbar wird? Fragen dieser Artlassen sich heute nicht beantworten, weil sie regelmäßige Leistungserhebungen über einen längeren Zeitraum hinweg erfordern, wozu sich die herkömmlichen Schulleis-tungstests nicht eignen. Mit zwei oder bestenfalls drei Paralleltests eines Schulleistungstests sind solche Fragen nicht beantwortbar. Anders liegen die Dinge, wenn es umdie Veränderung emotional – motivationaler Leistungskomponenten geht: Einen Fragebogen kann man in regelmäßigen Zeitabständen vorlegen und das gilt auch fürähnliche Selbstauskünfte etwa im Tagebuch, die wiederholt erbeten werden können wie dies beispielsweise Per-els, Gürtler und Schmitz (2005) erfolgreich demonstriert haben. Bemerkenswert in diesem Zusammenhang ist jedoch die amerikanische Entwicklung des Curriculum – Based Measurement (CBM), die auf Stanley Deno von der Uni-versität Minnesota in Minneapolis zurückgeht. Deno hat seit 1972 mit seinen Mitarbeitern in sonderpädagogischem Kontext die Idee entwickelt, den in der Klasse aktuell ver-mittelten Lehrstoff abzutesten statt überregionale Schulleistungstests einzusetzen, daher die (für uns nicht unmittelbar in diesem Sinne verständliche) Bezeichnung dercurriculumbasierten Leistungsmessung. Faktisch ging es ihm darum, in regelmäßigen  Abständen Leistungsmessungen bei genau dem Lehrstoff durchzuführen, der in der http://econtent.hogrefe.com/doi/pdf/10.1026/0049-8637/a000011 Monday, June 15, 2015 1:31:47 AM Universitaetsbibliothek Erlangen-Nuernberg IP Address:131.188.223.224  112 Alfons M. Strathmann und Karl Josef Klauer jeweiligen Klasse behandelt worden war. Genau das ist von Deno und Mitarbeitern gemeint mit „curriculumba-siert“. Es ging Deno darum, eine Möglichkeit zu entwickeln, den aktuellen Leistungsstand immer wieder in kurzen Abständen zu erheben, wobei aber die Prozedur – um nicht zuviel Zeit zu beanspruchen – nicht lange dauern sollte.So wählte er beispielsweise zur Lesediagnostik ein für die Klasse geeignetes Buch, schlug es irgendwo beliebig auf und ließ ein Kind für genau eine Minute laut vorlesen, umdie Anzahl richtig gelesener Wörter pro Minute (WpM) festzuhalten. Dabei wird also die Flüssigkeit des lauten Lesens ermittelt. Diese Prozedur kann man nahezu belie-big oft wiederholen, um die Leistungsentwicklung zu dokumentieren (vgl. Deno, 1985, 2003 a, 2003 b). Tatsächlich korreliert die Anzahl richtig gelesener Wörter sehr gut mitden Ergebnissen klassischer Lesetests (Deno, Mirkin & Chiang, 1982).  Shin, Deno und Espin (2000) haben später auch eine Computerversion des Verfahrens vorgelegt.Dabei wird ein Lückentext mit Auswahlantworten für genau 2,5 Minuten präsentiert, wobei der Schwerpunkt nun nicht auf dem flüssigen, sondern auf dem sinnverstehen-den Lesen liegt. Um die Entwicklung der Rechtschreibung zu verfolgen, haben Fuchs und Fuchs (1993) nicht ganze Sätze, sondern 20–25 einzelne, doch jedes Mal andereWörter diktiert. Ausgezählt wird dabei einfach die Anzahl richtig geschriebener Wörter. Ähnliche Arbeiten wurden in der Mathematik durchgeführt, so beispielsweise vonFuchs, Fuchs, Hamlett und Stecker (1991). Überdies haben viele Autoren sich bemüht, die Testqualität der Verfahren zu ermitteln. So wurde sehr häufig die Reliabilität der Tests bestimmt: Bei den zahlreichen Testwiederholungen lag es nahe, die „Paralleltestreliabili-tät“ zu bestimmen, obwohl es sich nicht eigentlich um Paralleltests handelt. Hierzu liegen zahlreiche Studien vor, die durchweg erfreulich hohe Werte erzielten, man verglei-che – um  nur einige zu nennen – die Arbeiten von Fuchs, Fuchs und Maxwell (1988), von Good und Jefferson (1998), Good, Simmons und Kameenui (2001), VanDerHeyden,Witt, Naquin und Noell, (2001), Deno et al. (2002), Kim und Sunderman (2005), Riley-Heller, Kelly-Vance und Shriver (2005) oder VanDerHeyden und Burns (2005). Einen gutenÜberblick über den damaligen Stand der Entwicklungen findet man bei Fuchs (2004). Allerdings sollte man den Erfolg der curriculumbasierten Messung in den USA nicht überschätzen. Das Verfahren ist dort nach wie vor ein Nischenprodukt und weitdavon entfernt, allgemeine Anerkennung oder gar verbreitete Anwendung zu finden. Selbst im sonderpädagogischen Kontext wird es nicht generell eingesetzt. Das hängtmöglicherweise mit technischen Problemen zusammen, auf die noch einzugehen sein wird. In Deutschland ist das Verfahren nach unserer Kenntnis überhaupt nicht beachtet worden, auch nicht in derSonderpädagogik. Erst ein Artikel von Klauer (2006) über diese Thematik in einer sonderpädagogischen Zeitschrift führte zu beachtlichen Reaktionen. So haben Diehl undHartke (2007) einen informativen Beitrag publiziert und Walter (2008) veröffentlichte eine besonders umfangrei-che empirische Studie zum Lernverlauf beim Lesen von Sonderschulkindern, wobei er ebenfalls über recht hohe Retestkorrelationen berichten konnte. Ein Jahr später leg-te er eine Weiterführung dieser Untersuchungen vor, die die sehr positiven Befunde bestätigt (Walter, 2009 a, 2009 b). Strathmann und Klauer (2008) führten eine Pilot-studie zur Entwicklung des Rechtschreibens durch, wobei sie ebenfalls einzelne Wörter statt ganzer Sätze diktierten. Die vorgelegten Ergebnisse sind allerdings nicht so er-freulich wie die von Walter und die von amerikanischen Autoren berichteten Befunde. Inzwischen haben Strathmann, Klauer und Greisbach (in Druck) eine weitere Studiezur Entwicklung der Rechtschreibung in sechs Grundschulklassen vorgelegt, die in mancher Hinsicht ernüchternde Ergebnisse brachte. Auf die Untersuchung wirdunten noch etwas näher einzugehen sein.  Nach unserer Ansicht sind folgende Probleme einer Lernverlaufsdiagnostik bislang nicht befriedigend gelöst. 1) Es ist völlig unklar, um welche Art von Tests  es sich bei dem Vorgehen handelt. Sicher hat man es nicht mit Tests gemäß der klassischen Testtheorie zu tun. Da jeder Test neue Items bringen muss, sind weder Itemschwierigkeiten noch Trennschärfen verwertbar und eine darauf basierende Itemse-lektion entsprechend wenig sinnvoll. Analoges gilt für die Bestimmung der inneren Konsistenz. Auf den ersten Blick kommt auch kein Test gemäß einem der Item – Response –Modelle in Frage, weil immer neue Items gegeben werden. Dennoch sollte man diese Möglichkeit nicht von vornherein ausschließen, auch wenn  bislang hierzu keineErfolg versprechenden Ansätze bekannt geworden sind. 2) Ferner ist  die Lehrzieloder Kontentvalidität  nicht ganz eindeutig geklärt. Auf den ersten Blick scheint gerade hier eine der Stärken des Verfahrens zu liegen, aber es stellt sich die Frage, ob dem wirklich so ist. Schlägt maneinen Text, der dem Leseniveau der Kinder angemessen ist, an irgendeiner Stelle auf, so ist keinesfalls gesichert, dass die gewählte Stelle nicht zu leicht oder zu schwer ist,dass sie wirklich dem Kompetenzniveau oder gar dem Lehrziel entspricht. Ähnlich liegen die Dinge, wenn in der Mathematik beliebige Aufgaben oder im Rechtschreibtestheute mal diese und morgen mal jene Wörter gewählt werden. Kurz und gut: Die Lehrzieloder Kontentvalidität der Testerhebungen müsste durch ein präzisiertes Verfahrengewährleistet werden. Die „face validity“ genügt keinesfalls. 3) Ein weiterer entscheidender Punkt betrifft die Schwierigkeit der einzelnen Tests . Angenommen, man würde unbeabsichtigt heute einen relativ schweren und morgen einen relativ leichten Test zur gleichen Thematik erheben, so würde vermutlich eine deutliche Leistungs-verbesserung zu verzeichnen sein, ohne dass sich die Leistung realiter  verbessert hätte. Eine Lernverlaufsdiagnostik muss gewährleisten, dass die einzelnen Tests, die http://econtent.hogrefe.com/doi/pdf/10.1026/0049-8637/a000011 Monday, June 15, 2015 1:31:47 AM Universitaetsbibliothek Erlangen-Nuernberg IP Address:131.188.223.224  113 Lernverlaufsdiagnostik da gegeben werden, nicht nur dasselbe erfassen, sondern auch gleich schwer sind. Ist das nicht der Fall, so wird manunvermeidbar Schlussfolgerungen ziehen, die in keiner Weise sachlich begründet sind. Die Homogenität der Testschwierigkeiten  ist also für eine Lernverlaufsdiagnostik von zentraler Bedeutung. Aber dieser Aspekt wurde unseres Wissens bislang nicht berücksichtigt, ja oft gar nicht thematisiert. In aller Regel wurde unterstellt, die ein-zelnen Tests seien alle gleich schwierig. 4) Schließlich sollen die Tests aber auch geeignet sein, Lernzuwächse  zu erfassen, also sensibel für Leistungsänderungen zu sein. Dieser Aspekt der Veränderungsmessung wurde im vorliegenden Zusammenhang von ande-ren Autoren bereits berücksichtigt, insbesondere etwa von Walter (2008; 2009 a). Allerdings wird oft übersehen, dass Veränderungen nur dann zu erfassen sind, wenn dieTests stets das Gleiche messen, sich also auch durch gleiche Schwierigkeit auszeichnen. Wenn aber zwischenzeitlich Lernen stattfindet und in den Tests nachweisbar seinsoll, so müssen die Tests notwendigerweise leichter werden, ihre Mittelwerte also ansteigen. Es wird darauf ankommen, diesem Dilemma in geeigneter Form Rechnungzu tragen. Die vorliegende Studie soll einen Beitrag leisten, wie in den genannten vier Punkten weiter zu kommen ist. Dabei konzentrieren wir uns in dem Beitrag darauf zu prüfen, ob für die Fragen Lösungen gefunden werden können, die esGrundschullehrkräften gestatten, das Verfahren der Lernverlaufsdiagnostik selbst vertretbar einzusetzen. Auf theoretisch wichtige und weitergehende Forschungen wirdabschließend nur kurz hingewiesen. Wir gehen aus von der Forderung, die jeweilige Kompetenz oder Fertigkeit, um die es im Einzelnen geht, durch eine Menge von Aufgaben zu definieren, zu deren Lösung die Kompetenz qualifiziert. Die Aufgabenmengen, derenLösung beherrscht werden soll, sind streng im mengentheoretischen Sinne so zu definieren, dass für jede beliebige Aufgabe eindeutig entscheidbar ist, ob sie Element derMenge ist oder nicht. Solche Aufgabenmengen können einerseits dazu dienen, den Unterricht zielgerichtet zu gestalten, und andererseits  dazu, den Lernerfolg abzutes-ten. Lehrzieloder Kontentvalidität ist also nur dann gegeben, wenn die Testaufgaben der definierten Menge angehören (vgl. Klauer, 1987). Für die Lernverlaufsdiagnostikfordern wir darüber hinaus, repräsentative Stichproben aus der Grundgesamtheit zu ziehen, so dass jeder einzelne Test die Grundgesamtheit valide abbildet. Dieses Verfah-ren gewährleistet erst die Kontentoder Lehrzielvalidität. Es ist, soweit wir sehen, im Kontext der curriculumbasierten Messung nie eingesetzt worden. Repräsentative Itemstichproben können auf zweierlei Weise hergestellt werden, wenn die Grundgesamtheiten entsprechend definiert wurden. Sind die Grundmengen in sich relativ homogen strukturiert, so kann man mittels ei-nes Zufallsgenerators direkt Zufallsstichproben von Aufgaben ziehen oder generieren lassen. Setzen sich die Grundmengen aus klar unterscheidbaren Teilmengen zu-sammen, die unterschiedliche Anforderungen stellen, so wählt man zweckmäßig ein stratifiziert – zufälliges Verfah-ren der Aufgabenerzeugung. In dem Fall wird zuvor festgelegt, zu welchem Anteil jede der Teilmengen in den Itemstichproben vertreten sein soll. Auf der Basis dieserFestlegung werden dann die Itemstichproben durch einen Zufallsgenerator ausgewählt oder erzeugt. Das Itemsampling auf der Basis präzise definierter Grundmengen hat darüber hinaus einen entscheidenden Vorteil. Lord und Novick haben bereits 1968 (S. 234 ff;S. 523) hergeleitet, dass man es mit einem Binomialtest  zu tun hat, wenn jeder Proband eine eigene Zufallsstichprobe von Aufgaben erhält. Zufallsstichproben von Aufga-ben lassen sich prinzipiell beliebig oft generieren, wenn (a) die Aufgabenmenge eindeutig definiert ist und (b) ein Zufallsgenerator darauf zugreifen kann. Im Zeitalter des PCsollten diese Bedingungen leichter als zu Zeiten von Lord und Novick erfüllbar sein. Zieht man also Zufallsstichproben heran, die jeder Teilnehmer erhält, so hat man es mit einem bekannten Testmodell zu tun, und der Personenparameter stellt sich einfachdar als der Anteil (oder Prozentsatz) richtig gelöster Aufgaben. Ferner haben Lord und Novick auch schon gezeigt, dass die Reliabilität eines solchen Tests durch dieKuder – Richardson Formel 21 (K – R 21) gegeben ist (Lord & Novick, 1968, S. 523; De Gruijter & Van der Kamp, 1984, S. 60; Klauer, 1987; S. 151 f). Außerdem steht dann zusätz-lich noch die Möglichkeit zur Verfügung, die Zufallsstichproben als Pseudo – Paralleltests aufzufassen und entsprechend die Pseudo – Paralleltestreliabilität zu ermitteln.In vergleichbaren Studien sprach man einfach von Paralleltests und Paralleltestreliabilität, was – streng genommen – nicht korrekt ist. Immerhin brachte die so ermittelteReliabilitätsschätzung bislang  im Allgemeinen brauchbare Ergebnisse.  Strathmann  et al. (in Druck) haben diese Variante von Lernverlaufsdiagnostik am Beispiel der Rechtschreibung in sechs Grundschulklassen demonstriert, wobei die Kin-der ein halbes Jahr lang jede Woche ein Wortdiktat zu schreiben hatten. Zu diesem Zweck wurde unter Rückgriff auf die einschlägige fachdidaktische Literatur ein Grund-wortschatz von 1.334 Wörtern festgelegt, aus dem bei jeder Testung eine Zufallsstichprobe von Wörtern durch einen Zufallsgenerator gezogen wurde. In den sechsGrundschulklassen erhielten alle Kinder das gleiche Diktat, weil es zu ungewöhnlich gewesen wäre, jedem Kind einzeln ein Diktat zu geben. Daher wurden in dem Fall diesechs Klassen als Individuen aufgefasst, deren Lernfortschritt dokumentiert werden sollte. Dabei stellten sich allerdings unerwartet niedrige Reliabilitäten und unglei-che Schwierigkeiten der verschiedenen Tests heraus, was – wie oben dargelegt – das Konzept einer Lernverlaufsdiagnostik konterkarieren kann. Nun hatten Strathmann et al. die Grundmenge ihres Wortschatzes nicht weiter ausdifferenziert, so dass beispielsweise der Anteil ein-, zweioder gar mehrsilbiger Wörter beliebig variieren konnte. Außerdem konnte ein http://econtent.hogrefe.com/doi/pdf/10.1026/0049-8637/a000011 Monday, June 15, 2015 1:31:47 AM Universitaetsbibliothek Erlangen-Nuernberg IP Address:131.188.223.224  114 Alfons M. Strathmann und Karl Josef Klauer Wortstamm mehrfach auftreten oder nicht, was die Schwierigkeit der Stichproben beeinflusst haben mag.Daher greifen wir hier das zweite Verfahren zur Erzeugung repräsentativer Stichproben auf, nämlich das Verfahren der stratifiziert – zufälligen Erzeugung von Itemstichproben. Im Fach Mathematik, genauer bei der Testung elementarer Rechenfertigkeiten ist dieses Verfahren ohnedies zweckmäßig. Daher werden die Aufgabenmengen nachfachdidaktischen Gesichtspunkten in Teilmengen zerlegt, die in jeder Testmenge nach einem festgelegten Schlüssel zu berücksichtigen sind. Ferner lässt es sich in der Mathematik leichter gewährleisten, dass jedes Kind bei jedem Termin eine eigene Zufallsstichprobe von Aufgaben erhält, so dass wir es uneingeschränkt mit Binomialtests für jedes Kind zu tun haben. Angenommen, die Grundmenge von Aufgaben und der Zufallsgenerator zur Erzeugung repräsentativer Testmengen stehen der Lehrkraft per Internet oder CD-ROM zur Verfügung, so ist es leicht möglich,  beliebig oft undbeliebig viele Tests zu erzeugen und jedem Kind ein eigenes Aufgabenblatt zur Bearbeitung vorzulegen. So kann die Lehrkraft bei geringem Aufwand lehrzielvalide Testserzeugen, die dem Binomialmodell gemäß höchst einfach auszuwerten sind. Methode Versuchspersonen und Datenerhebung In die Untersuchung einbezogen waren sieben Grundschulund drei Sonderschulklassen mit insgesamt 190 Kindern. Von den Grundschülern besuchten 44 eine zwei-te Klasse, 47 eine dritte und 64 eine vierte Klasse, wohingegen die 35 Sonderschüler aus Oberstufenklassen kamen.  Die Daten wurden im Abstand von zwei Wochenüber das ganze Schuljahr 2007/2008 erhoben, so dass bei 40 Schulwochen genau 20 Testerhebungen stattfanden. In jeder Klasse erschien zu diesem Zweck stets die gleichestudentische Hilfskraft, teilte die Testblätter aus, ließ die Blätter bearbeiten und sammelte sie danach ein. Anschließend gab sie die Daten in ein Computerprogramm ein. Die Ergebnisse einschließlich der Lernverlaufskurven pro Kind und Klasse standen den Lehrkräften per Internet zur Einsicht zur Verfügung. Das Aufgabenblatt, das ein Kind zum jeweiligen Termin erhielt, bot eine stets neue und eigene Zufallsstichprobe von Aufgaben. Daher mussten die Hilfskräfte vordem Gang in die jeweilige Schule zunächst aus dem Computerprogramm so viele verschiedene Aufgabenblätter generieren lassen wie sie Kinder zu testen hatten. Definition der Aufgabenmengen und Itemgenerierung Die Aufgabenmengen und ihre Definitionen wurden den Diagnoseund Förderblättern von Klauer (1994 a, b, c)entnommen, die spezifisch für das jeweilige Schuljahr Aufgaben zur Addition, Subtraktion, Multiplikation, Divisionund zum Rechnen mit Größen enthalten. Diese Definitionen waren bis auf das Rechnen mit Größen auf Computer gespeichert worden. Ferner war ein Zufallsgenerator in-stalliert und entsprechend programmiert worden, so dass beliebig viele Aufgaben erzeugt werden konnten. Jeder Test bestand aus 24 Aufgaben, die auf die einzelnen Teilmengen nach festgelegten Anteilen aufgeteilt waren. Die Anzahl von 24 Aufgaben wurde gewählt, weildie Zahl 24 durch besonders viele Zahlen teilbar ist. Beispiel: Für das 3. Schuljahr waren sechs Teilmengen zu berücksichtigen: Mündliche Addition und Subtraktion,schriftliche Addition und Subtraktion, ferner Multiplikation und Division. Für jede dieser sechs Teilmengen waren für jeden Termin und jedes Kind vier Aufgaben zufällignach Maßgabe der in den Diagnoseund Förderblättern vorliegenden Definitionen zu erzeugen (siehe Beispiel). Beispiel (nach Klauer, 1994 b, S. 12) für die Definitionder schriftlichen Subtraktion im dritten Schuljahr (H = Hunderter, Z = Zehner, E = Einer). Aufgabenform 1 Aufgabenform 2 Aufgabenform 3 HZE* H00* 1000 – HZE * – HZE* – HZE * Die Null darf bei Z und E höchstens zweimal vorkommen. Das obere H muss stets größer als das unteresein. Ein Übertrag darf maximal einmal nötig sein. Die Aufgabenformen 1, 2 und 3 sind im Verhältnis von 4 : 1 : 1 zu wählen. An diesem Beispiel soll ein weiterer Aspekt der Itemgenerierung erläutert werden. Laut Definition ist die Aufgabenform 1 viermal so häufig einzusetzen wie Aufgabenform 2 oder 3, einfach weil Form 1 den Normalfall der schriftlichen Subtraktion darstellt, während es sich bei den beiden anderen Aufgabenformen um Sonderfälle handelt. Da aber nur vier Aufgaben der schriftlichen Subtraktion vorgesehen sind, lässt sich dieses Verhältnis nicht auf einem einzelnen Aufgabenblatt umsetzen. Deshalb wurde dafür Sorge getragen, das vorgesehene Verhältnis bei den20 Aufgabenblättern eines Kindes einzuhalten. Im Extremfall finden sich in einem einzelnen Aufgabenblatt nur Aufgaben von Form 1, während im anderen Extrem nur eineeinzige Aufgabe dieser Art präsentiert wird. Das hatte leichte Variationen von Aufgabenblatt zu Aufgabenblatt zur Folge, zumal bei den anderen Rechenoperationen ana-loge Verhältnisse  gegeben waren. Diese Variabilität erscheint aber unvermeidlich, will man lehrzielvalide Leistungsmessung durchführen. Da aber jedes Kind zu jedemTermin eine neue Zufallsstichprobe von Aufgaben erhielt, sollte sich diese leichte Variabilität keinesfalls auf die mittlere Lösungshäufigkeit des Kindes oder der Klasse ausgewirkt haben. Die Aufgaben wurden vom Computer so auf einem Blatt angeordnet, dass die Kinder unmittelbar in das Blatt hineinschreiben konnten. http://econtent.hogrefe.com/doi/pdf/10.1026/0049-8637/a000011 Monday, June 15, 2015 1:31:47 AM Universitaetsbibliothek Erlangen-Nuernberg IP Address:131.188.223.224  115 Lernverlaufsdiagnostik Ermittlung der Testreliabilität Wie ausgeführt erhielt jedes Kind bei jedem Termin eine eigene Zufallsstichprobe von Aufgaben. Da die Zufallsstichproben aber repräsentativ für das jeweilige Lehrzielder Klasse waren, konnten die Ergebnisse, die die Kinder heute erzielten, mit den Ergebnissen korreliert werden, die sie zu einem späteren Zeitpunkt erhielten. Um nicht durchdifferentielle  Lernfortschritte der Kinder beeinträchtigte Werte zu erzielen, bezieht sich die Pseudo-Reliabilität auf die Korrelation unmittelbar aufeinander folgender Tests.Die sollten sich wenig unterscheiden. Nun basiert die Pseudo-Paralleltestreliabilität notwendigerweise auf zwei Testerhebungen, charakterisiert also nicht die Qualität derDaten einer  Testung.  Das ist anders bei der Berechnung der Reliabilität gemäß der Kuder – Richardson Formel 21. Sie ist speziell auf Tests dieser Art bezogen und kenn-zeichnet die Reliabilität des jeweiligen Tests als solchen. Homogenität der Testschwierigkeiten Da im Laufe des Schuljahres mit Lernzuwächsen zu rech-nen ist, werden die Mittelwerte der Tests im Laufe der Zeit ansteigen. Dennoch unterstellen wir, dass unmittelbar aufeinander folgende Tests noch am ehesten gleichschwierig sind und testen deshalb diese Testpaare auf Gleichheit der Mittelwerte. Das geschieht mittels t-Test für verbundene Stichproben. Vergleicht man so Test 1 mitTest 2, Test 2 mit Test 3 usw., so werden pro Klasse 19 Signifikanztests notwendig, wobei auch mit zufälligen Signifikanzen zu rechnen ist. Um also der Inflationierung desD-Fehlers zu begegnen, wenden wir die sequentielle Variante von Holm (1979) bei der Bonferroniprozedur an und testen deshalb die größte Mittelwertsdifferenz gegen D / 19, die zweitgrößte gegen D / 18 usw. Dadurch wird aber die Wahrscheinlichkeit des E-Fehlers deutlich erhöht, was im vorliegenden Fall auch ungünstig ist, denn es sollen jaLernfortschritte – also Leistungsverbesserungen – durchaus erfasst werden. Im Kompromiss zwischen diesen beiden Konsequenzen setzen wir D = .10 statt D = .05 an. Auf diese Weise testen wir den größten Mittelwertsunterschied gegen D = .10/19 = .0053, den zweitgrößten gegen D = .10 / 18 = .0056 und so fort. Nun sagt die Signifikanz einer Mittelwertsdifferenz noch nichts darüber aus, wie groß der Effekt ist, um den esda geht. Zur Abschätzung der praktischen Bedeutsamkeit eines Effekts wird daher dessen Effektstärke d bestimmt nach der Formel d = (M 2 –M1)/sp, wobei sp die gemittelte Standardabweichung bezeichnet. Nach Cohen (1988) gilt ein Effekt als groß,  wenn d gleich oder größer als .80 ist. Solche Effekte sollen herausgehoben werden. Darstellung der Verlaufskurven Da in allen Fällen pro Test 24 Aufgaben präsentiert wurden, werden die y-Achsen der Verlaufskurven aus 24 Einheiten bestehen und die x-Achsen werden die 20 Testter-mine repräsentieren. Zur Verdeutlichung der Zusammenhänge haben wir Regressionslinien eingezeichnet und dieRegressionsgleichungen geboten. Bei nichtlinearen Regressionen wird die optimale Passung bei möglichst niedrigem Grad bestimmt. Die Verlaufskurven sollen der besseren Übersicht wegen in vier Kategorien eingeteilt werden. Auf „Ceiling-effekt“ wird erkannt, wenn vor dem letzten Test der Serie mindestens 23 Aufgaben gelöst worden sind. „Linear ansteigend“ gelten alle Verläufe mit linearer Regressions-gleichung, während „nichtlineare Varianten“ ein Polynom höherer Ordnung enthalten. Schließlich gibt es noch die Gruppe „keine Verbesserung“, die angenommen wird,wenn ein linearer Trend durch die Regression b < .15 gekennzeichnet ist. Ergebnisse Messqualität der Erhebungen Bevor die eigentlichen Ergebnisse dargestellt werden, erscheint es angemessen, zunächst die Qualität der erfassten Daten zu prüfen. Was die Reliabilität der Testungen angeht, so bieten sich, wie angedeutet, zwei Varianten an,die Berechnung der Reliabilität nach Kuder – Richardson, Formel 21 (K – R 21), sowie die Pseudo-Paralleltestreliabilität. Die letztere sei definiert als die Korrelationen unmit-telbar aufeinander folgender Tests (so als die Korrelation zwischen Test 1 und Test 2, Test 2 und Test 3, usw.), weil bei den späteren Tests deutlicher unterschiedliche Lern-fortschritte modifizierend ins Spiel kommen könnten. Bei einer herausgegriffenen dritten Klasse Grundschule stellten sich die Mittelwerte und Standardabweichungen derVerteilungen beider Reliabilitätsmaße wie folgt dar: Mittelwert der 20 Koeffizienten KR – 21:    0.77 ± 0.06 (Range: 0.66 – 0.91) Mittelwert der 19 Pseudo-Paralletestreliabilitäten :   0.73 ± 0.09 (Range: 0.56 – 0.88) Wie man sieht, sind die Ergebnisse bei der K – R 21 nur unbedeutend günstiger als bei der Pseudo-Paralleltestreliabilität. Das wird auch bei der Verteilung der Koeffizienten in Abbildung 1 deutlich. In den übrigen Klassen stellen sich die Verhältnisse ähnlich dar, so dass darauf verzichtet wird, diese Ergeb-nisse ebenfalls aufzuführen. Da es nur geringe Unterschiede zwischen den Klassen gab, wurden die Grundschulklassen des zweiten, dritten und vierten Schuljahrszusammengenommen, um die Korrelationsmatrix zu berechnen (vgl. Tabelle 1). Die Hauptdiagonale zeigt die 19 Pseudo-Paralleltestreliabilitäten in der Gesamtheit der Grundschulklassen. Mittelwert und  Standardabweichung liegen bei 0.77 ± 0.02(Range: 0.72 – 0.81), so dass sich die Größenordnung hier bestätigt. Man wird also schließen können, dass die Reliabilität der Tests akzeptabel ist. http://econtent.hogrefe.com/doi/pdf/10.1026/0049-8637/a000011 Monday, June 15, 2015 1:31:47 AM Universitaetsbibliothek Erlangen-Nuernberg IP Address:131.188.223.224  116 Alfons M. Strathmann und Karl Josef Klauer Tabelle 1 bietet noch einen keineswegs erwarteten Befund. Die Korrelationsmatrix nähert sich deutlich einer Simplexstruktur an: Verfolgt man die erste Zeile  von links nach rechts, so fallen die Werte zwar nicht streng mono-ton ab, doch ist die Tendenz dazu unverkennbar. Und verfolgt man die letzte Spalte , also die von Test 20 von oben nach unten, so zeigt sich hier eine ansteigende Tendenz.Die Korrelationsmatrizen für die einzelnen Klassen offenbaren die gleichen Tendenzen, wenn auch weniger deutlich. Anschließend soll die Homogenität der Testschwierigkeiten geprüft werden. Wie oben dargelegt erscheint essinnvoll, die Mittelwerte unmittelbar aufeinander folgen-der Tests auf Schwierigkeitsunterschiede zu vergleichen. Mittels t-Tests für abhängige Stichproben wurde so die Homogenität der Tests pro Klasse überprüft. Die Anzahlsignifikanter t-Tests, die gemäß der sequenziellen Variante von Holm zur D-Adjustierung resultierten, ist der Tabelle 2 zu entnehmen. Trotz der vielen Tests gibt es nur fünf signifikante Mittelwertsdifferenzen und nur im Fall der Differenz in einer der dritten Klasse handelt es sich um einen großenEffekt.  In den übrigen vier Fällen geht es um kleinere Effekte. Verlaufskurven Die mittleren Lernverläufe in den Schulklassen  ähneln sich recht stark. Sie lassen sich alle mehr oder minder gut durch eine lineare Regression modellieren und unterschei-den sich im Wesentlichen durch ihren Startpunkt und die Steigung. Abbildung 2 bringt die Leistungsentwicklung der drei Klassen einer der beiden Grundschulen, die sichdeutlich voneinander abheben lassen. Man beachte, dass jede Klasse an ihrem eigenen Lehrziel gemessen wurde. Hätten die drei Klassen glei-chermaßen viel zugelernt, so wären parallele Verläufe zu sehen, die sich bei gleichem Ausgangspunkt sogar weitgehend überschneiden müssten. Und hätten alle ihr Lehr-ziel erreicht, so würden alle in der rechten oberen Ecke enden. Faktisch beherrscht keine der Klassen am Schuljahrsende die Rechenfertigkeiten, die sie beherrschen soll-ten. Aber auch die Startpunkte sind unterschiedlich: DieAbbildung 1. Verteilung der Reliabilitätskoeffizienten in einer dritten Klasse Grundschule (Grau: Koeffizienten ge-mäß Kuder – Richardson 21; weiß: Pseudo-Paralleltestreliabilitäten).024681012 0,6 0,6 0,7 0,7 0,8 0,8 0,9 0,9 ReliabilitätHäufigkeitTabelle 1.  Obere Hälfte der Korrelationsmatrix aller Grundschulklassen T2 T3 T4 T5 T6 T7 T8 T9 T10 T11 T12 T13 T14 T15 T16 T17 T18 T19 T20 T1 .77 .75 .68 .61 .67 .64 .66 .50 .56 .51 .50 .48 .47 .54 .46 .43 .44 .49 .25 T2 .80 .73 .70 .76 .73 .70 .53 .60 .54 .55 .45 .54 .55 .50 .48 .45 .45 .27 T3 .77 .72 .74 .76 .71 .57 .64 .67 .58 .54 .52 .58 .52 .47 .44 .48 .37 T4 .72 .78 .76 .75 .65 .68 .65 .62 .57 .53 .58 .54 .50 .48 .49 .42T5 .77 .81 .72 .60 .58 .57 .61 .53 .60 .62 .59 .57 .53 .57 .36 T6 .79 .79 .67 .66 .63 .61 .59 .60 .65 .64 .55 .54 .51 .43 T7 .79 .66 .62 .59 .58 .54 .56 .62 .61 .56 .51 .52 .47T8 .74 .67 .64 .68 .60 .67 .66 .60 .48 .56 .48 .45 T9 .75 .76 .72 .66 .76 .73 .64 .57 .64 .57 .53 T10 .80 .72 .69 .73 .73 .58 .66 .60 .56 .53T11 .76 .71 .69 .71 60 .58 .61 .62 .52 T12 .75 .76 .74 .68 .68 .69 .63 .64 T13 .76 .79 .70 .73 .73 .69 .71 T14 .76 .71 .72 .70 .68 .66 T15 .75 .72 .71 .74 .67 T16 .75 .79 .71 .73 T17 .81 .78 .79 T18 .75 .76 T19 .76 http://econtent.hogrefe.com/doi/pdf/10.1026/0049-8637/a000011 Monday, June 15, 2015 1:31:47 AM Universitaetsbibliothek Erlangen-Nuernberg IP Address:131.188.223.224  117 Lernverlaufsdiagnostik zweite Klasse brachte das geringste Vorwissen mit, während die dritte Klasse bereits mit der Hälfte des zu erler-nenden Wissens begann. Die vierte Klasse begann dagegen auf einem Niveau das zwischen dem der beiden anderen Klassen liegt.In den Regressionsgleichungen sind die Steigungen (Regressionskoeffizienten) und die Determinationskoeffi-zienten R 2 besonders bemerkenswert Klasse 2 y = .83 x + 2.75 R2 = .95 Klasse 3 y = .45 x + 12.13 R2 = .92 Klasse 4 y = .22 x + 9.7 R2 = .65 Klasse 2 zeigt eindeutig die größte Steigung, obwohl sie das geringste Vorwissen mitbrachte. Die Steigung von Klasse 3 ist fast nur halb so groß. Die Steigung von Klasse 4 ist wiederum nur etwa halb so groß wie die von Klasse 3.Legt man die Steigungen zugrunde, so ist für Klasse 4 abzuleiten, dass sie nach 10 Tests, also nach einem halben Schuljahr, gerade mal 2.2 Aufgaben im Durchschnitt mehrlöste als zu Beginn des Schuljahrs. Am Ende des Schuljahrs löste Klasse 4 danach 4.4 Aufgaben im Mittel mehr, Klasse 2 dagegen 0.83 × 20 = 16.6 Aufgaben. Der Lernzu-wachs ist in Klasse 4 unverständlich bescheiden, zumal die Klasse ja schon ein gutes Vorwissen mitbrachte. Die Determinationskoeffizienten lassen erkennen, wie die Varianz der Rechenleistungen in den Klassen 2 und 3 wesentlich von der Varianz der unabhängigen Variablen abhängt, praktisch also von der Dauer der Beschulung.Dagegen spielen in Klasse 4 offenbar auch noch andere Faktoren eine Rolle. Eine Varianzanalyse mit Messwiederholung und Innersubjektkontrasten wurde für die drei Schulen getrennt durchgeführt. Die Analysen bestätigten zunächst die linearen Trends, zeigen aber auch für die Schule von Abbil-dung 2 eine signifikante Interaktion ( p = .004) des Faktors Tests mit dem Faktor Klassen. Dabei geht es um einen signifikanten polynomialen Trend 2. Ordnung, der auf dievierte Klasse zurückzuführen ist. In Abbildung 3 ist die Verlaufskurve der Klasse erneut abgebildet, diesmal aber mit der leicht negativ beschleunigten Regressionslinie, dienun auch den quadratischen Term enthält. Der Determinationskoeffizient bestätigt mit R 2 = .83 die gute Passung der Daten und nähert sich somit der Größenordnung der Koeffizienten in den beiden anderen Klassen. In dieser Variante der Lernverlaufskurve wird deutli-cher, dass die Klasse anfangs noch etwas mehr, dann aber immer weniger zulegt, ja in der zweiten Hälfte des Schuljahres praktisch keinerlei Kompetenzzuwachs mehr zeigt. Auf individueller Ebene  begegnet man einer größeren Vielfalt von Entwicklungsverläufen. Ein Großteil dieser Verläufe stellt sich ebenfalls als linear dar, insbeson-dere in den Grundschulklassen. Allerdings unterscheiden sich die Verläufe hier deutlich bezüglich des Startniveaus einerseits und der Steigung andererseits. Daneben gibt esaber auch nichtlineare Verlaufskurven, auf die nun kurz einzugehen ist. Die Aufgabenmengen sind, wie dargelegt, spezifisch definiert für jede Klasse. Insofern ist zu erwarten, dass ein Großteil der Kinder im Laufe des Schuljahrs die Kompetenz erwirbt, alle in Frage kommenden Aufgaben bewälti-Tabelle 2. Signifikante Mittelwertsdifferenzen zwischen aufeinanderfolgenden Tests Signifikante Differenzen Sonderschule ( N = 35) 1* Klasse 2 Schule M ( N = 22) 2* Schule Z ( N = 22) 0 Klasse 3 Schule M ( N = 26) 1** Schule Z ( N = 21) 0 Klasse 4 Schule M ( N = 22) 0 4a Schule Z ( N = 22) 1* 4b Schule Z ( N = 19) 0 Anmerkungen: *Effektstärke d < .80; ** d = .83. Abbildung 2 . Lernverlaufskurve dreier Klassen Grundschule (2. Klasse ganz unten beginnend, 3. Klasse obere Kurve, 4. Klasse in der Mitte beginnend). Abbildung 3. Lernverlaufskurve der vierten Klasse von Abbildung 2 mit leicht negativ beschleunigter Regressionslinie (Regressionsgleichung: y = –.023 x2 + .712 x + 7.89, R2 = .83).04812162024 123456789 1 0 1 1 1 2 1 3 1 4 1 5 1 6 1 7 1 8 1 9 2 0 TestAnzahl richtig 04812162024 123456789 1 0 1 1 1 2 1 3 1 4 1 5 1 6 1 7 1 8 1 9 2 0 TestAnzahl richtig http://econtent.hogrefe.com/doi/pdf/10.1026/0049-8637/a000011 Monday, June 15, 2015 1:31:47 AM Universitaetsbibliothek Erlangen-Nuernberg IP Address:131.188.223.224  118 Alfons M. Strathmann und Karl Josef Klauer gen zu können. Faktisch impliziert dies die Möglichkeit, früher oder später alle präsentierten 24 Aufgaben lösen zukönnen, also an die „Decke“ zu stoßen (Abbildung 4). Im Fall von Abbildung 4 wird deutlich, wie zwangsläufig ein kurvilinearer Verlauf resultiert, wenn ein Kind sich schon vor Ende des Schuljahrs dem Lehrziel annähert oder es gar erreicht. Im vorliegenden Beispiel bringt erst einPolynom dritten Grades eine gute Anpassung an den Lernverlauf des Kindes. Das belegt auch der Determinationskoeffizient, der einen beachtlich hohen Wert zeigt.Das Kind bietet in der ersten Hälfte des Schuljahres ein leichtes Auf und Ab mit nur relativ geringer Verbesserung der Leistungen, während es in der zweiten Hälfte einenkräftigen Spurt vorlegt, so als ob irgendein Hemmnis be-seitigt worden oder gar „der Groschen endlich gefallen“ wäre. Die beiden Kinder von Abbildung 5 zeigen dagegen so gut wie keinen Leistungsfortschritt im Verlaufe des Schuljahrs. Hier die beiden Regressionsgleichungen unddie Determinationskoeffizienten: Drittklässler: y = .09 x + 14.8 R 2 = .02 Viertklässler: y = .13 x + 8.0 R2 = .15 Die untere Linie stammt von einem  Kind jener vierten Klasse von Abbildung 2, die insgesamt auffällig wenig zugelernt hatte. Dieses Kind hier zeichnet sich noch durchganz wenige Schwankungen aus, es bringt gleichbleibend mäßige Leistungen. Außerdem zeigt die Regressionslinie eine recht geringe Steigung ( b = .13), was bedeutet, dass für das Kind am Ende des Schuljahrs eine Verbesserung von etwa 20 × .13 = 2.6 Aufgaben pro Test erwartet werden kann. Bei dem Kind der oberen Linie handelt es sich umden Schüler eines dritten Schuljahres und einer anderen Grundschule. Auch dieser Junge lernt praktisch kaum was dazu, obwohl er doch von Anfang an recht gute Leistun-gen vorlegt und zwischendurch sogar Spitzenleistungen erbringt. Aber bei einer noch schwächeren Steigung der Regressionslinie von b =.09 dürfte die Lehrkraft keine Chance haben, überhaupt eine Leistungsverbesserung zu erkennen. Allerdings zeigt das Kind sehr viel stärkere Schwankungen in der Leistung, die möglicherweise aufbesondere Belastungen hindeuten. Noch ausgeprägtere Schwankungen offenbart der Schüler von Abbildung 6. Er gehört zu einer Sonderschul-klasse, der ein an sich zu leichter Test gegeben wurde, weil es einige besonders schwache Kinder darunter gab. Man erkennt unschwer, dass der Schüler zu guten Leistungenbefähigt ist, sonst würde er nicht mehrfach fast perfekte Ergebnisse gebracht haben. Aber man wird den etwas chaotischen Verlauf wohl auf andere Faktoren zurückführen,etwa auf Verhaltensstörungen, auf Probleme in der sozialen Interaktion oder auf Schwierigkeiten im häuslichen Umfeld. Selbst ein Polynom fünften Grades bringt nur einemäßige Anpassung an die Realität des Kindes, verdeutlicht aber die erheblichen Leistungsschwankungen, denen jedoch praktisch kein Zugewinn entspricht. Abschließend erscheint es sinnvoll, die Verlaufskurven grob in vier Typen einzuteilen, wie sie im Methodenteil definiert worden sind. Das ist in Tabelle 3 geschehen.Die Kinder mit dem Ceilingeffekt haben das Ziel des jeweiligen Schuljahres eindeutig erreicht und für alle anderen gilt das nicht. Auffällig ist der große Anteil von Sonder-schülern mit Ceilingeffekt. Allerdings erhielten, wie erwähnt, die Sonderschüler die leichteste Testvariante, nämlich die für Klasse 2, obwohl sich alle Kinder bereits in derOberstufe befanden. Hier war knapp die Hälfte der Kinder von Anfang an unterfordert, weil sie bereits mit einem Ceilingeffekt begannen. In der Grundschule zeigt der weitüberwiegende Teil der Kinder linear  ansteigende Leistungen, auch wenn sie nur in Einzelfällen im Zielbereich enden. Deutlich nichtlineare Verläufe sind offenbar anschei-Abbildung 4. Lernverlaufskurve mit Ceilingeffekt eines Mädchens der 2. Klasse Grundschule (Regressionsgleichung: y = –.01 x 3 + .32 x2 – 1.88 x + 6.75;  R2 = .93). Abbildung 5. Lernverlaufskurve zweier Kinder, die in dem Schuljahr nahezu nichts gelernt haben (Drittklässler obe-rer, Viertklässler unterer Verlauf). Abbildung 6. Etwas chaotischer Leistungsverlauf eines Sonderschülers ohne Lernfortschritt (Regressionsglei-chung: y = .005 x 5 –.025 x4  + .44 x3 – 3.02 x2 + 5.76 x + 18.8; R2 = .35).04812162024 123456789 1 0 1 1 1 2 1 3 1 4 1 5 1 6 1 7 1 8 1 9 2 0 Tests 04812162024 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 TestAnzahl richtig 04812162024 123456789 1 0 1 1 1 2 1 3 1 4 1 5 1 6 1 7 1 8 1 9 2 0 TestsAnzahl richtig Anzahl richtig Anzahl richtig http://econtent.hogrefe.com/doi/pdf/10.1026/0049-8637/a000011 Monday, June 15, 2015 1:31:47 AM Universitaetsbibliothek Erlangen-Nuernberg IP Address:131.188.223.224  119 Lernverlaufsdiagnostik nend relativ selten, jedoch ist der Anteil der Kinder, die praktisch keinen Fortschritt im Laufe des Schuljahrs zeigten, überraschend groß. Diskussion Zu den Lernverläufen auf Individualund Klassenebene Ehe auf die Verläufe im Einzelnen eingegangen wird, erscheint es sinnvoll herauszustellen, dass sich die Verläufenach einem allgemeineren Schema modellieren lassen: Unter der Voraussetzung, dass die Tests gleich schwierig sind und über längere Zeit in regelmäßigen Abständenerhoben werden, lässt sich offenbar der Zusammenhang zwischen dem erreichten Lernniveau y und der Zeitachse (bzw. der Testachse) x als Funktion y = f (x, a, e) darstellen.Dabei steht a für das Leistungsniveau am Beginn des Prozesses, während sich e auf nicht erfasste Komponenten bezieht, so insbesondere auf Messfehler, aber auch aufTagesschwankungen und andere unsystematische Einflüsse. Nach den vorliegenden Befunden dürfte in den meisten Fällen eine lineare Regression genügen, um den Verlauf angemessen zu beschreiben. Polynome zweiten oderhöheren Grades sind danach deutlich seltener gefordert, etwa wenn eine negativ oder eine positiv beschleunigte Lernkurve resultiert. Nach den vorliegenden Daten wirdes allerdings bei einzelnen Schülern notwendig sein, Polynome höherer Ordnung anzusetzen, beispielsweise wenn ein mehr oder minder periodisches Auf und Ab im Leis-tungsverlauf gegeben ist. Im Einzelnen stellen sich jedoch recht bemerkenswerte Verläufe dar, etwa die Lernverlaufskurven von Kindern, die das ganze Schuljahr über praktisch so gut wie keinen Fortschritt erkennen lassen. Solche Kinder stellen zweifel-los Problemfälle dar, und es erhebt sich die Frage, ob die Lehrkräfte den Stillstand wirklich immer entdecken und entsprechend intervenieren. Möglicherweise ist das denLehrkräften überhaupt nicht aufgefallen, dass bei den Kindern keine wesentliche Lernfortschritte erkennbar sind. Allerdings ist in dem Zusammenhang ein weiterer Befund zu beachten. Die Kinder, deren Leistungen über das Schuljahr hinweg mehr oder minder deutlich linear anstei-gen, unterscheiden sich sehr auffällig im Steigungswinkel. Es ist also gut möglich, dass schwache Kinder besondere Lernförderungen erhielten und es dadurch zu immerhin mäßigen und einigermaßen stetigen Lernzuwächsenbrachten, selbst wenn sie das Ziel der Klasse am Ende des Schuljahres nicht erreichten. Wenn es also solche spezielle Hilfen gab, so muss man mit einem Anteil von Kindernrechnen, die sich den besonderen Hilfen gegenüber als lernresistent erwiesen haben. Alternativ bleibt in der Tat nichts anderes übrig als zu vermuten, den Lehrkräften sei der Stillstand nicht aufgefallen. Immerhin gibt es deutliche Hinweise auf relativgeringe diagnostische Kompetenzen von Lehrkräften (Bromme, 1997; Helmke, Hosenfeld & Schrader, 2004; Schrader, 2001). Regelmäßige Leistungserhebungen imSinne der Verlaufsdiagnostik, wenn sie von den Lehrkräften selbst durchgeführt würden,  könnten ihre Aufmerksamkeit jedoch eher auf diese Kinder lenken und die diag-nostische Kompetenz der Pädagogen erheblich unterstützen. Auf diese Weise ließen sich nicht nur Problemfälle deutlich früher erkennen, sondern Fördermaßnahmen ein-leiten, deren Effekte sich in der Folge darstellen würden. Die nichtlinearen Verläufe von Tabelle 3 und die Verläufe mit einer hohen Variabilität der Rechenleistungen stellen zweifellos ebenfalls Problemfälle dar, hinter denen sich die unterschiedlichsten Ursachen verbergen können.Zweckmäßig wird man diesen Phänomenen zunächst mit Einzelfallstudien nachgehen, um das Spektrum möglicher Hintergründe kennenlernen zu können. Soviel zu den individuellen Verlaufskurven. Nun zeigen die mittleren Lernverläufe  der ganzen Klassen erwartungsgemäß eine relativ geringe Variabilität um die Regressionslinie und durchweg mehr oder minder deutlich ansteigende Lernfortschritte, auch wenn Letzteres für eineder Klasse nicht zutrifft. Bemerkenswert sind die unerwartet großen Unterschiede zwischen den Schulklassen in den Steigungskoeffizienten der Regressionsgleichungen.Diese Koeffizienten lassen sich unmittelbar als ein Maß für den Lernanstieg verstehen, der in der jeweiligen Klasse erzielt worden ist. Interessant ist in dem Zusammenhang, dass in den USA Bestrebungen im Gange sind, die Benotung vonSchülern wie die Besoldung von Lehrkräften nicht vom jeweils erreichten Leistungsstand der Kinder abhängig zu machen, sondern vom Lern zuwachs , der etwa im letztenTabelle 3 . Häufigkeitsverteilung der Verlaufstypen in Prozent (ohne die vier Sonderschüler, die mehr als dreimal bei den Tests fehlten) Mit Ceilingeffekt Linear ansteigend Nichtlineare Varianten Keine Verbesserung Grundschule 17 % 64 % 5 % 14 % (N = 136) Sonderschule 45 % 23 % 3 % 29 % (N = 31) http://econtent.hogrefe.com/doi/pdf/10.1026/0049-8637/a000011 Monday, June 15, 2015 1:31:47 AM Universitaetsbibliothek Erlangen-Nuernberg IP Address:131.188.223.224  120 Alfons M. Strathmann und Karl Josef Klauer Schuljahr erreicht worden ist (vgl. Amrein-Beardsley, 2008; Raudenbush, 2004). Die regelmäßige Lernverlaufs-diagnostik nach dem vorgestellten Muster mit Tests, die stets dasselbe messen, stellt hierfür ein geeignetes Mittel dar. Zur Qualität der zufallsgenerierten Pseudo-Paralleltests Was die messtechnische Problematik der Lernverlaufsdiagnostik angeht,  so wurde die Kontentoder Lehrzielvalidität  der Tests durch das Herstellungsverfahren gewährleistet. Zu prüfen waren deshalb die Reliabilität der Tests und die Homogenität der Testschwierigkeiten. DieReliabilität  der Tests wurde als Pseudo-Paralleltestreliabilität ermittelt, aber auch nach dem hier speziell geeigneten Verfahren gemäß der Formel von Kuder-Richardson.Nach beiden Verfahren wurden befriedigende Ergebnisse erzielt, die die Tests auch für diagnostische Zwecke einsetzbar erscheinen lassen. Überdies entsprechen sie denWerten, die in den Untersuchungen in den USA und Deutschland festgestellt wurden. Dieser Befund steht im Kontrast zu  den unbefriedigenden Reliabilitäten, dieStrathmann et al. (in Druck) bei ihren Untersuchungen zu den Lernverläufen im Bereich Rechtschreibung fanden. Möglicherweise sind die günstigeren Werte hier auf dieArt der Itemgenerierung zurückzuführen, die im vorliegenden Fall stratifiziert – zufällig erfolgte. Diese Technik dürfte auch zu den befriedigenden Werten geführt haben, die bei der Überprüfung der Homogenität der Testschwierigkeiten  gefunden wurden. Wie bereits ausgeführt, stellt die Homogenität der Testschwie-rigkeit eine unabdingbare Voraussetzung für eine Lern-verlaufsdiagnostik dar, zumal die Tests in der Lage seinmüssen, Veränderungen  zu erfassen, Leistungszuwächse abzubilden. Darüber hinaus muss man mit Tagesschwan-kungen rechnen, denen alle Beteiligten unterliegen, sowiemit Einflüssen weiterer Faktoren, die zu einer unvermeid-baren Variabilität der beobachteten Kurven führen. Zu-mindest in den Klassenverläufen ist die Variabilität um dieRegressionslinien aber keineswegs besonders auffälligund die statistischen Tests zur Überprüfung der Gleich-heit der Mittelwerte von Tests, die im Abstand von zweiWochen einander folgten, führten zu durchgehend akzep-tablen Befunden. Auch diese Ergebnisse stehen im Ge-gensatz zu den Daten der Rechtschreibstudie (Strathmann& Klauer, 2008; Strathmann et al., in Druck), wo zu deutli-che Unterschiede in der Schwierigkeit der einzelnen Tests nachzuweisen waren. Kann das Verfahren in Schulklassen eingesetzt werden? Zentrales Anliegen des Beitrags war es zu prüfen, ob das hier beschriebene Verfahren geeignet ist, von Lehrpersonen in Schulklassen eingesetzt zu werden. Unserer Ein-schätzung nach ist das möglich. Zunächst einmal können die Aufgabenstichproben bequem erzeugt werden, wenn das Programm dazu zur Verfügung steht. Jedes Kind kanneine eigene Aufgabenstichprobe bekommen, so dass Binomialtests zur Verfügung stehen, die eine zuverlässigeund valide Einschätzung des Personenparameters erlauben. Die Tests unterscheiden sich nicht bedeutsam in den Schwierigkeiten, erlauben daher, Lernfortschritte zu erfas-sen. Diese positive Bewertung gilt, wie angedeutet, nicht für das in mancher Hinsicht vergleichbare Rechtschreibprogramm in der derzeitigen Verfassung. In dem Zusammenhang sei noch auf die Möglichkeit verwiesen, Lernverlaufsdiagnostik in anderen Fächerndurchzuführen. Sehr einfach wäre es  möglich, für den Fremdsprachenunterricht etwa einen Grundwortschatz Englisch auf PC zu installieren und zufällig Aufgaben-stichproben in beide Richtungen (deutsch – englisch und englisch – deutsch) erzeugen zu lassen. Ähnlich wäre es möglich, bestimmte Satzkonstruktionen einzuüben, bei-spielsweise einen Satz vom Aktiv ins Passiv zu übertragen oder umgekehrt. In den Sachfächern wie Erdkunde, Biologie usw. könnte man auf Lehrtexte zurückgreifen, sie inBasaltexte umschreiben und auf dieser Basis Testitems erzeugen lassen wie dies in Klauer (1987) demonstriert ist. Adaptierte man die Tests noch auf PC, so würde jederTeilnehmer eine eigene Zufallsstichprobe von Aufgaben bekommen können und man hätte es eindeutig mit den methodologisch vorteilhaften Binomialtests zu tun. Au-ßerdem würde die lästige Notwendigkeit entfallen, jeden einzelnen Test jedes Teilnehmers von Hand auszuwerten, was im vorliegenden Fall noch notwendig war. Wie aber am Beispiel der Lernverlaufsdiagnostik in der Rechtschreibung (vgl. Strathmann & Klauer, 2008; Strath-mann et al., in Druck) deutlich wurde, müsste jede Entwicklung dieser Art zuvor gründlich getestet werden, um zu prüfen, ob sie vertretbar Lehrkräften zum Einsatz emp-fohlen werden kann. Ein nicht vorhergesehener Befund Die Korrelationsmatrix zeigt unerwartet eine Tendenz zurSimplexstruktur. In einer empirischen Korrelationsmatrix findet man (wenn es sich nicht um eine Guttmanskala handelt) selten eine perfekte Simplexanordnung, doch ist dieTendenz dazu hier unverkennbar. Mit Hilfe linearer Strukturgleichungsmodelle ist es möglich, in Fällen von Simplexstrukturen Entwicklungsverläufe  darzustellen, sofern hinreichend Daten über einen längeren Zeitraum vorliegen (Erdfelder, Rietz & Rudinger, 1996). Zwar ist die Datenlage im vorliegenden Fall nicht ausreichend, doch dürf-te es möglich sein, dieser Fragstellung mittels der Lernverlaufsdiagnostik nachzugehen, wenn dies von vornherein entsprechend geplant wird. Offene Forschungsfragen Die langfristige Lernverlaufsdiagnostik mittels Itemsamp-ling aus definierten Grundgesamtheiten von Aufgabengeht über den amerikanischen CBM-Ansatz deutlich hinaus. Dabei eröffnen sich allerdings Forschungsmöglichkeiten, die den Rahmen eines einzigen Artikels weit überhttp://econtent.hogrefe.com/doi/pdf/10.1026/0049-8637/a000011 Monday, June 15, 2015 1:31:47 AM Universitaetsbibliothek Erlangen-Nuernberg IP Address:131.188.223.224  121 Lernverlaufsdiagnostik steigen. Wegen der engen Beziehung zwischen dem Binomialmodell und der Item-Response-Theorie bieten sichzunächst Möglichkeiten, die Datenstruktur auf ein differenzierteres Testmodell zurückzuführen, das es gestattet, die Konfundierung zwischen Test und Testdatum zu über-winden, aber auch zwischen Individuum und Testdatum. Mit Hilfe der Generalisierungstheorie wäre es ebenfalls möglich, den Faktor „Zeit“ einzuführen, um so zeitabhän-gige von zeitunabhängigen Faktoren zu trennen (vgl. Nußbaum, 1987). Darüber hinaus sollten die verschiedenen Verfahren von Zeitreihenanalysen, Wachstumskurvenund seriellen Abhängigkeiten Anlass sein, um Modelle zu analysieren, die den Lernverlauf theoretisch verständlicher machen (vgl. Krauth, 1996; Schlittgen & Streitberg,1994). Probabilistische Latent-Trait-Modelle haben sich in vergleichbaren Zusammenhängen gut bewährt (vgl. Roskam, 1996; Rost, 1977; Willett & Sayer, 1994). Die unter-schiedlichen Verlaufstypen, wie sie für Tabelle 3 unterschieden wurden, legen die Analyse der Verläufe nach komplexeren Mischmodellen nahe, die in der Praxis relativhäufig auftreten dürften. Schließlich wird man an Mehrebenenanalysen denken, die es gestatten, den Einfluss des Faktors Schule von dem des Faktors Klasse zu tren-nen, um so die Zusammenhänge differenzierter analysieren und die individuellen Beiträge besser beurteilen zu können (vgl. Bryk & Raudenbush, 1987, 1992). In der Ent-wicklungspsychologie spielen Längsschnittstudien seit langem eine zentrale Rolle, wobei die – auch im vorliegenden Beitrag relevante – methodologische Problematik vonkohortenwie zeitabhängigen Faktoren zu bemerkenswerten Lösungen gefunden hat (vgl. Schneider, 1991; Schaie, 1994), eine Problematik, der hier ebenfalls nicht nachge-gangen werden konnte. Maxwell (1998) zeigte beispielsweise, dass die Power längsschnittlicher Gruppenvergleiche deutlich erhöht wird, wenn Daten an mindestens fünf,möglichst aber an mehr Terminen erhoben werden. Solche Vergleiche etwa zwischen Schulklassen können, wie deutlich geworden sein dürfte, in Schulen zu Resultaten füh-ren, die eine Intervention erforderlich machen. Abschließend wird man feststellen können, dass die Lernverlaufsdiagnostik ein weites und methodologisch umfangreiches wie herausforderndes Forschungsfeld zu öffnen vermag, das die Aufmerksamkeit von Forschernverdient. Literatur Amrein-Beardsley, A. (2008). Methodological concerns about the education value-added assessment system. Educational Researcher, 37, 65–75. Bromme, R. (1997). Kompetenzen, Funktionen und unterrichtliches Handeln von Lehrern. In F. E. Weinert (Hrsg.), Psychologie des Lernens und der Instruktion (S. 177–212). Göttingen: Hogrefe. Bryk, A. S. & Raudenbush, S. W. (1987). Application of hierarchical linear models to assessing change. Psychological Bulletin, 101 , 147–158. Bryk, A. S. & Raudenbush, S. W. (1992). Hierarchical linear models: Applications and data analysis methods.  Newbury Park, CA: Sage.Cohen, J. (1988). Statistical power analysis for the behavioral sciences . Hillsdale: Erlbaum. Deno, S. L. (1985). Curriculum-based measurement: The emerging alternative. Exceptional Children, 52, 219–232. Deno, S. L. (2003a). Developments in curriculum-based measurement. The Journal of Special Education, 37, 184–192. Deno, S. L. (2003b). Curriculum-based measures. Development and perspectives. Assessment for Effective Intervention, 28 (3–4), 3–12. Deno, S. L., Mirkin, P. K. & Chiang, B. (1982). Identifying a valid measure of reading. Exceptional Children, 49, 36–45. Deno, S. L., Reschly-Anderson, A., Lembke, E., Zorka, H. & Callender, S. (2002).  A model for school wide implementation: A case example. Paper presented at the annual meeting of the National Association of School Psychology, Chicago, Il. De Gruijter, D. N. M. & van der Kamp, L. J. T. (1984). Statistical methods in psychological and educational testing . Lisse: Swets & Zeitlinger. Diehl, K. & Hartke, B. (2007). Curriculumnahe Lernfortschrittsmessungen. Sonderpädagogik, 37, 195–211. Erdfelder, E., Rietz, C. & Rudinger, G. (1996). Methoden der Entwicklungspsychologie. In E. Erdfelder, R. Mausfeld, T. Meiser & G. Rudinger (Hrsg.), Handbuch Quantitative Methoden (S. 539–550). Weinheim: Beltz. Fuchs, L. S. (2004). The past, present, and future of  curriculumbased measurement research. School Psychology Review, 33, 188–192. Fuchs, L. S. & Fuchs, D. (1993). Formative evaluation of academic progress: How much growth can we expect? School Psychology Review, 22, 1–30. Fuchs, L. S. & Fuchs, D. (1998). Treatment validity: A unifying concept for reconceptualizing the identification of learningdisabilities. Learning Disabilities Research & Practice, 13, 204–219. Fuchs, L.S., Fuchs, D., Hamlett, C. L. & Stecker, P. M. (1991). The role of skills analysis in curriculum-based  measurementin math. School Psychology Review, 19, 6–22. Fuchs, L. S., Fuchs, D. & Maxwell, L. (1988). The validity of informal reading comprehension measures. Remedial and Special Education, 9, 20–28. Good, R. & Jefferson, G. (1998). Contemporary perspectives on curriculum-based measurement validity. In M. R. Shinn(Hrsg.), Advanced Applications of Curriculum-Based Measurement (S. 61–88). New York: Guilford Press. Good, R. H. III, Simmons, D. C. & Kameenui, E. J. (2001). The importance and decision-making utility of a continuum offluency-based indicators of foundational reading skills forthird-grade high stakes outcomes. Scientific Study of Reading, 5,  257–288. Helmke, A., Hosenfeld, J. & Schrader, F.-W. (2004). Vergleichsarbeiten als Instrument zur Verbesserung der Diagnosekom-petenz von Lehrkräften. In R. Arnold & C. Griese (Hrsg.),Schulleistung und Schulentwicklung (S. 119–143). Hohengehren: Schneider. Holm, S. (1979). A simple sequentially rejective multiple test procedure. Scandinavian Journal of Statistics, 6,  65–70. Kim, J. S. & Sunderman, G. L. (2005). Measuring academic proficiency under the No Child Left Behind Act: Implicationsfor educational equity. Educational Researcher, 34 (8), 3–13. Klauer, K. J. (1987). Kriteriumsorientierte Tests. Göttingen: Hogrefe. Klauer, K. J. (1994 a). Diagnoseund Förderblätter. Rechenfertigkeiten 2. Schuljahr. Berlin: Cornelsen. Klauer, K. J. (1994 b). Diagnoseund Förderblätter. Rechenfertigkeiten 3. Schuljahr. Berlin: Cornelsen. Klauer, K. J. (1994 c). Diagnoseund Förderblätter. Rechenfertigkeiten 4. Schuljahr. Berlin: Cornelsen. Klauer, K. J. (2006). Erfassung des Lernfortschritts durch curriculumbasierte Messung. Heilpädagogische Forschung, 32, 16–26. http://econtent.hogrefe.com/doi/pdf/10.1026/0049-8637/a000011 Monday, June 15, 2015 1:31:47 AM Universitaetsbibliothek Erlangen-Nuernberg IP Address:131.188.223.224  122 Alfons M. Strathmann und Karl Josef Klauer Krauth, J. (1996). Zeitreihenanalyse. In E. Erdfelder, R. Mausfeld, T. Meiser & G. Rudinger (Hrsg.), Handbuch Quantitative Methoden (S. 291–302). Weinheim: Beltz PVU . Lord, F. M. & Novick, M. R. (1968). Statistical theories of mental test scores. Reading, MA: Addison-Wesley. Maxwell, S. E. (1998). Longitudinal designs in randomized group comparisons: When will intermediate observations increasestatistical power? Psychological Merhods, 3 , 275–290. Nußbaum, A. (1987). Das Modell der Generalisierbarkeitstheorie. In K. J. Klauer, Kriteriumsorientierte Tests  (S. 114–136). Göttingen: Hogrefe. Perels, F., Gürtler, T. & Schmitz, B. (2005). Training of selfregulatory and problem-solving competence. Learning and Instruction, 15, 123–139. Raudenbush, S. W. (2004). What are value-added models estimating and what does this imply for statistical practice? Journal of Educational and Behavioral Statistics, 29, 121–129. Riley-Heller, N., Kelly-Vance, L. & Shriver, M. (2005). Curriculum-based measurement: Generic vs. Curriculum-dependentprobes. Journal of Applied School Psychology, 21,  141–162. Roskam, E. E. (1996). Latent-Trait-Modelle. In E. Erdfelder, R. Mausfeld, T. Meiser & G. Rudinger (Hrsg.), Handbuch Quantitative Methoden (S. 431–458). Weinheim: Beltz. Rost, J. (1977). Diagnostik des Lernzuwachses. IPN Arbeitsbericht Nr. 26. Kiel: Institut für die Pädagogik der Naturwis-senschaften. Schaie, K. W. (1994). Developmental designs revisited. In S. H. Cohern & R. W. Reese (Hrsg.), Life-span developmental psychology: Methodological contributions  (S. 45–64). Hillsdale: Erlbaum. Schlittgen, R. & Streitberg, B. (1994). Zeitreihenanalyse.  München: Oldenbourg. Schneider, W. (1991). Methodische Probleme und Möglichkeiten schulbezogener Längsschnittforschung. In R. Pekrun &H. Fend (Hrsg.), Schule und Persönlichkeitsentwicklung. Eine Resumee der Längsschnittforschung  (S. 57–82). Stuttgart: Enke. Schrader, F.-W. (2001). Diagnostische Kompetenz von Eltern und Lehrern. In D. H. Rost (Hrsg.), Handwörterbuch Pädagogische Psychologie (S. 95–100). Weinheim: Beltz PVU. Shin, J., Deno, S. L. & Espin, C. (2000). Technical aedequacy of the maze task for curriculum-based measurement of readinggrowth. The Journal of Special Education, 34,  164–172. Strathmann, A. M. & Klauer, K. J. (2008). Diagnostik des Lernverlaufs. Eine Pilotstudie am Beispiel der Entwicklung derRechtschreibkompetenz. Sonderpädagogik, 38, 5–24.Strathmann, A. M., Klauer, K. J. & Greisbach, M. (in Druck). Lernverlaufsdiagnostik in Schulklassen. Dargestellt am Bei-spiel der Entwicklung der Rechtschreibkompetenz in derGrundschule. Empirische  Sonderpädagogik. VanDerHeyden, A. M. & Burns, M. K. (2005). Using curriculum-based assessment and curriculum-based measurementto guide elementary mathematics instruction: Effect on indi-vidual and group accountability scores. Assessment for Effective Intervention, 30 (3), 15–31. VanDerHeyden, A. M., Witt, J. C., Naquin, G. & Noell, G. (2001). The reliability and validity of curriculum-based measurement readiness probes for kindergarten students.School Psychology Review, 30, 363–382. Walter, J. (2008). Curriculumbasiertes Messen (CBM) als lernprozessbegleitende Diagnostik: Erste deutschsprachige Er-gebnisse zur Validität, Reliabilität und Veränderungssensibilität eines robusten Indikators zur Lernfortschrittsmessung . Heilpädagogische Forschung, 34, 62–79. Walter, J. (2009 a). Theorie und Praxis Curriculumbasierten Messens (CBM) in Unterricht und Förderung. Zeitschrift für Heilpädagogik, 60,  162–170. Walter, J. (2009 b). Eignet sich die Messtechnik „MAZE“ zur Erfassung von Lesekompetenzen als lernprozessbegleitende Diagnostik? Heilpädagogische Forschung, 35, 62–75. Willett, J. B. & Sayer, A. G. (1994). Using covariance structure analysis to detect correlates and predictors of individualchange over time. Psychological Bulletin, 116, 363–381. Prof. em. Dr. Karl Josef Klauer Robert-Stolz-Weg 15 42781 HaanE-Mail: klauerk@uni-duesseldorf.de Prof. Dr. Alfons M. Strathmann Universität zu Köln Humanwissenschaftliche Fakultät Klosterstraße 79 b50931 KölnE-Mail: alfons.strathmann@uni-koeln.de http://econtent.hogrefe.com/doi/pdf/10.1026/0049-8637/a000011 Monday, June 15, 2015 1:31:47 AM Universitaetsbibliothek Erlangen-Nuernberg IP Address:131.188.223.224  