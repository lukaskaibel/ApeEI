1     Institut für Informatik  Didaktik der Informatik          Intuitive Modelle der Informatik                    Dissertation  zur Erlangung des akademischen Grades  "doctor rerum naturalium"  (Dr. rer. nat.)  in der Wissenschaftsdisziplin "Didaktik der Informa tik"                eingereicht am 1. März 2007 an der  Mathematisch-Naturwissenschaftlichen Fakultät  der Universität Potsdam      von  Dipl.-Inform. Michael Weigend          Potsdam, den 1. März 2007 2                                                                             1. Gutachter: Prof. Dr. Andreas Schwill, Universitä t Potsdam  2. Gutachter: Prof. Dr. Carsten Schulte, Freie Univ ersität Berlin  3. Gutachter: Prof. Dr. Werner Hartmann, Pädagogisc he Hochschule Bern    Disputation am 26.11.2007 3       Abstract (deutsch)  Intuitive Modelle der Informatik sind holistische g edankliche Vorstellungen über informatische  Konzepte, die mit subjektiver Gewissheit verbunden sind. Menschen verwenden sie, wenn sie die Ar beitsweise von Computerprogrammen nachvollziehen od er anderen erklären, die logische Korrektheit  eines Programms prüfen oder in einem kreativen Proz ess selbst Programme entwickeln.   Intuitive Modelle können auf verschiedene Weise rep räsentiert und kommuniziert werden, etwa  verbal-abstrakt, durch ablaufoder strukturorienti erte Abbildungen und Filme oder konkrete Beispiele.   Diskutiert werden in dieser Arbeit grundlegende int uitive Modelle für folgende inhaltliche Aspekte  einer Programmausführung: Allokation von Aktivität bei einer Programmausführung, Benennung von  Entitäten, Daten, Funktionen, Verarbeitung, Kontrol lstrukturen zur Steuerung von Programmläufen,  Rekursion, Klassen und Objekte. Mit Hilfe eines Sys tems von Online-Spielen, der Python Visual  Sandbox, wird die psychische Realität verschiedener  intuitiver Modelle bei Programmieranfängern  nachgewiesen und fehlerhafte Anwendungen (Fehlvorst ellungen) identifiziert.   Schlagworte  Analogie, Bildung, Didaktik, erklären, Fehlvorstell ung, Informatik, Intuition, mentales Modell,  Metapher, Problem lösen, programmieren, verstehen, visualisieren, Python Visual Sandbox.   Abstract (English)  Intuitive models in computer science are Gestalt-li ke mental concepts about information process ing, which are accompanied by subjective confidence . People use them, when they try to understand  the semantics of a computer programme, explain an a lgorithmic idea to someone else, check the logi cal correctness of existing code or create computer  programmes. Intuitive models can be represented  and communicated in different ways using static pic tures, animated movies, concrete examples or  verbal language. In this paper basic intuitions con cerning the following issues are discussed: allocat ion  of activity within a running programme, assignment of names to entities, data, functions, processing  concepts, control of programme execution, recursion , classes and objects. By observing activities with   a set of specially designed online games (the Pytho n Visual Sandbox), evidence has been collected to  proof the psychological existence of certain intuit ive models among high school students and identify  inappropriate applications (misconceptions).  Keywords  Analogy, computer science, didactics, education, ex plaining, intuition, mental model, metaphor,  misconception, problem solving, programming, unders tanding, visualization, Python Visual Sandbox.    4     Danksagung  An erster Stelle gilt mein Dank Prof. Dr. Andreas S chwill (Universität Potsdam) für die vielen Er munterungen, Anregungen und wissenschaftlichen Stel lungnahmen zu meiner Arbeit. Meine Vorträge  in Potsdam in den letzten drei Jahren waren immer e ine Quelle für Motivation, Inspiration und Er kenntnisgewinn, nicht zuletzt auf Grund scharfsinni ger Anmerkungen von Ralf Romeike und anderen  Mitarbeitern und Gästen des Instituts für Didaktik der Informatik.  Die empirischen Erhebungen wären nicht möglich gewe sen ohne die Kooperation der vielen Lehre rinnen und Lehrern, Schülerinnen und Schülern, Stud entinnen und Studenten, die an Visualisierungs übungen und Workshops mit der Python Visual Sandbox  teilgenommen haben und mir hoffentlich  verzeihen, dass ich an dieser Stelle nur ihre Schul en bzw. Universitäten erwähnen kann: Arlington  County School (Arlington, Virginia, USA), Rudolf-Di esel-Gymnasium (Augsburg), Ernst-AbbeGymnasium (Eisenach), Kopernikus-Gymnasium (Wissen) , Gustav-Heinemann-Oberschule (Berlin),  Humboldt-Gymnasium (Berlin), International American  Highschool (Hongkong), International Ger man and Swiss Highschool (Hongkong), Holzkamp-Gesam tschule (Witten), Klara-SchumannGymnasium (Bonn), Westfälische Wilhelms-Universität  Münster, FernUniversität Hagen.  Dank auch an Prof. Dr. Ming Ming Chiu und Prof. Dr.  Fong Lok Lee (Chinese University of Hong  Kong) für die anregenden Korrespondenzen und persön lichen Gespräche über Metaphern und ELearning. Verbunden fühle ich mich der Python Commu nity – insbesondere Jeff Elkner – für die Dis kussion der Python Visual Sandbox auf der PyCon 200 5 in Washington D. C. Nicht unerwähnt bleiben  soll Hendrik Büdding (Universität Münster), der sic h die Arbeit gemacht hat, das Manuskript kritisch  durchzusehen. 5     Inhaltsverzeichnis  Einleitung 12  1 Intuitive Modelle und informatisches Wissen 14  1.1  Intuition als Wissen 14  1.2  Intuition als prozedurales Wissen 14  1.3  Intuitive Modelle als bedeutungsbezogenes deklarati ves Wissen 15  1.3.1  Begriffe – Identifikation von Objekten 15  1.3.2  Schemata – Speichern struktureller Merkmale 15  1.3.3  Mentale Modelle 16  1.4  Merkmale intuitiver Modelle 16  1.5  Phänomenologische Primitive 18  1.6  Intuitive Modelle und Fehlvorstellungen 18  2 Repräsentation intuitiver Modelle 20  2.1  Duale Kodierung von Wissen 20  2.2  Vielfalt und Flüchtigkeit 21  2.3  Repräsentation und Metaphorisierung 21  2.3.1  Uneigentliche Redeweise in der Informatik 21  2.3.2  Metaphern und analoges Denken 22  2.3.3  Metaphern als Bilder für intuitive Modelle 23  2.4  Beispiele als Repräsentationen intuitiver Modelle 25  2.4.1  Prinzipien der Beispielbildung 25  2.4.2  Prototypische Beispiele 26  2.4.3  Repräsentation durch eine Beispielkollektion 26  2.4.4  Beispiel-basiertes Problemlösen 27  2.5  Strukturorientierte und ablauforientierte Repräsent ationen 27  2.6  Modellrepräsentationen im Unterricht 28  3 Verwendung intuitiver Modelle 29  3.1  Verstehen 29  3.1.1  Verstehen aus Sicht der Hermeneutik 30  3.1.2  Verstehen durch intuitive Modelle 30  3.2  Erklären 31  3.2.1  Fokussierung 31  3.2.2  Mehrperspektivität: Viele Modelle für eine Sache 33  3.3  Problemlösen 33  3.3.1  Antizipatorische Intuitionen 33  3.3.2  Ansatz und Verfeinerung 34  3.3.3  Paradigmatische Modelle und Software-Entwicklung 35   3.3.4  Entwurfsmuster (Design Patterns) 36  3.3.5  Use Cases – intuitive Modelle für Funktionalität 36  3.3.6  Intuitive Modelle im agilen Programmieren – The Pla nning Game 37  3.4  Kontrollmodelle 37  3.4.1  Zusicherungen 38  4 Empirische Erforschung intuitiver Modelle 40  4.1  Forschungsansätze und methodische Probleme 40  4.2  Visualisierungsübungen 40  4.3  Die Python Visual Sandbox 41 6     4.3.1  Die PVS als Spiel 41  4.3.2  Lernen mit der PVS 42  4.3.3  Überblick über den technischen Aufbau der Python Vi sual Sandbox 42  4.4  Python Visual 43  4.5  Python Puzzle 44  4.5.1  Dokumentation einer Session 46  4.5.2  Auswertung der Python Puzzle Sessions 46  4.5.3  Verwendung von Tipps 47  4.6  Python Puzzle assert 48  4.7  Python Quiz 48  4.7.1  Bewertung der Antworten 49  4.7.2  Dokumentation einer Session 49  4.7.3  Schlussfolgerungen zur Intuitivität von Modellen 50  4.8  Workshops mit der PVS 50  4.9  Systematisierung intuitiver Modelle der Informatik 51  5 Akteurmodelle 52  5.1  Daten als Akteure – Datenflüsse 52  5.2  Namen als Akteure 53  5.3  Funktionen 53  5.4  Allmächtige Steuerungsentität – monoaktive Systeme 53  5.5  Objekte 54  6 Benennung von Entitäten 55  6.1  Behältermodell und Referenzierungsmodell 55  6.2  Erscheinungsmodelle 56  6.3  Wem gehört ein Name? Zeiger versus Etiketten 58  6.4  Vermischung von Namensmodellen 59  6.5  Namen als Bezeichnungen für Rollenträger 60  6.6  Implizite Namen 60  6.7  Indirekte Namen 62  6.7.1  Funktionsaufrufe und mathematische Terme 62  6.7.2  Benennung durch Literale 63  6.8  Assoziationen 63  6.9  Benennung als Unterordnung 64  7 Daten 66  7.1  Ansicht versus Literal 66  7.2  Verwechseln von Wert (Datum) und Literal 66  7.3  Figürliche Ansichten 66  7.4  Nichts 67  7.5  Platzhalter für variable Teile in Dokumenten 68  7.6  Daten als Entitäten oder Zustände von Objekten 69  8 Funktionen 71  8.1  Funktion als Box mit Einund Ausgang für Daten 72  8.2  Dateneingabe über „Sensoren“ 73 7     8.3  Übergabe von Referenzen bei der Eingabe 74  8.4  Ursprung der Eingabespezifikation 74  8.5  Vergleich von Eingabemechanismen 74  8.6  Übergabe von Referenzen bei der Ausgabe 76  8.7  Ausgabe als Signal 78  8.8  Durchlässigkeit der Systemgrenze 79  8.8.1  Geschlossene Box 79  8.8.2  Box mit „Seitentür“ 79  8.8.3  Direkter Zugriff auf externe Objekte 79  8.8.4  Vergleich von offenen und geschlossenen Funktionsmo dellen 80  8.9  Dynamische und statische Funktionsmodelle 81  8.10  Auslösemechanismen 83  9 Kontrolle – Steuerung 84  9.1  Handhabung von Kontrolle: Kontrollfluss und Kontrol lübergabe 84  9.2  Anweisungssequenzen 84  9.3  Bedingte Anweisungen 85  9.3.1  Verzweigung des Kontrollflusses 85  9.3.2  Kontrolle von Datenflüssen – Datenweichen und Daten sperren 86  9.3.3  Ereignismodell – Steuersignale 86  9.4  Iterationen – datengesteuerte Wiederholungen 86  9.5  Wiederholungen mit nicht antizipierbarem Ende 88  9.5.1  Kontrollierte Wiederholung einer holistischen Aktiv ität 89  9.5.2  Schleifen 90  9.6  Rekursion 90  9.6.1  Rekursion als Schleife 91  9.6.2  Rekursion als Selbstaufforderung 91  9.6.3  Fehlerhafte Verwendung des Modells der Selbstauffor derung 92  9.6.4  Delegationsmodell 93  9.6.5  Protokoll-Modelle für rekursive Algorithmen 93  9.6.6  Schema einer rekursiven Funktion und Dedynamisierun g 93  10  Verarbeitung 95  10.1  Entstehen 95  10.1.1  Entstehen von Daten 95  10.1.2  Entstehung von Namen 95  10.2  Vernichtung 95  10.2.1  Implizite Vernichtung bei Zuweisungen 95  10.2.2  Sukzessive Zuweisungen ohne Vernichtung 97  10.2.3  Totale Vernichtung 98  10.3  Veränderung (Metamorphose) 98  10.3.1  Datenumwandlungen 99  10.4  Namenumwandlungen 99  10.5  Bewegen 100  10.5.1  Bewegung von Daten 100  10.5.2  Modellierung von Zuweisungen durch Datenbewegung 10 1  10.5.3  Modellierung von Zuweisungen durch Namenbewegungen 102  11  Klassen 106  11.1  Intuitive Modelle in der Objektorientierten Program mierung 106 8     11.2  Klassenbegriff 106  11.3  Klasse als Bauplan 106  11.4  Klasse als Fabrik für Objekte 107  11.5  Klasse als Menge von Objekten 107  11.6  Klasse als Prototyp 107  11.7  Klasse als Behälter für Funktionen (Toolbox) 108  12  Objekte 109  12.1  Zustand eines Objektes – Datenbesitz oder holistisc he Befindlichkeit 109  12.2  Instanzierung von Objekten – Produktion oder Auswah l 110  12.3  Instanzierungsmodelle in der PVS 110  12.4  Interaktion von Objekten – Verarbeitung von Botscha ften 112  12.4.1  Objekte als Verursacher von Aktivität 112  12.5  Übermittlung von Botschaften 114  12.6  Schlussfolgerungen 115  13  Intuitive Modellierung 116  13.1  Identifizierung von Entitäten 116  13.2  Abstrahieren 117  13.3  Gestaltbildung 118  13.4  Animieren 118  13.5  Clusterbildung und Fokussierung 119  13.6  Überstrukturierung 121  13.7  Einbeziehung der Umgebung 121  13.8  Dekorieren und Dramatisieren 122  13.9  Rückmodellierung 122  13.10  Exhaurierung 123  13.11  Konsistenzwahrung 124  14  Von der Intuition zum Programm 125  14.1  Prozedurale Intuition und fehlendes deklaratives Wi ssen 125  14.2  Aufbrechen der Gestalt 125  14.3  Fehlende Verbindungen zwischen intuitiven Vorstellu ngen und Programmkonstrukten 126  14.4  Schwierige intuitive Modelle 126  14.5  Fehlvorstellungen 127  15  Pädagogische Implikationen 128  15.1  Intuitive Modelle und Lernen formaler Programmierko nzepte 128  15.1.1  Molekulare Modelle 128  15.1.2  Atomare Modelle 128  15.1.3  Subatomare Modelle 129  15.2  Kompetenzen im Umgang mit intuitiven Modelle 129  15.2.1  Abstraktionsgrad erkennen 130  15.2.2  Fokus und Grenzen wahrnehmen 130  15.2.3  Medienund Kommunikationskompetenz 130 9     15.3  Intuitive Modelle und Scaffolding 131  15.4  Diskussion und Reflektion intuitiver Modelle 131  15.4.1  Visualisierungsübungen 131  15.4.2  Rollenspiele und Regelspiele 132  15.4.3  Gestaltete Medien und Mikrowelten 132  15.5  Informatik im Kontext 133  15.6  Schluss und Ausblick 134  Literatur 135  Anhang 144  Abbildungsverzeichnis 145  Tabellenverzeichnis 148  Abkürzungsverzeichnis 149  1 Ergänzungen zur Repräsentation intuitiver Modelle 150  1.1  Verwendung unterschiedlicher Metaphern beim mathema tischen Problemlösen 150  1.2  Repräsentation von Sprachkonzepten durch eine Beisp ielkollektion –   die Python-Kurzreferenz von O’Reilly 150  1.3  Von der Schwierigkeit intuitive Modelle zu visualis ieren 151  1.4  Beispiele für Tropen in der Informatik 152  1.5  Mikrowelten als einheitliche Domänen für konzeption elle Metaphern 152  1.6  Prototypische Beispiele 155  1.7  Beispiele für ablauforientierte Repräsentationen 156  1.8  Darstellung intuitiver Modelle in der Python Visual  Sandbox 157  1.8.1  Warum Animationen? 157  1.8.2  Entfernung und Nähe 157  1.8.3  Grafische Elemente der Python Visual Sandbox 158  1.9  Verwendung von Visualisierungen im Informatikunterr icht 161  2 Ergänzungen zur Verwendung intuitiver Modelle 164  2.1  Verstehen 164  2.1.1  Textformen in informatischer Fachliteratur 164  2.1.2  Experimente zur Beantwortung erkenntnisgewinnender Fragen 165  2.2  Das Bemühen um Verstehen bei der Vorbereitung auf e inen Test 166  2.2.1  Auswahl repräsentativer Beispiele 167  2.2.2  Beispiele ausprobieren – Streben nach Gewissheit 16 8  2.2.3  Beispiele für die Verwendung regulärer Ausdrücke 16 8  2.2.4  Ergebnisse 170  2.2.5  Verwendung von visuellen Modellen als Verstehenshil fe 171  2.3  Problemlösen 173  2.3.1  Fallstudie: Das Iterator-Pattern und seine Implemen tierung in Python 173  2.4  Kontrolle 175  2.4.1  Intuitive Modelle und Testen 175  2.4.2  Paradigmatische Modelle beim Testen 176  3 Materialien zu den empirischen Untersuchungen 178  3.1  Visualisierungsübungen 178  3.1.1  Aufgabenblatt 1 178  3.1.2  Aufgabenblatt 2 179  3.2  Aufbau der Datenbank der PVS 181 10     3.2.1  Allgemeine Tabellen 181  3.2.2  Tabellen für Python Visual 183  3.2.3  Tabellen für Python Puzzle 184  3.2.4  Tabellen für Python Quiz 186  3.3  Gruppen einrichten 187  3.4  Auswertung der Datenbank 187  3.4.1  Auswertungsmöglichkeiten für Spieler und Zuschauer 188  3.4.2  Wissenschaftliche Auswertung 189  3.5  Python Visual 190  3.5.1  Dokumentation einer Session 190  3.5.2  Auszug aus der automatisch erstellten Auswertung 19 0  3.6  Python Puzzle 214  3.6.1  Screenshots aus einer Sitzung mit dem Python Puzzle  „Modeling a group“ 214  3.6.2  Dokumentation einer Session mit XML 214  3.6.3  Beispiel für eine automatisch generierte statistisc he Auswertung 216  3.7  Python Quiz 218  3.7.1  Dokumentation einer Session 218  3.7.2  Auszug aus der automatisch erstellten Auswertung 21 9  4 Ergänzungen zu Steuerungsmodellen 285  4.1  Verzweigungen in Datenfluss-Modellen 285  4.2  Der Fetch-Execute-Zyklus als Beispiel einer Schleif e 285  4.3  Assoziierte Konzepte zur Rekursion 287  4.4  Fehlerhafte Verwendung des Modells der Selbstauffor derung bei eingebetteter Rekursion 288  4.5  Anwendung des Delegationsmodells zur Visualisierung  der Arbeitsweise rekursiver Funktionen 288  4.6  Bevorzugung vollständiger Modelle zur Darstellung e iner rekursiven Funktion 289  5 Ergänzungen zu Verarbeitungsmodellen 290  5.1  Entstehungsprozesse im Alltag 290  5.2  Vernichtungskonzepte im Alltag 290  5.3  Totale Vernichtung bei Zuweisungen 291  5.4  Beispiele für Datenumwandlungen 292  5.5  Umbenennungen bei der der Ausführung von Funktionen  294  5.6  Umbenennungen in Rechenprotokollen zur rekursiven B erechnung der Fakultät 295  5.7  Datenbewegung bei Iterationen 297  5.8  Namenbewegung bei Iterationen 298  6 Ergänzungen zu intuitiven Modellen in der OOP 299  6.1  Klasse und Schema 299  6.2  Visualisierung von Klassen in Schülerzeichnungen 299  6.3  Klasse als Entität 300  6.4  Prototyptheorien in der Kognitionspsychologie 300  6.5  Prototyporientierte Programmiersprachen 301  6.6  Implizite Verwendung des Prototypkonzepts bei der E ntwicklung einer Klasse 301  6.7  Das Prototyp-Konzept bei der Nutzung von Grafik-Too ls 302  6.8  Modelle für die Herstellung von Objekten 303 11     6.9  Modellierung verschachtelter Botschaften 303  6.9.1  Kontexte für die Verwendung von passiven  Objektmod ellen 305  6.10  Indikatoren für die Validität der Ergebnisse 306  7 Weitere Aspekte der intuitiven Modellierung 306  7.1  Intuitivität als messbare Größe 306  7.2  Überstülpen des EVA-Modells als Beispiel für Überst rukturierung 307  12     Einleitung  Intuitive Modelle der Informatik sind gestaltartige , kognitiv gut verarbeitbare und als gewiss und  richtig akzeptierte gedankliche Vorstellungen über informatische Konzepte. Sie werden bewusst oder  unbewusst verwendet, wenn Menschen versuchen, die A rbeitsweise von Informatiksystemen zu ver stehen, anderen zu erklären oder selbst – kreativ –  ein solches System zu entwickeln.   Intuitive Modelle fließen innerhalb der praktischen  Informatik in die Gestaltung von „FrontendSystemen“ an der Schnittstelle zum Menschen ein. Da zu gehören z.B. höhere Programmierund Mo delliersprachen oder Entwurfsmuster. Beispielsweise  ist eine Symbolik zur Beschreibung informati scher Systeme (wie z.B. UML) nur dann brauchbar, we nn sie zu schnell und sicher begreifbaren Do kumenten führt. Das Ziel ist, beim Rezipienten ein intuitives Verständnis des Gemeinten, verbunden  mit dem Gefühl von Gewissheit, zu erreichen. So bas ieren Zustandsübergangsgraphen auf dem intuiti ven Modell einer sprunghaften Bewegung von Ort zu O rt, ein Konzept, das viele Menschen schon als  Kinder bei einer Reihe von Straßenspielen trainiert  haben und das sie deshalb sicher beherrschen.  Entwurfsmuster – wie z.B. das Iteratorkonzept – sch öpfen ihren Wert für Softwareentwicklungen dar aus, dass sie die prinzipielle Arbeitsweise eines S ystems auf gut zugängliche, kompakte Weise in einer   kohärenten Gestalt beschreiben.  Intuitive Modelle sind wichtig für das Lernen infor matischer Konzepte. Aus konstruktivistischer  Sicht lässt sich Lernen als Aufbau interner mentale r Modelle über die Welt auf der Basis bereits vor handenen Wissens beschreiben. Es ist ein Vorgang, d er vom Subjekt ausgeht und nicht direkt von  einem Außenstehenden (z.B. einem Lehrer) beobachtet  oder kontrolliert werden kann. Intuitive Mo delle sind in dieser Hinsicht ein kognitionspsychol ogisches Phänomen (Kapitel 2). Lehrerinnen und  Lehrer sind hilflos, wenn sie nicht wissen, welche gedanklichen Konzepte ihre Schülerinnen und  Schüler verwenden. Erklärungen und Hilfestellungen greifen nicht, wenn sie an der Gedankenwelt des  Adressaten vorbei gehen. Um Fehlvorstellungen aufzu klären und Verständnislücken zu schließen,  muss man wissen wo diese liegen könnten. Intuitive Modelle sind auch die Grundlage für Medien  (Texte, Bilder, Filme) und Unterrichtsaktivitäten ( Rollenspiele, Programmierübungen, Explorations aufgaben), die der Vermittlung informatischer Konze pte dienen. Um diese effizient gestalten zu kön nen, braucht man Kenntnisse darüber, wie und wie gu t und wie schnell die verwendeten Anschauun gen und Analogien verstanden werden.  Die vorliegende Arbeit versucht dieses didaktische Wissen zu verbessern und verfolgt vier primäre  Forschungsziele: Das Finden und Beschreiben intuiti ver Modelle der Informatik, ihre Katalogisierung  und Systematisierung, die Überprüfung der psychisch en Realität bei Schülerinnen und Schülern und  schließlich die Identifizierung allgemeiner Mechani smen der Nutzung von Modellen bei der intellek tuellen Auseinandersetzung mit Programmtexten. Dabe i liegt der Fokus auf Modellen zu grundlegen den Programmierkonzepten, die typischerweise im Anf angsunterricht an allgemeinbildenden Schulen  thematisiert werden. 1  Identifikation und Beschreibung   Lehrbücher, Softwaredokumentationen, Sprachreferenz en, Schülervisualisierungen und andere Do kumente enthalten mehr oder weniger explizite Reprä sentationen intuitiver Modelle zur Arbeitsweise  von Programmen. Diese gilt es herauszuarbeiten und zu beschreiben. So unterstützt der Satz „Die  Funktion gibt eine Zahl zurück.“ unter anderem folg ende intuitiven Vorstellungen: Eine Funktion ist  eine aktive Entität, die z.B. etwas zurückgeben kan n. Es gibt eine andere Entität, von der die Funktio n  etwas erhalten hat, für das sie ersatzweise jetzt e twas zurückgibt. Zahlen sind Entitäten, die man bewegen (also auch z.B. zurückgeben) kann. Wir unters cheiden zwischen einem intuitiven Modell als  subjektivem gedanklichen Konstrukt (das möglicherwe ise unbewusst ist) und seiner Repräsentation in  einer materiellen Form (Abbildung, Text etc.). Die Darstellung eines intuitiven Modells ist (durch den   Rückgriff auf intersubjektive Symbolsysteme) vor al lem ein kulturelles Phänomen. Kapitel 3 widmet                                                         1 Anzumerken ist, dass neben Modellen zu Programmier konzepten noch viele andere intuitive Modelle exist ie ren, die sich primär auf andere Bereiche der Inform atik beziehen, wie z.B. Modelle zu Vorgehensweisen (Was serfallmodell etc.) oder zur Untersuchung einer Dom äne (Thomas 2003). 13     sich speziell dieser Perspektive und diskutiert ver schiedene Repräsentationsformen. In dieser Arbeit  werden intuitive Modelle vornehmlich durch Animatio nen (mit kleinen Textelementen) beschrieben.  In den Details eines visuellen Vorgangs können impl izite Bedeutungsfacetten einer sprachlichen For mulierung expliziert werden.   Systematisierung und Analyse  Das zweite Ziel ist, Ansätze für eine Systematik in tuitiver Modelle der Informatik zu finden. In den  Kapiteln 6 bis 13 werden Modelle nach inhaltlichen Kriterien eingeteilt: Allokation von Aktivität,  Benennung von Entitäten, Daten, Funktionen, Verarbe itungskonzepte, Kontrollstrukturen zur Steue rung von Programmläufen, Klassen und Objekte. Grund legende intuitive Modelle der Informatik tre ten meistens nicht isoliert sondern in größeren Zus ammenhängen auf. Daraus ergeben sich Interde pendenzen, die herausgearbeitet werden müssen. So p asst das Modell einer Funktion als Fabrik, die  Daten verarbeitet, gut zum Modell eigenaktiver Date n-Entitäten, die sich zum Eingang einer Funkti onsentität bewegen können. Für ein und dasselbe inf ormatische Konzept gibt es in der Regel mehrere  intuitive Modelle, die miteinander verglichen werde n. Je nach Kontext oder Erklärungsabsicht (Fokus)  ist mal das eine und mal andere Modell besser geeig net. So ist es bei endrekursiven Prozeduren denk ökonomisch, den rekursiven Aufruf als Aufforderung zur Wiederholung zu betrachten – eine Vorstel lung, die bei eingebetteter Rekursion zu Fehlern fü hrt.   Psychische Realität und kognitive Zugänglichkeit  Das dritte Ziel ist, Informationen darüber zu gewin nen, welche Modelle von Programmieranfän gern beim Verstehen, Erklären und Generieren von Pr ogrammtexten tatsächlich verwendet werden.  Dazu wurde mit der Python Visual Sandbox (PVS) ein technisches System entwickelt, das es erlaubt,  die intellektuelle Auseinandersetzung mit Programme n wenigstens ansatzweise zu beobachten (Kapi tel 5). Eng verbunden mit der Frage nach der psychi schen Realität ist die Frage der kognitiven Zu gänglichkeit eines Modells und damit der Eignung al s Basis für ein Unterrichtsmedium. Welche visu ellen Darstellungen sind verwirrend und missverstän dlich und welche verständlich und leicht  erfassbar? In welche „Denkfallen“ tappen Programmie ranfänger, wenn sie bestimmte anschauliche  Vorstellungen verwenden?  Allgemeine Prinzipien der Verwendung intuitiver Mod elle  Ein viertes Anliegen ist, allgemeine Prinzipien des  Umgangs mit intuitiven Modellen herauszufin den. Welche Strategien und Techniken wenden Schüler innen und Schüler an, wenn sie versuchen, die  Arbeitsweise eines Programms durch intuitive Modell e zu rekonstruieren? (Kapitel 14) Welche Hin dernisse gibt es auf dem Weg von einer intuitiven L ösungsidee zu einer programmtechnischen Reali sierung? Wie können sie überwunden werden? (Kapitel  15) 14       1 Intuitive Modelle und informatisches Wissen  Intuition (lat. intuieri: ansehen, hinschauen, betr achten) wird seit der Antike in der Philosophie und   Wissenschaft als Quelle für sicheres oder scheinbar  sicheres Wissen beschrieben. In manchen Kontex ten verwendet man den Begriff Intuition zur Bezeich nung eines Prozesses. Eine Handlung ist intuitiv,  wenn sie schnell und aus einem Gefühl heraus erfolg t. Im Gegensatz dazu stehen rational durchdachte  Entscheidungen, die auf logischen Schlussfolgerunge n basieren und bei denen jede Handlungsalterna tive in Gedanken durchgespielt worden ist. In ander en Zusammenhängen wird Intuition dagegen als  besondere Kategorie von deklarativem Wissen definie rt. Nach Fischbein (1987) sind Intuitionen  grundlegende Vorstellungen über die Beschaffenheit der Welt, die wir ohne weiteren Beweis als sicher  richtig akzeptieren. Sie sind unmittelbar wie sinnl iche Wahrnehmungen, gehen aber über beobachtbare  Einzelereignisse hinaus. Man sieht unmittelbar an k onkreten Beispielen, dass gegenüberliegende Win kel am Schnittpunkt zweier Geraden gleich sind. Die  Intuition liegt in der Verallgemeinerung, dass es  immer so ist. Eine Intuition im Sinne von Fischbein  hat somit Theoriecharakter und verallgemeinert  Einzelbeobachtungen zu einem Modell eines Wirklichk eitsaspektes.   1.1 Intuition als Wissen  Intuitive Modelle sind eine Form von Wissen. Man ka nn generell zwischen prozeduralem und de klarativem Wissen unterscheiden (Haberlandt 1994; A nderson 1996, 1996a). Prozedurales Wissen  bezieht sich auf kognitive und motorische Fertigkei ten, deklaratives Wissen dient der Repräsentation  von Objekten und Ereignissen der Umwelt. Ryle (1949 ) beschreibt diese beiden Wissenskategorien als  „knowing how“ und „knowing that“. Die Differenzieru ng zwischen prozeduralem und deklarativem  Wissen ist die Basis von Andersons ACT-R-Theorie (A nderson 1996a), die eine Architektur zur Simu lation kognitiver Prozesse beschreibt.  1.2 Intuition als prozedurales Wissen  Prozedurales Wissen ist Wissen, wie man etwas tut. Dazu gehören motorische und kognitive Fer tigkeiten wie Schreibmaschineschreiben, Rechnen, un d Programmieren. In der Alltagssprache wird  Intuitivität häufig prozedural gesehen. Man denkt v ielleicht an den Detektiv im Kriminalroman, der  sich auf seinen „Riecher“ verlässt und intuitiv das  Richtige tut um den Täter zu finden. Jagdish Parik h  (1994) befragte in einer internationalen Studie 131 2 Manager aus neun Ländern zur Bedeutung von  Intuition bei ihren täglichen Entscheidungen. Die B efragten beschrieben Intuition vor allem als kognitiven Prozess, der rationalem und logischem Denken antithetisch gegenübersteht. Weitere dominieren de Attribute, mit denen Intuition charakterisiert w urde, waren „innere Wahrnehmung“, „unerklärliches  Verständnis“, „Gefühl, das von Innen kommt“, „Integ ration vorheriger Erfahrung“, „Entscheidung  ohne vollständige Datenbasis“, „sechster Sinn“ und „spontane Vision“ (Parikh 1994, S. 57). Bemer kenswert ist, dass nur 38.9 % der befragten Manager  angaben, sich bei Entscheidungen mehr auf rati onale Überlegungen zu verlassen als auf Intuition ( Parikh 1994, S. 57).   Anderson betont, dass prozedurales Wissen unbewusst  sein kann, d.h. eine Person beherrscht be stimmte Problemlösungstechniken ohne die Regeln ang eben zu können, die sie verwendet. Eine ver sierte Schreibkraft kann zwar mit hoher Geschwindig keit eine Tastatur fehlerfrei bedienen, aber es  gelingt ihr in der Regel nicht aus dem Gedächtnis a nzugeben, an welcher Stelle sich welche Taste  befindet. In einem Experiment von Berry und Broadbe nt (1984) sollten Studenten in einem Simulati onsprogramm die Produktion einer hypothetischen Zuc kerfabrik steuern. Dieses gelang den Probanden  auch nach einigen Versuchen. Aber keiner konnte ein e Regel angeben, nach der er oder sie vorging.  Die Versuchspersonen behaupteten, das Problem „intu itiv“ gelöst zu haben (nach Anderson 1996, S.  229 f.)  Leiser (2001) beobachtete, dass deklaratives und pr ozedurales Wissen zu einer Domäne weitge hend unverbunden nebeneinander existieren können. E r interviewte 20bis 30-jährige Personen zu der  Frage, was ein gutes Paar ausmacht. Die Befragten w aren in der Lage, (deklarative) Prinzipien an zugeben, nach denen man gut zusammenpassende Mensch en auswählen kann. Sie hatten zweitens kein 15     Problem zu entscheiden, welche Personen aus ihrem B ekanntenkreis stabile Paare bilden würden. Je doch gerieten sie in Schwierigkeiten, als sie ihre (prozeduralen) Zuordnungen mit den zuvor genann ten (deklarativen) Paarbildungsprinzipien begründen  sollten, wichen von diesen Prinzipien ab oder  gaben plötzlich neue an.  Halten wir fest: Intuition kann prozeduraler Natur sein. Eine prozedurale Intuition ist eine  zielorientierte Aktivität, die ein Mensch sicher be herrscht. Die Besonderheit gegenüber deklarativem  Wissen ist, dass die Person nicht zwingend einen Al gorithmus für ihr Tun angeben kann. Das heißt  nicht, dass sie nicht einem Algorithmus folgt. Aber  er ist ihr möglicherweise nicht bewusst, oder es  fehlen ihr die sprachlichen Mittel die eigene Probl emlösung zu beschreiben. Es kann auch sein, dass  sie die Aufgabe jedes Mal auf andere Weise löst. Di e subjektive Gewissheit – ein Merkmal von  Intuition – liegt darin, dass man sich sicher ist, die Aufgabe lösen zu können. Dagegen bleibt (unter  Umständen) ungewiss, wie man das tut.   1.3 Intuitive Modelle als bedeutungsbezogenes dekla ratives Wissen   Intuitive Modelle werden häufig visuell durch Bilde r oder Animationen repräsentiert. Betrachtet  man in einem Programmtext eine Zuweisung x = 1 , so taucht vor dem inneren Auge vielleicht das  Bild eines Kasten mit dem Etikett x auf, in den ein  Zettel mit einer 1 gelegt wird. Doch eine solche  bildhafte Vorstellung allein ist noch kein intuitiv es Modell. Anderson (1996) unterscheidet zwischen  wahrnehmungsbezogenem und bedeutungsbezogenem Wisse n. Ein Beispiel für wahrnehmungsbezo genes Wissen sind mentale Bilder, gedankliche Vorst ellungen von früher wahrgenommenen Objekten  (Anderson 1996, 103 ff). Mentale Bilder müssen nich t unbedingt mit Bedeutung belegt sein. Bei spielsweise kann man einen Computer als mentales Bi ld, bestehend aus Monitor, Tastatur, Zentralein heit, Kabeln etc., vorstellen, ohne die Funktion de r einzelnen Komponenten zu verstehen. Die Kom ponenten bedeutungsbezogenen Wissens bezeichnet man  meist als Konzepte (concepts). Intuitive  Modelle sind bedeutungsbezogen und deklarativ. In d en folgenden Abschnitten vergleichen wir Intui tionen mit drei Arten von Konzepten: Begriffe, Sche mata und mentale Modelle.  1.3.1 Begriffe – Identifikation von Objekten  Nach Auffassung von Eckes (1991) sind Begriffe Beze ichnungen für Objekte oder Klassen von  Objekten. In diesem Sinne verwendet man Begriffe, u m Objekte oder Ereignisse der Realwelt identifi zieren und unterscheiden zu können. Begriffzuordnun gen spielen eine Rolle, wenn jemand ein intuiti ves Modell oder eine intuitive Prozedur als Grundla ge für die Entwicklung eines Programms verwen det. Der erste Schritt des Entwicklungsprozesses is t meist die Belegung von Entitäten oder  Einzelaktivitäten mit informatischen Begriffen (z.B . das Beschreiben einer gewissen Anzahl von Din gen einer Kategorie als Liste von Objekten einer Kl asse).   1.3.2 Schemata – Speichern struktureller Merkmale  Ein kognitives Schema ist eine Anordnung von Attrib uten (Slots), die bestimmte Merkmale einer  Klasse von Objekten benennen (Anderson 1996). Dabei  ist jedem Attribut ein typischer Wert (Default)  oder Wertebereich für denkbare Belegungen zugeordne t. Ein Haus z.B. ist ein Gebäude, enthält Zim mer, hat meist einen rechteckigen Grundriss, wird z um Wohnen verwendet, ist aus Holz oder Stein  gebaut und hat eine Größe zwischen 10 und 1000 Quad ratmetern. Diese typischen Merkmale ergeben  das Schema eines Hauses. Schemata gibt es nicht nur  für physische Objekte sondern auch für Ereig nisse, wie stereotype Handlungsabläufe. Solche Erei gnisschemata bezeichnet man als Scripts (Schank  & Abelson 1977). Ein Script für einen Restaurantbes uch besteht bei vielen Menschen aus der typi schen Abfolge Platz nehmen, Speisekarte lesen, best ellen, essen, bezahlen und gehen (Bower, Black &  Turner 1979). Das Schema-Konzept wird in der Kognit ionspsychologie vor allem verwendet, um das  effizientes Abspeichern von bedeutungsvollen Inhalt en im Gedächtnis zu erklären.  Wenn man erkennt, dass ein Objekt zu einer Objektkl asse gehört, braucht man sich nur noch An weichungen von den Default-Werten des Schemas zu me rken. Die anderen („typischen“) Merkmale  des Objektes kann man aus dem (bereits gespeicherte n) Schema ableiten. Brewer und Treyens (1981)  haben die Existenz von Schemata durch Erinnerungsex perimente nachgewiesen. Auch beim Pro16     grammieren greift man auf Schemata zurück. So gibt es Schemata über den Aufbau einer rekursiven  Funktion (siehe Abschnitt 9.6).  Intuitive Modelle kann man als Schemata betrachten,  wenn man Aspekte wie Erinnerbarkeit oder  Zuordnung einer Situation (aufgrund von wahrgenomme nen Merkmalen) zu einem Modell untersucht.  Dies ist dann jedoch eine reduzierte Sichtweise, in  der z.B. dynamische Aspekte eines Modells im  Hinblick auf eine Problemlösung vernachlässigt werd en.   1.3.3 Mentale Modelle  Mentale Modelle sind vereinfachte Repräsentationen realer oder hypothetischer Situationen. Sie er lauben das gedankliche Durchspielen von Abläufen un d können so zur Antizipation von Ereignissen  im abgebildeten Wirklichkeitsausschnitt verwendet w erden. Mentale Modelle enthalten also eine dy namische Komponente. Sie werden für komplexere kogn itive Aktivitäten wie Problemlösen und Er klären von Phänomenen der Realwelt verwendet.   Mentale Modelle wurden zum ersten Mal von dem schot tischen Psychologen Kenneth Craik (1943)  postuliert. Johnson-Laird (1983) erklärt logisches Schließen – insbesondere die Überprüfung der Gül tigkeit kategorialer Syllogismen – mit seiner Theor ie mentaler Modelle.   Insbesondere im Zusammenhang mit Computern wird gel egentlich zwischen konzeptuellen Model len und mentalen Modellen differenziert. Während ei n mentales Modell eine (eventuell unbewusste)  gedankliche Leistung eines Individuums ist – z.B. d ie Vorstellung eines Computernutzers über die  Arbeitsweise eines Computers –, ist ein konzeptuell es Modell von Experten (Lehrer, Wissenschaftler,  Softwareentwickler etc.) bewusst gestaltet. Es stel lt eine fachlich akzeptable Repräsentation eines  Zielsystems dar, d.h. es ist Expertenwissen. Dagege n können mentale Modelle, die Personen im Um gang mit Informatiksystemen heranziehen, auch unang emessen sein und im Widerspruch zum Wis senstand der Fachgemeinschaft stehen (Fehlvorstellu ng). Konzeptuelle Modelle dienen als Grundlage  für das professionelle Design von Softwaresystemen oder die Gestaltung von Medien und Aktivitäten  für den Unterricht (Wu et al. 1998). Inhaltlich unt erscheiden sich mentale Modelle und konzeptuelle  Modelle nicht. Im Unterricht oder in Handbüchern ve rbreitete konzeptuelle Modelle werden oft von  den Rezipienten übernommen und sind dann deren ment ale Modelle. Selbst Fehlvorstellungen können  von Pädagogen expliziert und in Lehrprozessen zur A bgrenzung vom „Richtigen“ und zur Vermittlung  eines vertieften Verständnis eingesetzt werden.  1.4 Merkmale intuitiver Modelle  Fischbein nennt u. a. folgende Merkmale intuitiver Vorstellungen (Fischbein 1987 S. 43 ff): Selbst evidenz (self evidence), Intrinsische Gewissheit (i ntrinsic certaincy), Dauerhaftigkeit (Persistenz),  Zwanghaftigkeit, Theoriestatus, Extrapolativität un d Globalität.  Selbstevidenz  Ein intuitives Modell ist unmittelbar einleuchtend und bedarf keiner weiteren Erklärung. Selbstevi denz ist nicht unbedingt eine Folge von Vertrauthei t durch Erfahrung. Die bekannte binomische For mel a²-b² = (a+b)(a-b)  ist nicht selbstevident, obwohl niemand, der die S ozialisation des  schulischen Mathematikunterrichts durchlaufen hat, an der Richtigkeit zweifelt.   Dagegen ist die Aussage „Jede ganze Zahl hat einen Vorgänger“ offensichtlich. Fischbein (1987)  stellt heraus, dass eine selbstevidente Aussage unm ittelbar etwas mit einem dahinter liegenden menta len Modell zu tun hat. Sie ist gewissermaßen eine B edeutungsfacette eines abstrakten Konzeptes. So  werden ganze Zahlen über Vorgänger und Nachfolger d efiniert. Selbstevidente Aussagen sind so et was wie die Atome von Argumentationen. Jeder Schrit t eines nachvollziehbaren Beweises muss  selbstevident sein. Anderenfalls könnte er nicht vo m Leser akzeptiert werden und müsste in weitere  „feinere“ Unterschritte zerteilt werden.   Intrinsische Gewissheit – Konfidenz  Eine Intuition wird vom Subjekt als sicher zutreffe nd akzeptiert. Gewissheit und Selbstevidenz sind  nicht das gleiche. Man kann überzeugt sein, dass z. B. ein mathematischer Satz wie der Satz des Pytha17     goras richtig ist, obwohl er nicht selbstevident is t, sondern eines Beweises bedarf. Andererseits gibt  es  (empirisch nachgewiesene) Fälle, in denen befragte Personen eine Aussage als selbstevident einschät zen, sich aber bezüglich der Korrektheit dieser Ein schätzung unsicher sind (Fischbein 1987). Selbst evident heißt lediglich, dass man keine „Beweismitt el“ für erforderlich oder gar vorstellbar hält, mit   denen die Richtigkeit der Behauptung nachgewiesen k ann. Der Begriff Gewissheit (oder Konfidenz)  bezieht sich vor allem auf die affektive Komponente  einer Intuition. Mit Gewissheit ist die Bereit schaft verbunden, persönliche Nachteile in Kauf zu nehmen, falls die betreffende Aussage sich uner wartet als falsch erweist. Dementsprechend kann Gew issheit z.B. dadurch gemessen werden, dass  Probanden sich bereit erklären, Geld zu zahlen, fal ls sie sich irren. (Fischbein 1987, S. 46, Fischhof f et  al. 1977, S. 559–560).  Intuitionen sind häufig trügerisch. Nicht selten ve rtrauen wir einer Intuition, die sich später als  falsch erweist. Fischbein nennt dieses Phänomen Übe rvertrauen (overconfidence). Bemerkenswert ist,  dass Menschen vor allem auf Gebieten, in denen sie sich nicht auskennen, zu Übervertrauen neigen.   Gewissheit ist bei informatischen Problemlösungen –  z.B. bei einer Programmentwicklung – von  besonderer Bedeutung. Denn mit jeder Programmzeile investiert man Arbeit in das Projekt und geht  das Risiko eines semantischen Fehlers ein, der spät er nur mit großer Mühe lokalisiert und beseitigt  werden kann, wenn er denn überhaupt gefunden wird. Ein Programmentwickler, der eine Programm zeile formuliert, verlässt sich also auf seine Intu ition. Ohne (subjektive) Gewissheit, dass die gewäh lte  Formulierung richtig ist, würde er oder sie leichtf ertig die Korrektheit des Gesamtsystems gefährden  und sich potenziell erhebliche Mehrarbeit (also Zus atzkosten) beim Debuggen aufbürden.  Persistenz und Zwanghaftigkeit  Fischbein (1987) ist der Auffassung, dass intuitive  Modelle niemals vergessen werden, sondern als  „stilles Wissen“ erhalten bleiben und mehr oder wen iger unbewusst das Denken eines Menschen ein  Leben lang beeinflussen, auch wenn er oder sie inzw ischen andere (unter Umständen geeignetere)  Konzepte gelernt hat. Diese Zwanghaftigkeit und Per sistenz intuitiver Modelle wurde oft im Zusam menhang mit Fehlvorstellungen beobachtet. Ein viel diskutiertes Beispiel aus der Physik ist das  „Schwungmodell“, das Kraft als Ursache von Bewegung  beschreibt (Nakamura 1974; Clement 1982;  Fischbein 1987, S. 171, S. 176 ff). Dabei handelt e s sich um die Vorstellung, dass ein sich bewegender   Körper immer langsamer wird und schließlich zum Sti llstand kommt, wenn man nicht ständig eine  Kraft in Bewegungsrichtung ausübt. Ein sich bewegen des Objekt hat einen Schwung, den es im Laufe  der Bewegung allmählich „aufbraucht“. Das Modell wi derspricht dem ersten Newtonschen Gesetz,  wonach Körper (infolge der Trägheit der Masse) ihre  Bewegung bis in alle Ewigkeit beibehalten, so fern keine Kräfte auf sie wirken. Doch nach unserer  alltäglichen Erfahrung hält keine Bewegung ohne  unterstützende Krafteinwirkung unendlich lange an, sondern erstirbt (infolge Reibung) mit der Zeit:  Eine Murmel rollt auf einer ebenen Fläche nur ein g ewisses Stück weit, ein Boot verliert an Ge schwindigkeit, wenn man nicht ständig rudert usw. C lement (1982) beobachtete, dass Studenten der  Ingenieurwissenschaften die Kräfte, die auf eine fl iegende Münze wirken, mit diesem Schwungmodell  beschrieben, obwohl ihnen die Gesetze der Mechanik vertraut waren. Ueno (1993) ist der Auffassung,  dass die Robustheit „naiver Erklärungen“ eher auf d en Einfluss der sozialen Umgebung zurückzufüh ren ist als auf die Persönlichkeit des Individuums (Ueno 1993, S. 244f.).  Gestaltcharakter   Intuitive Modelle repräsentieren einfache Gedanken.  Sie sind in sich geschlossene, holistische  Sinneinheiten. Sie haben den Charakter von Gestalte n. Der Begriff „Gestalt“ wurde seit den 1920iger  Jahren durch die Gestalttheorie (Max Wertheimer, Ku rt Koffka, Wolfgang Metzger, Rudolph Arn heim) geprägt, die damit menschliche Wahrnehmung er klärt. Nach ihrem Ansatz ist Wahrnehmung  keine passive Reizaufnahme sondern ein aktiver, sub jektgesteuerter Vorgang. Visueller Input wird als  Anordnung von (dem Individuum vertrauten) Gestalten  interpretiert.  18            Abb. 1: Gestalt eines Quadrats  So sehen die meisten Menschen in Abbildung 1 ein au f der Spitze stehendes Quadrat, obwohl eine  solche Figur nicht explizit umrandet ist. Gewisshei t und Selbstevidenz können sich nur auf kohärente  Sinngebilde beziehen. Wenn ich mir einer Sache gewi ss bin, muss diese Sache auch benennbar und als  geschlossene Ganzheit repräsentierbar sein.   Modelle von Softwaresystemen, die während einer Sof tware-Entwicklung entstehen und etwa  durch UML-Diagramme repräsentiert werden, sind in d er Regel zu komplex, um intuitiv zu sein. Das  gleiche gilt für Programmtext. Um ein komplexes Sys tem zu verstehen, zu erklären oder zu entwi ckeln, greifen Menschen häufig – quasi zeitgleich –  auf ein ganzes Bündel intuitiver Modelle zurück  (Modellcluster). Denn ein einzelnes Modell kann das  komplexe Original nur unzureichend abbilden.  Ein Problem ist, die verschiedenen Intuitionen scha rf zu trennen und die verwendeten Gestalten zu  verdeutlichen. Die Interpretation eines Programms ä hnelt zuweilen der Betrachtung eines Vexierbildes  („Kippbild“), bei dem der gleiche optische Reiz unt erschiedliche Gestalt-Wahrnehmungen auslöst.  1.5 Phänomenologische Primitive  Andrea diSessa (1988, 1993, 2001) beschreibt besond ers grundlegende intuitive Modelle, die auf  häufig erlebten sensorischen Erfahrungen basieren. Er nennt sie phänomenologische Primitive oder  kurz p-Prims. Sie sind Basismodelle bzw. Primitive in dem Sinne, dass sie die Grundlage für Erklä rungen sind und selbst nicht weiter begründet werde n. Das bedeutet, dass ein Modell M für einen  Menschen den Charakter eines p-Prims verlieren kann , wenn er noch einfachere, grundlegendere Mo delle findet, mit denen er M erklären kann.  Ein Beispiel ist das Konzept der Schwere. Jeder Men sch erlebt bereits in jungen Jahren, dass Ge genstände schwer sind und verallgemeinert diese häu fig gemachte Beobachtung z einem selbstver ständlichen Merkmal der Welt. Wenn jemand die Tatsa che, dass Dinge zu Boden fallen, wenn man sie  loslässt, damit begründet, dass sie schwer sind, ve rwendet er oder sie das p-Prim „Schwere“. Für diese   Person ist die Schwere von Gegenständen ein unmitte lbar akzeptiertes Phänomen, das selbst keiner  weiteren Erklärung bedarf.   Ein weiteres Merkmal von p-Prims ist ihre universel le Verwendbarkeit in verschiedenen Lebensbe reichen. Die Vorstellung von Widerstand, der nur mi t Anstrengung zu überwinden ist (ein von diSessa  häufig erwähntes Beispiel), wird sowohl zur Erkläru ng elektrischer als auch mechanischer Phänomene  herangezogen (Ohmsches Gesetz, Reibung etc.).  1.6 Intuitive Modelle und Fehlvorstellungen  In zahlreichen Untersuchungen sind Fehlvorstellunge n (misconceptions) von Schülern und Studen ten im Zusammenhang mit naturwissenschaftlichen (z. B. Griffith und Preston 1992; Clement 1982;  Brown 1992), mathematischen (z.B. Rosnick 1981; Cle ment, Lochhead, Monk 1981; Fischbein 1987)  und informatischen Themen (z.B. Bonar, Soloway 1985 ; Close, Dicheva 1997; Sleeman, Putman,  Baxter, Kuspa 1989; Ginat 2001; Madison Gifford 200 2) entdeckt und spezifiziert worden.  Intuitive Modelle werden in verschiedener Hinsicht als Quelle für Fehlvorstellungen gesehen:  • Sie können selbst objektiv falsch sein, weil die se nsorische Erfahrung, auf der sie fußen, irrefüh rend war. So ist das bereits erwähnte Schwungkonzep t für Bewegungen das Resultat von Alltags erfahrungen mit reibungsbehafteten Bewegungsvorgäng en.   • Sie werden auf unzulässige Weise verallgemeinert un d in einem Kontext verwendet, in dem sie  nicht gelten. So erklären Kindergartenkinder häufig , die Sonne gehe abends unter, weil sie müde 19     ist. Hier wird das intuitive Modell des Ermüdens au f Objekte der unbelebten Natur angewendet  (Anthropomorphismus, Animismus).  Intuitive Modelle, wenn sie denn zu Fehlvorstellung en führen, werden von Pädagogen als Barrieren  für den Erwerb wissenschaftlich fundierter Experten konzepte gesehen (Champagne, Gunstone und  Klopfer 1985, Strike und Posner 1985). Dementsprech end sollten Misconceptions möglichst vermie den werden (z.B. Holland, Griffiths, Woodman 1997).  Bereits vorhandene Fehlvorstellungen müssten  dann vom Lehrer entdeckt und im Unterricht gezielt aufgegriffen werden. Bei der „Konfrontationsme thode“ werden Expertenkonzepte den fehlerhaften Vor stellungen der Schüler/innen gegenüber gestellt.  Der Unterricht enthält Demonstrationen und Arrangem ents, die die vorhandenen Fehlvorstellungen  falsifizieren (Gegenbeweise). Als Ziel wird manchma l gesehen, falsche naive Vorstellungen durch  Expertenkonzepte zu ersetzen  (z.B. McClosky 1983, Brown 1992). Smith, diSessa u nd Roschelle  (1994) bezweifeln allerdings, dass man Misconceptio ns einfach ersetzen kann. Der Begriff „ersetzen“  impliziert, dass die falsche Vorstellung ausgelösch t wird. Doch konnte man beobachten, dass auch  Experten in bestimmten Situationen auf intuitive Vo rstellungen zurückgreifen anstatt abstrakte wis senschaftliche Modelle (durch Formeln beschriebene Gesetze) zu verwenden.  Jean Piaget (2003) hält Fehlvorstellungen für eine „natürliche Randerscheinung“ der kognitiven  Entwicklung eines Menschen. Er nennt für jede Entwi cklungsstufe typische „Denkfehler“. Beispiels weise kennen Kinder in der präoperationalen Stufe ( Kindergartenalter) noch nicht das Prinzip der Vo lumenkonstanz. Wenn sie z.B. eine Flüssigkeit von e inem breiten niedrigen Glas in ein schlankes ho hes Gefäß gießen, glauben sie, es sei mehr geworden , weil der Flüssigkeitsspiegel höher liegt.    Smith, diSessa und Roschelle (1994) sind der Auffas sung, dass die Sichtweise der Misconception forschung mit dem Konstruktivismus nicht vereinbar ist. Sie sprechen von einem „Lernparadox“. Der  Konstruktivismus beschreibt Lernen als Weiterentwic klung bereits existierender Wissensstrukturen.  Damit müssten eigentlich auch Fehlvorstellungen nüt zliches Vorwissen sein und nicht etwas, das Da zulernen behindert. Fazit: Nicht der Inhalt  einer Fehlvorstellung – also das intuitive Modell – ist das  Problem sondern seine unangemessene Verwendung.   Jede Fehlvorstellung, die vom Subjekt als solche er kannt worden ist, bedeutet einen Wissenszu wachs. Denn sie dient dazu, die Grenzen der Anwendb arkeit zu definieren. Betrachten wir ein Beispiel  aus der Informatik: Angenommen, Sandra stellt sich eine Liste s =[1, 3, 5, 6]  als Behälter mit  drei Fächern vor, in denen sich beschriftete Zettel  befinden. Dann verwendet Sandra ein intuitives  Modell. Sie ist den Umgang mit einem solchen Behält er gewohnt – vielleicht hat sie als Kind einen  solchen Kasten zum Sortieren von Legosteinen verwen det. Für sie ist es z.B. zweifelsfrei klar, was das   erste oder letzte Element ist oder was es heißt, da s erste mit dem letzten Element zu vertauschen. Für   viele Operationen in einem Computerprogramm, das ei ne solche Liste verarbeitet, ist das Behältermo dell perfekt geeignet. Die Änderung des ersten List enelements durch die Anweisung s[0] = 2  kann  z.B. so dargestellt werden, dass man den Zettel im ersten Fach durch einen anderen Zettel ersetzt. Allerdings gibt es auch Anweisungen, die mit dem Behä ltermodell nicht dargestellt werden können.  Wenn das zweite Element durch die Anweisung del s[1]  gelöscht wird, bedeutet das z.B. nicht,  dass der zweite Zettel aus dem Behälter entfernt wi rd. Wer das intuitive Modell des Behälters ange messen verwendet, kennt also erstens das Modell und  alle relevanten Situationen, in denen man es  nicht verwenden darf. D.h. er oder sie kennt potent ielle Fehlvorstellungen, die mit dieser Intuition  verbunden sind. 20       2 Repräsentation intuitiver Modelle  In diesem Kapitel richten wir das Augenmerk auf Fra gen der Repräsentation eines intuitiven Mo dells. Wir betrachten ein intuitives Modell als imm ateriales gedankliches Konzept, das auf verschiedene Weise repräsentiert werden kann. Die Repräsentat ion ist physisch existent und der Wahrnehmung  durch die Sinne zugänglich. Sie kann aufgeschrieben , gemalt, gedruckt, gefilmt d.h. in irgendeiner  Form auf einem physischen Medium gespeichert werden . Nur über eine physische Repräsentation  kann ein Modell externalisiert, kommuniziert und ar chiviert werden (vgl. auch Ueno 1993). Es macht  Sinn zwischen dem Modell und seiner physischen Repr äsentation zu differenzieren, weil letztere eine  gewisse Beliebigkeit und Variabilität aufweist, wäh rend das intuitive Modell dauerhaft ist. Anders  herum kann man auch sagen, dass die Annahme einer d auerhaften Intuition allein die Schlussfolge rung eines Beobachters ist, der im Verhalten einer Person gewisse Regelmäßigkeiten über die Zeit  feststellt. Beobachtbar sind allein physische Reprä sentationen wie z.B. ein Bild, das jemand in einer  bestimmten Situation zeichnet, um einem Gedanken Au sdruck zu verleihen. Aus mehreren solcher  „Äußerungen“ schließt ein Beobachter auf dahinter l iegende Modellvorstellungen.   Wenn man auch analytisch zwischen Modell und seiner  physischen Repräsentation unterscheiden  kann, so ist doch beides eng miteinander verwoben. DiSessa (2001) weist auf die Materialität von  Intelligenz hin. Ohne geeignete Ausdrucksmittel kön nen intuitive Modelle gar nicht entstehen.  Manchmal ist es schwierig die Grenze zwischen Reprä sentation und Modell zu ziehen. Ist ein konkre tes Beispiel nur eine Repräsentation eines Modells oder ist es bereits das Modell? Es gibt verschieden e  Dimensionen, die man bei einer Untersuchung von Rep räsentationsformen bedenken kann.   Kodierung. Mit welcher Art von materialen Bedeutungsträgern we rden intuitive Modelle darge stellt? Alan Paivio unterscheidet verbale und imagi nale Kodierung von Wissen.  Metaphorisierung.  Es muss eine geeignete, der menschlichen Vorstellu ngskraft zugängliche Do mäne gefunden werden, aus der ein Modell stammt. Fü r Auswahl der Domäne ist ein wichtiges Krite rium wie gut man in ihr die gemeinten Modelle physi sch repräsentieren kann.   Konkretisierung und Beispielbildung (Exemplarisieru ng).  Die Repräsentation eines Modells ist  immer konkret. Aus einer im Prinzip unendlichen Fül le von Möglichkeiten müssen eine oder mehrere  repräsentative Exemplare auswählt werden.  Strukturorientierte und prozessorientierte Darstell ungen . Eine strukturorientierte Darstellung ist  statisch und gibt dauerhafte Aspekte des Gemeinten wieder. So ist ein Struktogramm oder ein Pro grammtext eine strukturorientierte Repräsentation e ines Algorithmus. Ein Protokoll, das die Inhalte  von Variablen während eines beispielhaften Laufs da rstellt oder eine Animation, das die Veränderun gen während eines Programmlaufs visualisiert, ist p rozessorientiert. Wenn jemand sich die Arbeits weise eines Algorithmus über einen Beispielablauf –  also prozessorientiert – merkt, heißt das nicht,  dass er oder sie nur über prozessuales Wissen dazu verfügt. Eine prozessorientierte Repräsentation ist   kein prozedurales Wissen sondern bewusstes deklarat ives Wissen über einen Prozess. Aus dem Pro zessbeispiel kann in der Regel leicht eine struktur orientierte Darstellung (z.B. ein Programmtext) generiert werden und umgekehrt. Das Prinzip der Vielf alt und Flüchtigkeit (Abschnitt 2.2) gilt auch für  diesen Aspekt von Repräsentationen.  2.1 Duale Kodierung von Wissen  In der Theorie der dualen Kodierung (Paivio 1971; 1 986) werden zwei grundsätzliche physische  Darstellungsformen für Wissensinhalte unterschieden : verbale (sprachliche, begriffliche) und nonver bale (bildhafte, imaginale) Repräsentationen. Beisp iele für bildhafte Darstellungen sind Fotos, Zeichnungen, Karten und Diagramme. Sie sind analog, ikon isch und kontinuierlich. Beispiele für sprachli che Repräsentationen sind (natürlichsprachliche) Te xte, mathematische Modelle oder  Computerprogramme. Sie sind digital, nicht-ikonisch  und diskontinuierlich. Paivio nimmt an, dass es  für verbal und nonverbal repräsentierte Information  getrennte aber gleichwohl kooperierende Verar beitungssysteme gibt.  21     Es gibt eine Reihe von empirischen Befunden, die di eses Modell unterstützen: Doppelte Kodierung  eines Inhaltes durch sprachliche und bildhafte Repr äsentationen erhöht die Erinnerungswahrschein lichkeit. So werden leicht verständliche und benenn bare Bilder (z.B. ein Haus) nach einmaliger Prä sentation besser behalten als Wörter. Diesen „Bildü berlegenheitseffekt“ erklärt Paivio damit, dass die   Information doppelt repräsentiert wird, nämlich ers tens nonverbal als Bild und zweitens verbal durch  einen Begriff, der mit dem Bild assoziiert wird. Di e Annahme von getrennten Verarbeitungssystemen  für verbale und nonverbale Information wird durch h irnphysiologische Befunde unterstützt. EEGStudien (Ley, 1983) zeigten, dass bei der Verarbeit ung von sprachlichem Material vor allem die linke  Hirnhälfte aktiv ist, während beide Hirnhälften an der Verarbeitung nonverbaler Information beteiligt  sind. Sasse (1997) schlägt vor, sprachliche und bil dhafte Repräsentationen als zwei Endpunkte eines  Kontinuums zu betrachten. Viele Repräsentationen ko mbinieren sprachliche und visuelle Komponen ten. Eine Zeichnung ist oft leichter verständlich –  und repräsentiert das gemeinte Modell – besser,  wenn sie einige Wörter oder Symbole enthält.   2.2 Vielfalt und Flüchtigkeit  Inwiefern macht es Sinn zwischen mentalem Modell un d physischer Repräsentation zu unterschei den? Man könnte ja auch sagen, das Bild eines Behäl ters, der einen Zettel mit einer Zahl enthält, ist  bereits ein Modell.   Doch während intuitive Modelle einfache und in der Biographie eines Menschen dauerhafte Denk weisen darstellen, mit denen viele Erscheinungen de r Welt erklärt und verstanden werden können,  sind Repräsentationen dieser Modelle vielfältig und  flüchtig.  Für ein und dasselbe intuitive Modell gibt es im Pr inzip beliebig viele unterschiedliche Repräsenta tionen, von denen je nach Situation nur eine ausgew ählt wird. Nehmen wir als Beispiel das Behälter modell für Variablen. Dieses Modell wird in untersc hiedlichen Sprachäußerungen verwendet, die sich  in der exakten Wortwahl unterscheiden können, aber das gleiche meinen:  „Bei einer Zuweisung geht der alte Inhalt einer Var iablen verloren.“  „Bei einer Zuweisung wird der vorige Inhalt zerstör t.“  In visuellen Repräsentationen des Behältermodells k önnen Behälter, Namensschilder und Inhalte  auf mannigfache Weise dargestellt werden. Als Darst ellungsform kann man Zeichnungen, Fotos oder  reale Gegenstände verwenden. Inhalte einer Variable n lassen sich auf unterschiedlichen Abstraktions niveaus visualisieren. Ein Zettel mit einer Zeichen kette oder einer Zahl ist konkreter als die Abbildu ng  eines Gegenstandes, der ein Datum repräsentiert. Ma n hat die Wahl, einen Wert als Literal („Haus“)  oder in Form seiner Ansicht (Haus) wiederzugeben.   Intuitive Modelle werden in Kommunikationsprozessen  verwendet und dabei über Repräsentatio nen externalisiert. Jeder, der eine Idee durch eine  Grafik veranschaulicht, versucht zunächst alles mö g lichst einfach zu halten. Erst wenn die Gesprächspa rtner Nachfragen haben, werden weitere Details  hinzugenommen, verbale Erläuterungen gegeben oder z usätzliche Bilder zur Darstellung spezifischer  Aspekte angefertigt. Häufig werden Repräsentationen  intuitiver Modelle ad hoc erfunden und auf die  Bedürfnisse (Sehund Hörgewohnheiten) des Adressat en zugeschnitten. Im Schulunterricht denken  sich Lehrerinnen und Lehrer immer neue Formulierung en für ein und denselben Gedanken aus bis sie  das Gefühl haben, dass sie verstanden werden. Reprä sentationen intuitiver Modelle haben oft etwas  Flüchtiges. Manche Bilder werden nur einmal verwend et (um einem bestimmten Menschen in einer  bestimmten Situation mit bestimmten Medien etwas zu  erklären) und häufig kann man sich nach kur zer Zeit nicht mehr an sie erinnern. Das dahinter s tehende Konzept ist dagegen dauerhaft. Persistenz  ist ja ein Merkmal intuitiver Modelle.  2.3 Repräsentation und Metaphorisierung   2.3.1 Uneigentliche Redeweise in der Informatik  Die Sprache der Informatik ist voller Formulierunge n, die in der Rhetorik als Formen des uneigent lichen Sprechens (Tropen) bezeichnet werden (Baumga rten 2005). In einer Metapher (Übertragung)  wird der eigentliche Ausdruck (Ziel) durch einen an deren (Quelle) ersetzt, der aus einem anderen 22     Sachbereich (Domäne) stammt. Eine Metapher ist ein Vergleich ohne ein tertium comparationis, d.h.  ohne die Nennung der Hinsicht, in der sich die Begr iffe aus Quellund Zielbereich ähneln. Beispiele:   • Eine Klasse ist ein Bauplan (Quelldomäne ist Archit ektur).  • Variablen sind Behälter für Daten.  Wenn Metaphern lange genug in der Fachsprache verwe ndet worden sind, werden sie zu toten Me taphern, d.h. ihre ursprüngliche Bedeutung in der Q uelldomäne tritt in den Hintergrund. Beispiele für  tote Metaphern aus der Informatik sind Begriffe wie  Botschaft, Verzweigung oder Schleife.  Bei Metonymien (Umbenennungen) wird der eigentliche  Ausdruck durch einen anderen ersetzt, der  aus derselben Domäne stammt. Eine Metonymie in der Alltagssprache ist z.B. die Formulierung „vor  den Altar treten“ für „heiraten“. Wenn man unterste llt, dass die Hochzeit in der Kirche stattfindet,  stammt der Begriff „Altar“ aus derselben Domäne.   Viele Begriffe in der Informatik sind Metaphern ode r Metonymien, für die es keine eigene, eigent liche Bezeichnung gibt. So sagt man, dass eine Funk tion ihr Berechnungsergebnis zurückgibt. Damit  vergleicht man die Funktion mit einem Menschen, der  von einer anderen Person etwas in Empfang  nimmt und ihr anschließend etwas zurückgibt. Für di esen Ausdruck gibt es aber keine andere Formu lierung. Ja, er wird bei vielen Programmiersprachen  sogar in der Syntax als Schlüsselwort verwendet  (return). Solche notwendigen Metaphern oder Metonym ien bezeichnet man als Katachresen.  Eine Allegorie (Bild) ist eine komplexe Metapher, d ie einen abstrakten Begriff veranschaulichen  soll (z.B. „divide and conquer“). Bei einem Verglei ch werden Ausdrücke aus verschiedenen Domänen  durch das Partikel wie  verbunden (z.B. „Instanzen einer Klasse sind wie H äuser, die nach dem glei chen Bauplan gebaut worden sind.“) Ein Vergleich br ingt eine gewisse Distanz zwischen dem ver wendeten Modell und dem gemeinten Zielkonzept zum A usdruck.    Man verwendet Tropen – insbesondere Metaphern – um die Wirkung eines Textes auf den Leser  oder die Leserin zu erhöhen. Metaphern machen einen  Text abwechslungsreich und interessant. Es ist  ein Spiel mit der Bedeutung der Wörter. Die Spannun g wird erhöht, wenn die Quelldomäne unge wöhnlich ist und thematisch weit von der Zieldomäne  entfernt ist.    2.3.2 Metaphern und analoges Denken  In der kognitiven Linguistik löst man sich von dem rhetorischen Aspekt der (oberflächlichen) Re deverbesserung und betrachtet Metaphern als Vorstel lungen, die substanzielles Wissen repräsentieren.  Boyd (1993) zählt für verschiedene Wissenschaften t heoriekonstituierende Metaphern auf. Lakoff und  Nún ez (1997) beschreiben grundlegende Metaphern (groun ding metaphors oder conceptional me taphors) für die Mathematik. Diese Metaphern schlag en eine Brücke zwischen vertrauten Vorstel lungswelten und mathematischen Domänen. Beispiele s ind „arithmetic is object collection“ oder  „arithmetic is object construction”. 2  Kennzeichnend für diesen Ansatz ist, dass eine Meta pher als Abbildung A /barb2right B von einer Quelle  (base, source) A auf ein Ziel (target) B dargestell t wird. (Man liest eine solche Abbildung „B is A“.)   Jede Metapher besteht aus einer Sammlung von „Unter abbildungen“. So gehören zur Metapher „A rithmetic Is Object Collection“ unter anderem folge nde Zuordnungen:   • Zahlen sind Kollektionen von physischen Objekten gl eicher Größe.  • Arithmetische Operationen sind Akte des Bildens ein er Kollektion von Objekten.  • Eine Addition ist das Zusammenlegen zweier Objektko llektionen zu einer größeren Kollektion.  Das Beispiel zeigt, dass die Quelle einer Metapher intuitiv sein muss, wenn sie helfen soll, die  Zieldomäne (z.B. Arithmetik) zu verstehen. Nur wenn  man sich sicher ist, dass beim Zusammenlegen  von zwei Kollektionen keine Objekte verloren gehen und keine aus dem Nichts dazukommen, kann                                                         2 Daneben gibt es auch verbindende Metaphern (linkin g metaphors), mit denen Konzepte aus verschiedenen  Gebieten der Mathematik gekoppelt werden (Lakoff un d Nún ez 1997, S.34).   23     man Additionen verstehen. Intuitionen (subjektiv si cheres Wissen) fungieren somit als Quellkonzepte  grundlegender Metaphern.   Eine Analogie ist nicht das gleiche wie eine Metaph er. Während der Begriff Metapher aus der Rhe torik stammt und primär ein linguistisches Phänomen  beschreibt, ist die Analogie ein Begriff aus der  Logik. Analogien beziehen sich auf den Vergleich de r Struktur von Systemen. Aristoteles (384–322 v.  Chr.) beschreibt „geometrische Analogien“ als Gleic hheit zweier Verhältnisse in der Form A/B=C/D  (A verhält sich zu B wie C zu D). Dabei kann der Br uchstrich als mathematische Operation (z.B. Divi sion) aber auch nicht-mathematisch verstanden werde n (Coenen 2002). Beispiel: „Ein Baum verhält  sich zu einem Ast wie ein Körper zu einem Arm“. In analogem Denken (oder analogem Schlussfol gern) kann Wissen über eine vertraute Quelldomäne a uf eine neue noch unbekannte Zieldomäne über tragen werden. So verwendete Galileo sein Wissen üb er die bereits bekannte Kreisbahn des Mondes  um die Erde als Basis für seine Theorie, dass sich auch die Erde bewegt (English 2004).  Ein bekanntes Analogon für Elektrizität ist die Vor stellung von Wasser, das durch Rohre fließt.  Beide Systeme haben strukturelle Ähnlichkeit. Man k ann Entitäten und Beziehungen des Quellsystems  (Modell) auf das Zielsystem abbilden.   Fließendes Wasser entspricht sich bewegenden Elektr onen. Der Wasserdruck – z.B. in Folge eines  Höhenunterschiedes zwischen Anfang und Ende des Roh res – entspricht der elektrischen Spannung,  der Wasserfluss – d.h. die Wassermenge, die pro Zei teinheit einen Rohrabschnitt passiert – entspricht  der Stromstärke.   Zu bedenken ist, dass nur Systeme gleicher Komplexi tät wirklich analog sein können. Bei intuiti ven Modellen in der Informatik spielt aber häufig g erade die Reduktion von Komplexität eine Rolle.  Zum Beispiel haben intuitive Modelle, die die Idee eines Algorithmus zum Ausdruck bringen, oft eine  andere (einfachere) Struktur als das zugehörige Pro gramm. Eine Programmentwicklung auf der Basis  einer intuitiven algorithmischen Idee ist somit str enggenommen kein analoges Denken. Betrachten wir  die folgende Iteration (Python):  s = ["Monika", "Tim", "Sandra"]  for i in [0, 1, 2]:   print s[i]  Die Ausführung kann man sich anschaulich so vorstel len: Ein Behälter mit drei Fächern enthält mit  Namen beschriftete Zettel. Eine Stecknadel springt von Fach zu Fach. Der Text auf dem Zettel in dem  mit der Nadel markierten Fach wird auf ein Blatt Pa pier geschrieben. Dieses intuitive Modell ist keine   strukturgleiche Analogie für das Programm. Es ist e infacher und enthält zum Beispiel keine Entität,  die der Indexliste [0, 1, 2] entspricht. Gleichwohl kann die wandernde Stecknade l als Metapher  für einen Namen des aktuellen auszudruckenden Items  s[i]  betrachtet werden.  2.3.3 Metaphern als Bilder für intuitive Modelle  Intuitive Modelle können mehr oder weniger abstrakt  sein. DiSessas p-Prims sind besonders abs trakte Intuitionen und können deshalb in vielen unt erschiedlichen Situationen angewendet werden.  DiSessa weist darauf hin, dass diese Basisintuition en nur sehr schwer in Worte gekleidet werden kön nen. Im Zusammenhang mit der Erklärung von zusammen gesetzten Bewegungen identifiziert diSessa  drei relevante p-Prims: Verstärkung (reinforcement) , Kompromiss (compromise) und gegenseitige  Auslöschung (canceling) (diSessa 2001, S. 190ff). D ie Intuition „canceling“ spielt zum Beispiel eine  Rolle, wenn man die Bewegung einer Person, die in e inem langsam fahrenden Zug gegen die Fahrt richtung läuft, beschreibt.   Die gleiche Intuition wird aber auch verwendet, wen n man Additionen mit negativen Zahlen ver stehen will. Chiu (1996, 2001) hat in mehreren Unte rsuchungen festgestellt, dass Kinder und Erwach sene bei mathematischen Problemlösungen in ein und demselben Kontext mehrere unterschiedliche  Metaphern quasi parallel verwenden. Dabei verfügen Erwachsene über ein reichhaltigeres Repertoire  an Metaphern als Kinder, äußern diese aber nicht sp ontan während des Problemlösens sondern erst bei  Interviews, wenn sie veranlasst werden, einen mathe matischen Zusammenhang zu erklären. 24     Was veranlasst Menschen, zwischen unterschiedlichen  Domänen hin und her zu springen? Warum  äußern Erwachsene bei einer Problemlösung spontan f ast keine intuitiven Modelle? Eine Erklärung ist,  dass sie eigentlich ein  einheitliches abstraktes Konzept im Sinn haben, da s intern durch unterschiedli che konkretere Modelle repräsentiert wird (vgl. Abb . 2).   Problemlösen mit Hilfe von Metaphern lässt sich ans cheinend eher als zweistufiger kognitiver Pro zess verstehen. Primär hat man eine abstrakte Idee parat, die gleich durch ein ganzes Bündel von intui  tiven Modellen aus verschiedenen Domänen repräsenti ert wird. Erst im Nachhinein (z.B. bei kniffli gen Detailfragen und wenn man jemandem etwas erklär en muss) vergewissert man sich der  Brauchbarkeit und Angemessenheit der abstrakten Ide e und repräsentiert sie durch Metaphern.     Abb. 2: Problemlösen mit dem p-Prim „Auslöschen“  Menschen greifen also innerhalb eines Kontextes auf  unterschiedliche Vorstellungswelten zurück.  Bei manchen bildhaften Darstellungen ist es sogar s chwierig eine Domäne zu benennen, aus der sie  stammen könnten. Ein Beispiel dafür ist ein Bild au s konzentrischen Bögen, das ein Schüler gezeich net hat, der die Summe einiger Zahlen der Folge 5, 8, 11 … berechnen sollte (Presmeg 1997, S. 269).  Die Zeichnung visualisiert die Formel:  summe = n/2 *( s 1+s n)  Jeder Bogen stellt die (konstante) Summe zweier Fol genglieder s i und s n+1-i dar.   5  8  11 14 17 20 23 26 29 32 35 38 41 44   Abb. 3: Visualisierung der Idee eines Rechenalgorit hmus zur Berechnung der Summe von Gliedern einer Za hlenfolge.  Nach: Presmeg 1997  Der Schüler bezeichnete das Bild als „dome“ (Gewölb e), ein anderer Schüler, dem die Zeichnung  vorgelegt wurde, sah darin einen Regenbogen. Man kö nnte also behaupten, die beiden Schüler hätten  Architektur und optische Naturphänomene als Quelle (source) für eine Metaphorisierung verwendet.  Allerdings: Ihre Aussagekraft gewinnen die Bögen of fenbar nicht durch den Sinnkontext innerhalb der  Quelldomäne (sonst wäre sie nicht so einfach austau schbar). Vielmehr ist zu vermuten, dass die Be nennung der Abbildung (z.B. als Gewölbe) zwar ein e ffizientes Speichern ermöglicht (im Sinne der  doppelten Kodierung), die erklärende Kraft aber gan z abstrakt aus der Visualisierung von symmetrisch  angeordneten Zahlenpaaren durch Bögen gewonnen wird . Das heißt die Domäne ist für das Verstehen  unwichtig.  Von Bedeutung werden Domänen, wenn es sich um konze ptionelle Metaphern im Sinne von La koff und Johnson (1980) handelt. In ihrer Theorie d er konzeptionellen Metapher sehen sie Metaphori sierung als Mechanismus zum Aufbau konzeptuellen Wi ssens. 25     Norma Presmeg verwendet den Begriff des Vehikels (v ehicle) für lehrreiche Metaphern (1997).  Ein abstraktes Konzept (der Tenor) wird mit Hilfe e iner Metapher (Vehikel) erklärt. Die Metapher ist  in diesem Fall eine Lernhilfe und eröffnet einen Zu gang zu Konzepten, der ohne sie verschlossen blie be. Merkmal dieses Metapherntyps ist, dass die Konz epte der Quelldomäne intuitiv verständlich sind,  nicht aber die Konzepte der Zieldomäne.   In der didaktischen Literatur werden für den Unterr icht in verschiedenen Fächern Vorstellungswel ten abgezirkelt, in denen lehrreiche Aktivitäten st attfinden. Dazu kann man auch die Domänen der von  Lakoff (1997) zusammengestellten Metaphern aus dem Bereich der Mathematik zählen. Nehmen wir  als Beispiel „arithmetic is motion along a line“. F ür den Mathematikunterricht gibt es ausgearbeitete  Unterrichtsreihen auf der Basis der Domäne „Bewegun g entlang einer Linie“. Die Kinder verwenden  einen Ausschnitt der Zahlengeraden mit dem Nullpunk t in der Mitte und führen damit verschiedene  Aktivitäten aus, die Rechenoperationen mit ganzen Z ahlen entsprechen (z.B. eine gewisse Schrittzahl  nach links gehen bedeutet subtrahieren.) Nach der T heorie der konzeptionellen Metaphern bleiben die  Kinder zunächst ganz in der Welt der „Bewegung entl ang einer Linie“ und erwerben Konzepte, die sie  später verwenden um arithmetische Operationen mit g anzen Zahlen zu verstehen.   Vorstellungswelten können detailliert gestaltet und  z.B. als multimediale Software oder mechani sches Spielzeug implementiert werden. Man spricht d ann von Mikrowelten (microworlds). Mikrowel ten sind explorative Lernumgebungen (Schulmeister 2 002). Es sind künstliche Welten mit sehr einfa chen Regeln, in denen die Benutzer sich frei bewege n und eigenaktiv vom Designer (Pädagogen)  „verstecktes“ Wissen entdecken können. Das wohl bek annteste und historisch erste Beispiel einer  computerbasierten Mikrowelt ist die Turtle-Grafik d er Programmiersprache Logo (Papert 1980). Die  Bedeutung von Mikrowelten im Hinblick auf die Reprä sentation intuitiver Modelle wird in Anhang  1.5 diskutiert.   2.4 Beispiele als Repräsentationen intuitiver Model le  Metaphorisierung ist ein Prinzip, das bei der Reprä sentation abstrakter Konzepte Anwendung fin det. Die Hauptleistung liegt hier in der Auswahl ei nes geeigneten Sachbereichs (Domäne) und eines  Modells innerhalb dieser Domäne.   Ein zweites Prinzip der Repräsentation ist die Beis pielbildung. Eine physisch existente Repräsenta tion eines intuitiven Modells – auch eine Metapher – ist immer beispielhaft. Um ein abstraktes Kon zept bildhaft darzustellen, muss man konkret werden  und eine von unendlich vielen denkbaren Dar stellungen auswählen. Aber es gibt auch Beispiele o hne Metaphorisierung, deren Repräsentation aus  der gleichen Domäne stammt wie das Konzept, das abg ebildet wird. In der Rhetorik nennt man sie  Metonyme. So ist [1, 2, 3] ein Metonym für eine Python-Liste.   2.4.1 Prinzipien der Beispielbildung   Einfachheit.  Nicht jedes Beispiel repräsentiert ein intuitives Modell. Wenn es zu komplex ist, kann  man es sich nicht mehr als eine kohärente Gestalt v orstellen (z.B. komplexe Multiliste als Beispiel  einer Liste). Ein Beispiel kann aber auch so stark reduziert sein, dass es nur einen Sonderfall repräs en tiert (leere Liste, Liste mit drei gleichen Element en etc.). Dennoch kann ein solches für sich alleine   nicht repräsentatives Beispiel eine wichtige Rolle in einer Kollektion von Beispielen spielen.  Reichhaltigkeit.  DiSessa sieht Reichhaltigkeit (richness) als Merkm al phänomenologischer Primiti ve. Unter Reichhaltigkeit verstehen wir hier die Ei genschaft einer Intuition, mehrere unterschiedliche   Facetten eines abstrakten Konzepts wiederzugeben. O ffenbar ist Reichhaltigkeit mit Komplexität ver bunden. Die beiden Begriffe meinen aber nicht genau  das gleiche. Hinter dem Terminus „reichhaltig“  steckt auch der Gedanke, dass ein reichhaltiges Mod ell stärker zu kognitiven Aktivititäten inspiriert.   Es bietet mehr Anknüpfungspunkte für die interne Ve rnetzung mit anderen Konzepten. Ein triviales  Beispiel repräsentiert ein allgemeines Prinzip häuf ig schlechter als ein Beispiel, das eine gewisse  Komplexität besitzt. So wird von Schülern eine List e mit drei Elementen eher als typisches Beispiel  einer Liste gesehen als eine Liste mit nur einem od er gar keinem Element. Ein sehr einfacher regulärer   Ausdruck wie "a"  wird seltener als Merkbeispiel für reguläre Ausdrü cke gewählt als  ".*[bB]all" . Letzterer verrät mehr über die Möglichkeiten der Konstruktion regulärer Ausdrücke 26     (Platzhalter, Wiederholung) und ist insofern reichh altiger. Ein weiteres Beispiel für Modelle unter schiedlicher Reichhaltigkeit sind folgende zwei Met aphern für die Wirkungsweise regulärer Ausdrü cke:   • Ein Sieb, das passende Zeichenketten von unpassende n trennt, und   • ein Kran, der passende Zeichenketten (dargestellt d urch Karten mit unregelmäßig geformter Ober kante) nach dem Schloss-Schlüssel-Prinzip an ihrer „äußeren Form“ erkennt.  Das Sieb visualisiert allein das Prinzip der Trennu ng, nämlich die Tatsache, dass mit regulären  Ausdrücken bestimmte Zeichenketten aus der Menge al ler möglichen Zeichenketten „herausgefischt“  werden können. Das zweite Modell ist reichhaltiger.  Denn zusätzlich zum Trennungsprinzip als sol chem wird auch der Mechanismus der Trennung – das S chloss-Schlüssel-Prinzip – angedeutet.  Anwendungsmöglichkeit . Ein Beispiel, das man sich als intuitives Modell für ein abstraktes Kon zept merkt, kann mehr oder weniger eine typische An wendungsmöglichkeit sein. Fischbein spricht  dann von einer pragmatischen Intuition. Versteht ma n Anwendungsmöglichkeiten als Bestandteil ei nes Konzeptes, so hat ein anwendungsbezogenes Model l einen größeren semantischen Wert als ein  nicht anwendungsbezogenes. So kann man sich eine Py thon-Liste als Warteliste beim Arzt mit den  Namen von Patienten vorstellen ["Maier", "Schmidt", "Schulz"] . Eine typische Verwen dung von Listen ist, gleichartige Objekte in einem Container zusammen zu fassen. Das Kriterium der  typischen Anwendung kann in Konflikt mit dem Kriter ium der Reichhaltigkeit treten. So geht aus  obigem Beispiel nicht hervor, dass bei Python Liste n auch Objekte unterschiedlicher Klassen enthalten  dürfen.  Repräsentativität.  Beispiele können mehr oder weniger repräsentativ f ür eine abstrakte Vorstellung  sein. Kahneman &Tversky (1982) stellten fest, dass Schüler bei der Einschätzung von Wahrschein lichkeiten sich davon irritieren lassen wie sehr ei ne gegebene Häufigkeitsverteilung ihrem Bild einer  typischen zufälligen Zahlenfolge entspricht. Regelm äßige Zahlenfolgen wie (4, 4, 4, 4, 4)   hält man für „weniger zufällig“ als Folgen aus ungl eichen Zahlen. Vorstellungen über die Repräsenta tivität der Repräsentation eines intuitiven Modells  können eine kognitive Barriere darstellen und Prob  lemlösungen behindern.   2.4.2 Prototypische Beispiele  Manchmal genügt ein einziges Beispiel zur effizient en Repräsentation eines Konzeptes. Ein solches  prototypisches Beispiel kann kürzer formuliert und offenbar besser behalten werden als eine abstrakte,   allgemeingültige Erklärung (Beispiel in Anhang 1.6) . In Kalkulationstabellen haben Berechnungsfor meln den Charakter prototypischer Beispiele. In der  Formel = A2 + B2  sind die Bezeichner A2  und  B2  Beispiele für Referenzen auf andere Zellen der Tab elle, deren Bedeutung sich dem Leser erst  durch Betrachtung der Gesamttabelle erschließt. Bei m Kopieren der Formel greift das System quasi  auf die abstrakte Bedeutung zurück und berechnet di e Referenzen neu.  2.4.3 Repräsentation durch eine Beispielkollektion  In Kurzreferenzen, die auf wenig Platz (z.B. eine K arte im Format eines großen Lesezeichens)  möglichst viel Information zu einer Programmierspra che bieten müssen, werden abstrakte Konzepte  häufig allein durch konkrete Beispiele wiedergegebe n. Effiziente Beispielkollektionen enthalten meist  Prototypen mit besonders hoher Repräsentativität un d Sonderfälle.  Wenn in einem Programmierprojekt eine Funktion oder  Methode definiert werden soll, kann ihre  Funktionalität durch beispielhafte Testfälle defini ert werden. Jeder Testfall besteht aus einem Aufruf   der Funktion mit bestimmten Argumenten und dem erwa rteten Ergebnis. Die Kollektion der Testfälle  repräsentiert ein Modell der Funktionalität des zu entwickelnden Programmstücks. 3                                                         3 Zietsman & Clement (1997) zeigen, dass leicht nach vollziehbare Extremfall-Beispiele zum Aufbau abstra kter  Modelle führen können. 27     2.4.4 Beispiel-basiertes Problemlösen  Beispiele sind nicht in jedem Fall Repräsentationen  eines intuitiven Modells. Sie können auch di rekt – ohne den „Umweg“ über ein abstraktes intuiti ves Modell – als Muster für eine Problemlösung  verwendet werden. Beim Beispiel-basierten Problemlö sen (vgl. Chiu, 2001) verwendet man ein Fall beispiel, das mit der aktuellen Problemsituation st rukturell identisch ist. Der Problemlöser ersetzt E nti täten des bekannten Beispiels durch passende Entitä ten des Fallbeispiels und wendet das bekannte  Lösungsmuster an. Betrachten wir eine typische Text aufgabe mit Lösung aus einem Mathematikbuch  (nach Chiu 2001):   Ein Zug fährt 300 Kilometer nach Köln. Er fährt mit  150 Stundenkilometern. Wie lange braucht er  bis er Köln  erreicht .  Lösung: 300 km / 150 km/h = 2  Stunden   Durch Beispiel-basiertes Problemlösen kann man leic ht Aufgaben wie die folgende lösen:  Anna fährt mit 60 Stundenkilometern. Wie lange brau cht sie um das Haus ihrer Tante zu erreichen,  das 180 km  entfernt ist?    Hier braucht man nur in der Musterlösung andere Zah len für Geschwindigkeit und Entfernung ein setzen und kann damit das neue Problem lösen. Dabei  ist nicht einmal ein wirkliches Verständnis der  Begriffe Entfernung und Geschwindigkeit erforderlic h. Die passenden Zahlen können durch eine ober flächliche Analyse des Aufgabentextes ermittelt wer den: Hinter der ersten Zahl muss das Wort „Kilo meter“ oder „km“ stehen, hinter der zweiten die Zei chenkette „km/h“. Problemlösung durch oberfläch liches Nachmachen – bei dem man sich nur an äußeren  Merkmalen der Repräsentation orientiert ohne  das dahinter liegende Konzept zu verstehen – kann s chnell zu Fehlern führen, wie Anderson am Bei spiel mathematischer Beweise zeigt (Anderson 1996, S. 242 f.).   2.5 Strukturorientierte und ablauforientierte Reprä sentationen  In einer strukturorientierten Repräsentation eines (intuitiven) Modells werden Entitäten und Bezie hungen zwischen ihnen darstellt. Beispiele sind UML -Objektund Klassendiagramme, Flussdiagram me oder Geschäftsprozessdiagramme. In dynamischen V isualisierungen werden Beziehungen zwi schen Entitäten in Form kleiner Dramen durch typisc he Aktivitäten (Interaktionen) veranschaulicht.  Eine strukturorientierte Repräsentation einer rekur siven Funktion ist z.B. eine Animation auf der Basi s  von Execution Frames, die durch Kästen visualisiert  werden. Mit jedem (rekursiven) Aufruf der Funk tion erscheint ein neuer Kasten. Er ist eine aktive  Entität, die mit anderen Entitäten interagiert. So bald  er seine Aufgabe erledigt hat, verschwindet er wied er.  Das Beispiel deutet an, dass strukturorientierte Re präsentationen von Programmläufen schnell  komplex werden können und dann schlecht memoriert w erden können. Was man sich merken kann ist  die Grundstruktur oder ein Grundprinzip, aus dem ma n bei Bedarf in Gedanken oder mit Bleistift und  Papier eine detailreichere Version rekonstruieren k ann.   In der Standardliteratur zu Algorithmik (z.B. Horow itz & Sahni 1981, Wirth 1986) werden zur  Veranschaulichung der Arbeitsweise (und Komplexität ) von Algorithmen häufig Abbildungen ver wendet, die keine Struktur aus Entitäten und Bezieh ungen wiedergeben, sondern in irgendeiner Form  ein Protokoll der Ausführung des Algorithmus darste llen. Solche Repräsentationen nennen wir ablauf orientiert. Abb. 4 zeigt einen Entscheidungsbaum fü r die binäre Suche nach einem Element mit  Schlüssel k in einem sortierten Array.  28     12 3 54 6 7  Abb. 4: Entscheidungsbaum für die binäre Suche  Jeder Knoten repräsentiert eine Entscheidung für di e Weitersuche. Die Suche beginnt in der Mitte  des Arrays. Wenn k kleiner ist als der Schlüssel de s mittleren Elementes (hier: 4), sucht man links  weiter. Wenn k größer ist, sucht man rechts weiter,  sonst hat man das gesuchte Element bereits gefun den. Ein Pfad von der Wurzel zu einem Blatt repräse ntiert die Entscheidungen bei einer einzelnen  Suche. Der gesamte Baum repräsentiert alle denkbare n (binären) Suchprozesse. Wenn eine ablaufori entierte Darstellung eine gut einprägsame Gestalt h at (wie der Entscheidungsbaum), wird man dazu  tendieren, sie zur Repräsentation der algorithmisch en Idee zu verwenden. In einer Problemlösungssi tuation muss man jedoch aus dem ablauforientierten Modell ein strukturorientiertes Modell konstruie ren und letztlich zu einem Programmtext verfeinern.  Typische Beispiele für ablauforientierte Reprä sentationen sind auch Figuren, die durch rekursive Logo-Programme entstehen (siehe Anhang 2.7).  2.6 Modellrepräsentationen im Unterricht  Modellrepräsentationen können auf vielfache Weise i m Unterricht verwendet werden. Begleitend  zu den Workshops mit der PVS wurden 20 Lehrerinnen und Lehrer befragt, welche Formen der Visua lisierung sie im Unterricht verwenden (Fragebogen u nd Details in Anhang 1.9). Das Befragungsergeb nis (Abb. 5) lässt vermuten, dass Visualisierungen wie in der Python Visual Sandbox im Informatikun terricht an deutschen Schulen eine eher geringe Rol le spielen. Lediglich UML-Klassendiagramme,  Zeiger, Wertetabellen und Kästchen, in die der mome ntane Wert einer Variablen eingetragen wird,  werden im Mittel „gelegentlich“ (entspricht dem num erischen Wert 2) oder häufiger verwendet.    Abb. 5: Ergebnis einer Umfrage zur Häufigkeit der V erwendung von Visualisierungen im Informatikunterric ht (n = 20).  Dargestellt werden die Mittelwerte der numerisch codi erten Antworten (0: nie, 1: selten, 2: gelegentlich,  3: häufig, 4: immer,  wenn es passt). Weitere Details im Anhang 1.9. 29       3 Verwendung intuitiver Modelle  Welche Rolle spielen intuitive Modelle bei Software entwicklungen im Klassenraum? Zu welchen  Zwecken werden sie verwendet? In diesem Kapitel leg en wir das Augenmerk auf Verstehen, Erklären,  Problemlösen und Kontrollieren.  Verstehen  findet z.B. statt, wenn ein Schüler in einer Sprac hreferenz die Beschreibung einer Funk tion nachliest und aus abstrakten Darstellungen (se mantische) Intuitionen entwickelt.   Erklären  ist besonders bei gemeinsamer Softwareentwicklung im Team von Bedeutung. Erklärun gen finden sich in Programmkommentaren, Dokumentati onen oder Diskussionen des Programmier teams. Dabei werden intern verwendete intuitive Mod elle externalisiert, geeignete Repräsentationen  gefunden und die Darstellung auf das Wesentliche fo kussiert.   Problemlösen  ist die zentrale Aktivität bei einer Programmentwi cklung. Die Suche nach einer Lö sung wird häufig durch semantische Intuitionen beei nflusst. Wer z.B. eine Routine zum Sortieren einer  Liste entwickelt, wird sich zunächst mit der Frage beschäftigen, was eine Liste eigentlich ist und ver  schiedene Modellvorstellungen ins Bewusstsein rufen , die die Bedeutung des Konzeptes „Liste“ reprä sentieren. Die Lösungsidee selbst wird – in ihrer G esamtheit – durch ein antizipatorisches intuitives  Modell dargestellt.   Kontrollieren  mit Hilfe intuitiver Modelle spielt beim Testen un d Debuggen eines Programms eine  Rolle. Bei der Suche nach semantischen Fehlern oder  der Formulierung von Zusicherungen (z.B. in  Form von assert–Statements) werden einfache Modelle  mit besonders hoher subjektiver Gewissheit zu  Plausibilitätsprüfung verwendet.   3.1 Verstehen  Wie werden intuitive Modelle verwendet, um zu einem  Verständnis abstrakter Konzepte der In formatik zu gelangen? Fischbein nennt solche intuit iven Vorstellungen, die sich auf die Bedeutung  eines Konzeptes beziehen, semantische Intuitionen ( Fischbein 1987, S. 59 ff). Zum Beispiel gibt es für   das Konzept einer geraden Linie zwischen zwei Punkt en verschiedene semantische Intuitionen:  • Geometrisches Modell: Linie, die man mit einem Line al zwischen zwei Punkten zieht.  • Pragmatisches Modell: kürzester Weg zwischen zwei O rten.  • Physikalisches Modell: Lichtstrahl von einer Lichtq uelle zu einem beleuchteten Objekt.  Nun werden in der Informatik Konzepte meist durch m ehr oder weniger formale Texte definiert.  Typische Textdokumente für Informatiker sind Progra mmquelltexte, Kommentare in Programmtexten,  Sprachreferenzen oder allgemeine Lehrtexte, in dene n grundlegenden Ideen der Informatik erklärt  werden. Im Lernalltag eines Informatik-Schülers gib t es verschiedene Anlässe für Verständnisgewin nung:  • Erklärungen der Lehrperson etwa zur Arbeitsweise ei ner Funktion werden von Schülern individu ell nachvollzogen. Im Unterricht kann man beobachte n, dass Schüler nach einem Informationsin put der Lehrperson beispielhafte Programmzeilen, di e z.B. an der Tafel stehen, ausprobieren und  abwandeln um das soeben Gehörte zu verarbeiten.  • In einer Diskussion des Programmierteams (z.B. zum Entwurf eines Programms) verwendet ein  Kommunikationspartner einen Begriff, der den andere n nicht ausreichend klar sind. Die Diskussi on weicht nun von ihrer ursprünglichen Zielrichtung  ab und wendet sich nun für eine gewisse Zeit  der Beseitigung der Verständnisschwierigkeit zu.  • Bei der Suche nach einem semantischen Fehler in ein em Programmtext, kommt bei einer Schüle rin oder einem Schüler der Verdacht auf, ein im Pro gramm verwendetes Konzept (z.B. die Wir kungsweise einer Funktion) nicht richtig verstanden  zu haben. Er oder sie unterbricht die Fehler suche, widmet sich dem kritischen Konzept und versu cht es, besser zu verstehen und Zweifel  auszuräumen. 30     • Bei einer Programmentwicklung hat jemand die Idee, ein bestimmtes Programmierkonzept zu  verwenden – z.B. eine bestimmte Standardfunktion de r jeweiligen Programmiersprache – stellt  aber fest, dass er oder sie zu wenig über relevante  Details des Konzeptes weiß. Er hat Zweifel,  dass sein Verständnis in Tiefe und Weite ausreicht und versucht – etwa durch Studium der Sprach referenz oder kleine Testprogramme – sein Verständn is zu verbessern.  • Ein existierendes Programm soll weiterentwickelt we rden. Um die notwendigen lokalen Änderun gen vornehmen zu können, muss man zuerst das gesamt e Programm verstanden haben.  3.1.1 Verstehen aus Sicht der Hermeneutik   Weil Texte häufig die Grundlage für Verständnisgewi nnung sind, hat die Bedeutungsund Sinner fassung von Texten für Verstehensprozesse einen bes onderen Stellenwert. Fragen des Textverstehens  werden in der allgemeinen oder philosophischen Herm eneutik diskutiert. „Verstehen“ wird in der  Hermeneutik seit Heidegger nicht als bloße Methode sondern als „Grundzug des Mensch-Seins“ be schrieben (Capurro 1989 S. 16). Der Mensch ist hins ichtlich seiner Verhaltensmöglichkeiten offen, die  Grundlage jedes Handels ist das Verstehen der Welt,  in der er sich bewegt.   Der hermeneutische Zirkel – ein Konzept, das aus de r antiken Rhetorik stammt – beschreibt die  Auslegung eines Textes als im Prinzip unendlichen P rozess der Auseinandersetzung mit einem Text  (Capurro 1989). Das Ganze eines Textes wird aus den  Einzelheiten und die Bedeutung der Einzelhei ten aus dem Ganzen erfasst. Verständnis bleibt imme r vorläufig und wird bei jedem „Durchlauf“ des  Zirkels in Frage gestellt.   Der Begriff „Text“ ist hier im weitesten Sinne zu v erstehen. Auch formale und grafische Darstel lungen, in denen mathematische oder grafische Symbo le verwendet werden, zählen dazu. Das ent scheidende Merkmal des Textes ist, dass er „überlie fert“ wird. Er ist intersubjektiv verständlich und  (bei fachlichen Texten) Teil der Kultur der Fachgem einschaft, in der sich das lesende Subjekt befindet .   In gewissem Sinne ist das Verständniskonzept der He rmeneutik dem Intuitionsbegriff von Fisch bein entgegengesetzt. Die Hermeneutik betont die Un sicherheit des Verstehens. Die Auseinanderset zung mit dem Text ist niemals abgeschlossen. Dagege n ist eine intuitive Vorstellung von Selbstevi denz und subjektiver Gewissheit geprägt. Ein zweite r Unterschied betrifft die Persistenz. Intuitionen  halten ein Leben lang. Nach Auffassung von Fischbei n und diSessa kann man sich nicht von ihnen  „befreien“. Sie sind Teil der Persönlichkeit. Dageg en wird Verstehen im Verlauf des hermeneutischen  Zyklus‘ immer aufs Neue geprüft und gegebenenfalls revidiert. Das betrifft das Menschenbild der  Hermeneutik: Es ist Teil der Offenheit und Freiheit  des Menschen, sein Verständnis von den Dingen  weiterentwickeln zu können. Man kann diesen Widersp ruch zwischen Dauerhaftigkeit und Wandelb arbeit lösen, indem man folgendes annimmt: Einmal e rworbene Intuitionen bleiben als solche erhalten  – aber der Umgang mit ihnen, die Art und Weise, wie  man sie bei der Interpretation fachlicher Texte  anwendet oder dem Verstehen abstrakter Konzepte ver wendet, kann sich ändern.   3.1.2 Verstehen durch intuitive Modelle  Für den Verstehensprozess sind intuitive Modelle in  mehrerer Hinsicht von Bedeutung. Manchmal  werden neue intuitive Modelle zur Repräsentation de s im Text dargestellten Konzeptes geschaffen.  „Neu“ kann zweierlei bedeuten: Der Leser erfindet s elbst ein Modell, oder aber er wählt ein gegebenes  Modell als Repräsentanten für das abstrakte Konzept . Das Modell wird aber erst zur Intuition, wenn es  vom Subjekt als „gewiss richtig“ akzeptiert wird. D ies ist kann ein relativ langwieriger Prozess sein,   der mit Erfahrungen zu tun hat. Solche Erfahrungen können das Ergebnis von Experimenten sein (z.B.  Ausprobieren von Programm-Statements am Computer). Eine schnelle Form des Verstehens findet  statt, wenn im Bewusstsein des Lesers bereits vorha ndene Intuitionen mit dem neuen Konzept in Be ziehung gesetzt werden. So kann die „Idee“ reguläre r Ausdrücke durch das „Schloss-SchlüsselPrinzip“ modelliert werden, ein Konzept, das man au s anderen Zusammenhängen kennt.  Beim erkenntnisgewinnenden Fragen werden (neue oder  alte) intuitive Modelle dahingehend ge prüft, ob sie geeignete Interpretationen des im Tex t dokumentierten Konzeptes sind. Dabei werden  unpassende Intuitionen ausgegrenzt. Das kann dazu f ühren, dass man zu abstrakten Konzepten auch  unpassende Modelle expliziert und sich dauerhaft me rkt. So versteht man das Konzept der Länge einer 31     Liste (Anzahl der Elemente) besser, wenn man es von  der physikalischen Länge eines Gegenstandes  unterscheidet.   Meist wird ein Sachverhalt nicht durch ein einzelne s intuitives Modell sondern durch ein Bündel  verschiedener Intuitionen verstanden. Manchmal gibt  es ein „treffendes“ globales Modell, das eher  vage ist aber die „Grundidee“ in einer einzigen Ges talt wiedergibt. Dazu existieren weitere „unterstüt  zende“ Modelle, die einzelne Spezifika stärker hera usstellen aber nicht mehr so repräsentativ für das  gesamte Konzept sind. Häufig macht es Sinn, sich au ch Spezialfälle und Ausnahmen zu merken. So  gehört zum richtigen Verständnis einer Liste dazu, dass es auch leere Listen gibt.  Ein spezieller Fall ist das Verstehen konkreter Pro grammtexte. Untersuchungen auf diesem Gebiet  gehen von der Annahme aus, dass der Leser mentale M odelle zum Programmtext konstruiert  (Aschwander & Crosby 2006, von Mayrhauser & Vans 19 94, Storey et al. 1997). Dabei können unter schiedliche Vorgehensweisen beobachtet werden. Bei einer bottom-up-Strategie geht der Leser vom  Programmtext aus und fasst mehrere Programmzeilen z u abstrakteren Konzepten zusammen (d.h. in  unserer Redeweise bildet er sie durch passende intu itive Modelle ab). Oder aber er hat bereits be stimmte intuitive Vorstellungen, wie das Programm f unktionieren könnte und versucht sie beim Lesen  des Programmtextes zu verifizieren (top-down).  3.2 Erklären  Erklären hat viel mit Verstehen zu tun. Man kann an deren Leuten nur etwas erklären, das man  selbst verstanden hat. Erklären heißt, das eigene V erständnis, die eigene Interpretation eines Sachver  haltes anderen Menschen mitzuteilen. So verraten Er klärungen auch etwas über das Verständnis des  Erklärenden. Im Unterschied zum Verstehen spielt be im Erklären das Problem der Vermittlung eine  Rolle. Damit ist verbunden, dass man sich auf einen  Adressaten und dessen Wissenshorizont einstellt.  Zwar findet auch jedes Verstehen im „Miteinander in  einer gemeinsamen Welt“ statt (Capurro 1989,  S. 100 ff), aber die Zielrichtung des Verstehens is t gewissermaßen „egoistisch“, nämlich die Erweite rung des eigenen Horizontes.  Die Modelle, die dem Verständnis dienen, zielen auf  eine „globale Sicht“. Das Konzept muss ins gesamt richtig verstanden werden. Beim Erklären ist  häufig das gezielte Ausgrenzen bestimmter aus gewählter Aspekte wichtig (Fokussierung). Entsprech end können Erklärungsmodelle sehr spezifisch  sein. Das Bemühen um Verstehen geht in alle Richtun gen. Neue Konzepte werden möglichst vielfältig  mit bekannten Konzepten vernetzt und haben zudem Au swirkungen auf die vorhandenen mentalen  Vorstellungen. Die Hermeneutik spricht von einer Ho rizonterweiterung des Subjekts. Erklären dage gen ist gerichtet. Es geht darum, gezielt bestimmte  Aspekte durch geeignete Intuitionen darzustellen.  Anlass einer Erklärung kann eine Frage sein, die vo n außen kommt und die es zu beantworten gilt.  Dagegen ist Verstehen das (immer vorläufige) Ergebn is einer selbstgesteuerten Auseinandersetzung.   Erklärungen können Teil einer Verständnisgewinnung sein. In diesem Fall ist der Adressat der Er klärung die eigene Person. Man macht sich dann selb st einen Zusammenhang klar und versucht Ge wissheit zu erlangen.  Typische Anlässe für Erklärungen mit intuitiven Mod ellen im Klassenraum sind:  • Darstellung der Arbeitsweise eines Programmstücks i n einem Kommentar oder im Rahmen von  Diskussionen des Programmierteams.  • Bei der Suche nach einem semantischen Fehler muss e rklärt werden, warum das Programm eine  bestimmte (nicht korrekte) Ausgabe liefert.  • Erklärungen in einer Bedienungsanleitung zu einem s elbst geschriebenen Programm.  3.2.1 Fokussierung  Ein typisches Merkmal von Erklärungen ist, dass sie  von einem komplexen zu erklärenden Gegenstand einzelne Aspekte herausgreifen und durch unmi ttelbar einleuchtende intuitive Modelle verständ lich machen. Dabei treten andere Aspekte des Gegens tandes – die freilich für ein Gesamtverständnis  ebenso wichtig sind – in den Hintergrund. Sie werde n ignoriert oder eventuell sogar falsch dargestellt .  Wir nennen diese Facette des Erklärens Fokussierung .  32     Modelle können sich im Fokussierungsgrad unterschei den. Stark fokussierte Modelle werden im  Kontext einer Erklärung eher in Form eines (Distanz  wahrenden) Vergleiches (und nicht als Metapher)  verwendet. Zur Verdeutlichung des Geheimnisprinzips  in der OOP werden Objekte manchmal mit  einer Festung verglichen: Im Inneren befinden sich (wie ein Schatz) die Attribute. Außen liegen schützend wie eine Burgmauer die Methoden, die den Zugri ff von außen kontrollieren (siehe Balzert 1999,  S. 18). Ein solches Modell veranschaulicht den Schu tzaspektes, den eine Methode haben kann, ist aber  für die Erklärung anderer Aspekte des Objektkonzept es gänzlich ungeeignet.  Fokussieren ist eine Form der Vereinfachung. Ein in tuitives mentales Modell muss einfach sein,  um in gedanklichen Prozessen leicht verarbeitet wer den zu können. Vereinfachung geht immer auf  Kosten von Wirklichkeitsnähe. Von mehreren verfügba ren intuitiven Modellen wählen wir in der Re gel das einfachste, d.h. dasjenige, das für die geg ebene Problemstellung gerade eben noch ausreicht.  Betrachten wir als Beispiel Teilchenmodelle aus der  Chemie. Zur Erklärung der unterschiedlichen  Dichte von Gasen und Flüssigkeiten reicht ein einfa ches Kugelteilchenmodell (große Abstände zwi schen den Teilchen im gasförmigen Zustand und klein e Abstände im flüssigen Zustand). Um aber  Anziehungskräfte zwischen den kleinsten Teilchen zu  erklären, verwendet man ein komplexeres Mo dell, bei dem der Aufbau der Moleküle aus Atomen be rücksichtigt wird.  Wie in den Naturwissenschaften ist Fokussierung auc h in der Informatik ein wichtiger Aspekt von  Erklärprozessen. Abb. 6 zeigt einen Ausschnitt aus einem animierten Modell, das die Arbeitsweise der  folgenden Iteration (Python) erklärt:  for i in [1, 5, 4, 3, 2]:      print i**2  Die Liste wird durch einen Kasten mit mehreren Fäch ern repräsentiert. Aus dem Kasten werden  nacheinander Zettel entnommen, jeweils die darauf s tehende Zahl quadriert und ein Zettel mit dem  Ergebnis an eine Tafel, die die Standardausgabe dar stellt, geheftet. Die Entnahme der Zettel ist sug gestiv, da in jedem Moment deutlich wird, welches L istenelement als nächstes „dran ist“. Die Wieder holung ist beendet, wenn der Kasten leer ist, also keine weiteren Listenelemente mehr zur Verfügung  stehen. Die Vorstellung der Entnahme von Elementen entspricht aber nicht dem Listenkonzept, da die  Liste bei der Iteration nicht verändert wird. Wer d iese Animation als Erklärung wählt, verzichtet auf  Realitätsnähe zugunsten einer pointierten Darstellu ng der Idee der Iteration (Fokussierung).    Abb. 6: Intuitive Modellierung einer Iteration über  eine Liste durch Entnahme von Items.   Das Beispiel illustriert, dass Fokussierung – wie j ede Vereinfachung – eine potenzielle Quelle für  Fehlvorstellungen ist. Somit ist das Risiko von Feh lvorstellungen eine normale Begleiterscheinung  von Erklärungen. Es ist prinzipiell nicht zu vermei den – auch nicht durch geschickte Wahl von Model len. Wie diSessa (2001) und Smith, diSessa und Roch elle (1994) hervorheben, liegt das Problem nicht  in den Unzulänglichkeiten des intuitiven Modells se lbst. Ein intuitives Modell, das in einem bestimm ten Zusammenhang hervorragend für eine Erklärung ge eignet ist, kann in einem anderen Kontext irre führend sein.  Das Rezept zur Vermeidung von Fehlvorstellungen dur ch fokussierte Modelle kann nun nicht sein,  auf Vereinfachungen bei Erklärungen zu verzichten. Stattdessen müssen mehrere Erklärungsversuche  mit unterschiedlichen Intuitionen vollzogen werden.  Genau das liegt ja gerade im Wesen von fokussie33     renden Erklärungen: Der zu erklärende Gegenstand wi rd aus unterschiedlichen Perspektiven betrach tet. Jeder Blick ist begrenzt und dieser Begrenzthe it muss man sich bewusst sein. Auf diesen Punkt  kommen wir nun im folgenden Abschnitt zu sprechen.  3.2.2 Mehrperspektivität: Viele Modelle für eine Sa che  Erklärungen sind immer Bestandteil einer Kommunikat ion. Ein Erklärungsversuch muss also auf  den Verstehenshorizont des Gegenübers abgestimmt se in. Diese Überlegung macht zwei Probleme  sichtbar:  • Es kann immer nur vermutet werden, welche intuitive n Modelle der Kommunikationspartner ver steht, d.h. welche Konzepte für sie oder ihn intuit iv einleuchtend sind.   • Dokumentierte Erklärungsversuche (etwa Kommentare i n Programmlistings oder Erklärungen in  Bedienungsanleitungen) wenden sich an ein heterogen es Auditorium, also an Personen mit völlig  unterschiedlichen Vorkenntnissen.   Beide Probleme legen die gleiche Schlussfolgerung n ahe: Für Erklärungen ist es in der Regel not wendig, unterschiedliche intuitive Modelle für die gleiche Sache zu verwenden. Darüber hinaus kann  es sinnvoll sein, für die Darstellung eines Modells  unterschiedliche Repräsentationen zu verwenden.  Dabei ist es aber kaum zu entscheiden, ob zwei unte rschiedliche Darstellungen, die das gleiche Modell  meinen, im Grunde nicht doch zumindest in Nuancen u nterschiedliche intuitive Modelle repräsentie ren, ohne dass sich der Erklärende dessen bewusst i st.  Professionelle Erklärer halten für eine Wissensdomä ne eine breite Palette unterschiedlicher intuiti ver Modelle bereit, auf die sie situationsspezifisc h zurückgreifen (vgl. auch Chiu 2001, Ueno 1993).  Bei einer Erklärung im Rahmen einer bidirektionalen  Kommunikation (z.B. im Schulunterricht) wird  der Erklärende (im Idealfall) so lange immer wieder  neue Modelle anbieten, bis er merkt, dass er einen   »Augenöffner« gefunden hat und dem Gesprächspartner  die Erklärung einleuchtet. Dabei kann es  notwendig sein, kreativ zu werden und ad hoc völlig  neue intuitive Modelle zu erfinden.  3.3 Problemlösen   3.3.1 Antizipatorische Intuitionen  In vielen Problemlöseprozessen gibt es einen Moment  der „Erleuchtung“. Nach einer Phase des  Suchens und gedanklichen Durchspielens verschiedene r Möglichkeiten, erscheint vor dem geistigen  Auge plötzlich die Vision, wie das Problem im Prinz ip gelöst werden könnte. Der französische Ma thematiker Poincaré berichtete unter anderem folgen des Beispiel:  „Eines Morgens, als ich auf dem Kliff spazieren gin g, kam mir innerhalb kürzester Zeit mit einer  ungeheuren Plötzlichkeit und sofortigen Gewissheit der Gedanke, dass die arithmetischen Transforma tionen unbestimmter quadratischer Formen mit den Fo rmen der nichteuklidischen Geometrie identisch  waren.“ (Poincaré 1929, S. 388, zit. nach Anderson 1996, S. 263)  Fischbein nennt dieses Phänomen eine antizipatorisc he Intuition. Sie repräsentiert als zusammen hängende Gestalt die entscheidende Idee einer Probl emlösung. Der Begriff antizipatorisch bezieht sich  auf die Rolle des Modells in einem Problemlösungspr ozess („Vorwegnahme“ der Lösung) und nicht  auf den Inhalt. In der Informatik gibt eine Reihe i ntuitiver Modelle, die jeweils die grundsätzliche I dee  eines relativ komplexen Algorithmus verkörpern. Neh men wir die klassischen Sortierverfahren als  Beispiel:   Bubblesort basiert auf der Vorstellung, dass in ein er aufsteigend sortierten Liste der linke Nachbar  eines jeden Elementes kleiner ist, sofern ein linke r Nachbar existiert. Der Blick konzentriert sich au f  eine Stelle der Liste. Ein Element wird mit seinem linken Nachbarn verglichen. Falls dieser größer ist ,  tauschen die beiden Elemente die Plätze. Wenn das g enügend oft geschieht, ist die Liste sortiert. Auch   wenn man zur Beschreibung der Idee mehrere Sätze br aucht, so kann man sie sich dennoch als ein  abstraktes zusammenhängendes Ganzes vorstellen.   Das Beispiel zeigt, dass antizipatorische Intuition en durch semantische Intuitionen inspiriert und  unterstützt werden können (vgl. Fischbein 1987). Bu bblesort basiert auf dem Gedanken, dass in einer 34     aufsteigend sortierten Liste der linke Nachbar eine s Elementes kleiner ist. Das ist zunächst eine se mantische Intuition, die das Konzept der sortierten  Liste verständlich macht, aber noch in keinem Zu sammenhang mit einer Problemlösung steht. Die antiz ipatorische Intuition des Sortierens durch Aus wahl (straight selection) wird dagegen durch das (s emantische) Konzept des Minimums gestützt. In  einer sortierten Liste [s 0, s 1, ..., s n] ist jedes Element si das Minimum der Teil-Liste [s i,  si+1 , ..., s n].   3.3.2 Ansatz und Verfeinerung  John Anderson stellt den Problemlösungsprozess als Suche in einem Suchbaum von Handlungs möglichkeiten dar (Anderson 1996, S. 233ff). Beim P roblemlösen wird ein Ziel in Teilziele zerlegt,  für deren Erreichen der oder die Problemlösende Ope ratoren besitzt. Die Anwendung eines Operators  überführt das Problem von einem Problemzustand in e inen neuen Problemzustand, der (hoffentlich)  dem Zielzustand (Lösung) näher liegt. Der gesamte L ösungsweg (Folge von Operatoranwendungen)  kann durch einen Pfad von der Wurzel (Anfangszustan d) zu einem Blatt (Zielzustand) dargestellt wer den (Abb. 8 links).  Das Modell des „blinden“ Suchens in einem Suchbaum ist insofern unrealistisch, als es bereits bei  einfachen Problemsituationen eine unüberschaubar gr oße Anzahl von Aktionsfolgen gibt, die in Ge danken zu prüfen sind. Im Grunde geht man davon aus , dass nur solche Operatoren in Betracht gezo gen werden, die in irgendeiner Beziehung zu einer L ösungsidee stehen.   Der „erste Schritt“, die Bewegung von der Ausgangsi tuation (Wurzel des Suchbaumes) zu einem  ersten Zwischenziel, ist mehr als nur die Auswahl e ines Operators. Es ist im Grunde die Entscheidung  für einen kompletten Lösungsansatz (eine antizipato rische Intuition), der dann in späteren Überlegun gen nur verfeinert, d.h. in eine Folge konkreter Op erationen überführt werden muss.    Abb. 7: Suchbaum und geschachtelte antizipatorische  Intuitionen  Spohrer, Soloway und Pope (1989) verwenden zur Mode llierung von Problemlösungen Und-OderBäume, die sie GAP-Trees nennen (GAP = goal and pla n). Ein GAPTree repräsentiert sämtliche  Lösungsmöglichkeiten einer Aufgabe, die man sich al s oberstes Ziel vorstellt (siehe Abb. 8). Zu einem  Ziel gehören in der Regel mehrere alternative Pläne , über deren Realisierung das Ziel erreicht werden  kann. Jeder dieser Pläne führt wiederum zu mehreren  Zielen, die erreicht werden müssen, damit der  Plan umgesetzt wird. Auf jedem Pfad von der Wurzel zu einem Blatt folgen immer abwechselnd Ziel und Plan-Knoten. Bei einer konkreten Implementierun g des Projekts (Lösung) wird von mehreren  alternativen Plänen zu einem Ziel einer ausgewählt (oder-Verknüpfung). Die Teilziele, die zu einem  Plan gehören, müssen aber alle erreicht werden (und -Verknüpfung). Es ergibt sich ein Teilbaum des  GAP-Trees mit genau einem Plan pro (Sub-)Ziel. Eine n solchen Teilbaum des aus der Aufgabenstel lung abgeleiteten GAP-Trees erhält man z.B. durch A nalyse eines Programms, das die Aufgabe löst  (in der Abbildung durch dicke Linien und dunkle Kno ten dargestellt). 35        Abb. 8: Aufbau eine GAP-Trees und eines Lösungsbaum s (dunkel)  Wenn jemand sich für einen von mehreren alternative n Plänen entscheidet, geht er oder sie erstens  von seiner Realisierbarkeit aus und betrachtet ihn zweitens als benennbares geschlossenes Ganzes.  Jeder Plan ist mit einem Ziel verbunden. Durch die Existenz eines Plans wird ein Ziel zum erreichba ren Ziel. Hinter dem Plan steht ein intuitives Mode ll, eine antizipatorische Intuition, die eine Lösun gs idee repräsentiert (also die Lösung vorwegnimmt). M an braucht einen Plan, um überhaupt mit dem  Programmieren anfangen zu können. Bei strukturierte r Programmierweise wird häufig eine verbale  Bezeichnung eines Ziels oder Plans zur Benennung vo n Funktionen oder Klassen verwendet (z.B. eine  Funktion namens eingabe()  realisiert den Plan, Möglichkeiten zur interaktive n Eingabe von Daten  zu schaffen).   GAP-Trees sind ein Instrument der Analyse. Sie gebe n aber nicht unbedingt den Problemlösungs prozess wieder. Spohrer, Soloway und Pope (1989) un tersuchten die ersten lauffähigen (also syntak tisch korrekten) Versionen von Programmen, die Anfä nger zu verschiedenen Aufgaben geschrieben  haben. Sie beobachteten, dass die Teilnehmer zuerst  vereinfachte Versionen schrieben und Teilziele  wegließen. Die fehlenden Elemente wurden als „missi ng“-Fehler registriert. Dies kann man so inter pretieren, dass sie sich Gewissheit verschaffen wol lten, dass ihr (als Ganzheit gedachter) Plan realisierbar ist. Diese ersten Versuche kann man also al s Teil einer Antizipation der Lösung – verbunden  mit einer Reduktion auf gewisse essentielle Element e – sehen.  3.3.3 Paradigmatische Modelle und Software-Entwickl ung  Intuitive Modelle können eine Art „Muster“ für eine  Problemlösung darstellen. Das ist eine etwas  andere Rolle als Antizipation, bei der die Frage de r grundsätzlichen Idee und Realisierbarkeit im Vordergrund steht. Fischbein nennt sie paradigmatische  Modelle. Paradigmatische Modelle sind häufig  (konkrete) Beispiele, die eine ganze Klasse von Pro blemlösungen repräsentieren. Paradigmatische  Modelle spielen in der Software-Entwicklung eine gr oße Rolle. Ein seit der Frühzeit der Informatik  verwendetes Modell ist das „EVA-Prinzip“. Viele Pro gramme sind nach dem Muster EingabeVerarbeitung-Ausgabe gestaltet. Ein solches Program m enthält Eingabe-Funktionen zur Aufnahme  von Daten, verarbeitet diese und gibt über Ausgabef unktionen das Ergebnis zurück. Die ersten interak tiven Programme, die Schüler schreiben folgen diese m Paradigma. Dieses Muster verwendet man auch  in anderen Zusammenhängen:  • Arbeitsweise einer Funktion: Eine Funktion nimmt üb er Argumente Daten auf (Eingabe), verar beitet diese und gibt mittels einer return-Anweisun g das Berechnungsergebnis zurück (Ausgabe).   • Arbeitsweise eines cgi-Skriptes: Ein cgi-Skript ver wendet einen Querystring oder ein besonderes  Paket mit Daten als Eingabe, verarbeitet die enthal tenen Daten und liefert dem Kommunikations partner (Client) die Beschreibung einer HTML-Seite als Ausgabe.  Nicht nur für Programmier-Anfänger sondern auch und  vor allem für professionelle Programment wickler gibt es einen reichhaltigen Fundus an Liter atur in Form von Sprachreferenzen, Cookbooks,  Pattern-Sammlungen etc. mit Hilfen zur Problemlösun g. Nun wird man dort niemals ein Beispiel fin den, das haargenau auf das eigene aktuelle Programm ieraufgabe passt. All diese Bücher und Websites  enthalten letztlich paradigmatische Modelle, die ab strakter sind als eine konkrete Lösung. Sie werden  meist in Form von Programmbeispielen dargeboten. Di eser Programmtext ist dann aber nicht als pra36     xistaugliche Lösung gemeint. Vielmehr handelt es si ch um ein (mehr oder weniger gelungenes) be wusst reduziertes, verständliches und auf eine Lösu ngsidee zugespitztes Beispiel.   3.3.4 Entwurfsmuster (Design Patterns)  Paradigmatische Modelle finden sich in der Informat ik auf vielen Ebenen. Auf hohem Abstrakti onsniveau versucht man strukturierte Sammlungen von  so genannten Software Patterns oder Design  Patterns anzulegen (Gamma, Helm, Johnson, Vlissides , 1995). Patterns werden als Musterlösungen für  häufig vorkommende Problemstellungen verstanden („a  solution to a recurring problem in a context“).  Das Ziel ist, die Wiederverwendung von Softwarelösu ngen zu ermöglichen. Riehle & Züllighoven  (1996) definieren den Begriff Pattern etwas abstrak ter. Patterns sind in ihrer Sichtweise nicht allein   auf Programmtexte beschränkt, sondern können auch d er Analyse von Wirklichkeitsausschnitten die nen. Ein Beispiel für ein Pattern, das sich z.B. in  Bürosoftware findet, ist die Unterscheidung von Ma  terialien und Werkzeugen, die man auf die Materiali en anwenden kann. Typische Materialien sind  Textdokumente oder Terminkalender. Typische Werkzeu ge sind z.B. Editoren. Die Unterscheidung  von Material und Werkzeug dient nun sowohl der Anal yse eines Büros (Welche realen Werkzeuge  und Materialien werden in einem realen Büro verwend et? Welche Aufgaben werden mit den Werk zeugen durch Anwendung auf Materialien gelöst?) als  auch der Entwicklung einer Bürosoftware  (Klassen für Werkzeuge und Materialien). Freilich i st ein paradigmatisches Modell nicht dasselbe wie  ein Pattern. Die Unterschiede sind folgende:  • Ein Pattern ist elaboriert und expliziert. Es ist i n irgendeiner Form (z.B. durch einen Text, UMLDiagramm oder Programmcode) schriftlich fixiert. Da gegen ist ein paradigmatisches Modell Sa che eines Individuums. Es wird – wie alle intuitive n Modelle – individuell unterschiedlich, manch mal auch vielfältig repräsentiert und kann unter Um ständen sogar unbewusst sein. Das heißt, ein  Pattern ist mehr als ein paradigmatisches Modell.  • Ein Pattern dient letztlich der Wiederverwendung vo n Programmcode in Softwareprojekten. Die  Absicht, Ressourcen zu sparen, spielt jedoch bei pa radigmatischen Modellen eigentlich keine Rol le. Ein paradigmatisches Modell verkörpert zwar ein e Lösungsidee für eine Problemlösung. Diese  ist aber so unspezifisch, dass man eher von Anwende n und nicht von Wiederverwenden redet. Das  impliziert, dass nicht jedes paradigmatische Modell  ein Pattern verkörpert.  Patterns gewinnen ihren Wert für Problemlösungen au s ihrem intuitiven Charakter, also daraus,  dass sie ein zugrunde liegendes intuitives Modell b esitzen. Das rasch erfassbare intuitive Modell er leichtert den Zugriff. Man kann blitzschnell den Ka talog bekannter Patterns durchstöbern und ein pas sendes Muster finden – sofern es existiert. Oder an ders herum: Ein Pattern, dem das Intuitive fehlt, i st  nicht so gut geeignet, weil man während eines Probl emlösungsprozesses gar nicht darauf kommt, dass  es auf einen bestimmten Anwendungsfall passt.  Was macht ein Pattern intuitiv? Cooper (1998, S. 12 ) weist darauf hin, dass Patterns nicht einfach  so erfunden werden. Sie werden eher entdeckt als ge schrieben. („In fact, most such patterns are rather   discovered than written.“). Riehle und Züllighoven betonen, dass Patterns aus der Erfahrung erwach sen. Man kann sie also als bewährte Muster zur Stru kturierung der Wirklichkeit betrachten. Manche  Patterns (oder genauer: ihre Modelle) ähneln in die ser Hinsicht diSessas phänomenologischen Primiti ven. Sie sind fest verwurzelt in persönlicher Leben serfahrung. Das Material-Werkzeug-Pattern ist ein  Konzept, das in sehr vielen Alltagskontexten auftau cht. Kinder lernen es bereits in jungen Jahren, z.B .  wenn sie das Werkzeug „Buntstift“ auf verschiedene Materialien wie Malblöcke, Tapeten, Tischober flächen oder Haut ausprobieren.   3.3.5 Use Cases – intuitive Modelle für Funktionali tät  Eine Software-Entwicklung, die dem objektorientiert en Paradigma folgt, beginnt mit einer objekt orientierten Analyse (vgl. z.B. Balzert 1999). Währ end dieser Phase werden zunächst Geschäftspro zesse (Use Cases) festgelegt, die Systemfunktionali tät beschreiben. In einem Geschäftsprozessdia gramm werden Akteure festgelegt, denen bestimmte Ge schäftsprozesse zugeordnet werden. Bei einem  System zur Verwaltung einer Bibliothek sind typisch e Akteure: 37     Leser:  Er kann typischerweise im Bestand der Bibliothek n ach Büchern suchen, feststellen ob sie  ausgeliehen sind etc.  Sachbearbeiter der Ausleihstelle:  Er kann Bücher als ausgeliehen oder zurückgegeben vermerken,  Beschädigungen dokumentieren etc.   Jeder Akteur ist ein intuitives Modell eines Bündel s von zusammengehörigen Aufgaben. Allein die  Gestalt eines Akteurs liefert eine ziemlich gute Vo rstellung von den damit verbundenen Aufgaben.  Diese Akteur-Intuitionen reichen bereits als Grundl age für vollständige Erfassung aller vom System zu  leistenden Aufgaben. Das heißt: Wenn man ein sinnvo lles System zueinander passender Akteure ge funden hat, besitzt man bereits einen Überblick übe r die gesamte Funktionalität des geplanten Pro gramms.  3.3.6 Intuitive Modelle im agilen Programmieren – T he Planning Game  Bei Software-Entwicklungen arbeiten häufig Personen  mit unterschiedlichem technischem Hinter grundwissen zusammen. Das gilt insbesondere für das  agile Programmieren (z.B. Extreme Program ming, Beck 1999). Hier fühlen sich Softwareentwickl er (Developers) und Kunden (Customers) ge meinsam für den Entwicklungsfortschritt verantwortl ich. Aufgrund der Heterogenität der Gruppe  spielt die Kommunikation intuitiver Modelle eine be sondere Rolle. In regelmäßigen Abständen trifft  sich das Team zu einem Planning Game. Die Entwicklu ng beginnt mit einem (einmaligen) Release  Planning. Im ersten Schritt wird das Gesamtsystem d urch ein einfaches intuitives Modell beschrieben  („Metapher“ genannt). Dieses globale Modell wird nu n entfaltet, indem die Customers in sogenannten  Stories umgangssprachlich die Aufgaben des Systems beschreiben. Dabei zerlegen sie eine globale  und diffuse Aufgabe in mehrere konkretere Teilaufga ben. Dies ist insofern ein Problemlösungspro zess, als die Summe der Teilaufgaben einen Weg zur Lösung der Gesamtaufgabe darstellt. Hinter jeder  Story steckt ein intuitives Modell, das innerhalb d es Teams kommuniziert werden muss. Dieses Mo dell wird in Gesprächen (negotiations) zwischen Kun den und Entwicklern geklärt. Ein wichtiger Punkt  in diesen Verhandlungen ist die Sicherstellung der richtigen Komplexität. Eine Story muss einfach  sein. Man muss sie in wenigen Worten beschreiben kö nnen. Ist sie zu komplex, wird sie gespalten. Für  jede Story spezifizieren die Kunden einen Set von A nwendungstests, die das implementierte Pro grammfeature am Ende der Iteration bestehen muss (C ohn 2004, S. 24 ff.). Diese (von NichtInformatikern entworfenen) Tests haben nicht so seh r den Charakter softwaretechnischer Korrektheits tests, bei denen systematisch das korrekte Systemve rhalten in allen möglichen Situationen geprüft  wird. Vielmehr operationalisieren und präzisieren s ie das intuitive Modell der Story durch Beispiele.  Damit die Entwickler im Team die Kosten für die Imp lementierung einer Story einschätzen kön nen, benötigen sie eine Lösungsidee, also ein parad igmatisches Modell. Die Kosten ermitteln sie auf  der Basis eines Vergleichs mit Lösungen, deren Kost en sie kennen. Falls im Repertoire des Teams  kein brauchbares Modell verfügbar ist,  wird zunäch st eine Erkundungsstory geschrieben (Investigati on Story), die schnell (zumindest sicher in der näc hsten Iteration) implementiert werden kann (Spike  Solution). Erst nach Auswertung eines solchen Exper imentes wird dann die eigentliche Story in An griff genommen. Bemerkenswert ist folgender Aspekt:  In jedem Fall arbeiten die Entwickler mit para digmatischen Modellen, die sie gut kennen und mit d enen sie schon mehrfach gearbeitet haben, so  dass sie den Zeitaufwand für eine Implementierung e inschätzen können. Sie haben nur Modelle und  keine Lösungen – denn sonst gäbe es ja nichts mehr zu programmieren. Die Schwierigkeit im Planning  Game liegt also darin, geeignete paradigmatische Mo delle zu finden.  3.4 Kontrollmodelle  Intuitive Modelle sind klein und unmittelbar einleu chtend. Sie können verwendet werden, um eine  komplexere und schlecht durchschaubare Problemlösun g auf Korrektheit zu prüfen. Sie bilden dann  eine Art „Alarmsystem“, das anschlägt, wenn man ein en Fehler gemacht hat. Ein Beispiel aus der  Mathematik wird von Fischbein erwähnt (1987, S. 40) .   Aufgabe: „0,65 l Fruchtsaft kosten 2 Dollar. Was is t dann der Preis für einen Liter? “ 38     Das Problem ist hier, eine geeignete arithmetische Operation zu finden, um aus den gegebenen  Zahlenwerten die Lösung zu berechnen. In diesem Fal l müssen 2 Dollar durch 0,65 Liter dividiert  werden um den Literpreis zu erhalten.  Als Kontrolle kann das folgende einfache intuitive Modell dienen: Man stellt sich eine kleinere  Flasche mit 0,65 l und eine größere Flasche mit 1 l  Fruchtsaft vor. Zweifellos muss die größere  Literflasche teurer sein als die kleinere Flasche.   Das Kontrollmodell ist einfacher als das vollständi ge Lösungsmodell. Es erlaubt nur Aussagen über  bestimmte Merkmale der Lösung (Literpreis ist größe r als 2 Dollar), ist aber kein Korrektheitsbeweis.  Allerdings können intuitive Kontrollmodelle „Bauste ine“ eines Korrektheitsbeweises sein. Die Zuver sicht in die Korrektheit einer Lösung steigt, wenn sie mehreren Kontrollen durch unterschiedliche  intuitive Modelle standhält. Die ist vergleichbar m it der „Bewährung einer Theorie“ in der Popper schen „Logik der Forschung“ (Popper 1934). Die Einb ettung eines Modells in ein Kontrollsystem von  einfachen intuitiven Modellen kann man als Verstehe nsprozess auffassen. Je mehr Kontrollmodelle  ich verwende, desto besser ist das Erlernte veranke rt.   Im Zusammenhang von Programmierprojekten verwendet man Kontrollmodelle bei der Suche nach  semantischen Fehlern (Debuggen), Testen und beim Ei nbau von Zusicherungen in den Programmtext.  Wir gehen im folgenden Abschnitt auf intuitive Mode lle zur Formulierung von Zusicherungen ein.  3.4.1 Zusicherungen  Bei einer Softwareentwicklung werden intuitive Kont rollmodelle verwendet, wenn man in einen  Programmtext Zusicherungen einbaut. Das sind Beding ungen, die während des Programmlaufs auf  Gültigkeit geprüft werden. Falls die Bedingung nich t gilt, wird das Programm mit einer Fehlermel dung abgebrochen. Mit Zusicherungen kann ein Progra mm „logisch sicher“ gemacht werden. Die  Technik ähnelt der Kontrolle einer Maschine durch S ensoren und Messgeräte, die etwaige Störungen  anzeigen. So findet man auf dem Armaturenbrett eine s Autos Warnleuchten, die z.B. Ölmangel, eine  angezogene Handbremse oder überhöhte Temperatur sig nalisieren.   Bei Python werden Zusicherungen, durch assert-State ments realisiert, die folgende Syntax haben:  assert Bedingung  Die Bedingung ergibt sich aus einem intuitiven Mode ll, das einen Teilaspekt des Gesamtmodells,  das hinter dem Programm steht, pointiert. Als Beisp iel betrachten wir die Definition einer rekursiven  Funktion (Python), die den Quicksort-Algorithmus im plementiert.   def qsort (liste):      s = liste[:]             # s ist eine Kopie von  liste      if s == []:          return s      else:          assert len(s) >= 1                              #1          x = s[0]          s.remove(x)          # entferne x aus der L iste s          s1 = []          s2 = []          for i in s:              if i <= x:                  s1.append(i)              else:                  s2.append(i)          assert len(s1) < len(liste)                     #2          assert len(s1) <= len(s)                        #3             ergebnis = qsort(s1) + [x] + qsort (s2)          assert len(ergebnis) == len (liste)             #4          assert ergebnis[0] == min(liste)                #5          assert ergebnis[0] <= ergebnis[-1]              #6          return ergebnis  39     Hier sind einige assert-Statements eingefügt, die f olgende Intuitionen wiedergeben:  #1: Die Liste s muss mindestens ein Element enthalten.  #2: Die Teilliste s1 , die im rekursiven Aufruf von qsort()  als Argument übergeben wird, ist  kürzer als die (als Argument übergebene) zu sortier ende Liste liste . Anderenfalls droht eine End losrekursion. Hier wird also eine Grundidee rekursi ver Algorithmen aufgegriffen: In einem rekursiven  Aufruf wird der Lösungsalgorithmus auf einen kleine ren Teil des Gesamtproblems angewendet.  #3: Variante von Zusicherung 2. Da die Liste s um ein Element kürzer ist als die ursprüngliche  Liste, kann s1  auch die gleiche Länge wie s haben.  #4: Hinter dieser Zusicherung steht die intuitive V orstellung, dass beim Sortieren die Anzahl der  Elemente erhalten bleibt. Es geht nichts verloren u nd es kommen keine Elemente hinzu.  #5: Bei einer aufsteigend sortierten Liste muss das  kleinste Element am Anfang stehen.  #6: In einer aufsteigend sortierten Liste ist das l etzte Element mindestens so groß wie das erste.  Eine Gruppe von 21 Schülerinnen und Schülern, die m it dem Quicksort-Algorithmus und PythonZusicherungen vertraut waren, mussten in einem (ben oteten) Test folgende Aufgabe lösen. Gegeben  war die obige Definition der Funktion qsort()  – allerdings ohne Zusicherungen. An den Stellen, w o  sich im obigen Listing die assert -Statements befinden, war jeweils eine Lücke gelass en. Außerdem  gab es eine Liste von geeigneten und ungeeigneten a ssert-Statements. Die Aufgabe bestand darin min destens drei geeignete assert -Anweisungen an den passenden Stellen einzufügen. T ab. 1 gibt zu  jeder korrekten Zusicherung die Häufigkeit an, mit der sie (auf korrekte Weise) in das gegebene Pro gramm eingesetzt wurde. Bemerkenswert ist, dass die  Zusicherung len(ergebnis)==  len(liste) nur von acht Teilnehmern gewählt wurde, obwohl sie doch ein sehr einfaches, intuiti ves Konzept verkörpert: „Beim Sortieren einer Liste  verändert sich die Anzahl der Elemente nicht“.  Eine mögliche Erklärung ist, dass dieser Gedanke ni cht unmittelbar mit der primären Aufgabe der  Funktion (Sortieren, in eine bestimmte Reihenfolge  bringen) verbunden ist. Für diese Erklärung sprich t  auch, dass in 20 Fällen eine Eigenschaft einer aufs teigend sortierten Liste geprüft wurde, nämlich die   Tatsache, dass das erste Element das kleinste sein muss ( ergebnis[0]== min(liste) ).   Zusicherung Häufigkeit   assert len(s) >= 1 21  assert len(s1) < len(liste)                    7  assert len(s1) <= len(s)                       8  assert len(ergebnis) == len (liste) 8  assert ergebnis[0] == min(liste) 20  assert ergebnis[0] <= ergebnis[-1] 8  Tab. 1: Zusicherungen für eine Implementierung von Quicksort. Häufigkeit der korrekten Verwendung bei e inem Test mit  21 Schülerinnen und Schülern eines Informatik-Grund kurses der Jahrgangsstufe 13.1 (Herbst 2004). 40       4 Empirische Erforschung intuitiver Modelle  4.1 Forschungsansätze und methodische Probleme  Viele empirische Studien zu Fehlvorstellungen und i ntuitiven Modellen in der Informatik folgen  einem der folgenden Muster:  • Schüler oder Studenten schreiben ein Programm oder vervollständigen ein Skelett-Programm, das  eine vorgegebene Funktionalität besitzen soll (z.B.  Mayer 1989).  • Die Versuchsteilnehmer erhalten eine Aufgabe und ve rschiedene Programme, die die Aufgabe  lösen sollen, zur Auswahl. Sie haben zu entscheiden , welches Programm die Aufgabe löst und  welches nicht (z.B. Kahney 1989).  • Die Teilnehmer erhalten Programme und sollen antizi pieren, welche Ausgabe sie liefern (Kurland,  Pea 1985).  Aus den Lösungen (insbesondere Fehlern) wird auf di e Verwendung bestimmter mentaler Modelle  geschlossen. Dabei ist zu bedenken, dass ein vermut etes Konzept das geistige Produkt des Untersu chers ist. Das zentrale Grundproblem derartiger Lab orexperimente ist aber, dass die Motivation der  Teilnehmer unklar bleibt. Die Lösung eines algorith mischen Problems ist eine anspruchsvolle kogniti ve Leistung, die eine gewisse Anstrengung erfordert . Auf der anderen Seite ist es leicht, aus einer  Auswahlliste nach dem Zufallsprinzip eine mögliche Antwort anzukreuzen, wenn man keine Lust hat  sich ernsthaft mit der Aufgabe auseinanderzusetzen.  Bei freien Programmieraufgaben konnte beobach tet werden, dass die Versuchsteilnehmer die ursprün gliche Aufgabe umformuliert (vereinfacht) haben  und in der Versuchssituation ein Programm entwickel ten, das nur einen Teil der geforderten Funktio nalität besaß (z.B. Spohrer et al. 1989).  Eine Lösung des Motivationsproblems ist, die Erhebu ngen in reguläre Tests des normalen Unter richts zu integrieren (z.B. Fothe 2005). Da die Sch ülerinnen und Schüler gute Noten erhalten wollen,  sind sie motiviert, ihr Bestes zu geben. Die Schwie rigkeiten bei diesem Ansatz liegen darin, dass eine   enge Kooperation mit Lehrerinnen und Lehrern erford erlich ist und der Test inhaltlich und methodisch  curricularen Vorgaben entsprechen muss.   Eine zweite Erhebungsmethode sind Beobachtungen und  Interviews, bei denen die Teilnehmer  „laut denkend“ ihre Überlegungen während eines Prob lemlösungsprozesses mitteilen (z.B. Chiu 1996,  2000, 2001). Ein Problem ist jedoch, dass intuitive  Konzepte unbewusst sein können oder es den Ver suchsteilnehmern an sprachlichen und visuellen Ausd rucksmöglichkeiten mangelt.   In „Teach back“-Befragungen werden die Teilnehmer a ufgefordert, bestimmte Sachverhalte mit  Hilfe von selbst angefertigten Texten und Bildern z u erklären. Mit diesem Verfahren versuchte Gerrit  van der Veer (1994) in einer umfangreichen Untersuc hung (607 Schülerinnen und Schüler aus drei  europäischen Ländern) mentale Modelle über die Arbe itsweise von Computersystemen zu ermitteln.  Untersuchungsgegenstand waren auch die verwendeten Ausdrucksmittel. Es zeigte sich, dass visuelle  Darstellungsformen gegenüber Text nur eine untergeo rdnete Rolle spielten. So enthielten nur 25% der  Teach-back-Produkte bildhafte und 28% ikonische Dar stellungen.   4.2 Visualisierungsübungen  Der deutsch-amerikanische Kunstpsychologe Rudolph A rnheim ließ seine Studenten Visualise rungsversuche machen. Die Versuchspersonen sollten zu abstrakten Begriffen Zeichnungen anferti gen, die den Begriff bildhaft darstellen sollten. D abei sollten sie für jede neue Version ein neues Bl att  verwenden, damit man die Entwicklung ihrer Idee ver folgen konnte. Die Studenten brauchten viel Zeit  und ein Dutzend Blätter und mehr bis sie zu einer b efriedigenden Lösung kamen (Arnheim 1972,  S.120 ff). Aus Arnheims Erfahrungen kann man folgen des Fazit zeihen: Eine visuelle Repräsentation  für ein intuitives Modell zu finden ist erstens ein e Kunst, die gelernt werden muss, und zweitens ein  Entwicklungsprozess. Das muss bei der Gestaltung vo n Visualisierungsexperimenten mit Schülern  bedacht werden. Besser als ein einmaliger Individua ltest (wie bei van der Veer) erscheint deshalb die 41     Integration derartiger Aktivitäten in den Unterrich t – und zwar so, dass Dazulernen ermöglicht wird.  Im Juni 2006 habe ich mit 73 Schülerinnen und Schül ern einer Wittener Gesamtschule (Grundkurse  Informatik 11.2 und 12.2) eine Reihe von Visualisie rungsübungen durchgeführt. Die Aufgabe war, mit  Bleistift und Papier ein Storyboard zu entwickeln, das die Ausführung eines kurzen Java-Programms  visualisiert. Die meisten der Schüler haben dann sp äter auf der Basis ihrer Storyboards FlashAnimationen erstellt. Die Schüler konnten an Gruppe ntischen zusammenarbeiten und Ideen austau schen. Es sollte aber jeder seine eigene subjektive  Vorstellung zu Papier bringen. Wie in Arnheims  Übungen wurden die Schüler außerdem ermuntert, zu e iner Aufgabe mehrere Lösung zu zeichnen  (Aufgaben und Arbeitsblätter finden sich in Anhang 3.1).   4.3 Die Python Visual Sandbox  Die Python Visual Sandbox (PVS) ist eine Sammlung v on interaktiven Online-Applikationen  (Spielen) mit insgesamt etwa 150 Animationen, die i nformatische Konzepte veranschaulichen. Im  Unterschied zu freien Visualisierungsübungen (siehe  voriger Abschnitt) werden hier vorgefertigte  Repräsentationen intuitiver Modelle vorgeführt, von  denen vermutet wird, dass sie Schülerinnen und  Schülern (bewusst oder unbewusst) verwenden. Die PV S setzt darauf, dass die Nutzer (Spieler) interne  mentale Modelle wieder erkennen, die sie vielleicht  selbst – mangels Visualisierungskompetenz –  nicht explizieren können. Es gibt drei Typen von PV S-Applikationen. Zwei davon haben den Charak ter von wettkampfartigen Spielen, bei denen man in Abhängigkeit von der Leistung Punkte gewinnen  kann. Beim Python Puzzle setzen die Teilnehmer aus vorgefertigten Bausteinen Python-Programme  zusammen und testen sie. Die Animationen dienen hie r als Hilfe. Bei Python Quiz beurteilen die Spie ler Animationen dahingehend, ob sie die Arbeitsweis e eines vorgegebenen Programmstücks richtig  wiedergeben. Beim dritten Typ – Python Visual – spi elt der Aspekt der Leistung keine Rolle. Zu ver schiedenen animierten Modellen, die einen Programml auf veranschaulichen sollen, werden einfach  nur drei Fragen gestellt. Punkte gibt es hier allei n für die Teilnahme.   Eine PVS-Applikation kann von einer oder zwei Perso nen gleichzeitig benutzt werden. Damit wird  den Arbeitsbedingungen in einer typischen Schule Re chnung getragen, wo häufig zwei Schüler sich  einen Rechner teilen müssen. Zu Beginn einer Sitzun g loggen sich die Teilnehmer mit einem Passwort  ein, das sie zuvor bei der Registrierung spezifizie rt haben. In Abhängigkeit von den Passwörtern wird  die Sprache für Textelemente (Deutsch oder Englisch ) gewählt. Das System registriert wichtige Akti vitäten während der Sitzung und speichert das Sitzu ngsprotokoll in einer Datenbank ab. Durch Aus wertung der Datenbank können Erkenntnisse über die Verwendung visueller Modelle gewonnen wer den. Die PVS ist aber nicht nur ein Forschungsinstr ument, sondern sie hat auch die Merkmale eines  Spiels und einer Lernumgebung.  4.3.1 Die PVS als Spiel  Nach Scheuerl (1975) ist Spiel freiwilliges, intrin sisch motiviertes und Freude bereitendes Verhal ten. Nun ist das Lösen von Aufgaben in der PVS kein  oberflächliches Amüsement, sondern anstren gende intellektuelle Aktivität. Durch spielerische Elemente kann die Motivation gesteigert werden,  diese Anstrengung auf sich zu nehmen. Cailloise (19 58) beschreibt vier Merkmale, die bei Spielen in  unterschiedlich starken Maße auftreten können, durc h lateinische und griechische Begriffe: Agôn  (griech.: Wettkampf), Alea (lat.: Würfel), Mimicry (griech.: Schauspiel, Verkleidung) und Ilnix  (griech.: Extase). Alea ist eine Metapher für die d ie Ungewissheit von Spielereignissen wie sie typi scherweise bei Würfelspielen auftreten. Der Begriff  Mimicry bringt zum Ausdruck, dass Spiele quasi  neben der Realität stehen und in einer geschlossene n Fantasiewelt mit eigenen Regeln stattfinden. Für  Rollenspiele und Adventure-Games ist die Mimicry-Ko mponente von zentraler Bedeutung. Ilnix  schließlich meint das fast rauschartige Gefühl, das  man zum Beispiel beim Achterbahnfahren empfin det.  Zwei der PVS-Applikationen haben den Charakter von Wettkampfspielen (Agôn). Beim Spielen  kann man in Abhängigkeit von der Leistung Punkte ge winnen. Der Reiz des Wettkampfes ergibt sich  einmal aus dem Vergleich mit anderen Spielern und z weitens aus der Möglichkeit die eigene Leistung  zu beobachten und zu verbessern. Jeder Spieler kann  für die Applikationen, die sie oder er wenigstens  einmal gespielt hat, Highscore-Listen anfordern, di e Punktzahl, Nicknames der Spieler und Datum der 42     besten zehn Sessions enthalten. Außerdem kann jeder  Spieler einen Activity-Report abrufen, der seine  erreichte Gesamtpunktzahl und Kurzbeschreibungen al ler absolvierten Sessions auflistet.   Eine Sitzung mit einer PVS-Applikation enthält viel e ungewisse Ereignisse (Alea), die eine gewis se Spannung hervorrufen. In einem Python Puzzle kan n ein Spieler niemals sicher sein, ob sein Pro gramm korrekt ist, bis er es getestet hat. Auf der anderen Seite ist es oftmals überraschend, dass ein   kleines Programm nicht das vorhergesehene Verhalten  zeigt. Bei einem Python Quiz erlebt man die  Ungewissheit, wie das System die eigenen Antworten beurteilt.  Aktivität und angeregte Spannung (Ilnix) wird durch  die hohe Spielgeschwindigkeit gefördert.  Python Puzzles haben eine maximale Spielzeit von ze hn Minuten, ein Python Quiz mit 20 bis 30 Ein zelaufgaben dauert im Schnitt acht bis neun Minuten . Die PVS enthält keine Fantasieelemente. Die  Mimicry-Komponente fehlt fast völlig. Hier besteht noch viel Entwicklungspotenzial. Die Verlage rung von Aktivitäten in eine Fantasiewelt kann helf en, eine entspannte Spielhaltung (Scheuerl) einzu nehmen.  4   4.3.2 Lernen mit der PVS  Empirische Untersuchungen in der Schule sind besser  zu rechtfertigen, wenn für die beteiligten  Schülerinnen und Schüler Profit in Form von Lernerf ahrung herausspringt. Deshalb wurde die PVS  auch als Lernwerkzeug konzipiert, das im Unterricht  eingesetzt werden kann. Lernziele betreffen na türlich vor allem intuitive Modelle für Konzepte de r Informatik:  • Erweiterung des Repertoires an intuitiven Modellen und Metaphern und damit verbunden eine  Verbesserung der Kommunikationsfähigkeit.  • Unbewusste Intuitionen werden durch Visualisierunge n expliziert und ins Bewusstsein gerufen.  • Intuitive Vorstellungen werden reflektiert und Fehl vorstellungen aufgedeckt.  Die Python Puzzles bieten zusätzlich die Gelegenhei t, metakognitive Kompetenzen zu üben, die für  eine Softwareentwicklung (und andere Bereiche des L ebens) wichtig sind wie z.B. Zeitmanagement,  Selbstbeobachtung, Verwendung visueller Modelle, di e eine Lösungsidee repräsentieren, und Strate gien des Problemlösens.  Unterrichtsmethodisch kann die PVS zum individuelle n Üben oder als Vorbereitung einer Ple numsdiskussion über intuitive Modelle eingesetzt we rden.  4.3.3 Überblick über den technischen Aufbau der Pyt hon Visual Sandbox  Die PVS ist ein Client-Server-System und besteht au s folgenden Komponenten (siehe Abb. 9):  • Flash-Applikationen und interaktive HTML-Seiten, di e mit einem Web-Browser über das Internet  abgerufen werden und auf dem Client-Rechner ausgefü hrt werden,  • Dienstprogramme (Python-Skripte), die auf einem zen tralen Server laufen.    Abb. 9: Aufbau der Python Visual Sandbox                                                         4 Ein weitergehende Diskussion der PVS als webbasier tes Spiel findet man in Weigend 2006c 43     Client  Herzstück der PVS ist eine Sammlung interaktiver mu ltimedialer Spiele (Python Visual, Python  Puzzle und Python Quiz), die über den Web-Browser a ufgerufen werden. Diese Applikationen führen  ein Protokoll über die Benutzeraktionen während ein er Sitzung und senden die Daten an ein Dienst programm auf dem Server, das die jeweilige Session in der Datenbank dokumentiert.  Vor der ersten Nutzung der PVS muss sich ein Spiele r auf einer HTML-Seite mit Formular regist rieren. Sie oder er spezifiziert einen Nickname (öf fentlich) und ein Passwort (geheim) und macht fol gende Angaben zur Person: Geschlecht, Alter, Beruf,  Zeit, die sie oder er wöchentlich mit Program mieren verbringt. Die Webseite ist mit einem Servic e-Skript verbunden, das die Daten in die  Datenbank einträgt.   In einem zweiten Verwaltungsbereich (HTML-Seiten mi t Formularen), können Lehrpersonen (Co aches) Gruppen definieren und jeder Gruppe Personen  (Nicknames) zuordnen. Erhobene Gruppen merkmale sind z.B. Größe der Stadt, Programmiervork enntnisse, minimales und maximales Alter der  Gruppenmitglieder. Einige dieser Gruppenmerkmale kö nnen verwendet werden, um die Korrektheit  der Registrierungsdaten der Gruppenmitglieder zu pr üfen (Validitätskontrolle).  Server  Die Daten zu den Spielern, zu den verwendeten Model len und Protokolle der Sessions werden in  einer zentralen MySQL-Datenbank gespeichert (Detail s in Anhang 3.2). Für die Python Puzzles gibt  es einen Online-Interpreter, der die vom Spieler au s Bausteinen zusammengesetzten Python-Skripte  empfängt, ausführt und das Ergebnis (Ausgabe des Sk riptes) zurückgibt. Zu Beginn eines Spiels,  nachdem die Benutzer ihre Passwörter eingegeben hab en, wird ein Dienst aufgerufen, der die Validität  der Passwörter prüft und im positiven Fall die zuge hörigen Nicknames zurückgibt, die dann im Spiel  verwendet werden. Für jede Spielkategorie gibt es e in Dienstprogramm, das die Protokolldaten (z.B.  die Zeit, wie lange sich ein Spieler eine Animation  angesehen hat) zu einer Spielsession aufnimmt und  in die Datenbank einträgt. Die Kommunikation erfolg t über XML-Dokumente. Passwort-geschützte  Auswertungsprogramme liefern formatierte und bebild erte Dokumente mit statistischen Angaben zu  den Sitzungen mit der PVS. Ein öffentliches Auswert ungsprogramm berechnet eine HTML-Seite mit  einem allgemeinen Überblick über die Nutzung der PV S (Anzahl registrierter Spieler, Anzahl der Sit zungen etc.). Weitere Service-Skripte dienen der Ve rwaltung von Gruppen, Ermittlung von Highsco res und Activity-Reports.  4.4 Python Visual  Bei einem Python Visual sehen die Spieler einen kur zen Programmtext oder eine kurze Beschrei bung eines allgemeinen Konzeptes der Informatik (z. B. reguläre Ausdrücke). Danach folgen drei bis  vier Animationen, die das Programm bzw. Konzept erl äutern. Die Animationen können beliebig oft  abgespielt und zwischenzeitlich gestoppt werden. Am  Ende werden den Spielern drei Fragen gestellt,  die sie beantworten müssen. Im Unterschied zu Pytho n Quiz gibt es keine richtigen oder falschen  Antworten. Für das erstmalige Bearbeiten eines Pyth on Visuals gibt es 20 Punkte für den ActivityReport. In der Regel wird eine gewisse Mindestbearb eitungszeit verlangt, um auf ernsthaftes Beant worten der Fragen hinzuwirken.   Am Ende einer Session wird ein XML-Paket mit den Be trachtungszeiten und gewählten Antworten  der Spieler an das zugehörige Service-Programm gesc hickt, das die Datenbank aktualisiert.          Abb. 10: Screenshots aus dem Python Visual „Multili sts“ 44     Die Antworten der Mitglieder einer Gruppe (z.B. Tei lnehmer/innen eines Workshops) können mit  einem (online verfügbaren) Werkzeug ausgewertet wer den. Es liefert in einer HTML-Seite zu jedem  Modell folgende Informationen (siehe Abb. 11):  • Einen Screenshot aus der Animation als Erinnerungsh ilfe.  • Zu jeder Frage den Anteil der Personen aus der betr effenden Gruppe, die dieses Modell gewählt  haben (numerisch und grafisch als farbigen Balken).   • Zeitliche Dauer der Animation und mittlere Betracht ungszeit in der Gruppe.  In Workshops mit der PVS wurden diese Übersichten a ls Anlass für eine Plenumsdiskussion über  die Modelle und ihre Schwächen verwendet. Durch die  Einbettung in einen sozialen Kontext sollte  (neben dem Lerneffekt) auch eine gewisse Ernsthafti gkeit bei der Bearbeitung der Python Visuals  bewirkt werden.     Abb. 11: Auszug aus der Evaluation der Antworten zum  Python Visual „Changing lists“   4.5 Python Puzzle  Bei einem Python Puzzle bauen die Spieler aus vorge gebenen Programmtext-Zeilen („Bausteine“)  unter Zeitdruck ein lauffähiges Python-Skript zusam men. Dabei können sie Tipps abrufen, die bei der  Problemlösung helfen. Das zusammengebaute Programm kann getestet werden. Erst wenn das Pro gramm fehlerfrei läuft und die korrekte Ausgabe lie fert, kommt man zur nächsten Aufgabe.        Abb. 12: Screenshots aus einem Python Puzzle. Links  die Seite mit der Problemstellung (kann immer wiede r hervorgeholt  werden), rechts die Editorseite. 45     Es gibt eine gewisse Anzahl von Aufgaben, die inner halb einer fest vorgegebenen Zeit bearbeitet  werden müssen. Für jede Aufgabe gibt es je nach Sch wierigkeitsgrad eine gewisse Punktzahl. Ziel ist  es, möglichst viele Punkte zu sammeln. Wer alle Auf gaben gelöst hat, bekommt Bonuspunkte zuge schlagen, die aus der Anzahl der verbleibenden Seku nden berechnet werden. Bei den meisten Aufga ben soll eine Funktion definiert und getestet werde n.   Abb. 12 zeigt zwei Screenshots aus dem Python Puzzl e „Modeling a group“. Darin wird eine  Gruppe von Personen durch eine Liste modelliert, de ren Elemente Listen aus Name und Alter sind:  p = [['Anna', 22], ['Tim', 21], ['Sarah', 19]]  In Aufgabe 1 soll eine Funktion definiert werden, d ie zu einer solchen Liste eine Liste mit den Namen  der Gruppenmitglieder liefert. Zu dieser Funktionsd efinition ist nur der Funktionskopf vorgegeben:  def getNames(persons):  Die Anweisungen des Funktionskörpers müssen eingefü gt werden. Angeboten werden Puzzlestü cke mit korrekten und falschen Anweisungen, die mit  der Maus in das Editorfeld verschoben werden  (siehe Abb. 12). Die korrekte Lösung lautet:  def getNames(persons):     result = []     for person in persons:         result.append(person[0])     return result  Durch die Auswahl an Bausteinen, die zur Verfügung stehen, wird erzwungen, einen bestimmten  Algorithmus zu implementieren. Es gibt also im Prin zip (wie bei einem richtigen Puzzle) nur eine  mögliche Lösung. Lediglich einige wenige Marginalie n sind variabel (z.B. Reihenfolge einiger An weisungen). Ein wesentlicher Vorteil der Verwendung  von Bausteinen liegt darin, dass syntaktische  Flüchtigkeitsfehler (wie vergessene Kommata oder Kl ammern), die für wissenschaftliche Fragestel lungen weitgehend irrelevant sind, ausgeschlossen w erden. 5 Es kann sich um ein „geschlossenes Puzz le“ handeln, in dem alle Programmbausteine verwende t werden oder ein „offenes Puzzle“, in dem  auch falsche oder nicht benötigte Bausteine angebot en werden. Mit offenen Puzzles kann man unter suchen, für welche Fehler Programmentwickler besond ers anfällig sind. Es werden dann in Konkur renz zu einer richtigen Anweisung verschiedene fehl erhafte Statements mit unterschiedlichen Merk malen als Puzzlesteine angeboten.  Zu Beginn einer Sitzung erscheint (nach dem Einlogg en) eine Seite, in der der Problemkontext der  Puzzleaufgaben erklärt wird (Abb. 12 links). Nach e inem Klick auf den Knopf rechts unten wird die  Uhr gestartet und man gelangt auf die Editorseite ( Abb. 12 rechts).  Im Editorfeld (Überschrift „Script“) befindet sich oben die Kopfzeile der Funktion und unten eine  print-Anweisung, in der die Funktion zum Testen auf gerufen wird. Ein Kommentar enthält eine Be schreibung der Funktionalität („Was soll die Funkti on leisten"). In einigen Fällen wird auf diese verb a le Beschreibung komplett verzichtet. Stattdessen wi rd die Funktionalität in einer Animation beschrie ben. Dann steht im Kommentar nur „See hints“.   Wenn der Spieler den Test-Knopf betätigt, wird das Skript aufbereitet, an den Server geschickt, die  Ausgabe und eventuell Fehlermeldung im Ausgabefenst er dargestellt und eine Rückmeldung für den  Spieler generiert. Liefert das Skript die korrekte Ausgabe, erscheint ein „next task“-Knopf., der den  Übergang zur nächsten Aufgabe ermöglicht.  Falls ein Laufzeitfehler auftritt, wird die Antwort  des Python-Interpreters vom Client-Programm  (Flash) auf die eigentliche Fehlermeldung (z.B. SyntaxError ) verkürzt und erscheint im Ausgabe feld (Ausgabe). Der Testlauf wird nun vom System an alysiert und eine Rückmeldung für den Spieler  generiert. Insbesondere wird der Testlauf mit Punkt en bewertet.                                                          5 Solche Flüchtigkeitsfehler (engl. „flaws“) dominie ren sehr stark bei realen Programmentwicklungen und  ihre  Beseitigung kostet gerade Programmieranfängern viel  Zeit (vgl. z.B. Anderson & Jeffries 1985). 46     4.5.1 Dokumentation einer Session  Zu Beginn einer Session wird ein XML-Paket an das z ugehörige Serviceprogramm geschickt. Es  enthält die IDs (Passwörter) der Spieler, sowie Pri märschlüssel (IDs) für das Spiel und die Session.  Vom Serviceprogramm wird ein Datensatz für die Besc hreibung der Session angelegt, als Spieldauer 0  Sekunden und als erreichte Punktzahl –200 eingetrag en. Ein vorzeitiger Spielabbruch wird also durch  Minuspunkte „bestraft“. Damit soll vermieden werden , dass ein Spieler bei einem schlechten Start  sofort „die Flinte ins Korn wirft“. Für die wissens chaftliche Auswertung sind gerade die ersten – noch   völlig unvoreingenommenen – Spieldurchgänge interes sant.  Am Ende einer Session wird ein XML-Dokument mit dem  Sessionprotokoll an das ServiceProgramm geschickt. Es enthält globale Informatione n über die Session (Spieler, erreichte Punktzahl  etc.) und zu jeder bearbeiteten Aufgabe folgende sp ezifischen Angaben:   • Bearbeitungsbeginn, Bearbeitungszeit, erreichte Pun ktzahl, Anzahl der Testläufe.  • Für jedes als Hinweis verwendete Modell: Modell-ID,  Zeitpunkt und Dauer der Betrachtung, Be wertung (hilfreich, etwas hilfreich, nicht hilfreic h).  • Jede falsche und richtige verwendete Programmzeile (Puzzlestück) und Zeitpunkt der Verwen dung (erstmaliges Verschieben in das Editorfeld).  • Das Serviceprogramm berechnet aus den Zeitstempeln die Reihenfolge, in der richtige und falsche  Programmzeilen verwendet worden sind (für jedes Stü ck gibt es einen Rang) und aktualisiert die  Datenbank.  4.5.2 Auswertung der Python Puzzle Sessions  Ein spezielles Dienstprogramm wertet die in der Dat enbank gespeicherten Sessionprotokolle aus.  Es zielt vor allem auf die Beantwortung folgender F ragen ab:  (1) In welcher Reihenfolge werden korrekte Programm zeilen in das Programm eingebaut?   (2) Welche fehlerhaften Programmelemente (bei unvol lständigen Puzzles) werden verwendet?  (3) Wie lange und wie häufig werden die angebotenen  Tipps betrachtet?  (4) Wie werden die angebotenen Tipps von den Spiele rn beurteilt?  Als Beispiel betrachten wir einen Auszug aus dem Be richt des Auswertungsdienstes zu Aufgabe 1  aus dem Puzzle „Modeling a group“ (Anhang 3.6.3 zei gt den vollständigen Bericht).   Die folgenden Tabellen beziehen sich auf die Auswer tung der Sessions von 20 Schülern und 4  Hochschulstudenten, die die Aufgabe erfolgreich gel öst haben. Bis zur korrekten Lösung wurden im  Schnitt 3.3 Testläufe und insgesamt eine Zeit von 3 20 Sekunden benötigt.  Korrekte Programmzeile Verwendung (Prozent) Mittl. Rang (Std.-Abw.)  result = [] 24 (100.00 %)  1.38 (0.88)   return result 24 (100.00 %)  2.96 (0.95)   for person in persons: 24 (100.00 %)  2.67 (1.05)   result.append(person[0]) 24 (100.00 %)  3.00 (0.78)   Tab. 2: Verwendung korrekter Programmzeilen in Pytho n Puzzle „Modeling a group“  Tab. 2 gibt Aufschluss darüber in welcher Reihenfol ge korrekte Programmzeilen in die Funktions definition eingebaut worden sind. Der Rang einer ko rrekten Programmzeile ist eine Zahl zwischen 1  und der Anzahl aller einzufügenden Programmzeilen. Er gibt – für eine bestimmte Session – den rela tiven Zeitpunkt, also die Position in der Folge all er korrekten Einfügungen, wieder. In der rechten  Spalte der Tabelle wird zu jeder korrekten Programm zeile der mittlere Rang angegeben. So erkennt  man, dass meist die Initialisierung der leeren List e zuerst vorgenommen wurde. Auch bei anderen  Puzzles konnte festgestellt werden, dass die Spiele r mit der Initialisierung von Variablen begannen. 47     Dagegen hat Samurçay (1989) beobachtet, dass Anfäng er häufig die Initialisierung von Variablen  weglassen. 6 Aus den Ergebnissen mit der PVS kann man also schl ießen, dass hinter dem Weglassen  einer Initialisierung keine grundlegende Fehlvorste llung sondern allein Flüchtigkeit steht, die viel leicht das Resultat einer Fokussierung auf den algo rithmischen Kern des Programms ist. Bei den ande ren Programmzeilen gibt es keine deutliche Tendenz in der Reihenfolge der Verwendung. Das hängt  unter anderem damit zusammen, dass vor der korrekte n Programmzeile (in unterschiedlichem Maße)  zunächst fehlerhafte Anweisungen verwendet wurden. 7  Tab. 3 gibt einen Überblick über den Gebrauch falsc her Puzzle-Stücke. Die Zahlen bestätigen Beo bachtungen, die auch in anderen Studien gemacht wur den, nämlich dass Anfänger in Programmtexten  alltagssprachliche Formulierungen verwenden (Bonar & Soloway 1985). So hat die Zeile   for all in persons:  als englischer Text durchaus Sinn, ist aber kein gü ltiger Python-Programmtext.   Falsche Programmzeile Verwendung (Prozent) Mittl. R ang (Std.-Abw.)  for all in persons: 8 (33.33%)  2.62 (1.69)   for persons in person: 11 (45.83 %)  2.82 (1.66)   result.append(name) 7 (29.17 %)  2.14 (1.35)   result.append(person) 14 (58.33 %)  1.71 (1.14)   result.append(person[1]) 6 (25.00 %)  3.33 (1.03)   result= "" 5 (20.83 %)  2.60 (1.82)   Tab. 3: Verwendung falscher Programmzeilen in Python  Puzzle „Modeling a group“.  Zu jedem als Tipp angebotenen Modell beschreibt der  Bericht des Dienstprogramms die gesamte  Betrachtungszeit, die Häufigkeit der Betrachtung un d die Bewertung. Die Spieler sind gezwungen, die  betrachtete Hilfe zu bewerten, bevor sie mit der Pr ogrammedition fortfahren können.   4.5.3 Verwendung von Tipps   Ein zentrales Anliegen der Python Puzzles war, Erke nntnisse über die Verwendung von visuellen  Modellen als Hilfe bei Programmieraufgaben zu finde n. Bedauerlicherweise wurden die angebotenen  visuellen Modelle nur in geringem Maße genutzt, sel bst wenn die Spieler erhebliche Probleme mit der  Aufgabe hatten und keine Lösung finden konnten. Mög licherweise empfanden die Spieler die Ausei nandersetzung mit den Modellen als Zeitverlust. Sie  bevorzugten, die knappe Zeit allein dem Testen  von Programmvarianten zu widmen.   In den Workshops zeigte sich außerdem, dass Spielst rategien und insbesondere die Verwendung  der Modelle erst durch mehrfaches Spiel gelernt wer den müssen. Eine sinnvolle Vorgehensweise ist  z.B. folgende:   • Betrachte eine Animation zuerst als Hilfe, um zu ve rstehen, was  die zu implementierende Funkti on leisten soll.   • Wenn du nicht sofort auf eine Lösung kommst, analys iere die angebotene Animation dahinge hend, wie  das Programm arbeitet. Was passiert zuerst? Welche  Programmzeilen passen zu den  dargestellten Aktionen?                                                           6 Johnson (1990) hält ausgelassene Initialisierungen  für so typisch für Anfänger, dass sein didaktische s Debug ging-System PROUST, in solchen Fällen lehrreiche Hi nweise gibt.  7 Aus der undeutlichen Reihenfolge kann man also nic ht schließen, dass die Spieler uneinheitliche Vorge hens weisen zur Lösung der Aufgabe verfolgten.  48            Abb. 13: Zwei Screenshots aus dm „Tipp“ des Python P uzzles „Multilists“.   In zukünftigen Versionen müsste der Abruf von Tipps  auf geschickte Weise belohnt werden, damit  ein Anreiz geschaffen wird, sich überhaupt auf die Verwendung paradigmatischer Visualisierungen  einzulassen und in einen Lernprozess einzusteigen.  4.6 Python Puzzle assert  Python Puzzle Assert ist eine Variante von Python P uzzle. Hier ist ein fertiger Programmtext vor gegeben, in den noch Zusicherungen (assert-Anweisun gen) durch Verschieben mit der Maus eingebaut  werden können. Eine assert-Anweisung hat folgenden Aufbau:  assert Bedingung   Wenn die Bedingung nicht erfüllt ist, wird die Ausf ührung des Programms mit einer Fehlermel dung abgebrochen. Mit assert-Statements kann man di e logische Korrektheit eines Programms absi chern. Hinter jeder Zusicherung steht eine kontroll ierende Intuition. Je mehr Assert-Statements eingebaut worden sind, desto mehr Punkte gibt es, sofern  jedes assert-Statement logisch sinnvoll ist.   Für jedes Programm stehen mehrere assert-Statements  zur Verfügung. Sie befinden sich am rechten  Bildschirmrand und können mit der Maus zwischen bel iebige Zeilen des Programmtextes geschoben  werden. Manchmal wird in einem Spiel der gleiche Pr ogrammtext mehrfach verwendet, aber jeweils  unterschiedliche Sets von assert-Statements angebot en. Für jedes Programm, das mit Zusicherungen  logisch abgesichert werden soll, gibt es drei Testl äufe. (Das ist ein Unterschied zu Python Puzzle.)  Somit kann ein Spieler z.B. zunächst nur ein assert -Statement ausprobieren und bei späteren Testläu fen weitere hinzufügen. Das System verlangt, dass m indestens eine Zusicherung eingebaut worden ist,  bevor es einen Testlauf zulässt.  Nach einem Testlauf gibt es folgende Möglichkeiten einer Rückmeldung:  • Alle Zusicherungen sind logisch richtig. In diesem Fall gibt es für jede Zusicherung 5 Pluspunkte.  • Mindestens eine Zusicherung ist logisch fehlerhaft.  Dann gibt es 10 Minuspunkte. Logisch fehler haft heißt, dass die Zusicherung einen AssertionError  auslöst, obwohl das Programm korrekt  ist.   • Mindestens eine Zusicherung hat einen Fehler ausgel öst, der kein AssertionError  ist (z.B.  falsche Einrückung). Dann gibt es 5 Minuspunkte und  einen zusätzlichen Testlauf.    Generell wurde versucht die Punktevergabe so zu ges talten, dass es sich einerseits lohnt, möglichst  viele Zusicherungen zu verwenden, man aber anderers eits logisch falsche Zusicherungen meiden  möchte.   Die Kommunikation mit dem Server und die Dokumentat ion der Sessions sind genauso wie bei den  anderen Python Puzzles.  4.7 Python Quiz  Python Quiz ist ein System, mit dem Zuordnungen von  visuellen Modellen zu Programmtexten be obachtet werden können. Bei jeder Aufgabe ist ein k leines Stück eines Programms (eine oder zwei  Zeilen) optisch hervorgehoben. Dazu werden nacheina nder mehrere Modelle angeboten (zufällige  Reihenfolge). Für jedes Modell entscheidet der Spie ler, ob es die Arbeitsweise des Programmstücks 49     richtig wiedergibt oder nicht. Dabei kann sie oder er 0, 5 oder 10 Punkte setzen. Liegt der Spieler ri ch tig, erhält er oder sie die gesetzte Punktzahl als Pluspunkte. War die Entscheidung falsch, wird die  dreifache Punktzahl abgezogen. Entscheidungen nach dem Zufallsprinzip werden also drastisch „be straft“. Es ist strategisch günstiger, null Punkte zu setzen, wenn man die Antwort nicht weiß. Schnell e  Entscheidungen (Zeitbedarf weniger als 10 Sekunden)  führen zu einer Verdoppelung der erhaltenen  Plusoder Minuspunkte. Somit ist die gesetzte Punk tzahl ein Maß dafür, wie sicher der Spieler ist, di e  richtige Entscheidung getroffen zu haben. Bei 10 ge setzten Punkten kann man als zweites Maß für die  subjektive Sicherheit die Zeit betrachten, die für die Entscheidung benötigt wurde.    Abb. 14: Screenshot aus einem Python Quiz.  4.7.1 Bewertung der Antworten  Eine Animation kann unterschiedlich interpretiert w erden. Strukturelle Abweichungen des Modells  vom Original können als Fehler oder als Vereinfachu ng gesehen werden. Generell reagiert das System  sehr tolerant. Nur eindeutig falsche Bewertungen we rden mit Minuspunkten bestraft. Die strittigen  Fälle werden immer zu Gunsten des Spielers bepunkte t.   Merkmale eines eindeutig falschen Modells sind:  • Es enthält symbolische Bezeichnungen, die mit dem P rogrammtext nicht übereinstimmen (z.B. –  statt +)  • Es enthält strukturelle Abweichungen vom Programmte xt, die nicht als Vereinfachung interpretiert  werden können. Beispiel: Die Zuweisung x=1 wird durch einen Behälter modelliert, der das Eti kett „1“ trägt und als Inhalt einen Zettel mit der Aufschrift „x“ erhält.   In Workshops mit der PVS zeigte sich, dass manche S pieler nicht alle Systembewertungen, die mit  Punktverlust verbunden waren, hinnahmen und in Einz elfällen sogar aggressiv reagierten. Um das  Risiko eines derartigen Abrückens von einer gelasse nen „spielerischen Attitüde“ (im Sinne von  Scheuerl) zu verringern, könnte man bei zukünftigen  Entwicklungen weitere Fantasieelemente in  Quiz-ähnliche Applikationen einbauen. Beispielweise  könnte man die Figur eines Schiedsrichters in tegrieren, der zwar fehlbar ist, aber dessen Entsch eidungen man – wie beim Fußball – dennoch akzep tieren muss.  4.7.2 Dokumentation einer Session  Wie bei Python Puzzle wird zu Beginn einer Session ein XML-Paket an ein Service-Programm ge schickt, das einen Datensatz für die Beschreibung d er Session angelegt, als Spieldauer 0 Sekunden und  als erreichte Punktzahl –200 einträgt, um vorzeitig en Spielabbruch unattraktiv zu machen. Am Ende  einer Session wird ein XML-Paket mit dem Sessionpro tokoll (Beurteilungen der gezeigten Modelle, 50     gesetzte Punktzahl und Entscheidungszeiten) an ein zweites Service-Programm gesendet, das die Da tenbank aktualisiert.  4.7.3 Schlussfolgerungen zur Intuitivität von Model len  Aus dem Verhalten der Spieler kann man ablesen, in welchem Maß sie die dargestellten Modelle  als intuitiv empfinden:  (1) Geschwindigkeit der Reaktion.  Je schneller das Modell analysiert und bewertet wi rd, desto intuitiver ist  es. Bei einer schnellen Reaktion kann man davon aus gehen, dass der Spieler bereits früher einmal mit  einem ähnlichen Modell in Gedanken operiert hat. Be i einer langsamen Reaktion ist eher zu vermuten,  dass diese Art der Interpretation für sie oder ihn neu ist.  (2) Gesetzte Punktzahl.  Je mehr Punkte gesetzt werden, desto sicherer sind  die Spieler, dass ihre Einschät zung korrekt ist.  (3) Korrektheit.  Fehlerhafte Bewertungen – insbesondere wenn ein ei ndeutig falsches Modell als richtig  eingestuft wird – können verschiedene Ursachen habe n. Vielleicht wurde das Modell gar nicht durch schaut und es wurde nach dem Zufallsprinzip geantwo rtet. Oder ein eindeutig falsches Detail des Mo dells (z.B. falscher Bezeichner) wurde übersehen. I n jedem Fall weist eine fehlerhafte Bewertung auf  eine geringere Vertrautheit mit dieser Art der Dars tellung und damit auf geringere Intuitivität hin.   4.8 Workshops mit der PVS  In den Jahren 2005 und 2006 habe ich insgesamt 14 W orkshops mit der Python Visual Sandbox an  Schulen und Universitäten in Deutschland und Hongko ng (China) durchgeführt. Daran haben insge samt 241 Personen teilgenommen, davon kamen 187 aus  Deutschland, 54 waren weiblichen und 187  männlichen Geschlechts. Unter den Teilnehmern waren  195 Schüler/innen, 24 Universitätsstudierende  und 22 Lehrer/innen.   Jeder Workshop war ein Unikat und orientierte sich inhaltlich an den Vorkenntnissen und Interes sen der Teilnehmer. Thematische Schwerpunkte (z.B. Rekursion, Sortieren, Modellieren mit Listen  oder nur allgemeine Grundlagen der Programmierung) wurden vorher mit den Verantwortlichen an der  jeweils besuchten Bildungsinstitution abgesprochen.    Die Workshops waren in eine Spielsituation eingebun den. Es galt, in den Übungen mit der PVS  möglichst viele Punkte zu sammeln. Die Person mit d en meisten Punkten erhielt am Ende einen Preis.  Alle Workshops hatten folgende gemeinsame Struktur:   • Kurze Einführung in die Idee der PVS, das Ziel und den Ablauf des Workshops.   • Registrierung der Teilnehmer.  • Vor jedem Übungsblock mit der PVS wurden in einer P lenumsdiskussion kurz die relevanten As pekte der Python-Syntax angesprochen, um sicher zu stellen, dass die Teilnehmer nicht völlig ü berfordert wurden.  • Vor der Nutzung einer PVS-Applikation wurde das Han dling präsentiert und insbesondere darauf  hingewiesen, dass der Abbruch einer Session zu Punk tverlust führt.  • Übungen mit der PVS nahmen den größten Teil der Zei t ein.  • In den meisten Workshops wurden an einer Stelle die  Ergebnisse von Python Visuals präsentiert  und diskutiert.  • Am Ende gab es die Preisvergabe und ein kurzes Debr iefing, bei dem die Teilnehmer allgemeine  Anmerkungen und Kritik äußern konnten.   Generell konnte man bei den Workshops ein hohes Maß  an Aktivität und Kommunikation beo bachten. Die meisten Teilnehmer arbeiteten allein a n einem Rechner, diskutierten aber kritische Spielsituationen mit ihren Nachbarn. Dies war – im Hinbl ick auf den Lerneffekt –erwünscht. Die Frage ist,  inwieweit dadurch die Validität der Beobachtungen b eeinträchtigt wird. Systematisches Mogeln, z.B.  indem man einfach die Ergebnisse von seinem Nachbar n übernimmt, war nur selten zu beobachten.  Wegen der Vielfalt der Aufgaben – die zudem von den  Applikationen zum Teil in zufälliger Reihen51     folge angeboten werden – und der hohen Geschwindigk eit der Spiele war zu einem Zeitpunkt jeder  Teilnehmer gerade mit einer anderen Aufgabe beschäf tigt. Die meisten Diskussionen entstanden bei  einem Python Quiz, wenn das System ein Modell ander s beurteilt hatte als der Spieler. Es ging dann  z.B. um die Frage, was an dem betrachteten visuelle n Modell falsch ist. Eine solche Diskussion ist für   die Beteiligten lehrreich – weil intuitive Modelle reflektiert werden – im Hinblick auf die Validität des  Sessionprotokolls aber unschädlich, da sie nach  der Entscheidung erfolgt ist.  4.9 Systematisierung intuitiver Modelle der Informa tik  In den folgenden Kapiteln werden eine Reihe von int uitiven Modellen der Informatik inhaltlich be schrieben, ihre Herkunft und Probleme (Anwendungsgr enzen, Konflikte mit anderen Modellen etc.)  diskutiert und – soweit möglich – ihre psychische R ealität insbesondere bei Programmieranfängern  quantitativ eingeschätzt. Dabei setzen wir den Foku s auf einfache, grundlegende und deshalb häufig  verwendete Konzepte. Sie werden im Alltag der Progr ammierung nur selten in aller Ausführlichkeit  visuell oder verbal expliziert, sondern häufig nur stillschweigend verwendet oder sind sogar gänzlich  unbewusst. Nicht Gegenstand dieser Arbeit sind spez iellere Modelle wie z.B. Architekturen für große  Software-Systeme oder Modelle für Vererbungshierarc hien in der Objektorientierten Programmierung.  Die hier untersuchten intuitiven Modelle ordnen wir  folgenden Themen zu: Akteure, Namen, Da ten, Funktionen, Verarbeitung, Steuerung, Klassen u nd Objekte. Da intuitive Modelle Gestaltcharakter  haben und Aspekte aus verschiedenen Bereichen der P rogrammierung in einer geschlossenen Figur  vereinigen, sperren sie sich oft gegenüber einer st rengen taxonomischen Einteilung. So kommt es  zwangsläufig zu gewissen Überschneidungen. Zum Beis piel enthält das Zeigermodell für Variablen  eine besondere Art der Benennung von Objekten und w ird in Abschnitt 6.3 mit anderen Benennung modellen verglichen. Gleichzeitig impliziert dieses  Modell bestimmte Vorstellungen zur Datenverar beitung (z.B. Entstehungsund Vernichtungskonzepte ), die in Abschnitt 10.2 diskutiert werden.  Wie findet man intuitive Modelle? Aus der subjektiv en Sicht der Menschen, die sich mit Pro grammtexten intellektuell auseinander setzen, gibt es unter anderem folgende Quellen für intuitive  Modelle:  • Programmiersprachen (textuell oder visuell)  • Entwicklungsumgebungen (z.B. BlueJ, Delphi)  • Visuelle und verbale Erklärungen in der Literatur ( z.B. Schulbücher, Sprachreferenzen, Klassen dokumentationen)  • Erklärungen anderer Menschen im Rahmen von face-toface-Kommunikationsprozessen (Pro grammierteam, Lehrer etc.)  • Alltagserfahrungen mit informatischen Phänomenen (z .B. Umgang mit Behältern, Büchern, No tizzetteln)  Wer informatische Intuitionen aufspüren und erfasse n will, kann grundsätzlich diese Quellen unter suchen. Welche intuitiven Modelle werden von Progra mmiersprachen wie Visual Basic oder LabView  unterstützt? Welche informatischen Konzepte stecken  hinter dem Gebrauch von selbstklebenden No tizzetteln? Auf welche veranschaulichenden Analogie n wird in Lehrbüchern zurückgegriffen?   Intuitive Modelle der Informatik – die man für sich  als kulturelle Phänomene dokumentieren kann  – haben für Denkprozesse im Zusammenhang mit Comput erprogrammen unterschiedliche Relevanz.  Zur quantitativen Einschätzung ihrer psychischen Re alität werden in dieser Arbeit vor allem die auto matisch aufgenommenen Protokolle der PVS herangezog en.   Die Signifikanz der Daten aus den Sitzungen mit Pyt hon Visual wurde durch Vergleich der beo bachteten Antwortmuster mit einer Gleichverteilung geprüft. An den entsprechenden Stellen wird das  Signifikanzniveau (p-Wert) des χ²-Tests angegeben, das die Wahrscheinlichkeit zum A usdruck bringt,  dass das Ergebnis durch zufälliges Antworten zu Sta nde gekommen ist. Beim Vergleich von Modell bewertungen in Python-Quiz-Sitzungen wurde der zwei seitige exakte Fisher-Test (Summe kleiner pWerte) angewendet. Rechnungen wurden mit MS Excel ( χ²-Test) und SISA (Uitenbroek 2000) durch geführt. 52       5 Akteurmodelle  Wenn man über die Arbeitsweise eines Programms spri cht, unterscheidet man häufig aktive und  passive Entitäten. Man stellt sich vor, dass es sic h um ein strukturiertes System handelt, in dem verschiedene Akteure am Werk sind, die in irgendeiner Weise kooperieren und gemeinsam eine Aufgabe  lösen. Sichtbar werden Akteurkonzepte bei sprachlic hen Formulierungen wie   • „An dieser Stelle macht der Computer dies und das.“    •  „Das Objekt a schickt eine Botschaft an Objekt b“  • „Funktion f ruft Funktion g auf.“  • „Die Funktion gibt den Wert x zurück.“  Betrachten wir folgendes Programm:  def quadrat(n):      print n*n  zahl = input()  quadrat(zahl)  Ein Beispiel für eine typische verbale Erklärung is t folgender Text:  „Das Programm wartet auf eine Eingabe. Sobald der B enutzer über die Tastatur eine Zahl eingege ben hat und <ENTER> gedrückt hat, wird die Funktion  quadrat()  aufgerufen. Sie berechnet das  das Quadrat und gibt das Ergebnis auf dem Bildschir m aus.“  Hier kann man zumindest drei Akteure erkennen, die zum System gehören:   • Ein Akteur wird als „Programm“ bezeichnet. Dieser A kteur wartet zunächst auf eine Eingabe und  ruft später eine Funktion auf.  • Die <ENTER>-Taste (betätigt von einem Menschen, den  wir nicht zum System zählen) löst die  Fortsetzung des Programms aus  • Die Funktion quadrat()  wird vom Programm aufgerufen, verarbeitet den über gebenen Wert  und sorgt dafür, dass etwas auf dem Bildschirm ausg egeben wird.  Daneben gibt es in diesem Modell auch passive Eleme nte:  • Die eingegebene Zahl  • Das Rechenergebnis der Funktion  Es sei darauf hingewiesen, dass dieses Modell mit d er technischen Realität wenig zu tun hat. Aus  technischer Perspektive gibt es eine klare Hierarch ie von Akteuren: Das Betriebssystem ruft den Interpreter auf und startet damit einen Prozess. Der Int erpreter führt das Programm aus und ist damit Ak teur. Bei der Abarbeitung werden Betriebssystem-Bef ehle aufgerufen, damit wird das Betriebssystem  wieder Akteur, das Betriebsystem startet wiederum M ikroprogramme des Prozessors, damit wird die ser aktiv.   5.1 Daten als Akteure – Datenflüsse  In vielen intuitiven Modellen der PVS, die die Arbe itsweise eines Programms darstellen, werden  Daten durch fliegende Zettel dargestellt, die sich selbstständig ihren Weg durch das System suchen.  Ein solcher Zettel kann spontan entstehen (z.B. als  Folge einer Eingabe oder als Kopie eines bereits  existierenden Zettels) bewegt sich dann auf magisch e Weise zu einer Box, die eine Funktion darstellt,  so als wisse er, was nach dem Algorithmus als nächs tes zu tun ist. Im Unterschied etwa zu einer Funk tion oder eines Objektes im Sinne der OOP hat eine solche Daten-Entität primär mit sich selbst zu tun  (z.B. den richtigen Weg finden) und nur in wenigen Fällen Einfluss auf seine Umgebung. Einer dieser  Fälle ist, dass das Datum eine Funktion aktivieren kann, sobald es ihren Eingang passiert. 53     In Datenflussdiagrammen im Sinne des funktionalen P rogrammierparadigmas (Hubwieser 2004, S.  93; Sommerville 1997, S.275 ff.) bewegen sich Daten  auf festen Bahnen von Funktionsblock zu Funk tionsblock. Solche Darstellungen ähneln Materialflu sssystemen, die eine chemische Fabrik modellie ren. Im Grund ist hier der entscheidende Akteur das  Transportsystem. Das Datenflussmodell mit fes ten Wegen (Transportsystem) ist konzeptuelles Herzs tück einer Reihe von visuellen  Programmiersprachen bzw. Entwicklungsumgebungen wie  VIPER (Sanner et al. 2002), LabView  (www.labview.com), DRLP (Anjaneyulu & Anderson 1992 ) oder Alligator (Mosconi et al. 2003). Das  Problem dieser Sprachen ist, dass sie eine vollstän dig deterministische Definition eines Programms  ermöglichen. Deshalb müssen sie z.B. auch Steuerung selemente bereitstellen, mit denen man Pro grammverzweigungen darstellen kann. Modelle mit Dat en-Entitäten als Akteuren, die selbst ihren  Weg finden, können von dem Problem der Steuerung ab strahieren und sind deshalb einfacher.   Datenbewegungen werden gelegentlich bei spielerisch en Aktivitäten (ohne Computer) zur Erarbei tung eines Algorithmus verwendet. Beispielsweise be im Sortieren von Spielkarten werden Karten auf  dem Tisch hin und her geschoben und dabei versucht eine algorithmische Beschreibung des intuitiven  Vorgehens (innerhalb der Mikrowelt sich bewegender Datenobjekte) zu finden. Diese kann später die  Grundlage für die Formulierung einer Sortierfunktio n sein. Neben der Bewegung gibt es noch weitere  Formen der Aktivität von Daten-Entitäten:  • Verarbeitungsprozesse werden manchmal so beschriebe n, dass Daten sich verändern (Metamor phose, siehe Abschnitt 10.3).   • Viele Menschen stellen sich vor, dass bei einer Zuw eisung eine Datenentität die Verbindung zu  einem Namen sucht (siehe Abschnitt 10.5.3).  5.2 Namen als Akteure  Manche Verarbeitungsprozesse können dadurch visuali siert werden, dass ein Namensschild, eine  Stecknadel, ein Zeiger oder sonst eine benennende E ntität sich von Objekt zu Objekt bewegt. Ein Bei spiel ist die Darstellung einer Iteration über eine  Liste der Form (Python):  for i in [1, 2, 3]:     tue etwas  Man kann sich vorstellen, dass während der Ausführu ng der Iteration eine Markierung (etwa ein  Etikett mit der Aufschrift i) sich nacheinander an die Zahlen der Liste heftet und so das aktuelle Item  benennt.  5.3 Funktionen  Funktionen können als Akteure, die z.B. Daten empfa ngen und Daten produzieren (zurückgeben)  können, modelliert werden. Ein Funktionsaufruf wird  dann als Delegation einer Aufgabe an einen  anderen Akteur verstanden. Wir gehen später detaill iert auf Modelle für die Ausführung von Funktio nen ein.  5.4 Allmächtige Steuerungsentität – monoaktive Syst eme  Manche intuitiven Modelle implizieren eine übergeor dnete Entität, die „willkürlich“ die anderen  Objekte verändern kann. Diese allmächtige Entität i st dann der einzige Akteur, die anderen Entitäten  sind passiv und warten auf Manipulationen „von oben “.   Ein Beispiel für eines solches Modell ist die Visua lisierung der Auswertung eines arithmetischen  Terms durch sukzessive Ersetzungen. Zuerst sieht ma n einen komplexen Term, in dem nach und nach  Teile „wie von Geisterhand“ ersetzt oder entfernt w erden.   (2+1)*4  (3) * 4  3 * 4  12  In einer Animation kann die allmächtige Entität auc h explizit visualisiert werden (etwa durch einen  Greifer, der von oben ins Bild kommt und Objekte ma nipuliert) oder auch nur implizit enthalten sein. 54     Im obigen Beispiel ist sie implizit vorhanden, weil  man die Auslösung einer Veränderung (Ersatz ei nes Subtermes) keinem anderen Objekt des Systems zu ordnen kann.  Im Metaphernsystem von Lakoff und Núnez gibt es für  jede Domäne einen „mathematical agent“,  der alle Aktionen vornimmt. Wenn zum Beispiel arith metische Operationen als Manipulation von  Objekten konzeptionalisiert werden, ist der mathema tical agent der Akteur, der Objekte verschiebt.  Für die Addition 2 + 3 könnte er z.B. zwei Äpfel un d drei Äpfel zu einer Kollektion von fünf Äpfeln  zusammenlegen (Lakoff & Núnez 1997, S. 33).  Monoaktiv sind auch die einfachen Computermodelle ( „notional machines“), die bei Programmier anfängern beobachtet werden, wenn sie versuchen die  Arbeitsweise eines Programmes zu erklären (du  Boulay 1989). Das Bild des Computers als einer  Entität, die Anweisungen eines Programms ausführt,   kommt in anthropomorphen Redeweisen wie „Er versuch te gerade, …“, „Er dachte, du meintest …“  zum Ausdruck.   In einem monoaktiven System wird ein Funktionsaufru f nicht als Delegation einer Aufgabe an ei nen eigenen Akteur betrachtet, sondern als Kopieren  und Einschieben von Programmtext.   5.5 Objekte  Objekte im Sinne der objektorientierten Programmier ung sind komplexe Akteure, die über einen  internen Datenbestand, den man abfragen und verände rn kann, und über ein Repertoire von Operatio nen verfügen. Sie reagieren auf Botschaften, durch die sie veranlasst werden, aktiv zu werden.  Im Hinblick auf intuitive Modellierung haben Objekt e den Vorteil, dass sie viel Information in ei ner kohärenten Gestalt zusammenfassen können. Abb. 15 zeigt eine „Summierungsmaschine“. In der  Animation hüpft sie in der Liste von Element zu Ele ment und summiert die über ihren Sensor „abge tasteten“ Werte. Sie ist insofern ein Objekt als si e ein Attribut ( summe ) besitzt, dessen Wert zu jeder  Zeit abgelesen werden kann. Sie beherrscht zumindes t zwei Operationen, die in der Animation ange deutet werden, nämlich das Aufaddieren eines Wertes  zum aktuellen Wert des Attributs Summe und  das Zurücksetzen der Summe auf null.  Ein solches intuitives Objekt kann zur Interpretati on eines nicht objektorientierten Programms  verwendet werden, in dem nur eine Variable namens summe  vorkommt, die initialisiert und in einer  Iteration verändert wird.   summe = 0  for i in liste:      summe += i  Das Modell ist intuitiv und in sich gut verständlic h, aber „strukturell entfernt“ von dem Programm text, der damit erklärt werden soll.     Abb. 15: Ein Objekt als Akteur zur Veranschaulichun g der Idee eines nicht objektorientierten Programms . 55       6 Benennung von Entitäten  Namen für Entitäten der Realwelt werden in früher K indheit gelernt. Sie ermöglichen die interne  gedankliche Repräsentation der externen Welt – nach  Piaget der Beginn der Intelligenz. Namen haben  verschiedene Funktionen. Sie identifizieren eine En tität, ermöglichen den Zugriff (Adressierung),  bringen ihre Funktion innerhalb eines Kontextes zum  Ausdruck und repräsentieren somit auch Bezie hungen zwischen Entitäten. Namen können explizit ab er auch implizit sein. So ist die Position eines  Objektes in einer Sequenz (Index) ein Name für das Objekt. Eine Stecknadel auf einer Landkarte mar kiert (benennt) einen Ort. Wir diskutieren nun eini ge intuitive Modelle, die sich um die Benennung  von Entitäten drehen.  6.1 Behältermodell und Referenzierungsmodell  Eine bekannte Intuition für Variablen ist die Vorst ellung eines Behälters für Daten (Behältermo dell). Der Behälter – z.B. eine Schachtel – ist mit  einem Etikett versehen, das den Variablennamen  trägt. Eine Zuweisung der Form  x = 1  wird so interpretiert, dass der Behälter mit Namen (Etikett) x mit einem neuen Inhalt, einer Repräsen tation der Zahl 1 gefüllt wird. Der vorige Inhalt wird dabei vernich tet. Der Behälter zusammen mit  seinem Etikett dient der Identifikation des momenta n „gespeicherten“ Objektes (Inhalt) und ermög licht den Zugriff.    Ein alternatives intuitives Modell verzichtet auf d as Behälterkonzept und sieht eine Zuweisung al lein als Benennung eines Objektes. Der Variablennam e wird als Name eines Objektes interpretiert  (Referenzierungsmodell). Man sagt auch: Der Name is t an das Objekt gebunden. Im obigen Beispiel  wird der Zahl 1 Name x zugeordnet. Anschaulich kann man sich eine Benennu ng so vorstellen: Man  zeichnet einen Pfeil von dem Namen zum Objekt oder etikettiert ein Objekt mit einem Zettel, das ei nen Namen trägt. Es gibt noch weitere Formen, auf d ie wir später zu sprechen kommen.  Was ist der Unterschied zwischen beiden intuitiven Modellen? Das Behältermodell stellt den Na men einer Variablen in den Vordergrund. Der Behälte r ist eine dauerhafte Entität, sein Inhalt ist flüc h tig und austauschbar. Dagegen ist beim Referenzieru ngsmodell das Objekt die dauerhafte Entität. Der  Name kann geändert werden. Im Referenzierungsmodell  kann ein Objekt erst benannt werden, wenn  es existiert. Unter Umständen ist es anonym und hat  keinen expliziten Namen. Dagegen kann ein Be hälter auch leer sein. Insofern unterstützen dynami sche Programmiersprachen wie z.B. Python, die  ohne Variablendeklarationen auskommen, eher das Nam ensmodell. Denn erst mit einer Zuweisung  wird ein neuer Name eingeführt. Dagegen kann man si ch eine Variablendeklaration bei Java oder Pas cal so vorstellen, dass ein zunächst leerer Behälte r bereitgestellt wird, der erst später mit einem Ob jekt  gefüllt wird. Gravierende Konsequenzen werden sicht bar, wenn man folgende Anweisungsfolge inter pretiert.  x = 1  y = x  Im Namenmodell erhält das Objekt 1 nun einen zweiten Namen, nämlich y. Das entspricht voll kommen dem Alltagsgebrauch von Namen. Für ein und d asselbe Objekt werden häufig verschiedene  Namen verwendet. Wendet man das Behältermodell korr ekt an, so ergibt sich folgende Interpretation:  Der Inhalt der Variablen x wird kopiert und in der Variablen y gespeichert.  56        Abb. 16: Modelle für Mehrfachnamen  Bei Programmieraufgaben deutet die Bevorzugung des Behältermodells für Variablen und der In terpretation einer Zuweisung als Kopiervorgang auf eine Tendenz zur Vermeidung von Mehrfachna men hin. Man arbeitet manchmal lieber mit doppelten  Datenentitäten als mit doppelten Namen für ein  und dasselbe Objekt.  6.2 Erscheinungsmodelle  Bei unveränderbaren Objekten wie z.B. Zahlen ist da s Behältermodell unproblematisch. Schwierig  wird es, wenn es sich um änderbare Objekte handelt wie Listen (Python) oder Instanzen selbst defi nierter Klassen. Betrachten wir die folgende Python -Anweisungsfolge aus der PVS-Applikation Chan ging Lists :  s = [1, 1, 1]  t = s  s[0] = 5  print t  Die Ausgabe auf dem Bildschirm lautet [5, 1, 1]  und nicht etwa [1, 1, 1] . Zur Erklärung  dieses Verhaltens werden vier Visualisierungen ange boten:  (1) Die erste Animation zeigt ein komplett ungeeign etes Modell (Abb. 17). Liste s wird als Behälter mit 3  Fächern dargestellt, in denen sich Zettel mit der Z ahl 1 befinden. Es erscheint ein zweiter zunächst lee rer Behälter gleicher Bauart mit der Beschriftung  t . Von jedem Zettel in s wandert eine Kopie in t.  Der erste Zettel in Behälter s wird durch einen Zet tel mit der Zahl 5 ersetzt. Behälter  t  bleibt unver ändert. Hier müsste die Anweisung print t  die Ausgabe [1, 1, 1]  liefern.    Abb. 17: Ungeeignetes visuelles Modell für das Prog ramm  (2) Auch die zweite Animation verwendet ein Behälte rmodell und interpretiert die Zuweisung t = s als  eine Art Kopiervorgang. Es entsteht ein neuer Behäl ter mit Etikett t, der den gleichen Inhalt wie s hat  (Abb. 18). Allerdings ist der Behälter t keine Kopi e im üblichen Sinne. Stattdessen handelt es sich um   zwei Erscheinungen desselben Objektes. Jede Verände rung von s – wie z.B. die Neubelegung der ers ten Kammer mit der Zahl 5 – wird auf magische Weise  ebenfalls mit t ausgeführt. 57         Abb. 18: Behältermodell für die Veränderung einer L iste mit zwei Namen (Erscheinungsmodell).  (3) Die dritte Animation stellt Liste s als Behälter dar, der ein Schild mit der Aufschrif t s trägt. Es er scheint ein zweites Schild mit der Aufschrift t, das neben dem alten Schild an dem Kasten befestig t  wird. Dem Listenobjekt wird also ein neuer (zweiter ) Name zugeordnet (Abb. 19).    Abb. 19: Modell einer Liste mit zwei Namen  (4) Die vierte Animation schließlich visualisiert d as Programm mit einem Zeigermodell (Abb. 20). Die  Liste s wird durch ein Brett mit drei Zeigern dargestellt,  die auf einen einzigen Zettel mit der Zahl 1  zeigen. Ein Pfeil mit der Beschriftung s zeigt auf das Brett. Die Zuweisung t = s wird dadurch visu alisiert, dass ein zweiter Pfeil mit der Beschriftu ng  t  erscheint, der auf dasselbe Brett verweist.  Schließlich erscheint ein neuer Zettel mit Aufschri ft 5. Der erste Pfeil auf dem Brett, das die Liste dar stellt, löst sich von dem Zettel mit der 1 und zeigt auf die 5.    Abb. 20: Konsistentes Zeigermodell für die Veränderu ng einer Liste mit zwei Namen  In dem Python Visual wurden folgende Fragen gestell t:  • Welche Animation würden Sie verwenden um jemandem z u erklären, wie das Python-Skript funk tioniert?  • An welche Animation können Sie sich am besten erinn ern?  • An welche Animation denken Sie, wenn Sie sich die A usführung des Skriptes vorstellen?  Tab. 4 zeigt die Antworten von 70 Schülerinnen und Schülern, die an einem PVS-Workshop teil genommen haben.  Die Verteilung weicht signifikant von einer Gleichverteilung ab (p = 0.000), die  bei zufälligem Antworten zu erwarten wäre. Die Schü lerinnen und Schüler bevorzugten das Erschei nungsmodell (Modell 2). Dagegen wird das konzeption ell einfachere Zeigermodell abgelehnt und  sogar von weniger Personen gewählt als das falsche Modell 1. 58     Wie in Abschnitt 13.10 erläutert wird, kann die Ann ahme von Erscheinungen als Exhaurierung des  Behältermodells gesehen werden. Wenn dieses Konzept  trotz seiner (unnötigen) Komplexität von  Anfängern zur Interpretation von Programmen verwend et wird, ist das ein Indiz für die hohe Intuitivi tät des Behältermodells.  n = 70 Falsch Erscheinung Zweites Schild Zeiger  Erklären 15 40 11 4  Sich erinnern 12 23 16 19  Sich vorstellen 10 34 17 9  Summe 37 97 44 32  Tab. 4: Wahl verschiedener Modelle zur Veranschauli chung eines Programms. Ergebnisse von 70 ersten Sit zungen wäh rend Workshops mit der PVS. Teilnehmer: 56 Schüler und 14 Schülerinnen aus Deutschland, sie beschäftig ten sich im Schnitt  3.9 Stunden pro Woche mit Programmierung und hatten  ein Durchschnittsalter von 17.0 Jahren.  6.3 Wem gehört ein Name? Zeiger versus Etiketten  Wenn ich bei einem Abendessen am Tisch einen Mensch en mit seinem Namen anspreche, um ihm  eine Botschaft zukommen zu lassen, gehe ich davon a us, dass die Angesprochene den Namen kennt.  Der Name, der im Personalausweis steht, wird als Ei gentum des Benannten gesehen. Er ist Teil der  persönlichen Daten und das Besitzrecht ist sogar du rch Gesetze geschützt.   Wir nennen diese Intuition Etikettmodell . Sie geht davon aus, dass der Name einer Entität z ur be nannten Entität gehört und gewissermaßen Teil von i hr ist. Typische Beispiele aus dem Alltag sind  Etiketten auf Weinflaschen, Schulheften und anderen  Produkten.  Andererseits existieren im sozialen Alltag auch Nam en, die der benannten Person unbekannt sind.  Zum Beispiel erfinden Schüler hinter dem Rücken ihr er Lehrer Spitznamen für sie. Diese Namen ge hören den Individuen, die sie verwenden. Sie eignen  sich zur Identifikation eines Objektes, aber nur  mit Einschränkungen zur Kommunikation mit ihm. Wir nennen dieses intuitive Modell Zeigermodell .  Beispiele für Zeiger im Alltag sind Wegweiser, die sich in einer gewissen Entfernung vom durch sie  benannten Zielort befinden.  In Modellen zur Veranschaulichung von Computerprogr ammen können Namen durch Pfeile oder  Etiketten visualisiert werden. Das Etikett klebt an  einem Objekt und gehört ihm damit. Andererseits  kann man nicht mehr erkennen, wer das Etikett angek lebt und so die Benennung vorgenommen hat.  Beim Pfeil dagegen sind Name und Objekt räumlich ge trennt. Der Pfeil beginnt bei einem Namen, und  dieser Name kann z.B. Attribut eines anderen Objekt es sein. Hier wird also der Besitzer des Namens  mit dargestellt.    Abb. 21: Etikettenmodell   Besitz eines Namens bedeutet nicht zwangsläufig auc h Kontrolle über den Namen. Wer entscheidet  über Benennungen und Umbenennungen? Das benannte Ob jekt oder eine andere Entität? Im Alltag  nimmt man Beziehungen zu anderen Menschen auf, inde m man sich Ihnen vorstellt. Dabei wählt man  selbst den Namen, mit dem man angeredet werden möch te. Im Französischen wird diese Kontrolle  über den eigenen Namen durch die Formulierung „Je m ’appel …“ (wörtlich: „ich nenne mich …“)  besonders deutlich zum Ausdruck gebracht. Etiketten  dagegen werden von anderen Entitäten vergeben  und geändert. Die Vorstellung, dass ein Objekt sein e Namen kontrolliert, verwenden viele Schüler bei  der Interpretation von Zuweisungen. Abb. 22 zeigt e inen Screenshot aus einer Visualisierung, in der  ein Objekt (Zahl 3) sich selbst Namen sucht. 59        Abb. 22: Zahl als aktive Entität, die ihre Namen kon trolliert  6.4 Vermischung von Namensmodellen   Das Python Quiz „Modeling a group“ enthält Animatio nen, die die Arbeitsweise einer Iteration der  folgenden Form (Python) modellieren (Abb. 23):  for n, a in personen:     tue etwas  Das erste Modell verwendet konsequent das Referenzi erungsmodell mit Zeigern. In der zweiten  Animation werden alle Variablen durch Behälter darg estellt. Nach und nach werden Kopien der Daten  aus dem Behälter personen  herausgenommen und in die Behälter n und  a  gelegt. Die dritte Ani mation verwendet eine Kombination aus Zeigern und B ehältern. Die Zeiger n und a „wandern“ über  den Listenbehälter und zeigen nach und nach auf die  Zettel in den Fächern. In der vierten Animation  schließlich wird eine Variante des Behältermodells für Listen in Kombination mit Etiketten verwen det.                Abb. 23: Modelle für eine Iteration über eine Liste  von Paaren   Die Spieler sollten die Modelle als passend oder un passend qualifizieren. Tab. 5 zeigt, dass von 68  Schülerinnen und Schülern, die an Workshops mit der  PVS teilgenommen haben, die meisten alle vier  Modelle akzeptierten. Deutliche Bevorzugungen sind nicht zu beobachten. Offenbar hat in diesem  Beispiel die Konsistenz des Modells keinen Einfluss  auf die Intuitivität. Das inkonsistente Modell 3  gibt eine typische Iteration im Alltag wieder: Man durchsucht z.B. Bücher im Bücherregal (Behälter  für Bücher), indem man nacheinander einen Blick auf  jedes Buch wirft (Neuorientierung eines Zei gers), ohne dabei irgendein Buch zu bewegen.   Bereits Grudin (1989) hat im Zusammenhang mit Benut zungsoberflächen beobachtet, dass es nicht  immer auf die interne Konsistenz des konzeptuellen Modells ankommt. Analogien zu Objekten der  Realwelt sind häufig wichtiger für die Qualität ein es User Interfaces hinsichtlich Erlernbarkeit und  „intuitive“ Anwendbarkeit in neuen Situationen. 60     n = 68 Dauer der   Animation Entscheidungs zeit (Stdabw.) Als passend  beurteilt von  Konfidenz  (Stdabw.)  1. Nur Zeiger  (pq_list_a2_3) 4 s 19.4 s (65.9 s) 57 (84 %) 75% (39%)  2. Nur Behälter mit Kopien  (pq_list_a2_6) 10 s 11.2 s (10.5 s) 49 (72%) 75% (40%)  3. Zeiger und Behälter   (pq_list_a2_8) 7 s 10.3 s (11.1 s) 54 (76.0 %) 80% (33%)  4. Etiketten und Behälter  (pq_list_a2_7) 9 s 12.4 s (17.7 s) 54 (79%) 76% (36%)  Tab. 5: Beurteilung von Modellen zur Veranschaulich ung von Zuweisungen. Berücksichtigt wurden die Antwort en aus  ersten Spieldurchgängen von 68 Schülerinnen und Sch ülern, die an Workshops mit der PVS teilgenommen ha ben.   6.5 Namen als Bezeichnungen für Rollenträger  Namen haben Bedeutungen und sie werden in guten Pro grammen so gewählt, dass die Bedeutung  erkennbar ist. In einem Funktions aufruf  können als Argumente (Positionsargumente) andere N amen  verwendet werden als in der Liste der formalen Para meter in der Funktions definition .  def quadrat (n):     return n*n    seitenlaenge = input()  flaeche = quadrat (seitenlaenge)  Mehrfache Namen kommen auch im Alltag vor. Die selb e Person besitzt neben ihrem Namen, der  im Personalausweis eingetragen ist, Spitznamen von Freunden und weitere Namen, die nur in be stimmten sozialen Kontexten verwendet werden. Versc hiedene Namen für ein Objekt bringen meist  zum Ausdruck, dass ein und dasselbe Objekt verschie dene Rollen spielt. Das Konzept des Namens ist  eng mit dem Rollenkonzept verbunden, das heißt mit der Tatsache, dass ein Objekt in verschiedene  „soziale“ Kontexte eingebunden sein kann.   Im obigen Programmbeispiel wird ein Zahlenobjekt, d as zur Laufzeit über die Tastatur eingegeben  wird, mit zwei unterschiedlichen Namen belegt. Im H auptprogramm repräsentiert es die Seitenlänge  eines Quadrats. Innerhalb der Definition der Funkti on quadrat()  wird das gleiche Objekt durch den  Namen n referenziert. Hier wird das Objekt nicht mehr als Seitenlänge einer Fläche gesehen, sondern  als abstraktes mathematisches Objekt. Es steht in e inem anderen Kontext. Man könnte sagen, es spielt  eine andere Rolle.  Namensgebung ist mit der Spezifikation von Rollen v erbunden und somit ein wichtiger Teil der  Modellbildung (siehe Abschnitt 13.1). Betrachtet ma n ein Programm als System von miteinander ver wobenen Minimodellen, so wird über Mehrfachbenennun g ein und dasselbe Objekt zum Bestandteil  mehrerer Minimodelle.   6.6 Implizite Namen  Unter impliziten Namen verstehen wir solche Namen, die sich aus dem Kontext ergeben, aber nicht  explizit „ausgesprochen“ werden. Beispiele aus dem Alltag sind folgende:  • Eine Stecknadel auf einer Landkarte markiert einen Ort (z.B. Städte, die man schon einmal be sucht hat, Tatorte von Banküberfällen im Zuständigk eitsgebiet einer Kriminalkommission).  • Eine Unterstreichung markiert eine besonders wichti ge Textstelle.  Abb. 24 zeigt Screenshots verschiedener Animationen  aus der Python Visual Sandbox, die die „in  place“-Sortierung einer Liste nach dem Verfahren de r direkten Auswahl (straight selection) veran schaulichen.   s = [10, 4, 1, 3]  for i in range(len(s)): 61       for j in range(i+1, len(s)):       if s [j] < s[i]:          s[i], s[j] = s[j], s[i]  Die Modelle unterscheiden sich in der Implizität de r verwendeten Namen. Die Laufvariablen i  und j sind so genannte Stepper in Sajaniemis Systematik von Visualisierungen (Sajaniemi 2002, siehe  auch Abschnitt 13.1). Sie werden im ersten Modell e ntsprechend seinem Vorschlag durch Papierstrei fen mit Zahlen dargestellt, auf denen die aktuelle Zahl durch ein „Sichtfenster“ hervorgehoben wird.  In den beiden folgenden Animationen werden i und j durch Zeiger und Marken repräsentiert. Ihre Rol le ergibt sich allein aus dem Kontext der Animation . Die vierte Animation geht noch einen Schritt  weiter. Hier wird die Existenz von Steppern nicht e xplizit erwähnt sondern nur dadurch angedeutet,  dass immer zwei Karten ein Stück aus der Kiste hera usgezogen sind. Der bereits sortierte Teil der  Liste wird mit einem Glaskasten „zum Schutz vor Zug riff“ abgedeckt.                 Abb. 24: Modelle für die Sortierung einer Liste nac h dem Algorithmus straight selection (Screenshots)  In dem Python Visual wurden folgende Fragen gestell t:  • Welche Animation würden Sie verwenden um jemandem z u erklären, wie das Python-Skript funk tioniert?  • An welche Animation können Sie sich am besten erinn ern?  • An welche Animation denken Sie, wenn Sie sich die A usführung des Skriptes vorstellen?  Tab. 6 zeigt die Antworten von 16 Personen, die an einem PVS-Workshop teilgenommen haben.  Die Verteilung weicht signifikant von einer Gleichv erteilung ab, die bei zufälligem Antworten zu er warten wäre ( χ²-Test, p = 0.0005). Demnach wird das vierte Modell  mit impliziten Namen bevorzugt.  Zu beachten ist, dass diese Animation eine Informat ion expliziert, die im Programmtext nicht direkt  enthalten ist. Der bereits sortierte Teil der Liste  wird nämlich markiert und mit „ok“ gekennzeichnet.   Eine solche Benennung fehlt im Programmtext und mus s aus der Semantik erschlossen werden. Mög licherweise ist der Erfolg von Modell 4 auf diese Z usatzinformation, die ein wichtiges Element der  Idee des Algorithmus darstellt, zurückzuführen.   Das erste Modell, das die beiden Indexe i und j exp lizit durch eigene Ziffern darstellt, hat offenbar  den geringsten Nutzen bei einer intellektuellen Aus einandersetzung mit dem Programm.  62     n = 16 Streifen Stecknadeln Zeiger anheben  Erklären 2 5 0 9  Sich erinnern 1 8 2 5  Sich vorstellen 1 5 3 7  Summe 4 18 5 21  Tab. 6: Wahl verschiedener Modelle zur Veranschauli chung eines Programms.   Ergebnisse von 16 ersten Sitzungen während Workshops  mit der PVS. Teilnehmer: 15 Schüler und ein Studen t aus Deutsch land, 3 weiblich und 13 männlich, sie beschäftigten sich im Schnitt 2.5 Stunden pro Woche mit Programmi erung und hatten  ein Durchschnittsalter von 18.06 Jahren.  Um die Komplexität eines Modells zu reduzieren und seine Gestaltartigkeit zu erhalten, werden  implizite Namen verwendet, die dann bei einer Forma lisierung durch Programmtext expliziert werden  müssen. Eine Aufgabe bei der Lösung einer Programmi eraufgabe ist es, implizite Namen in einem  intuitiven Lösungsmodell zu entdecken.   6.7 Indirekte Namen  Manchmal wird als Name für ein Objekt keine neue Wo rtschöpfung verwendet, sondern es wird  aus bereits bekannten und verwendeten (belegten) Na men ein Name konstruiert. Der indirekte Name  ist ein Name „über einen Umweg“ Er gibt einen Weg a n, wie man das gemeinte Objekt identifizieren  und ansprechen kann. Im Alltag wird z.B. die Phrase  „Die älteste Tochter meines Bruders Andi“ zur  Bezeichnung einer Person verwendet. Beispiele für i ndirekte Benennungen in Programmtexten sind  • Funktionsaufrufe, z.B. sqrt(2)   • Verwendung von Indizes bei Listen oder Schlüsseln b ei Dictionaries, z.B. s[2]  oder eng lisch["Haus"]  • Verwendung von Literalen.   6.7.1 Funktionsaufrufe und mathematische Terme  Bei Alltagsrechnungen wird die Wurzel aus zwei nich t explizit als Literal angegeben (was auch gar  nicht geht) sondern der Name √2 verwendet. In Animationen, die eine komplexe Rech nung veran schaulichen, kann ein Zettel mit der Aufschrift f(3) , der an eine Karte mit einem Wert geheftet ist,  eine Erinnerung sein, dass dieser Wert von der Funk tion  f  nach Eingabe von 3 zurückgegeben wor den ist. Beim Nachvollziehen der Arbeitsweise einer  rekursiven Funktion kann es hilfreich sein, rekursive Funktionsaufrufe als Namen für ein Objekt zu v erstehen, das zum aktuellen Zeitpunkt noch nicht  bekannt ist. Betrachten wir die folgende Anweisung aus einer rekursiven Funktion, die die Fakultät  berechnet:  return n* fak(n-1)  Es ist denkökonomisch, die Anweisung so zu verstehe n: fak(n-1)  ist ein Name für die Fakultät  von n-1, also eine Zahl. Diese Zahl wird mit n multiplizie rt um, die Fakultät von n zu erhalten. Der  einzige dynamische Aspekt bei dieser Interpretation  ist die Multiplikation zweier Zahlen. Wenn ich  dagegen fak(n-1)  nicht als Name sondern dynamisch als Funktionsaufr uf deute, muss ich in meiner  Vorstellung unter Umständen viele rekursive Aufrufe  durchspielen – eine gewaltige Denkleistung.  In der Mathematikdidaktik (Crowley et al. 1994, Knu th et al. 2006) wurde beobachtet, dass zuwei len mathematische Objekte ohne innere Dynamik dynam isch interpretiert werden. So fassen Kinder  eine Gleichung vom Typ   x = a + b   als Rechenvorschrift auf, also als Anweisung, eine Addition auszuführen. Analog zu dieser Dynami sierungstendenz kann man in unserem Zusammenhang di e Verwendung indirekter Namen als Dedy namisierung  verstehen. Wiederum ist mit der Dedynamisierung ei ne Reduktion der Komplexität ver bunden. Indem ich ein Objekt als n!  (die Fakultät von n) bezeichne, erspare ich mir die Vorstellung  den Wert der Fakultät tatsächlich ausrechnen zu müs sen. Ich blende also einen Teil der Mechanik des 63     Modells aus. Der verbleibende Rest ist einfacher un d intuitiver. Untersuchungen mit der PVS im Zu sammenhang mit Rekursion zeigen jedoch, dass Funkti onsaufrufe und Terme (trotz des kognitiven  Vorteils) eher selten als Benennung verstanden werd en (vgl. Abschnitte 8.8.4, 10.6).  6.7.2 Benennung durch Literale  Literale sind Zeichenketten, die Objekte repräsenti eren. 1, 1.0, 1.00000, 1.0E0, 01 sind unter schiedliche Literale für das gleiche Objekt, nämlic h die Zahl 1. Im Unterschied zum Literal ist eine  Zahl ein ideelles mathematisches Objekt, das auch d ann existiert, wenn es niemals aufgeschrieben  oder sonst wie materiell repräsentiert wird. Progra mmiersprachen erlauben in der Regel, dass man  Objekte über ein Literal ansprechen kann. In diesem  Fall fungiert das Literal als indirekter Name. Bei  spiel: Mit "klein geschrieben".upper()  wird an das Objekt, das durch das Literal  "klein geschrieben" repräsentiert wird, eine Botschaft geschickt (Aufru f der Methode up per() ). Gegenüber anderen Benennungsverfahren weisen Lit erale folgende Besonderheiten auf:  • Ein Literal für ein Objekt muss nach einem vorgegeb enen Verfahren gebildet werden, das in der  Grammatik der Programmiersprache spezifiziert ist.   • Ein Literal kann Informationen über den Typ des Obj ektes enthalten, das es bezeichnet. Bei  Python z.B. bezeichnet ein Literal aus Dezimalziffe rn, das mit einer Ziffer ungleich null beginnt,  immer eine ganze Zahl (Typ int ).  • Explizite Namen können privates Wissen darstellen. Literale dagegen müssen von allen Objekten  eines Systems interpretiert werden können. Sie sind  immer öffentlich.  6.8 Assoziationen  In den bisher erwähnten Benennungsmodellen ist der Name etwas grundsätzlich anderes als das  Objekt, das er benennt. Alle gängigen imperativen P rogrammiersprachen (Programmiersprachen, die  Zuweisungen verwenden) gehen von dem Grundsatz aus,  dass ein Bezeichner ein Objekt spezifiziert,  aber nicht selbst ein Objekt ist. Bei Zuweisungen s teht links vom Zuweisungsoperator ein Name (Be zeichner) n und rechts davon irgendeine Spezifikation eines Ob jektes o, die man sich als das Objekt  selbst vorstellt. Nach Ausführung der der Zuweisung  ist n ein Name für o. Die rechte Seite einer Zu weisung kann auch ein Name sein. Aber nicht dieser Name sondern das gemeinte Objekt wird neu  benannt. Nach den Zuweisungen  a = 3  b = a  ist b nicht ein Name für den Namen a sondern ein Name für das Objekt 3. Visualisierungsübungen  mit Schülern zeigten jedoch, dass Zuweisungen manch mal als Herstellung einer Assoziation interpre tiert werden. In Abb. 25 wird die Zuweisung   wort = "Hallo"   mit Vokabelnlernen verglichen. Das Ergebnis ist ein e gedankliche Verbindung zwischen zwei Wör tern.   64        Abb. 25: Illustration des 17-jährigen Schülers T. ( Jahrgangsstufe 11)  Die Unterschiede zwischen Assoziationen und Benennu ngen im Sinne einer Zuweisung sind fol gende:  (1) Die assoziierten Objekte repräsentieren Inhalte  und sind in diesem Sinne gleichartig. D.h. es wird  nicht  zwischen Namen und benanntem Objekt unterschieden. Die Vorstellung der Gleichartigkeit von Name  und benanntem Objekt wird z.B. verwendet, wenn Pers onen Zuweisungsfolgen durch Kettenbildung  modellieren. In diesem Fall wird der Zustand nach d en Zuweisungen  a = 3  b = a  durch die Assoziationskette b /barb2right a /barb2right 3 dargestellt (siehe Abschnitt 10.5.3).   (2) Die Assoziation ist symmetrisch. Wenn a mit b assoziiert ist, dann auch b mit a. Bei Workshops mit  der PVS konnte beobachtet werden, dass viele Schüle r „umgedrehte Zeigermodelle“ mit Zeigern, die  vom Objekt zum Namen verweisen, für passende Visual isierungen von Zuweisungen halten (siehe Ab schnitt 10.5.3).   (3) Assoziationen werden kumuliert. Das bedeutet zw eierlei: Erstens wird mit der Entstehung einer neue n  Assoziation eine bereits existierende nicht gelösch t. Zweitens werden durch eine neue Assoziation  gleichzeitig noch weitere Einheiten miteinander ver netzt. Wenn a mit b assoziiert ist und a mit c,  dann ist auch b mit c assoziiert. Dagegen besteht bei zwei Zuweisungen d er Form  a = b  a = c  keine Verbindung zwischen  den Objekten b und c. Außerdem wird mit der zweiten Zuweisung die  Bindung von a an b aufgehoben.   6.9 Benennung als Unterordnung  Eine Zuweisung wort = "Hallo"  wird manchmal auch als Unterordnung interpretiert (siehe  Abb. 26). Name und benanntes Objekt stehen in einem  hierarchischen Verhältnis zueinander. Damit  wird dem Namen die Bedeutung eines Oberbegriffs zug emessen. Die untergeordneten Objekte sind  Exemplare einer Kategorie, die im Namen zum Ausdruc k kommt. So ist "Hallo"  ein Beispiel für ein  Wort. 65        Abb. 26: Illustration der 17-Jährigen Schülerin J. zur Visualisierung der Unterordnung eines Objektes unter einen Na men  Die Interpretation einer Zuweisung als Unterordnung  kann als Spezialfall einer Rückmodellierung  interpretiert werden. Darunter verstehen wir den Ve rsuch zu einem Programmtext einen Wirklich keitsausschnitt (Original) zu finden, der durch den  Programmtext modelliert wird. In der Tat modellieren Zuweisungen häufig Subsumierungssituationen. Be trachten wir als Beispiel die Aufgabe, einen  Würfel zu modellieren. Ein Programm soll eine Zufal lszahl zwischen 1 und 6 ausgeben. Etwas forma ler ausgerückt lautet eine Teilaufgabe des Problems : „Erzeuge ein Objekt, das in die Kategorie Zu fallszahl zwischen 1 und 6  fällt.“ Das folgende Python-Programm löst die Aufg abe:  from random import *  zufallszahl = randint(1,6)  print zufallszahl  Das Objekt, das der Funktionsaufruf in der zweiten Zeile zurückgibt, ist eine ganze Zahl. Die Zu weisung ist hier tatsächlich das Modell der Unteror dnung eines Objektes (Zahl) unter einen Begriff. 66       7 Daten  Unter Daten verstehen wir Information, die so reprä sentiert ist, dass sie vom Computer verarbeitet  werden kann. Aus Sicht der OOP kann man ein Datum a ls Zustand eines Objektes verstehen, der  durch die Belegung der Attribute gegeben ist. Wir v erwenden den Begriff Wert synonym für Datum  (Singular von Daten).   7.1 Ansicht versus Literal  Daten werden in Programmtexten durch Literale darge stellt. Für die Bildung von Literalen gibt es  Syntaxregeln in der Grammatik der Programmiersprach e. Man kann zwischen der Ansicht eines Wer tes und seiner Beschreibung durch ein Literal unter scheiden. Beide Begriffe beziehen sich auf die  Repräsentation eines Wertes. Im Unterschied zum Lit eral ist die Ansicht eines Wertes unabhängig von  der Programmiersprache. Ansichten sind Teil unserer  Vorstellungswelt. Sie zeigen Daten, wie sie von  uns wahrgenommen und verstanden werden. Sie repräse ntieren die Bedeutung eines Literals. Sie sind  somit kein informationstechnisches sondern ein psyc hologisches und kulturelles Phänomen.  Bei Zahlen ist häufig die Unterscheidung zwischen L iteral und Ansicht schwierig. Mit 1 kann man  sowohl ein abstraktes mathematisches Objekt (Ansich t) als auch ein Literal zur Repräsentation dieser  Zahl meinen. Gleichwohl kann die Zahl 1 (Ansicht) a uch durch andere Literale dargestellt werden, in  Python z.B. 01 , 0x1, 1.0 .  In der Interpretation von Programmtexten durch intu itive Modelle verwendet man Ansichten von  Daten an Stelle der Literale, wenn dadurch die Intu itivität gesteigert werden kann. Hier spielen vor  allem Abstaktion und Gestaltbildung eine Rolle. Die  Ansicht eines Datums abstrahiert von Fragen der  technischen Repräsentation und sie betont die Bedeu tung, was die Bildung einer sinnhaften Gestalt  erleichtert.   7.2 Verwechseln von Wert (Datum) und Literal  Der Unterschied zwischen Literal und Wert ist sehr feinsinnig. Bei numerischen Objekten ignoriert  man ihn häufig ohne dass dies zu Problemen führt. I ntuitiv setzt man Dezimalzahlen (Literale) mit den  repräsentierten mathematischen Werten gleich und tu t z.B. so, als ob es von einer Zahl mehrere Ex emplare geben kann.  „An der Tafel stehen Zahlen, von denen einige gleic h sind: 1, 2, 4, 1, 1“  „Schreibe eine Drei auf.“  In manchen Formulierungen wird jedoch tatsächlich z um Ausdruck gebracht, dass bestimmte Ob jekte (z.B. Zahlen) einmalig sind: „Nach der deutsc hen Rechtschreibung beginnt das Wort Schule  mit  einem großen Buchstaben.“ (Es gibt nur ein Wort Schule .) Es gibt Situationen, in denen die Differen zierung zwischen Literal und Wert von Bedeutung ist . Mathematische Operationen sind für Werte  definiert und nicht für Literale. In den folgenden Beispielen, die in Python formuliert sind, liefert der  Gleich-Operator ==  jedes Mal den Wert True , obwohl die Literale sich unterscheiden:  "Hall\0xf6" == "Hallo"  "Wort" == 'Wort'  1.0 == 1 == 0.1E1  010 == 8   7.3 Figürliche Ansichten  Intuitive Modelle von Programmen sind häufig kleine  Beispielprogrammläufe, die die algorithmi sche Idee repräsentieren. Daten, die von dem Progra mm verarbeitet werden, sind austauschbar und  kommen im zu interpretierenden Programmtext unter U mständen gar nicht vor.   Eine Möglichkeit die Intuitivität eines Modells zu verbessern ist die Verwendung von vertrauten,  kognitiv gut zugänglichen Objekten zur Repräsentati on von Daten. Wir nennen sie figürliche Ansich67     ten. Ein Beispiel ist, wenn man zur Visualisierung eines Sortieralgorithmus Figuren unterschiedlicher  Größe als Platzhalter für Zahlen, Tupel oder andere  Daten verwendet (Abb. 27).                                     Abb. 27: Figuren als Platzhalter für Zahlen  7.4 Nichts  Ein besonderes Thema im Zusammenhang mit der Repräs entation von Daten ist die Repräsentation  des Nichts. Leere Objekte können in verschiedenen Z usammenhängen eine wichtige Rolle spielen:  • Eine Prozedur kann als Funktion aufgefasst werden, die ein leeres Objekt (bei Python das Objekt   None ) zurückgibt. Andererseits gibt eine Funktion, die nicht terminiert, auch nichts zurück, doch  dieses Nichts kann nicht durch ein Objekt „material isiert" werden.  • Leere Objekte (z.B. Listen, Dictionaries oder Menge n) werden bei der Initialisierung eines Con tainers verwendet, in dem z.B. in einer Iteration b estimmte Daten gesammelt werden.  • Für eine leere Zeichenkette gibt es keine eindeutig e Ansicht. Sie kann nur durch ein Literal (z.B.  "" ) von einer Zeichenkette aus Whitespaces (Leerzeich en, Tabulatorzeichen etc.) unterschieden  werden.  Beobachtungen mit der PVS zeigen, dass Schülerinnen  und Schüler Probleme mit der Beurteilung  von Visualisierungen leerer Objekte haben. Abb. 28 zeigt einige passende und unpassende Modelle für  die leere Liste [] mit Länge 0. Das erste Modell ist bei Anwendung der  sonst in der PVS verwende ten Bildersprache eine Liste mit einem leeren Eleme nt (z.B. leerer String) und damit unpassend (eine  leere Liste enthält kein einziges Element). Das zwe ite Modell beschreibt die Python-Liste [None,  None, None, None, None] , also eine Liste der Länge 5 mit fünf leeren Objek ten und ist damit  ebenfalls ungeeignet. Das dritte Bild kann als Behä lter mit null Fächern interpretiert werden und ist  passend. Das vierte Bild stellt einen Zeiger dar, d er ins Leere (auf ein unbestimmtes Nichts) zeigt, i st  somit weniger spezifisch, verstößt aber nicht wie d ie ersten beiden Modelle gegen Merkmale einer  leeren Liste.     Abb. 28: Geeignete und ungeeignete intuitive Modell e zur Darstellung einer leeren Liste   Tab. 7 gibt die Einschätzungen von 68 Schülerinnen und Schülern wieder. Die Beurteilungen pas sender und unpassender Modelle unterscheiden sich k aum. 68       n = 68 Als passend beur teilt von Konfidenz  (Stdabw.) Als unpassend  beurteilt von Konfidenz  (Stdabw.)  Behälter mit leerem Zettel  (pq_list_a1_1) 41 (60%) 61% (40%) 27 (40%) 68% (42%)  Behälter mit leeren Fächern  (pq_list_a1_2) 47 (69%) 62% (45%) 21 (31%) 50% (45%)  Behälter ohne Fach  (pq_list_a1_4) 41 (60%) 56% (45%) 27 (40%) 54% (46%)  Unbestimmtes Nichts   (pq_list_a1_5) 44 (65%) 52% (46%) 24 (13%) 73% (39%)  Tab. 7: Beurteilung von Modellen zur Darstellung ei ner leeren Liste. Berücksichtigt wurden die Antworten  aus ersten  Spieldurchgängen von 68 Schülerinnen und Schülern, die an Workshops mit der PVS teilgenommen haben.    7.5 Platzhalter für variable Teile in Dokumenten  In vielen Zusammenhängen verwenden wir die Vorstell ung eines Dokumentes (z.B. Text), das aus  konstanten (unveränderlichen) und variablen Teilen besteht. Die variablen Teile werden auf bestimmte  Weise durch Platzhalter markiert und während der In terpretation des Dokumentes durch andere Zei chenfolgen ersetzt. Im Verlaufe dieses Ersetzungspr ozesses entsteht sukzessive eine vollständig interpretierte Ausprägung des Dokumentes, in der keine P latzhalter mehr enthalten sind.   Die Programmiersprache PHP wird verwendet um „dynam ische HTML-Seiten“ zu generieren. Die  Idee ist, dass ein Webseite durch (statischen) HTML -Text definiert wird, der einige Stellen enthält, d ie  erst zur Betrachtungszeit durch den PHP-Präprozesso r mit Inhalt (d.h. HTML-Text) gefüllt werden.  Im eigentlichen PHP-Programmtext wird algorithmisch  festgelegt, durch welche Werte (Zeichenket ten, die der HTML-Syntax entsprechen) die Platzhalt er zum Zeitpunkt der Betrachtung ersetzt werden  sollen.   Programmiersprachen wie C oder Python erlauben die Definition „formatierter Zeichenketten“.  Anstatt eine Zeichenkette durch Konkatenation aus m ehreren Teilen zusammenzusetzen, definiert man  eine Zeichenkette mit Platzhaltern. Man gibt sozusa gen ein Muster vor, von dem durch Einsetzungen  unterschiedliche konkrete Ausprägungen erzeugt werd en. Beispiel (Python):   >>> text1 ="%s geht nach %s." % ("Axel", "Berlin")  >>> print text1  Axel geht nach Berlin.  Das Beispiel zeigt eine Möglichkeit, wie variable Z eichenketten mit Python mit Platzhaltern spezi fiziert werden können. Äußerlich ist ein Formatieru ngsplatzhalter bei Python eine Zeichenkette, die  mit dem Prozentzeichen % beginnt. Danach kann in Kl ammern ein Variablenname folgen. Der Platz halter endet schließlich mit einer Angabe zum Forma t der Texteinfügung. Dabei bedeutet s, dass es  sich um einen String handeln muss. Insbesondere bei  numerischen Werten (z.B. float) kann man wei tere Angaben zur textuellen Darstellung machen wie z.B. Anzahl der Nachkommastellen oder Ge samtzahl der Stellen, die für den Wert reserviert w erden sollen.  Die Auswertung eines Ausdrucks in einem Computerpro gramm stellt man sich häufig so vor, dass  sukzessive Subterme mit Variablen, Operatoren und F unktionsbezeichnern durch Literale ersetzt wer den (siehe Abschnitt 5.4).  Platzhalter sind keine Namen für Objekte. Sie könne n aber Namen für Objekte enthalten. Der Na me dient dazu, einen Wert zu identifizieren, durch den der Platzhalter bei der Interpretation ersetzt  wird. Beispiel (Python):  >>> text2 = "%(name)s geht nach %(stadt)s." % vars( )  >>> print text2  Axel geht nach Berlin. 69     Es gibt auch Platzhalter ohne explizite Namen. Im e rsten Beispiel dieses Abschnitts ist die Position  des Platzhalters im Dokument entscheidend für die W ertzuweisung.   Eine Verwechslung von Platzhaltern mit Namen liegt vor, wenn jemand glaubt, bei einer Zuwei sung werde ein Name durch einen Wert ersetzt oder b ei einer Neuzuweisung werde erst ein Objekt  einschließlich seines Namens vernichtet (siehe Absc hnitt 10.2.3).  7.6 Daten als Entitäten oder Zustände von Objekten  Ein Datum (Wert) kann man als eigene Entität begrei fen (Entität-Modell), oder als Zustand eines  Objektes (Zustand-Modell). Abb. 29 zeigt Screenshot s aus drei Animationen der PVS, die die Ausfüh rung der beiden Zuweisungen  a = 3  b = a   veranschaulichen. Im ersten Modell wird der Wert 3 der Variablen a durch einen beschrifteten Zettel  repräsentiert. Bei die Zuweisung b = a entsteht eine Kopie des Zettels in Behälter a und f liegt in  den Behälter b, der kurz zuvor ins Bild gekommen is t. Hier sind Daten separate Entitäten, die – wie  materielle Dinge – kopiert und bewegt werden können .  In den beiden anderen Modellen wird ein Wert als Zu stand eines Objektes dargestellt. Im mittleren  Modell (pq_assign_a1_1) wird der Wert 3 durch die Position einer Drehschreibe an den Objek ten a  und b repräsentiert. Der Wert ist also keine eigene  Entität, sondern immateriell und integraler Bestan d teil eines Objektes. Die Zuweisung b = a  wird dadurch visualisiert, dass Objekt b durch ein en über geordneten Akteur (Greifarm, der von oben ins Bild kommt und die Drehscheibe von b bewegt) in den  gleichen Zustand wie Objekt a gebracht wird. Im rec hten Modell (pq_assign_a1_3) werden zwei un terschiedliche Visualisierungen für den Zustand „3“  verwendet.          Abb. 29: Screenshots aus drei Animationen zur Visua lisierung von Zuweisungen. Von links nach rechts: pq _assign_a1_5  (Entität-Modell), pq_assign_a1_1 (Zustand-Modell) u nd pq_assign_a1_3 (Zustand-Modell).  Die Mehrheit der beobachteten Schülerinnen und Schü ler, die an PVS-Workshops teilgenommen  haben, sehen alle drei Animationen als geeignete Vi sualisierungen (siehe Tab. 8). Allerdings hat die  Animation, die ein Entitätsmodell für Daten verwend et, eine deutlich höhere Akzeptanz (86.4%) als  die beiden Animationen mit Zustandsmodellen (p < 0. 0001).  n = 154 Dauer der A nimation Entscheidungs zeit (Stdabw.) Als passend  beurteilt von  Konfidenz  (Stdabw.)  Wert (Datum) als eigene Entität  (pq_assign_a1_5) 6 s 9.06 s  (7.39) 133 (86.4%) 8.77 (2.76)  Wert als Zustand eines Objektes  (pq_assign_a1_1) 14 s 19.93 s  (10.96) 100 (64.9%) 8.30 (3.03)  Wert als Zustand eines Objektes  (pq_assign_a1_3) 14 s 15.92 s (11.04) 103 (66.7%)  8.83 (2.54)  Tab. 8: Beurteilung von Modellen zur Veranschaulich ung von Zuweisungen. Berücksichtigt wurden die Antwort en aus  ersten Spieldurchgängen von 154 Schülerinnen und Sc hülern, die an Workshops mit der PVS teilgenommen h aben.   Ein Problem des Zustand-Modells für Daten ist, dass  bei einer Zuweisung der Form b = a  der  Bezug zwischen den beiden Variablen a und b nicht so einfach abgebildet werden kann. Beim Enti tät-70     Modell (linke Animation in Abb. 30) entsteht eine K opie des Inhalts von a, die zu b wandert. Dagegen  wird bei den beiden Animationen, die ein Zustand-Mo dell verwenden, der Zustand von b auf „3“ ein gestellt ohne dass expliziert wird, woher dieser We rt stammt.    Abb. 30: Zuweisung b = a als Manipulation des Zustan des von Objekt b durch Objekt a.  Abb. 30 zeigt eine Möglichkeit, diesen „Datentransp ort“ von a nach b mit dem Zustand-Modell  wiederzugeben. In dieser Animation manipuliert Obje kt a mit Hilfe eines Greifarms den Zustand von  b. D.h. die Zuweisung b = a  wird als Auftrag an Objekt a interpretiert, seinen eigenen Zustand auf  Objekt b zu übertragen. 108 (70.1 %) der 154 beobachteten S chülerinnen und Schüler hielten dieses  Modell für geeignet. 71       8 Funktionen  Funktionen ermöglichen die strukturelle Zerlegung e ines komplexen Problems in weniger komple xe Probleme und realisieren damit eine fundamentale  Idee der Informatik (Schwill 1993). In der Ma thematik definiert man eine Funktion als eine einde utige Zuordnung der Elemente einer Menge A zu  den Elementen einer Menge B. Jedem Element von A da rf höchstens ein Element von B zugeordnet  sein. In der Informatik wird eine Funktion meist al s Akteur beschrieben, der eine Aufgabe lösen kann.  In Programmtexten werden Funktionen als eigenständi ge Objekte oder Methoden einer Klasse defi niert und können an anderer Stelle auf verschiedene  Weise aufgerufen werden:  • Als eigenständiges aufrufbares Objekt, z.B. in der Anweisung x = sqrt(2) ,  • als Botschaft an ein Objekt, z.B. x = rechner.sqrt(2) ,  • als statische Methode einer Klasse, ohne dass zuvor  ein Objekt instanziert worden ist, z.B. x =  Math.sqrt(2) ,  • über einen Operator in einem mathematischen Term, z .B.  x = y + 2 .  Aufrufe von Methoden können auch als Aufrufe eigens tändiger Funktionen und nicht als Botschaf ten an Objekte betrachtet werden. Der Name des Obje ktes (oder bei statischen Methoden der Name  der Klasse) wird dabei einfach als Teil des Funktio nsnamens gesehen.   In der Definition einer Programmiersprache sind Syn tax und Semantik von Funktionsaufrufen ein deutig festgelegt. Dennoch verwenden Programmierer bei Problemlösungen, bei der Interpretation von  Programmtexten oder in der Kommunikation über Progr amme je nach Kontext unterschiedliche  Cluster von intuitiven Modellen, die jeweils bestim mte Aspekte des „Phänomens“ Funktion repräsen tieren. Das Statement  x = f(2)  kann z.B. auf folgende Weise gelesen und verstanden  werden:   „Die Funktion mit dem Namen f wird aufgerufen und erhält als Eingabe die Zahl 2. Dieser Wert  wird von f verarbeitet und das Ergebnis (ein Wert) zurückgege ben. Dieser Wert wird der Variablen x  zugewiesen.“  In dieser verbalen Beschreibung werden zumindest dr ei intuitive Modelle über Funktionen ver wendet.   • Die Funktion wird aufgerufen. Hier wird unterstellt , dass die Funktion ein Akteur ist, der schon  vor der Ausführung der Anweisung existiert und dara uf wartet, aufgerufen zu werden. Etwa so  wie ein Schraubenzieher in einer Werkstatt zur Benu tzung bereit liegt oder ein Handwerker, den  man zur Erledigung eines Auftrags anrufen kann.   • Der Funktion wird ein Wert übergeben. Dieses Konzep t der Übergabe ist intuitiv und aus dem  Alltag bekannt. Man übergibt einen Zettel an jemand en. Der übergebene Wert hat – wie ein Ge genstand – den Besitzer gewechselt und die Funktion  kann als neuer Besitzer „damit machen was  sie will“.   • In der Formulierung „zurückgeben“ steckt die Annahm e, dass die Funktion selbst (und niemand  anderes) dafür sorgt, dass das Berechnungsergebnis an einen bestimmten Akteur des Systems  (nämlich den Auftraggeber) übergeben wird. Das impl iziert, dass sie sich ihren Auftraggeber mer ken muss.  In anderen Zusammenhängen dagegen (z.B. bei der Int erpretation rekursiver Funktionen) sieht man  die Ausführung des Textfragments f(2)  eher als Generierung eines neuen Akteurs (Prozess) , der  vorher noch nicht existierte und erst im Moment des  Aufrufs nach dem Bauplan der Funktionsdefiniti on erstellt und aktiviert wird. 72     8.1 Funktion als Box mit Einund Ausgang für Daten   Eine populäre Metapher beschreibt eine Funktion als  statische Einheit mit Einund Ausgang. Über  den Eingang nimmt die Funktion Werte auf, verarbeit et diese und liefert über ihren Ausgang ein Er gebnis zurück. Einund Ausgang sind die einzigen V erbindungen (Schnittstellen) zur Umgebung. Die  Datenübergänge werden analog zu einem Materialtrans port dargestellt. Sobald die Ausgabedaten die  Funktion verlassen haben, ist der Verarbeitungsproz ess der Funktion beendet. Sie kümmert sich z.B.  nicht mehr darum, ob die produzierten Daten den Emp fänger erreichen.    Abb. 31: Funktion (eigentlich statische Methode ein er Klasse) als Materialverarbeitungseinheit mit Ein und Ausgang.  Visualisierung der 17-jährigen C.  Dieses Modell wird in datenflussorientierten visuel len Programmiersprachen wie LabView oder  VIPER oder im Datenflussmodell der funktionalen Mod ellierung verwendet (siehe Abschnitt 5.1).  Eine (einfachere) Variante ist die Vorstellung eine s „magischen Bechers“, der ein Objekt aufnimmt  und das Berechungsergebnis aus der gleichen Öffnung  wieder ausgibt. Diese Vorstellung klingt in der  lexikalischen Metapher „zurückgeben“ an.     Abb. 32: Funktion (eigentlich Aufruf einer Methode)  als „magischer Becher“, der Objekte „verwandelt“.   Visualisierung des 17-jährigen Schülers M.  Man verwendet sie z.B. in folgenden sprachlichen Äu ßerungen:   • „Der Funktion quadrat()  wird die Zahl 3 übergeben, sie liefert als Ergebnis die Zahl 9“.  • „Beim Aufruf f(3)  erhält die Funktion f den Wert 3.“  • „Die Funktion random()  liefert eine Zufallszahl zwischen 0 und 1, wenn sie ohne Argument  aufgerufen wird.“  Es gibt eine Reihe von Alltagsanalogien für das Dat enflussmodell:  • Fahrscheinautomat: Man gibt Münzen ein und erhält e ine Fahrkarte  • Toaster: Eingabe von Weißbrot, Ausgabe von heißem T oast. 73     Das Modell ist kompatibel mit dem Behältermodell fü r Variablen (Variablen als Behälter für Da ten). Die Funktion nimmt einen Wert auf (z.B. Kopie  eines Variableninhalts), behält diesen (er wird zu   ihrem Eigentum) und liefert einen neuen Wert.   In einer Variante des Datenflussmodells bleiben die  Eingabedaten im Eingang stecken. Auf diese  Weise kann man später noch erkennen, mit welchen We rten die Funktion arbeitet. Das spielt bei dra matischen Modellen eine Rolle, in denen mehrere Fun ktionen interagieren und die Ausführung einer  Funktion relativ lange dauert.  Das Datenflussmodell mit Einund Ausgang kann auch  auf Prozeduren angewendet, also auf Funk tionen, die nichts zurückgeben, und zwar in zweifac hem Sinne:  • Eine Prozedur wird als Funktion interpretiert, die ein leeres Objekt zurückgibt.  • Wenn eine Prozedur ein Objekt verändert, so kann ma n sich das ursprüngliche Objekt als Eingabe  und das veränderte Objekt als Ausgabe vorstellen. D ie folgende Abbildung zeigt ein Datenfluss modell für eine Prozedur, die alle Elemente einer L iste von Zahlen quadriert (Python):  def quadriereListe (liste):      for i in range(len(liste)):            liste[i] =  liste[i] **2  1 4 2 1 416    Abb. 33: Visualisierung einer Prozedur als Box mit Einund Ausgang  8.2 Dateneingabe über „Sensoren“  Zur Darstellung des Eingabemechanismus kann die Met apher eines Messgerätes mit Sensoren he rangezogen werden. Alltagsanalogien sind:  • Ein Stück Indikatorpapier, das durch seine Farbe de n pH-Wert einer Lösung anzeigt (einstellige  Funktion)  • Ein Spannungsmessgerät, das die Potenzialdifferenz zwischen zwei elektrisch geladenen Gegenständen erfasst (zweistellige Funktion).  • Ein Finger, der die Temperatur eines Gegenstandes e rfühlt (einstellige Funktion).      Abb. 34: Eingabe über Sensoren (PVS) 74     Der Eingabemechanismus dieses Modell verzichtet auf  die Intuition eines Transports von Daten.  Eíngabeobjekte bleiben außerhalb der Box. Über eine n Greifarm oder ähnliches wird eine Verbindung  von der Funktion zum Objekt hergestellt. Der Eingab emechanismus ist ein Sensor, der einen Wert  abtastet.  8.3 Übergabe von Referenzen bei der Eingabe  Funktionen können auf Objekte zugreifen, ohne sie s ich einzuverleiben. Die Eingabeobjekte (die in  der Parameterliste aufgeführt werden) bleiben außer halb der Box.   Sofern die Funktion ein referenziertes Objekt auch verändert, be arbeitet sie es, anstatt es zu ver ar beiten. Der Zugriff kann z.B. durch Manipulatoren v isualisiert werden, Greifer, die z.B. aus einer Lis te  Elemente herausnehmen und verändern. Insbesondere d er konkurrente Zugriff mehrerer Funktionen  auf ein Objekt kann auf diese Weise veranschaulicht  werden. Eine Alltagsanalogie ist das Schnitzen,  d.h. das Bearbeiten eines Holzstückes mit unterschi edlichen Messern.  Bei der Eingabe wird spezifiziert, auf welche Objek te die Funktion zugreifen kann („call by refe rence“). Diese Bindung kann auf unterschiedliche We ise visualisiert werden:  • Die Funktion wird in die Nähe des zu bearbeitenden Objektes gebracht (Analogien: Schnitzmes ser, Messgerät, Zauberstab, Mauszeiger und Mausklic k)  • Zu bearbeitende Objekte werden durch zusätzlichen N amen (Etikett, Pfeil) markiert. Eine Analo gie aus der Forstwirtschaft ist die Markierung eine s Baumes, der gefällt werden soll.  • Die Referenz wird durch eine Linie dargestellt.  Wenn Eingabeobjekte einfach sind, kann eine Referen z mit der Vorstellung des Abtastens von  Werten gekoppelt werden. In der Mikrowelt Logotron (aus Lehotská, 2006) werden Referenzen durch  gestrichelte Linien dargestellt, die von einem (num erischen) Objekt zu einem Eingang (kleine Raute)  eines Operators führen (Abb. 35). Man kann sich vor stellen, dass über diese „Leitung“ der momentane  Wert des „angeschlossenen“ Objektes „übertragen“ wi rd.      Abb. 35: Verknüpfung von Operatoren (Funktionen) un d Objekten bei Logotron (aus Lehotská 2006)  8.4 Ursprung der Eingabespezifikation  Ein weiterer Aspekt bei der Modellierung von Eingab e ist die Frage, welche Entität die Argumente  spezifiziert. Programmtechnisch ist der Fall klar: Beim Aufruf einer Funktion werden in Klammern  die Argumente aufgeführt. Die Aktivität geht also v om aufrufenden Akteur aus. In Modellen zur Visu alisierung von Programmabläufen kann das jedoch auc h genau anders herum dargestellt werden: Die  Funktion holt sich selbst die Eingabedaten. Dieser Fall liegt beispielsweise vor, wenn eine boolesche  Funktion, die einen Größer-Vergleich realisiert, al s Akteur mit Sensoren dargestellt wird und dieser  Akteur über die Szenerie wandert und gezielt bestim mte Objekte abtastet und vergleicht.   8.5 Vergleich von Eingabemechanismen   Im Python Quiz Modeling a group geht es in Aufgabe 4 um die Visualisierung des Funk tionsaufru fes   olderThan(group, 19).  75     Dabei beschreibt das erste Argument group  eine Personengruppe durch eine Liste von Tupeln de r  Form (name, alter) . Das zweite Argument ist eine Altersangabe. Die Fu nktion liefert eine Liste  von Namen aller Personen, die älter sind. Es werden  unter anderem folgende Modelle angeboten (sie he Abb. 36):  (1) Die erste Animation (pq_list_a5_1) verwendet ei n Behältermodell für die Liste group  und stellt die  Funktion olderThan()  als Kasten mit einem Greifarm dar. Diese Entität i st eigenaktiv und nimmt  mit dem Greifarm zunächst eine Kopie aller Zettel a us der Liste group heraus und stopft sie in ihr Inn e res. In gleicher Weise verleibt sie sich einen Zett el mit der Altersangabe 19  ein. Schließlich zieht der  Greifarm aus dem Inneren des Kastens das Ergebnis ( zwei Zettel mit Namen) heraus.  (2) In der zweiten Animation (pq_list_a5_4) wird di e Funktion durch einen Kasten mit beweglichen Sen soren visualisiert. Die Sensoren nehmen mit der Lis te und einem Zettel, der die Altersangabe 19  trägt,  Kontakt auf. Danach kommen unten aus dem Funktionso bjekt zwei Zettel mit Namen heraus.  (3) Hier wird ein Eventmodell (Blitz) für den Funkt ionsaufruf verwendet. Aus dem Kasten, der die Liste   darstellt, steigen Kopien der enthaltenen Zettel he raus. Sie treffen auf einen Zettel mit der Altersan gabe  19 , mit einem Blitz verschwinden diese Zettel und es erscheinen stattdessen zwei neue Papierstücke  mit den Namen der gesuchten Personen.  (4) Die Animation stellt die Funktion olderThan()  durch ein Ein-Ausgang-Modell (umgedrehter Py ramidenstumpf) dar. In das Funktionsmodell fliegen Kopien aller Zettel aus der Liste und ein Zettel mi t  der Altersangabe 19 . Unten kommt das Ergebnis heraus, zwei Zettel mit Personennamen (Datenfluss).    Abb. 36: Modelle mit unterschiedlichen Eingabemecha nismen zur Visualisierung eines Funktionsaufrufs  Tab. 9 zeigt die Bewertungen dieser Modelle (passen d/unpassend) von 68 Schülerinnen und Schü lern, die an einem PVS-Workshop teilgenommen haben.  Alle vier Modelle wurden von der Mehrheit  akzeptiert, das besonders eigenaktive Modell mit Gr eifarmen sogar von 81 % der Spieler, allerdings  ließ sich keine signifikante Bevorzugung gegenüber den anderen Modellen nachweisen.   76     n = 68 Dauer der A nimation Entscheiungs zeit (Stdabw.) Als passend  beurteilt von  Konfidenz  (Stdabw.)  Box mit Greifarmen (pq_list_a5_1) 14 s 12.75 s  (12.56) 55 (81%) 76% (37%)  Box mit Sensoren (pq_list_a5_4) 9 s 7.75 s  (6.09) 48 (71%) 72% (39%)  Ereignis   (pq_list_a5_5) 6 s 8.01 s  (6.32) 49 (72 %) 67% (40%)  Datenfluss  (pq_list_a5_5) 9 s 10.37 s  (9.02) 46 (68%) 73% (40%)  Tab. 9: Beurteilung von Modellen mit unterschiedlic hen Eingabemechanismen für Funktionen. Berücksichti gt wurden die  Antworten aus ersten Spieldurchgängen von 12 Schüler innen und 56 Schülern, die an Workshops mit der PVS  teilgenommen  haben. Das Durchschnittsalter beträgt 17.15 Jahre. Die Teilnehmer haben sich im Durchschnitt 3.81 Stun den pro Woche mit  Programmierung beschäftigt.  8.6 Übergabe von Referenzen bei der Ausgabe  Die Ausgabe einer Funktion kann darin bestehen, das s sie der aufrufenden Entität ein Objekt, das  außerhalb der Funktion existiert, zeigt. Ein typisc hes Beispiel ist eine Suchfunktion, die aus einem  großen Datenbestand ein bestimmtes Objekt heraussuc ht. Zurückgegeben wird nicht eine Kopie des  gesuchten Objekts sondern eine Referenz darauf, so dass gezielt dieses Objekt verändert werden kann.  Dieses Ausgabekonzept kann z.B. folgendermaßen visu alisiert werden:  • Die aufrufende Entität hält ein Etikett (Namen) ber eit, das von der Funktion (z.B. mit Hilfe eines  Greifers) an das zurückzugebende Objekt geheftet wi rd. Das Problem ist, dass die Übergabe des  Etiketts als weitere Eingabe missverstanden werden kann.  • Die aufrufende Entität hält einen Zeiger bereit, de r mit einem Namen versehen ist und zunächst  „ins Leere“ zeigt. Er wartet darauf, an ein Objekt gebunden zu werden. Wenn die Funktion ihre  Rechnungen abgeschlossen hat, „manipuliert“ sie den  Pfeil und sorgt dafür, dass er auf das richti ge Objekt zeigt.  Beide Modelle für die Rückgabe einer Referenz basie ren auf der Idee wartender Namen. D.h. die  aufrufende Entität hält einen Namen bereit, der sch on existiert, bevor die Funktion eine Referenz ge liefert hat. Wenn man diesen wartenden Namen nicht voraussetzt, kommt man in logische Schwierig keiten. Es ist dann so, als ob man jemandem etwas z eigen will, aber dieser Jemand gar nicht existiert.   Dies kann als Widerspruch zum Namenskonzept gesehen  werden. Denn streng genommen muss  ein Name immer an ein Objekt gebunden sein (sonst w äre es kein Name). Die Annahme eines warten den Namens ist ein weiteres Beispiel für eine Übers trukturierung. Ein an sich atomarer Vorgang – die  Bindung eines Namens an ein Objekt – wird aufgeteil t in zwei Vorgänge: Generierung des Namens  und Bestimmung des zugehörigen Objektes (durch eine  andere Entität).   Die PVS enthält eine Applikation (Python Visual What happens, when a function returns so mething? ), in der das Problem der Rückgabe einer Referenz t hematisiert wird. Gegeben ist ein PythonProgramm mit einer Multiliste (Liste von Listen).  s = [[4], [5], [1]]  x = min(s)  x[0] = 10  print s  Es liefert folgende Ausgabe auf dem Bildschirm:  [[4], [5], [10]] 77     Das heißt, die Funktion min()  gibt eine Referenz auf die kleinste Subliste (letz tes Element), der in  der zweiten Programmzeile der Name x zugeordnet wird. In der dritten Zeile wird das ers te und einzi ge Element dieser Liste überschrieben.   Zur Erklärung dieses Verhaltens – und insbesondere des Rückgabemechanismus – werden vier vi suelle Modelle angeboten. In allen Modellen wird di e Multiliste als Behälter mit Behältern dargestellt .  Die Funktion stellen wir durch eine Box dar, die di e Liste mit Hilfe eines „Sensors“ (grauer Zeiger)  „abtastet“. Die Modelle unterscheiden sich in der A rt und Weise, wie die Funktion ihr Ergebnis zu rückgibt.  (1) Die Funktion holt aus ihrem Inneren eine Nadel mit einem Zettel, der die Aufschrift x trägt und setzt  ihn auf den Behälter der Unterliste mit dem kleinst en Inhalt (Abb. 37 oben links). Das Modell ist in s o fern unpassend, als die Funktion den Namen x, mit dem sie ein Objekt markiert, ja gar nicht ken nt.  (2) Die Funktion produziert eine Kopie der Unterlis te mit dem kleinsten Inhalt und gibt sie zurück. So wohl  in der Kopie als auch im Original wird der Zettel m it der Zahl 1 gelöscht und durch einen Zettel mit  der Zahl 10  ersetzt (Erscheinungsmodell, Abb. 37 oben rechts).    (3) Bevor die Funktion erscheint, ist bereits die V ariable x im Bild angedeutet (Name x und Pfeil, der ins  Leere zeigt). Aus der Funktionsbox kommt ein Greifa rm, der die Spitze des Zeigers mit dem Namen x  auf das kleinste Element der Liste zieht (Abb. 37 u nten links).  (4) Bevor die Funktion erscheint, ist bereits die d er Name x im Bild (Schild). Aus der Funktionsbox  kommt ein Greifarm, der dieses Schild auf dem Behäl ter der kleinsten Unterliste befestigt (Abb. 37 unten rechts).    Abb. 37: Visuelle Modelle für die Rückgabe einer Re ferenz auf ein Objekt  Den Spielern wurden folgende Fragen gestellt:  • Welche Animation würden Sie verwenden, um jemandem zu erklären, wie das Python-Skript  funktioniert?   • An welche Animation können Sie sich am besten erinn ern?  • Welche Animation war am schwierigsten nachzuvollzie hen?  Tab. 10 zeigt die Verteilung der Antworten von 23 W orkshop-Teilnehmern. Es lässt sich aufgrund  der geringen Teilnehmerzahlen keine deutliche Bevor zugung oder Ablehnung nachweisen (der χ²-Test  ergibt keine signifikante Abweichung von einer Glei chverteilung).   78     n = 23 Nadel mit x Kopie der Liste Zeiger Neues Sch ild x  Erklären 6 6 6 5  Sich erinnern 5 6 4 8  Schwierig  10 7 3 3  Tab. 10: Wahl verschiedener Modelle zur Veranschaul ichung der Rückgabe einer Referenz. Ergebnisse von 23 ersten Sit zungen während Workshops mit der PVS. Teilnehmer: 16  Schüler, ein Student und sechs Lehrer aus Deutschl and (vier weib lich und 19 männlich), sie beschäftigten sich im Sc hnitt 5.5 Stunden pro Woche mit Programmierung und hatten ein Durch schnittsalter von 22,5 Jahren.  8.7 Ausgabe als Signal  Boolesche Funktionen (Tests) liefern einen Wahrheit swert, der meist zur Steuerung des Programm laufs (in Programmverzweigungen oder Schleifen) ver wendet wird. Die Besonderheit ist hier, dass der  Name des ausgegebenen Objektes in der Regel irrelev ant ist. In Programmtexten wird in solchen Fäl len auch kein expliziter Name für das Testergebnis verwendet wird. Beispiel:  if a < b:      …  Hier ist der Informationsgehalt des zurückgegebenen  Objektes minimal. Das Ausgabeobjekt selbst  tritt in den Hintergrund. Viel wichtiger ist der As pekt, dass (im Beispiel, wenn das Ergebnis das Ob jekt True  ist) eine bestimmte Aktionsfolge ausgelöst wird. D ie Ausgabe wird als Signal zur Steue rung des Geschehens gesehen und kann dementsprechen d veranschaulicht werden (z.B. als Schild, das  für kurze Zeit sichtbar ist).   Abb. 38 zeigt Screenshots aus Animationen der PVS, die eine Testfunktion als Ereignisauslöser  darstellen und sich auf folgende Python-Anweisung b eziehen:  if a > age:     …  Links wird die Testfunktion „größer als“ als Kasten  dargestellt, der über „Sensoren“ die Inhalte  zweier Variablen abfragt. Das Signal wird durch ein  Schild (in diesem Fall mit der Aufschrift True)  visualisiert, das aus dem Kasten herauskommt, für k urze Zeit sichtbar ist und dann wieder verschwin det (Boxmodell mit Sensoren und Signalausgabe).              Abb. 38: Vergleich zweier Zahlen als steuerndes Erei gnis. Screenshots aus Python Quiz „Modeling a group “.  Die zweite Animation zeigt die Funktionsausführung als Ereignis (Blitz), bei dem aus Kopien der  Inhalte der Variablen a und age  eine Karte mit einem Wahrheitswert entsteht.  Das dritte Bild zeigt ein Boxmodell mit Einund Au sgang. Bei den letzten beiden Modellen wird  das ausgegebene Objekt (eine Karte mit einem Wahrhe itswert) zu keiner Entität weitergeleitet, son dern bleibt eine kurze Weile sichtbar und verschwin det wieder. Es hat damit den Charakter eines Sig nals.  Tab. 11 zeigt, dass Schülerinnen und Schüler alle d rei Modelle in etwa mit gleicher Häufigkeit als  passend beurteilen. Insbesondere kann man (vorsicht ig) den Schluss ziehen, dass die explizite Model lierung eines Signals wie im ersten Modell keinen k ognitiven Vorteil gegenüber Funktionsmodellen 79     bietet, die ein Objekt ausgeben, das im Prinzip auc h an einen Akteur zur Verarbeitung weitergegeben  werden kann – also per se kein Signal darstellt.    n = 68 Dauer der   Animation Entscheidungs zeit (Stdabw.) Als passend  beurteilt von  Konfidenz  (Stdabw.)  1. Boxmodell mit Sensoren  (pq_list_a3_4) 8 s 10.65 s  (7.18) 58 (85.3%) 74.1% (30.8%)  2. Blitz   (pq_list_a3_2) 7 s 7.88 s  (5.58) 58 (85.3%) 76.7% (37.7%)  3. Boxmodell mit Einund Ausgang  (pq_list_a3_1) 9 s 14.84 s  (25.25) 56 (82.35 %) 72.3% (4.04%)  Tab. 11: Beurteilung von Modellen für Testfunktione n, deren Ausgabe als Signal interpretiert wird. Berü cksichtigt wur den die Antworten aus ersten Spieldurchgängen von 68  Schülerinnen und Schülern, die an Workshops mit de r PVS teilge nommen haben.   Ein Modell mit einer booleschen Funktion, die einen  Wahrheitswert liefert, kann nur zweiseitige  Entscheidungen darstellen. Bei verschachtelten Ents cheidungsstrukturen muss ein Ereignismodell alle  vorkommenden Fälle als logische Aussagen expliziere n. Es gibt eine Entität, die den Systemzustand  prüft und ein Ereignis (z.B. a < b  oder a == b  oder a > b ) generiert, auf das jeweils ein Akteur  reagiert.   8.8 Durchlässigkeit der Systemgrenze  8.8.1 Geschlossene Box  Ein geschlossenes Modell einer Funktion lässt einen  Datenaustausch mit der Umgebung nur über  „kontrollierte“ Einund Ausgänge zu. Probleme mit dem geschlossenen Ein-/Ausgabemodell treten  dann auf, wenn man einen Zugriff der Funktion auf O bjekte darstellen will, die außerhalb der Funkti on existieren (z.B. Zugriff auf globale Variablen o der Aufruf von anderen Funktionen).  8.8.2 Box mit „Seitentür“  Um die eben erwähnten Probleme zu lösen, kann das g eschlossene Box-Modell um eine „Seiten tür“ erweitert werden, über die die Maschinerie der  Funktion mit ihrer Umgebung Kontakt hat. Sie  stellt neben Einund Ausgang einen weiteren Kommun ikationskanal dar. Wenn eine Funktion eine  andere Funktion aufruft, so kann man dies so darste llen: Über die Seitentür „wandert“ ein Objekt – das   Argument des Funktionsaufrufs – nach draußen in den  Eingang der aufgerufenen Funktion. Sie liefert  (über ihren Ausgang) ein Ergebnis, das durch den Se iteneingang in das Innere der ersten Funktion  gelangt und dort in die weitere Rechnung einbezogen  wird (Abb. 39 links). Boxen mit Seitentüren  werden in er PVS als Veranschaulichung einer rekurs iven Funktion zur Berechnung von FibonacciZahlen verwendet (siehe Abschnitt 8.9).  8.8.3 Direkter Zugriff auf externe Objekte  Seiteneffekte und die Verwendung globaler Variablen  kann man durch die Metapher eines „Mani pulators“ darstellen, der Objekte verändern kann, d ie sich außerhalb der Funktionsbox befinden. Da mit ist die Systemgrenze sehr durchlässig. Kooperie rende Akteure, die auf ihre Umgebung Einfluss  nehmen, kann man beobachten, wenn eine Gruppe von M enschen gemeinsam eine handwerkliche  Aufgabe mit verteilten Rollen löst. Betrachten wir als Beispiel die Situation nach einem Essen. Je mand räumt das Geschirr vom Tisch, eine andere Pers on spült, eine dritte räumt ab und eine vierte  Person räumt das Geschirr in den Schrank. Die von d en verschiedenen Akteuren verarbeiteten Objekte  befinden sich sämtlich in einer gemeinsamen, öffent lichen Sphäre.  Kommen wir wieder zurück zu Programmtexten. Die Man ipulatormetapher kann auch dann für  Funktionen verwendet werden, wenn überhaupt kein Zu griff auf externe Objekte erfolgt. Die PVS  enthält ein Beispiel zur Visualisierung einer rekur siven Funktion, die eine Zeichenkette spiegelt. Obwohl auf programmtechnischer Ebene in jedem rekursi ven Aufruf ein separates String-Objekt verar80     beitet wird, geht die Animation von einem einzigen String aus (Folge von Buchstabenkarten), dessen  Zeichen von den verschiedenen Akteuren (die Funktio nsaufrufe repräsentieren) bewegt werden (siehe  Abb. 39 rechts).     Abb. 39: Modelle für Funktionen mit offener Systemg renze  8.8.4 Vergleich von offenen und geschlossenen Funkt ionsmodellen  Stellt man eine Funktion als geschlossene Box mit E inund Ausgang dar, so muss bei einem inter nen Funktionsaufruf der zugehörige Akteur sich im I nneren befinden. Er ergibt sich eine geschachtelte  Struktur von Boxen, die andere (kleinere) Boxen ent halten (siehe Abb. 40). Das Problem einer solchen  Visualisierung ist, dass die inneren Boxen und scho n bei geringer Rekursionstiefe nicht mehr sichtbar  sind. Andererseits werden geschachtelte Strukturen (wie Russian Dolls) mit Rekursion assoziiert. Bei  offenen Modellen mit durchlässiger Systemgrenze kön nen gleichgroße Modelle für Funktionen ver wendet werden.   In Python Visual Mirrors wird die Ausführung einer rekursiven Funktion veranschaulicht, die eine  Zeichenkette spiegelt (aus roma  wird amor ). In den Animationen werden offene und geschlossen e  Modelle einander gegenüber gestellt (Abb. 40):  def mirror (w):     if w== "": return w     else: return mirror(w[1:]) + w[0]      print mirror "roma"    Abb. 40: Offene und geschlossene Modelle zur Visual isierung der Ausführung einer rekursiven Funktion.  (1) Die erste Animation zeigt nur einen Rekursionss chritt des Programmlaufs. Der zu einem Funktionsauf  ruf gehörende Prozess wird als Brett mit der Aufsch rift mirror()  visualisiert. Es besitzt einen Grei fer, der Zettel manipuliert. Ein derartiger Akteur erhält vier Zettel mit den Buchstaben des Wortes  "roma" . Der Greifer nimmt die hinteren drei Zettel ( "oma" ) und übergibt sie einem zweiten Akteur  (rekursiver Aufruf der Funktion). Dieser vertauscht  die Buchstaben, so dass ihre Reihenfolge umge kehrt wird und gibt das Ergebnis zurück ( "amo" ). Der erste Akteur nimmt diese drei Zettel in Empfang, setzt den Buchstaben "r"  hinten an und gibt das Ergebnis ( "amor" ) nach oben zurück. 81     (2) Das zweite Modell entspricht dem ersten, stellt  jedoch die vollständige Rekursion (vier Funktionsa uf rufe) bis zum Rekursionsabbruch dar (Abb. 40 links) .   (3) Das dritte Modell stellt die vollständige Rekur sion (vier Funktionsaufrufe) bis zum Rekursionsabbr uch  dar. Rekursive Funktionsaufrufe werden durch gescha chtelte Kästen (Rahmen) visualisiert. Zettel mit  Buchstaben fliegen in die Kästen (Eingabe) und werd en innnerhalb des Kastens verarbeitet. Das Er gebnis fliegt wieder heraus und der betreffende Rah men verschwindet.  (4) Die letzte Animation stellt wie Modell 3 den Pr ozess, der zu einem Funktionsaufruf gehört, durch e i nen Rahmen dar. Allerdings wird hier nur ein rekurs iver Funktionsaufruf explizit visualisiert.   Den Spielern wurden folgende Fragen gestellt:  • Welche Animation würden Sie verwenden, um jemandem zu erklären, wie das Python-Skript  funktioniert?   • Welche Animation gibt am besten die Idee einer reku rsiven Funktion wieder?  • Welche Animation war am schwierigsten nachzuvollzie hen?  Tab. 12 zeigt das Ergebnis aus 30 Sessions, von den en aber nur 22 im Rahmen von Workshops mit  der PVS stattfanden. Es weicht signifikant von eine r Gleichverteilung ab ( χ²-Test, p = 0.0003). Offene  und geschlossene Modelle wurden etwa gleich bewerte t. Auffällig ist, dass die vollständige Darstel lung der Funktionsausführung bis zum Erreichen des Trivialfalls und Abbruch der Rekursion (Modelle  2 und 3) einer verkürzten Darstellung vorgezogen wi rd – ein Punkt, auf den wir in Abschnitt 9.6 im  Zusammenhang mit Rekursion zurückkommen werden.  n = 30   offen, ein Schritt   offen,   volle Rekursion geschlossen,   volle Rekursion geschlossen,  ein Schritt  Erklären 3 12 11 4  Idee  2 11 14 3  Schwierig  10 7 4 9  Tab. 12: Wahl verschiedener Modelle zur Veranschaul ichung der Rückgabe einer Referenz. Ergebnisse von 30 ersten Sit zungen, davon 22 während Workshops mit der PVS. Teil nehmer: 22 Schüler, vier Studenten und vier andere Personen, davon  24 aus Deutschland. Es gibt 26 männliche und 4 weibl iche Teilnehmer; sie beschäftigten sich im Schnitt 4.5 Stunden pro  Woche mit Programmierung und hatten ein Durchschnit tsalter von 21.2 Jahren.  8.9 Dynamische und statische Funktionsmodelle   Ein statisches Funktionsmodell betrachtet eine Funk tion als Entität, die während der gesamten Le benszeit des Programms (Prozesses) existiert und in  Bereitschaft ist, aufgerufen zu werden. In Daten flussmodellen (siehe Abschnitt 5.1) geht man davon aus, dass jede benötigte Funktion genau einmal  existiert. Es gibt einen gewissen Vorrat an vorgefe rtigten Funktionen, die bereits zu Beginn des Pro grammlaufs sichtbar sind.   Ein Problem tritt z.B. bei rekursiven Funktionen au f. Von rekursiven Funktionen müssten in dieser  statischen Sichtweise im Prinzip unendlich viele Ex emplare existieren. Im „Schleifenmodell“ endre kursiver Funktionen (Kahney 1984, Close & Dicheva 1 997) stellt man sich eine statische Funktion  vor, die immer wieder (mit neuen Parametern) aufger ufen wird.   Ein dynamisches Funktionsmodell repräsentiert im Pr inzip den Prozess der Funktion, der durch ei nen Aufruf gestartet wird. Das Funktionsmodell ersc heint also erst bei Aufruf der Funktion in der Szene und verschwindet wieder nach Beendigung.      82     Abb. 41: Funktionen als Boxen mit Ein/Ausgang und S eitentüren (PVS)  Abb. 41 zeigt Screenshots aus Animationen der PVS, die die Ausführung einer rekursiven Funktion  zur Berechnung von Fibonacci-Zahlen veranschauliche n und Boxen mit Eingang (oben), Ausgang  (unten) und Seitentüren verwenden. Das Argument des  Funktionsaufrufes wandert von oben in den  Eingang, bleibt aber dort stecken bis der Berechnun gsvorgang abgeschlossen ist. Alle Animationen  fokussieren also auf die Struktur der rekursiven Au frufe und lassen interne Berechnungen weg. Das  vorgegebene Python-Programm lautet  def fib(n):      if n<= 1: return n      else: return fib(n-1) + fib(n-2)    print fib(3)  (1) Die erste Animation (links) enthält ein dynamis ches Akteurmodell. Bei jedem rekursiven Funktions aufruf entsteht mit einem Blitz ein neuer Akteur. D urch die Seitentür der aufrufenden Entität wandert  eine Karte mit einer Zahl in den Eingang der soeben  entstandenen Box. Diese führt Berechnungen aus,  muss dabei wieder Funktionsaufrufe durch ihre Seite ntür initiieren und gibt schließlich über ihre unte re  Öffnung (Ausgang) eine Karte mit dem Ergebnis aus, das durch die Seitentür in die Box der aufrufen den Funktion wandert. Sobald eine Box ein Ergebnis geliefert hat, verschwindet sie wieder. Alle Akti onen laufen im ersten Modell streng seriell. Das he ißt beim ersten Aufruf fib(3)  wird zuerst rekursiv  fib(2)  aufgerufen (Karte mit Aufschrift 2 wandert durch d ie Seitentür nach draußen). Erst wenn das  Ergebnis (Karte mit Aufschrift 2) durch die Seitent ür zurückgekommen ist, wird der zweite rekursive  Aufruf fib(1)  ausgelöst d.h. eine Karte mit Aufschrift 1 wird durch die Seitentür verschickt und  durch eine neue Box verarbeitet und so weiter.  (2) In der zweiten Animation gibt es nur einen einz igen Akteur, der die Funktion fib()  repräsentiert. Ein  rekursiver Funktionsaufruf wird so dargestellt, das s eine Karte mit dem Argument durch die Seitentür  die Box verlässt und nach oben zum Eingang wandert.  Da die Karten mit den Argumenten der Funkti onsaufrufe erst verschwinden, wenn eine Berechnung abgeschlossen ist, sammeln sich am Eingang  Karten mit Zahlen und erinnern an noch laufende Ber echnungsprozesse.  (3) Im dritten Modell sind die Funktionsakteure von  Beginn an vorhanden (statisches Akteurmodell) und  warten auf ihren Einsatz. Von der Funktion fib()  gibt es also einen unerschöpflichen Vorrat von Exemplaren. Jede Zahlenkarte (Argument eines Aufrufs der Funktion fib() ) sucht sich ihren Weg zu  einer noch freien Box, die daran erkennbar ist, das s in ihrem Eingang noch keine Karte steckt. Die  Ausführung der rekursiven Aufrufe ist wieder seriel l wie beim ersten Modell.  (4) Die vierte Animation verwendet wie Modell 1 ein  dynamisches Akteurmodell, die rekursiven Aufrufe  werden aber parallel ausgeführt. D.h. aus der Seite ntür der Box für den Aufruf fib(3)  wandern kurz  hintereinander Karten mit den Argumenten für die re kursiven Aufrufe fib(2)  und fib(1)  und  werden in quasi gleichzeitig erscheinenden neuen Ak teuren nebenläufig verarbeitet.   Den Spielern wurden die gleichen Fragen gestellt wi e im Python Visual aus Abschnitt 8.8.4. Tab.  13 zeigt die Verteilung der Antworten von 21 Worksh op-Teilnehmern. Sie weicht signifikant von  einer Gleichverteilung ab ( χ²-Test, p = 0.05). Die Daten zeigen eine Bevorzugun g dynamischer und  Ablehnung statischer Varianten des Seitentür-Modell s. Insbesondere das (realitätsferne) Modell, das  eine parallele Ausführung rekursiver Funktionsaufru fe darstellt, wurde für Erklärungen als besonders  geeignet angesehen.   n = 21 Dynamisch,  seriell Statisch,  ein Akteur Statisch,   viele Akteure Dynamisch,   parallel  Erklären 5 3 3 10  Idee 8 4 3 6  Schwierig  5 6 8 2 83     Tab. 13: Wahl verschiedener Modelle zur Veranschaul ichung einer rekursiven Funktion. Ergebnisse von 21  ersten Sit zungen während Workshops mit der PVS. Teilnehmer: 19  Schüler, ein Student und ein Lehrer aus Deutschlan d (7 weiblich  und 14 männlich), sie beschäftigten sich im Schnitt  1,6 Stunden pro Woche mit Programmierung und hatte n ein Durch schnittsalter von 18.2 Jahren.  8.10 Auslösemechanismen   Wann wird eine Funktion aktiv und beginnt mit der V erarbeitung der ihr übergebenen Daten? Mo delle für Funktionen unterscheiden sich in der Art und Weise, wie sie die Aktivierung einer Funktion  veranschaulichen (Auslösemechanismen). Oft wird ein e implizite Auslösung verwendet. Die Funktion  beginnt „automatisch“ mit der Verarbeitung, sobald sie alle Daten empfangen hat. Über andere For men der Auslösung braucht man nur bei statischen Fu nktionsmodellen nachdenken, die keine Einga bedaten verarbeiten (nullstellige Funktionen). Ein Beispiel für eine Funktion ohne Eingabedaten ist ei n  Generator für Zufallszahlen.  Die visuelle Darstellung einer Funktion wird häufig  allein auf ihre Auslösung reduziert. Die Aus führung der Funktion wird als Ereignis dargestellt,  das z.B. als Darstellung als Blitz, der eventuell  noch mit dem Funktionsnamen beschriftet ist, visual isiert werden kann. Solche Ereignisse bewirken  dann die Umwandlung der Argumente des Funktionsaufr ufs in das Ergebnis. Eine ähnliche Vorstel lung verwendet man bei der Erklärung chemischer Rea ktionen: Ausgangsstoffe „verwandeln sich“  unter bestimmten Bedingungen in neue Stoffe. Auch h ier reduziert man die Darstellung eines an sich  komplexen Ablaufs auf seine Auslösung. 84       9 Kontrolle – Steuerung  Kontrollstrukturen regeln die Reihenfolge, in der O perationen in einem Programm ausgeführt wer den. Im Grunde ist ein Programmtext mit Kontrollinf ormation vollkommen durchdrungen. In einem  imperativen Programm ist jede Anweisung zumindest T eil einer Sequenz, wird also vor oder nach  einer anderen Anweisung ausgeführt. Nancy Penningto n (1987) beschreibt Kontrolle als eine „Abs traktion“ eines Programmtextes, die neben den Abstr aktionen Datenfluss und Funktionalität eine Di mension des Verstehens eines Programms ist 8.   9.1 Handhabung von Kontrolle: Kontrollfluss und Kon trollübergabe  Kontrolle kann man sich als Entität vorstellen, die  auf geregelte Weise von Akteur zu Akteur be wegt wird. Nur die Entität, die gerade die Kontroll e besitzt, ist aktiv. Im Bereich der Datenkommuni kation sind Kontroll-Entitäten expliziter Bestandte il von Algorithmen, die den Zugriff eines Senders  auf das Übertragungsmedium regeln. Im Token-Bus (IE EE 802.4) und Token-Ring (IEEE-802.5)  wandert ein Token (eine bestimmte Bitfolge) von Sta tion zu Station. Wer das Token besitzt, darf sen den. Auch im Alltag gibt es Gegenstände, die Kontro lle repräsentieren. Bei einem Staffellauf markiert  das Staffelholz den Läufer, der gerade aktiv ist.   Im Kontrollflussmodell wandert die Kontrolle auf vo rgegebenen Bahnen. Kontrollflüsse werden in  Flussdiagrammen oder bestimmten visuellen Programmi ersprachen wie Labview (National Intru ments) verwendet. Bei der Interpretation eines Flus sdiagramms geht man davon aus, dass zu einem  Zeitpunkt nur eine Entität aktiv sein darf, also nu r eine bestimmte Anweisung ausgeführt wird. Man  kann den Kontrollfluss nachspielen, indem man mit d em Finger den Bahnen des Flussdiagramms  folgt.   Das Kontrollflusskonzept ist grundlegend und wird i n intuitiven Modellen für Sequenzen, Schlei fen und Programmverzweigungen zur Modellierung des Programmlaufs verwendet.  Den Aufruf einer Funktion dagegen kann man durch Üb ergabe der Kontrolle von einem Akteur an  einen anderen modellieren. Nach der Abgabe wartet d er aufrufende Akteur. Wenn die aufgerufene  Funktion terminiert, gibt sie die Kontrolle an die aufrufende Einheit zurück. Hier wird die Bewegung  der Kontroll-Entität nicht durch ein räumliches Geb ilde (eine Bahn) dargestellt. Stattdessen beschreib t  man die Handhabung der Kontrolle als soziales Phäno men. Geben und Annehmen von Kontrolle ist  Teil der Aktivität interagierender Entitäten.   Es gibt auch Darstellungsformen für Steuerungsproze sse, die keine explizite Kontroll-Entität ent halten wie das Ereignismodell (Abschnitt 9.3.3) und  datengesteuerte Modelle für Iterationen (Ab schnitt 9.4).  9.2 Anweisungssequenzen   In der Redeweise des imperativen Programmierparadig mas ist eine Sequenz eine Folge von Anwei sungen, die in einer festgelegten Reihenfolge hinte reinander ausgeführt werden. In textuellen Pro grammiersprachen sind die Anweisungen einer Sequenz  hintereinander und untereinander geschrie ben. Bei der Programmausführung wird aus der räumli chen Anordnung ein zeitliches Nacheinander.  Sequenzen werden durch Verwendung bestimmter Sprach konstrukte (bei Pascal begin  und end ,  bei Java und C durch geschweifte Klammern und bei P ython durch Einrückung) zu Blöcken zusam mengefasst. Häufig – insbesondere bei „gutem Progra mmierstil“ – enthält ein Block eine Sequenz von  logisch zusammengehörigen Anweisungen, die ein abst rakt beschreibbares Stück Programmfunktiona lität enthalten. In Flussdiagrammen und Struktogram men (Nassi-Shneidermann-Diagrammen) wird  ein Block durch einen Kasten dargestellt.                                                          8 Pennington spricht von Kontrollfluss  (control flo w). Ein Begriff, der an dieser Stelle vermieden  wird, weil er ein bestimmtes intuitives Modell impl iziert.    85     In Visualisierungsübungen mit Schülern kann man beo bachten, dass von der durch den Programm text gegebenen Sequenzialität in einem Block abgewi chen wird. Ein Block von Einzelanweisungen  kann als sinnvolle Ganzheit interpretiert werden, b ei der die Reihenfolge der Einzelaktionen im Detail   unwichtig ist. Abb. 42 zeigt vier Screenshots aus e iner Flash-Animation, die eine 17-jährige Schülerin   zur Visualisierung der folgenden Anweisungsfolge (J ava) angefertigt hat:  int a;  int b;  a = 2;  b = a + 3;  Der Ablauf ist folgender: Zwei Behälter, etikettier t mit a und b fliegen von rechts und links in die  Mitte der Bildfläche (erstes Bild). Anschließend be wegen sich Karten mit der Aufschrift  2  bzw.  a + 3 in die beiden Behälter (zweites Bild), die Karte 2 fliegt aus Behälter a in Behälter b und ver deckt den Buchstaben a auf der Karte a + 3  (drittes Bild), die daraufhin verschwindet und dur ch  eine Karte mit Aufschrift 5 ersetzt wird (viertes Bild).     Abb. 42: Visualisierung der Ausführung einer Sequen z durch konkurrente Prozesse  In einem Interview wurde sichergestellt, dass die S chülerin die Reihenfolge der Ereignisse sich ge nauso vorstellte, wie sie in der Animation dargeste llt hatte 9. Offenbar gab es einige Abweichungen  von der im Programmtext festgelegten Sequenzialität :  Die beiden Zuweisungen beginnen gleichzeitig (und u nabhängig voneinander), obwohl sie laut Pro grammtext nacheinander geschehen müssten. Die Paral lelisierung verkürzt die Ablaufzeit, macht das  Modell kompakter und verbessert den Gestaltcharakte r.  Zur Darstellung der zweiten Zuweisung wird zuerst d er Term in den Behälter b bewegt und dann  ausgewertet. In einer exakten Schritt-für-Schritt-I nterpretation des Programmtextes müsste aber zuerst   der Term ausgewertet werden und dann das Ergebnis i n den Behälter gegeben.   9.3 Bedingte Anweisungen  In diesem Abschnitt diskutieren wir drei Arten intu itiver Modelle zur Repräsentation von bedingten  Anweisungen (if-Anweisungen): Verzweigung des Kontr ollflusses oder Datenflusses und Ereignismo delle.  9.3.1 Verzweigung des Kontrollflusses  Häufig verwendet man die Begriffe „Verzweigung“ ode r „Programmverzweigung“ als Synonyme  für bedingte Anweisungen. Gemeint ist dann meist di e Verzweigung des Kontrollflusses. Es gibt einen  Akteur (Steuereinheit), der eine Bedingung auswerte t und in Abhängigkeit von dem Ergebnis die Kon trolle an unterschiedliche Akteure (die üblicherwei se jeweils einen Block des Programmtextes reprä sentieren) weitergibt. Verzweigungen des Kontrollfl usses werden in Flussdiagrammen und NassiShneidermann-Diagrammen verwendet.                                                          9 Sie wurde gefragt, ob in ihrer Vorstellung tatsäch lich die beiden Behälter gleichzeitig Erscheinung t reten. Au ßerdem wurde ihr Hilfe angeboten, falls sie am zeit lichen Ablauf noch etwas ändern wollte. 86     9.3.2 Kontrolle von Datenflüssen – Datenweichen und  Datensperren  Im Datenflussmodell wandern Daten von einer Verarbe itungseinheit zur nächsten. Zur Modellie rung von if-Anweisungen wird ein Mechanismus benöti gt, der eine Daten-Entität (in Abhängigkeit  von der Gültigkeit einer Bedingung) einer Verarbeit ungseinheit zuführt („Weiche“). Dieser Mecha nismus ist keine Funktion, die definitionsgemäß ein  eindeutiges Ergebnis liefern muss. Die visuelle  Programmiersprache DRLP (Dataflow Representation La nguage for Programming, Anjaneyulu &  Anderson 1992) verwendet Sperren für Datenflüsse (E NABLE), die geöffnet oder geschlossen werden  können (vergleichbar mit steuerbaren Ventilen).   9.3.3 Ereignismodell – Steuersignale  Die Animationen der PVS zur Visualisierung von Prog rammausführungen verwenden meist ein  Ereignismodell um Entscheidungen darzustellen. Ein solches Modell besteht aus zwei Komponenten:  Anstelle einer Steuereinheit, die Kontrolloder Da tenflüsse regelt, gibt es eine boolesche Funktion, die  eine Bedingung prüft und einen Wahrheitswert ausgib t (Testfunktion). Diese Ausgabe wird als Ereig nis interpretiert, das bestimmte Aktionen auslöst. Das ist ein Unterschied etwa zur Vorstellung, dass  eine Funktion einen Wert zurückgibt. Die Ausgabe de r Testfunktion ist ein Signal, d.h. die Daten  (boolesche Werte) werden nicht einem bestimmten Akt eur zugeführt sondern sind allgemein sichtbar.  Der Begriff Signal betont den Kommunikationsaspekt eines Ereignisses, d.h. durch Signale werden  Ereignisse mitgeteilt. Man beachte, dass das eigent liche Ereignis das Zutreffen einer logischen Aussage ist (z.B. a < b), die aus der Funktionalität der Testfunktion und ihrem Ergebnis zusammengesetzt  ist. Zum Beispiel ergibt sich das Ereignis a < b , wenn eine Testfunktion, die prüft ob a >= b zu trifft, den Wert False  signalisiert. Die zweite Komponente des Ereignismo dells sind dementspre chend Akteure, die ihre Umgebung beobachten, Ereign isse (dargestellt durch Signale) wahrnehmen  und dann darauf reagieren.   Die Idee der Signale ist sehr alt. In China wurden etwa 800 v. Chr. (in der Westlichen Zhou-Zeit)  Jahren so genannte Fengsui-Türme gebaut (feng: Feue r, sui: Rauch), von denen aus durch Feuerund  Rauchsignale im Falle drohender Gefahr die Armee al armiert wurde. Im modernen Alltag kennt man  in verschiedenen Zusammenhängen Steuerung durch Sig nale wie etwa Ampeln an Kreuzungen,  Schiedsrichterpfiffe auf dem Fußballplatz oder die Rhythmisierung eines Schultages mit dem Schul gong.  Zu beachten ist, dass moderne Programmiersprachen K onstrukte enthalten, mit denen die Verarbei tung von Ereignissen explizit implementiert werden kann. Bei der Programmierung von grafischen  Benutzungsoberflächen etwa bindet man asynchron auf tretende Events (z.B. Mausklicks) an Prozedu ren (Eventhandler), die darauf reagieren (vgl. z.B.  Weigend, 2006 S. 542ff). Eine andere Program miertechnik, die Ereignisse verarbeitet, ist das Ab fangen von Ausnahmen (Exceptions) während der  Laufzeit eines Programms etwa in try...except Anweisungen (Python) oder Zusicherungen  (assert -Anweisungen bei Python). An dieser Stelle geht es jedoch darum, dass eine Entscheidung,  die programmiersprachlich als if-Anweisung dargeste llt wird, in der Welt gedanklicher Vorstellungen  als Ereignisverarbeitung interpretiert wird.  9.4 Iterationen – datengesteuerte Wiederholungen  Eine Iteration ist das Durchlaufen (iter: lat. „Mar sch“) einer aufzählbaren (eventuell unendlichen)  Kollektion von Items. Programmiersprachen enthalten  iterierbare Standard-Objekte, die oft auch als  Container bezeichnet werden. Im einfachsten Fall si nd das Listen, Zeichenketten oder andere Sequen zen. Es gibt aber auch Container, deren Items keine  bestimmte Reihenfolge haben, bei Python z.B.  Dictionaries oder Mengen (Weigend 2006). Mit der It eration verbunden ist das Konzept des Iterators,  eines der von Gamma et al. (1995) vorgeschlagenen E ntwurfsmuster (design pattern). Darunter ver steht man einen Akteur, der zu einer Kollektion nac h und nach alle Elemente liefert (siehe auch van  Rossum & Yee 2001).   Iterationen sind ein wichtiges Konzept der Alltagsa lgorithmik. Folgende Aufgaben können vermut lich von den meisten Menschen intuitiv durch eine I teration gelöst werden: 87     • Iss alle Pralinen aus der Pralinenschachtel.  • Begrüße alle Partygäste.  • Klebe auf jede Urlaubskarte eine Briefmarke.  Bei einer Iteration geht die Steuerung des Programm laufs letztlich von einer Ansammlung von Da ten aus (Kollektion). Für jedes Element der Kollekt ion wird etwas getan. Wenn die Kollektion, über  die die Iteration läuft, bekannt ist, kann man auch  die Anzahl der Wiederholungen vorhersehen. Selbst  wenn die Iteration (etwa bei der Suche nach einem b estimmten Objekt der Kollektion) vorzeitig ab gebrochen werden kann, ist doch zumindest die maximale Anzahl der Durchläufe im Vorhinein be kannt.   Programmtechnisch werden Iterationen durch for-Anwe isungen realisiert. Im Falle von Python hat  eine solche Anweisung das Format  for i in kollektion:     anweisungsblock   Bei anderen Programmiersprachen wie Java oder C kan n für eine Iteration nicht einfach ein belie biges Container-Objekt angegeben werden. Stattdesse n wird eine Sequenz (andere Arten von Kollek tionen kann man nicht verwenden) indirekt durch ein e Art Generatorausdruck spezifiziert. Das Format  einer for -Anweisung mit Generatorausdruck (in runden Klammer n) ist bei Java:  for (i = Startwert; Bedingung, die für i erfüllt se in muss;       Berechnungsvorschrift für den Nachfolger von i )       {Anweisungsfolge}  Bei der Ausführung einer for-Anweisung wird ein imp liziter Iterator verwendet, der das jeweils ak tuelle Element der Kollektion liefert. Im Python Vi sual Analogies for Iterations   wurde die Arbeits weise des Iterators in folgendem Python-Programm du rch verschiedene intuitive Modelle  beschrie ben.   s = [1, 5, 4, 3, 2]  for i in s:      print i*i  (1) Im ersten Modell (Abb. 43 links) werden aus ein em Behälter mit Fächern nach und nach Items (Karten   mit Zahlen) entnommen und verarbeitet (Entnahme-Mod ell). Das Modell lässt sich für alle Arten von  Kollektionen verwenden. Im Falle einer Sequenz (wie  hier), in der die Items eine bestimmte Reihen folge haben, ist das nächste Element dasjenige, das  im Behälter am weitesten links steht. Durch die  Entnahme wird garantiert, dass jedes Item der Kolle ktion nur ein Mal verarbeitet wird. Wenn der Be hälter leer ist, ist die Iteration beendet. Das Ent nahme-Modell ist das einfachste und prägnanteste de r  hier betrachteten Iterationsmodelle. Es wird im All tag in vielen Situationen verwendet, etwa beim Ausräumen einer Spülmaschine oder wenn man alle Pralin en aus einer Schachtel nimmt und aufisst. Aller dings impliziert das Entnahmemodell, dass die Liste  während der Iteration verändert wird, was nicht  der realen Arbeitsweise des Programms entspricht. G leichwohl ist das Entnahmemodell nicht als Fehl vorstellung zu werten, wenn es im Rahmen eines Mode llclusters verwendet wird und man sich gleich zeitig bewusst macht, dass beim modellierten Progra mmlauf tatsächlich die Liste erhalten bleibt.  (2) Im zweiten Modell (Abb. 37 zweites Bild) wird d er Iterator überhaupt nicht expliziert. Der Betrach ter  muss selbst in Gedanken Buch führen, welches Item a ls nächstes verarbeitet wird. Die Liste wird wäh rend der Iteration nicht verändert. Es entstehen na ch und nach Kopien der Karten im Behälter, die dann   verarbeitet werden.   (3) Im dritten Modell (Markierungsmodell) zeigt ein  roter Punkt das aktuelle Item an. Er wandert durch   die Liste und repräsentiert den Namen i im Programm text. Wiederum wird die Liste als Behälter mit  Karten dargestellt (Abb. 37 drittes Bild).  (4) Das vierte Modell schließlich verwendet eine an dere Metapher für die Liste. Sie wird als Zahlenkolumne auf einem Blatt Papier dargestellt. Von den Z ahlen werden nach und nach Kopien auf Karten  angefertigt und verarbeitet. Jede bereits verarbeit ete Zahl wird durch einen Haken markiert. Dieses  Modell der Markierung bereits verwendeter Elemente („Abhaken“) wird häufig bei Iterationen im All88     tag benutzt – zum Beispiel beim Einkauf mit einer E inkaufsliste. Im Unterschied zur wandernden Mar kierung im dritten Modell hat das Abhaken keine Ent sprechung im Programmtext.                  Abb. 43: Visualisierung einer Iteration. Screenshot s aus dem Python Visual „Iteration“  Am Ende der Sitzung wurden folgende Fragen gestellt :  • Welche Animation würden Sie verwenden, um jemandem zu erklären wie das Python-Skript funk tioniert?  • An welche Animation können Sie sich am besten erinn ern?  • An welche Animation denken Sie, wenn Sie sich die A usführung des Skriptes vorstellen?  Tab. 14 zeigt die Verteilung der Antworten von 66 S chülerinnen und Schülern, die an Workshops  mit der PVS teilgenommen haben. Die Angaben zu den Fragen unterscheiden sich sämtlich signifikant  von einer Gleichverteilung ( χ²-Test, p = 0.00033, p = 0.00013, p = 0.00012). Nac h diesen Ergebnissen  wurde das Entnahmemodell (in Konkurrenz zu den ande ren Modellen) überwiegend abgelehnt, ob wohl es das einfachste ist. Der Grund liegt vermutl ich darin, dass es im Gegensatz zur Semantik des  Programms die Iterationssequenz (Liste) verändert. Bevorzugt werden die beiden letzten Modelle  (wandernde Markierung und Abhaken) mit unterschiedl ichem Schwerpunkt hinsichtlich der Verwen dung (Erklären, Memorieren, in Gedanken nachspielen ).     n = 66   Entnahme von  Karten aus einem  Behälter Kein Iterator   (Entnahme von  Kopien) Wandernde Mar kierung  Abhaken bereits  verwendeter Ele mente  Erklären   6 (9%) 13 (20%) 30 (45%) 17 (26%)  Erinnern   8 (12%) 8 (12%) 20 (30%) 30 (45%)  In Gedanken vorstel len 9 (14%) 7 (11%) 30 (45%) 20 (30%)  Tab. 14: Wahl verschiedener Modelle zur Veranschaul ichung einer Iteration. Ergebnisse von 66 ersten Se ssions in  Workshops mit der PVS. Teilnehmer: 66 Schülerinnen und Schüler, davon 52 aus Deutschland, 12 weiblich u nd 54 männlich,  sie beschäftigten sich im Schnitt 5.05 Stunden pro Woche mit Programmierung und hatten ein Durchschnit tsalter von 16.64  Jahren.  9.5 Wiederholungen mit nicht antizipierbarem Ende  Neben Iterationen gibt es noch einen zweiten Typus von Wiederholungen, der in Programmierspra chen wie C, Pascal, Java oder Python durch eine while -Anweisung implementiert wird. Sie hat im  Falle von Python folgendes Format:  while bedingung:     Anweisungsblock  Hier geht die Steuerung vom Test einer Bedingung au s. Solange sie erfüllt (wahr) ist, wird der An weisungsblock ausgeführt. Dabei ist – im Unterschie d zur Iteration – ohne tiefgehende Analyse der  Semantik des Programms nicht vorhersehbar, ob und w ann die Bedingung nicht mehr erfüllt ist und  die Wiederholung abgebrochen wird.  89     Eine programmtechnische Variante sind repeat…until oder do…while -Anweisungen, die  von einigen Programmiersprachen angeboten werden. D er Unterschied ist marginal und liegt allein  darin, dass der Test der Bedingung nach Ausführung des Anweisungsblocks im Innern erfolgt. Wir  beschränken unsere Betrachtungen hier auf den zuers t genannten Fall von while -Anweisungen.   Die steuernde Bedingung der while-Anweisung ist for mal eine Aussage, die wahr oder falsch sein  kann. Für die intuitive Modellierung ist jedoch die  Bedeutung wichtig. Generell ist die Bedingung eine   Aussage über den momentanen Systemzustand. Man kann  folgende Interpretationen unterscheiden:  • Die Bedingung ist die negative Formulierung eines Z iels. Solange die Bedingung erfüllt ist, ist das  Ziel noch nicht erreicht. Der Anweisungsblock hat d ie Aufgabe, das System dem Ziel ein Stück  näher zu bringen. Diese Interpretation wird z.B. be i der algorithmischen Darstellung von Nähe rungsverfahren (z.B. Wurzelberechnung nach Heron) v erwendet. Das Ziel ist hier eine gewisse  Genauigkeit des berechneten Näherungswertes.  • Die Bedingung beschreibt einen Systemzustand, in de m es keinen Sinn mehr macht, den Anwei sungsblock auszuführen. Der Anweisungsblock kann im  Prinzip beliebig oft ausgeführt werden.  Es gibt keine Annäherung an ein Ziel. Ein Beispiel ist der fetch-execute-Zyklus einer Benutzungs schnittstelle. Der Anweisungsblock wird solange wie derholt, bis der Benutzer (aus welchen Grün den auch immer) das Programm beendet. Ein Spezialfa ll dieser Interpretation sind Endloswieder holungen, bei denen die steuernde Bedingung immer w ahr ist ( while True: … )   Die beiden Interpretationen der while-Bedingung kor respondieren in etwa mit zwei unterschiedli chen intuitiven Modellen für while-Anweisungen, die  im Folgenden diskutiert werden: Die  kontrollierte Wiederholung und die Schleife.  9.5.1 Kontrollierte Wiederholung einer holistischen  Aktivität  Nassi-Shneiderman-Diagramme (Struktogramme, DIN 662 61) unterstützen die Vorstellung eines  Akteurs, der die Ausführung eines untergeordneten P rogrammblocks (den man sich als eigenen Akteur  vorstellen kann) steuert. Dieser Steuerungsakteur p rüft die Einhaltung der while-Bedingung und regelt  letztlich, wie oft der angeschlossene Anweisungsblo ck ausgeführt wird.          Abb. 44: Nassi-Shneiderman-Diagramm (Sinnbild nach D IN 66261) und Modell eines Steuerungsakteurs  Diese Intuition wird z.B. von LabView (National Ins truments, www.ni.com/labview/) unterstützt.  Hier ist es möglich, eine Anordnung in einen Rahmen  zu packen und mit einem Wiederholungsicon zu  versehen.  Eine Besonderheit gegenüber dem Schleifenmodell (si ehe nächster Abschnitt) ist, dass der wieder holte Anweisungsblock als eine einzige holistische Einheit vorstellbar ist. Das heißt man kann von  Einzelheiten insbesondere auch von der zeitlichen R eihenfolge, in der atomare Einzelanweisungen des  Blocks ausgeführt werden müssen, abstrahieren.   Die Verwendung dieses Modells kommt in folgenden Fo rmulierungen aus der „Algorithmik des  Alltags“ zum Ausdruck:  • Solange noch Erbsen in der Asche liegen, nimm eine Erbse heraus.  • Solange das Auto noch nicht steht, bremse.  • Solange du die Aufgaben noch nicht schnell genug lö sen kannst, übe.  Der zweite Unterschied zum Schleifenmodell liegt in  der pointierten Modellierung der Steuerungs komponente als eigenem Akteur, der die Ausführung d es (gesamten als geschlossene Gestalt gedach ten) Anweisungsblocks überwacht und steuert.  90     Mit dieser Intuition der Wiederholungskontrolle ist  eine mögliche Fehlvorstellung verbunden, näm lich dass die wiederholte Aktion sofort abgebrochen  wird, wenn die while-Bedingung nicht mehr er füllt ist.   9.5.2 Schleifen  Im Programmierjargon ist der Begriff Schleife (loop ) für Wiederholungen außerordentlich gut etab liert. Dahinter steht die Vorstellung eines kreisfö rmigen Kontrollflusses. Die zeitliche Abfolge von  Aktivitäten wird durch einen zyklischen gerichteten  Graphen visualisiert. Typischerweise denkt man  bei einer Schleife nicht an eine einzige holistisch e Aktion, die wiederholt wird, sondern an eine Se quenz von mindestens zwei Aktionen, die immer wiede r in der gleichen Reihenfolge hintereinander  ausgeführt werden. Diese Sequenz von Aktionen bilde t das Herzstück des Modells. Beispiele von Ak tionszyklen im Alltag sind:  • Der Wechsel von Tag und Nacht im Verlauf eines Tage s.  • Der Zyklus der Jahreszeiten.  • Das Wechselspiel von Frage und Antwort in einem Int erview.   Schleifen werden z.B. in Programmablaufplänen (PAP,  Flussdiagramm) visualisiert. PAPs enthal ten kein besonderes Sinnbild für Wiederholungen. De r Austritt aus der Schleife wird durch eine Ver zweigung des Kontrollflusses (wie bei einer if-Anwe isung) dargestellt. Die schleifenförmige Struktur  wird erst durch Betrachtung der Gesamtstruktur sich tbar. In Anhang 4.2 wird als Beispiel der Fetchexecute-Zyklus eines interaktiven Systems diskutier t.   Mit dem Schleifenkonzept ist die Vorstellung von Sp rüngen der Kontrolle verbunden. Beim Pro grammtext in einer üblichen Programmiersprache (C, Java, Pascal Python) werden Anweisungen von  oben nach unten ausgeführt. Nach der letzten Anweis ung des wiederholten Blocks, springt die Kon trolle wieder zur ersten Anweisung der wiederholten  Sequenz.  Schleifen werden in der graphischen Programmierspra che für Robotersteuerungen von LegoRoboLab (www.lego.com) verwendet. Da hier der Kontr ollfluss standardmäßig immer von links nach  rechts gerichtet ist, werden zur Darstellung der Sc hleife Sprungmarken verwendet.   Mit Macromedia Flash werden komplexe Animationen al s Aggregate von zyklisch ablaufenden  Filmen (Movie Clips) konstruiert. Jeder Film ist ei ne Folge von Bildern (Frames), die von links nach  rechts durchlaufen werden. Die Wiederholung wird du rch einen Sprung vom letzten an das erste Bild  realisiert.   9.6 Rekursion  Eine rekursive Funktion ist eine Funktion, in deren  Definition mindestens ein Aufruf derselben  Funktion vorkommt. Die Ausführung einer Funktion ka nn als Prozess beschrieben werden. Beim Auf ruf wird ein Objekt (Execution Frame) angelegt, in dem der aktuelle Zustand der Funktionsausführung  gespeichert ist. Bei jedem rekursiven Aufruf erzeug t das Laufzeitsystem einen neuen Prozess mit neu em Execution Frame. Der aufrufende Prozess wartet, bis der rekursive Funktionsaufruf abgearbeitet ist  und fährt dann fort.  Gegenseitige Rekursion entsteht, wenn zwei Funktion en sich abwechselnd gegenseitig aufrufen.  Rekursion ist ein Konzept zur Steuerung von Program mläufen. Rekursion ist aber auch ein allge meines Prinzip, das zur Beschreibung von Dingen in der Welt herangezogen werden kann. Manche  Phänomene des Alltags legen eine rekursive Beschrei bung nahe:  • Vorfahren: Meine Vorfahren sind meine Eltern und de ren Vorfahren.  • Matroschka (Russian Doll): Eine Matroschka ist entw eder massiv oder sie besteht aus einer hohlen  Puppe, die eine Matroschka enthält (Fothe 2005).  Solche „rekursiven Phänomene“ (insbesondere die Rus sian Dolls) werden gelegentlich als Modelle  für Rekursion bezeichnet (Wu et al. 1998). Fothe (2 005) verwendet sie zum Testen von Wissen über 91     Rekursion. Levy und Lapidot (2001) beschreiben kogn itive Konzepte, die mit Rekursion assoziiert  werden, wie z.B. Regelmäßigkeit, Gradualität, Perio dizität und Zirkularität (siehe Anhang 4.3).  9.6.1 Rekursion als Schleife  Eine Reihe von Autoren bezeichnen das „Schleifenmod ell“ („loop model“) als typische Fehlvor stellung von Anfängern über die Arbeitsweise rekurs iver Funktionen (Kahney 1984, Kurland & Pea  1985, Bhuiyan et al. 1994, Close & Dicheva 1997).   Im Schleifenmodell wird die Ausführung einer rekurs iven Funktion als Wiederholung gesehen. Der  rekursive Aufruf wird als Aufforderung gesehen, die  (bisherige) Sequenz von Anweisungen noch  einmal von vorne zu beginnen – allerdings unter Ver wendung eines anderen Argumentes). Der rekur sive Aufruf wird als Sprungbefehl in Kombination mi t der Veränderung von Variablen (Argumente)  interpretiert. Insofern liegt tatsächlich eine Schl eife vor.  Das Schleifenmodell führt bei endrekursiven Prozedu ren nicht zu Widersprüchen. Bei diesem Spe zialfall rekursiver Funktionen wird kein (nichtleer es) Objekt zurückgegeben und der rekursive Aufruf  erfolgt ganz am Ende der Anweisungsfolge. Man beach te, dass jede Funktion, die ein Ergebnis zu rückgibt (also keine Prozedur ist) nicht endrekursi v sein kann, weil die Rückgabe des Ergebnisses die  letzte ausgeführte Anweisung ist und der rekursive Aufruf vorher erfolgt.  Bhuiyan et al. (1994) sind der Auffassung, dass es zum Schleifenmodell kommt, wenn Program mieranfänger vorher erworbenes Wissen über Iteratio nen auf die Interpretation und Generierung von  rekursiven Funktionen anwenden. Auf der anderen Sei te konnten Anzai & Uesato (1982) für den Be reich der Mathematik nachweisen, dass Schüler rekur sive Funktionen wie die Fakultätfunktion leichter  formulieren konnten, wenn sie zuvor mit iterativen Funktionsdefinitionen experimentiert hatten. Kess ler und Anderson (1989) beobachteten, dass Übungen mit iterativen Programmen einen positiven  Transfereffekt auf anschießendes Erstellen rekursiv er Programme hatten. Dagegen führte ein Training  mit rekursiven Programmen bei nachfolgender iterati ver Programmierung zu einer Leistungsver schlechterung (negativer Transfereffekt). Die Autor en schlossen daraus, dass bei Übungen mit iterati ven Programmen relativ gut grundlegende mentale Mod elle zur Steuerung von Programmabläufen  gelernt werden, die später als Basis zum Verständni s rekursiver Funktionen dienen können.   9.6.2 Rekursion als Selbstaufforderung  Was in der Literatur als „Schleifenmodell“ bezeichn et wird, kann man – zumindest im Zusammen hang mit endrekursiven Prozeduren – auch als eigens tändige Intuition betrachten, die sich von der  Schleife unterscheidet. Wir nennen sie das Modell d er rekursiven Selbstaufforderung. Es lässt sich  durch folgende Merkmale charakterisieren:  • Es gibt nur einen Akteur, der für die Ausführung ve rantwortlich ist. Darin unterscheidet sich das  Modell von Delegationsmodellen (siehe nächster Absc hnitt), bei denen bei rekursiven Aufrufen  neue Akteure ins Spiel kommen.  • Es gibt ein holistisches Konzept eines Handlungsabl aufs, der komplett wiederholt wird (falls es  notwendig ist).   • Die gesamte Aktivität ist eigentlich nicht von vorn herein auf Wiederholung angelegt (siehe All tagsbeispiele unten). Es kann durchaus sein, dass e ine einmalige Ausführung ausreicht. Dagegen  geht man bei der Planung einer typischen Wiederholu ng mit while immer von vielen Durchgängen  aus. Typische Schleifen wie der Fetch-Execute-Zyklu s eines interaktiven Systems sind von der I dee her sogar Prozesse mit beliebig vielen Wiederho lungen. Das heißt innerhalb des Systemde signs gibt es keinen Grund, die Aktivität abzubrech en.  Im Alltag gibt es viele Beispiele für rekursive Sel bstaufforderungen:  • Lösen einer Mathematikaufgabe: Löse die Gleichung u nd mache die Probe. Wenn sich die Lösung  als falsch erweist, löse die die Aufgabe noch einma l.  92     • Brennen einer CD: Nachdem die CD gebrannt ist, frag t das System, ob man noch eine weitere CD  mit dem gleichen Inhalt beschreiben möchte. Wenn ma n eine neue CD einlegt und den entspre chenden Button anklickt, wird der Vorgang wiederhol t.  • Sich zum Bahnhof durchfragen: Frage jemanden nach d em Weg zum Bahnhof und folge den An weisungen. Wenn du dann noch nicht am Bahnhof bist (z.B. weil die Beschreibung unvollständig  oder teilweise falsch war), frage dich weiter durch .  Zu beachten ist, dass das Modell der rekursiven Sel bstaufforderung nur bei endrekursiven Algo rithmen Sinn macht, weil es nur hier eine Gestalt d er zu wiederholenden Aktivität gibt. Bei eingebette  ter Rekursion gibt es zumindest zwei Blöcke, einer vor und einer nach dem rekursiven Aufruf).   Ein Beispiel für eine endrekursive Prozedur ist das  Logo-Programm aus Abb. 45. Es wurde mit  Microworld EX (www.microworlds.com), einer modernen  Variante der Logo-Turtle-Mikrowelt, er stellt.     Abb. 45: Screenshot aus einer Sitzung mit Microworld  EX. Links das Arbeitsblatt mit der Turtle t1, rechts der Backpack  der Turtle mit einer rekursiven Prozedur.  Die Logo-Turtle-Grafik unterstützt das Modell der S elbstaufforderung, weil es nur einen Akteur  gibt (die Turtle), dem die in der Prozedur definier te Aktivität zugeordnet wird. Microworld EX ver wendet die Metapher eines Rucksacks, den die Schild kröte trägt. Der Rucksack enthält z.B. aktuelle  Attributbelegungen (z.B. Zeichenstift angehoben ode r gesenkt), die den Zustand definieren, und Akti vitäten (Procedures), die die Schildkröte über die fest eingebauten Operationen (wie vorwärts gehen,  drehen etc.) hinaus beherrscht.  In diesem Fall der Prozedur draw zeichnet die Turtle ein Quadrat mit einer als Param eter überge benen Seitenlänge n. Sofern die Seitenlänge nicht z u klein ist, fordert sich die Turtle am Ende selbst   auf, ein weiteres Quadrat mit der halben Seitenläng e zu zeichnen usw. Alles macht dieselbe Turtle  ganz allein. Es kommen keine weiteren Akteure ins S piel.   9.6.3 Fehlerhafte Verwendung des Modells der Selbst aufforderung  Die Vorstellung eines einzigen Akteurs, der sich im mer wieder selbst auffordert, dieselbe Aktivität  (mit geänderten Parametern) durchzuführen, ist so e inleuchtend, dass sie in der wohl gängigsten Kurz definition rekursiver Funktionen verwendet wird: „E ine rekursive Funktion ist eine Funktion, die sich  selbst aufruft“. Doch ist dieses Modell nur für den  Spezialfall endrekursiver Prozeduren geeignet.  Wenn der rekursive Aufruf nicht die letzte Aktivitä t ist, kann er nicht als Wiederholung eines ansonsten abgeschlossenen Vorgangs betrachtet werden. Man  spricht dann von eingebetteter Rekursion. Un tersuchungen von Dicheva und Close (1996) belegen, dass Schüler bei der Interpretation von LogoProgrammen das Modell der Selbstaufforderung auch f ür eingebettete Rekursion verwenden (Details  in Anhang 4.4). 93     9.6.4 Delegationsmodell   Im Delegationsmodell wird deutlich zwischen der Def inition und Ausführung einer Funktion diffe renziert. Eine Funktion wird nur einmal definiert, kann aber durch mehrere Akteure (die Prozesse rep räsentieren und sich zu einem Zeitpunkt in untersch iedlichen Zuständen befinden) ausgeführt werden.  Beim Aufruf einer Funktion (durch einen Akteur) wir d eine Aufgabe an einen anderen Akteur dele giert, der entweder schon existiert oder in diesem Moment erzeugt wird. Das Delegationsmodell ist  nicht nur auf rekursive Aufrufe beschränkt, sondern  kann für jede Art von Funktionsaufruf verwendet  werden. Bei einem rekursiven Aufruf ist allein die Besonderheit, dass der neue Akteur gemäß dersel ben (einmaligen) Funktionsdefinition arbeitet wie d er aufrufende Akteur. Das Konzept der Wiederho lung spielt hier keine Rolle. Der aufrufende Akteur  (Prozess) wartet bis die delegierte Aufgabe erle digt ist und arbeitet dann (eventuell unter Verwend ung eines zurückerhaltenen Ergebnisses) weiter.  Das Delegationsmodell (ohne Schachtelung mit statis chen Akteuren) kann in Rollenspielen veran schaulicht werden, indem mehrere Personen gemeinsam  einen rekursiven Algorithmus ausführen und  jeweils Teilaufgaben an andere Personen delegieren.  Visualisierungen, die auf dem Delegationsmodell  basieren werden in Anhang 4.5 diskutiert.  Wie das Beispiel aus Abschnitt 9.6.2 zeigt, unterst ützt die Logo-Mikrowelt nicht das Delegations modell, weil die gesamte rekursiv beschriebene Akti vität ein und demselben Akteur (Turtle) zuge schrieben wird. Ebenso passt das Delegationsmodell nicht zum Paradigma der objektorientierten Pro grammierung. Beim rekursiven Aufruf innerhalb einer  rekursiven Methode wird kein neues Objekt der  Klasse instanziert, sondern dasselbe Objekt erneut beauftragt.   9.6.5 Protokoll-Modelle für rekursive Algorithmen  Visualisierungen der Arbeitsweise rekursiver Funkti onen wie die in Abb. 41 (Abschnitt 8.9, Fibo nacci-Zahlen) stellen die Mechanik des Zusammenspie ls verschiedener Akteure in den Mittelpunkt der  Modellierung. Sie fokussieren auf eine Veranschauli chung der Semantik eines rekursiven  Funktionsaufrufs. Dabei bleibt die „Gesamtidee“ des  Algorithmus im Hintergrund.   Protokollmodelle (siehe Abschnitt 2.5) dagegen abst rahieren weitgehend von der Steuerungsme chanik und geben ein als Gestalt erfassbares und gu t merkbares Bild vom Ablauf eines rekursiven  Algorithmus. So liefert ein Suchbaum eine holistisc he Vorstellung der (rekursiven) binären Suche.  Jeder Pfad von der Wurzel zu einem Blatt ist ein Pr otokoll eines Suchvorgangs. Eine Matroschka  (Russian Doll) ist ein Abbild ihres rekursiven Hers tellungsprozesses.  Viele „rekursive Phänomene“ (Levi & Lapidot 2000, L evi et al. 2001) oder Abbildungen aus Logo  Art Galleries (z.B. Tuzova & Katz 2001) können als Protokoll des Ablaufs einer rekursiven Funktion  interpretiert werden. D.h. das Ergebnis (das Bild) liefert gleichzeitig eine Vorstellung von seiner (r e kursiven) Herstellung.   9.6.6 Schema einer rekursiven Funktion und Dedynami sierung   Anderson, Pirolli und Farell (1988) sehen die Schwi erigkeit rekursiver Programmierung darin, dass  es Menschen schwer fällt, die Ausführung einer reku rsiven Funktion in Gedanken nachzuspielen: „…  recursive mental procedures are very difficult – pe rhaps impossible – for humans to execute” (S.160).  Ist damit Rekursion eine Denkweise, für die der Men sch nicht geschaffen ist?  Versuchen wir eine differenzierte Betrachtungsweise . Das Delegationsmodell zur Erklärung eines  rekursiven Aufrufs als solches  ist einfach und intuitiv. Dass Aufgaben an andere delegiert werden  können, ist eine Alltagserfahrung und Funktionsaufr ufe werden in nicht-rekursiven Zusammmenhän gen leicht verstanden. Dagegen ist es eine völlig a ndere, äußerst anstrengende Aktivität, die konkrete   Ausführung einer bestimmten rekursiven Funktion in Gedanken nachzuspielen – zu simulieren.  Schließlich muss ein  Individuum Protokoll über alle beteiligen Prozesse  führen und ihre Zwischenzu stände memorieren.   Mehr noch: Für das Verstehen oder Kreieren eines re kursiven Algorithmus kann der Gedanke an  die konkrete Ausführung geradezu schädlich sein. De nn der Versuch des Nachspielens ist eine unnöti ge mentale Belastung und lenkt von der eigentlichen  Aufgabe ab.  94     Durch rekursive Funktionen können Probleme nach dem  Prinzip des „divide and conquer“ gelöst  werden, nach Schwill (1993) eine fundamentale algor ithmische Idee der Informatik. Ein divide-andconquer-Algorithmus ist nach folgendem Muster aufge baut:  Wenn das Problem einfach genug ist, löse es direkt (Elementarfall).  Sonst:         Spalte das Problem in kleinere Teile,           Löse die Teilprobleme durch einen oder mehr ere rekursive Funktionsaufrufe          Generiere  aus den Teillösungen, die von re kursiven Aufrufen geliefert werden,        eine Gesamtlösung  Es handelt sich nicht um ein mentales Modell, sonde rn um ein Schema zur Beschreibung des  (sprachlichen) Aufbaus der Definition einer rekursi ven Funktion. Es gibt einen festen Rahmen vor und  enthält Slots für variable Teile, die an die jeweil ige Problemstellung angepasst werden müssen. Genau  genommen gibt es mehrere Schemata für das divide-an d-conquer-Muster, die sich aber nicht in den  verwendeten Konzepten sondern nur in der Reihenfolg e ihrer Anwendung unterscheiden. Eine beson ders einfache Konkretisierung ist die folgende reku rsive Funktion zur Berechnung des Spiegelbildes  einer Zeichenkette (Python):  def mirror (w):     if w== "": return w     else: return mirror(w[1:]) + w[0]           Ein wichtiger Punkt ist, dass in dem divide-and-con quer-Schema keine Wiederholungen vorkom men. Sie entstehen erst, wenn ein Interpreter – der  aber nicht Gegenstand der Modellierung ist – das  Programm ausführt. Die Besonderheit rekursiver Funk tionen liegt im rekursiven Aufruf, im Beispiel  mirror(w[1:]) . Anderson et al. (1988) vergleichen ein solches St ück Programmtext mit einem  Neckerschen Würfel, einer Abbildung, für die es zwe i Interpretationen gibt (Kippbild). Man kann  mirror(w[:1])  einmal als Aufruf einer Funktion (deren Ausführung  man in Gedanken nachvoll ziehen möchte) oder zum anderen einfach als Name fü r einen Wert (in diesem Fall die gespiegelte  Version des Teilstrings w[1:] ) auffassen.   Mit letzterem Modell wird von der komplexen Mechani k der Ausführung praktisch komplett abs trahiert. Offenbar ist es denkökonomisch, bei einer  Analyse einer rekursiven Funktion – wie bei einem  Kippbild – gewissermaßen „innerlich umzuschalten“ u nd die Betrachtungsweise zu ändern: Man be ginnt mit dem schrittweisen Nachvollziehen der Anwe isungen des Programmtextes. Doch beim rekur siven Aufruf bricht man diese Aktivität ab und nimm t das Ergebnis des rekursiven Aufrufs als gege ben hin. Dieser Wechsel der Sichtweise scheint jedo ch Schwierigkeiten zu bereiten. Das ergeben  Untersuchungen mit der PVS. In verschiedenen Python  Visuals wurden Teilnehmer mit verschiedenen  Animationen zur Erklärung der Arbeitsweise rekursiv er Funktionen konfrontiert. Die meisten Teil nehmer der PVS bevorzugten die längeren und komplex eren Animationen, die die Rekursion vollstän dig bis zum Abbruch im Elementarfall nachvollziehen , gegenüber Darstellungen, die nur den ersten  rekursiven Aufruf zeigen (Details im Anhang 4.6).  95       10 Verarbeitung   Ein Computer wird häufig als Gerät beschrieben, das  Daten verarbeitet. In diesem Kapitel wird un tersucht, wie elementare intuitive Modelle zur Ents tehung, Vernichtung, Veränderung und Bewegung  verwendet werden, um Verarbeitungsprozesse darzuste llen.  10.1 Entstehen  Modelle für Verarbeitungsvorgänge implizieren häufi g die Entstehung neuer Entitäten. Entstehung  kann als Erschaffung (Kreation) oder als Auswahl ge sehen werden. 10   10.1.1 Entstehen von Daten  Die Anweisung b = a wird bei Verwendung eines Behältermodells für Varia blen als Kopieren  des Inhalts von a beschrieben. Dabei wird eine neue  Datenentität (die Kopie) geschaffen. Das Refe renzierungsmodell dagegen korrespondiert mit der Vo rstellung einer Entstehung durch Auswahl. Die  Zuweisung a = 3  wird hier so interpretiert, dass aus einem konstan ten Reservoire von Zahlen, die  Zahl 3 ausgewählt und mit a benannt wird.  10.1.2 Entstehung von Namen  In einem Programm, das in einer typisierenden Progr ammiersprache formuliert worden ist, wird die  Erzeugung einer Variablen in zwei Teile aufgeteilt:  Deklaration (d.h. Zuordnung des Namens zu ei nem Datentyp) und erste Zuweisung (Initialisierung) . Man kann sich die Deklaration als Entstehung  eines leeren Behälters mit Aufschrift a vorstellen oder als Reservierung eines Namens, der  aber zu nächst nichts benennt.   Die üblichen höheren Programmiersprachen lassen es zu, dass man sich die Definition eines Na mens als Kreation vorstellen kann. Die Menge möglic her Namen wird durch die Grammatik der Spra che begrenzt, ist aber dennoch riesig. Zu gutem Pro grammierstil gehört es, dass Variablennamen aus sagekräftig sind und dem Leser die Rolle der Variab len im Programm verraten (z.B. summe ,  minimum ). Subjektiv kann somit die Schaffung eines Namens sogar mit dem Entstehen von Algo rithmik verbunden sein.   Es konnte beobachtet werden, dass Schüler Variablen  Eigenschaften zumessen, die sie nicht besit zen. Sie verwenden damit ein überzogenes („magische s“) Entstehungskonzept und glauben, dass  durch Schaffung eines Namens auch Funktionalität kr eiert wird. Wenn z.B. eine Variable smallest   genannt wird, glauben diese Schüler, dass beim Lese n von Zahlen aus einem Datenstrom dieser Vari ablen automatisch der kleinste vorkommende Wert zug ewiesen wird (Putnam et al. 1989).  Bei einem Tabellenkalkulationsprogramm dagegen wähl t man eine Zelle (d.h. einen Namen der  Form SpalteZeile  für einen Wert) aus einem relativ kleinen Angebot von Zeichenkombinationen aus.  Die Namen dienen allein der Adressierung und sind k eine Bedeutungsträger. Ähnliches gilt für Mik roprogramme eines Prozessors mit gegebenem Set von Registern. Allerdings sind hier die Register mit  bestimmten Möglichkeiten der Verarbeitung verbunden .  10.2 Vernichtung  10.2.1 Implizite Vernichtung bei Zuweisungen  Programmiersprachen enthalten spezielle Konstrukte zur Vernichtung. Beispielsweise gibt es bei  Python das Kommando del zum Löschen von Objekten. Python-Listen besitzen di e Methode re move()  zur gezielten Entfernung von Elementen. Es gibt ab er auch Programmteile, die mit Vernich tung verbunden sind, ohne dass dies – durch eine be sondere Anweisung – expliziert wird. So impli ziert die Überschreibung einer Variablen die Vernic htung des vorigen Inhalts.                                                         10  Zu Entstehungskonzepten im Alltag siehe Anhang 5.1  96     Aufgabe 2 des Python Quiz Modeling assignments  enthält Animationen, die folgende Anweisungs folge visualisieren:  today = "Monday"  today = "Tuesday"  today = "Wednesday"  In den von den Spielern zu bewertenden Animationen wurden drei verschiedene Modelle zur Dar stellung der Variablen today  verwendet:  • Notizzettelmodell. Ein Blatt Papier trägt als Übers chrift (größerer Schrifttyp und blaue Schriftfar be) den Variablennamen today . Darunter werden mit einem Stift die aktuellen Wer te geschrie ben.  • Behältermodell. In eine Box mit Etikett today  werden Zettel mit dem aktuellen Wert gegeben.   • Zeigermodell. Von einem Brett mit dem Namen today  führt ein Zeiger zu dem aktuellen Wert.  Mit diesen Grundmodellen werden in den Animationen Zuweisungen veranschaulicht und dabei  verschiedene Vernichtungskonzepte verwendet:  (1) Als ungültig markieren: Auf einem Notizzettel m it Überschrift today  werden sukzessive neue Werte  (Monday , Tuesday , …) geschrieben, nachdem der alte Wert in der Zeil e darüber durchgestrichen  worden ist (Abb. 46 links).  (2) Zerstörung (1): Auf einem Notizzettel werden su kzessive neue Werte geschrieben, nachdem jeweils  der alte Wert ausradiert worden ist (Abb. 46 zweite s Bild).  (3) Zerstörung (2): Die Variable wird durch einen B ehälter mit der Aufschrift today  repräsentiert, in den  sukzessive neue Zettel mit den Wochentagen wandern.  Kurz bevor ein neuer Zettel in den Behälter ge langt, wird der alte Zettel mit einem Blitz zerstör t (Abb. 46 drittes Bild).  (4) Verlust: Bevor in den Behälter mit der Aufschri ft today  ein neuer Zettel gelangt, bewegt sich der  vorige Inhalt heraus, so dass sich immer nur ein Ze ttel in dem Behälter befindet (Abb. 46 viertes Bild ).  (5) Lösen von Bezügen: Die Variable wird durch ein Zeigermodell repräsentiert. Die Daten-Entitäten (Ze t tel mit den Wochentagen) bleiben während der Zuweis ungen erhalten. Allein der Zeiger wechselt von  einem Zettel zum nächsten. Dabei löst sich jeweils der Bezug des Variablennamens zum vorigen Wert  (Abb. 46 rechts).                Abb. 46: Darstellung von Zuweisungen mit unterschied lichen Vernichtungsmodellen.  Tab. 15 zeigt, dass alle fünf Varianten von der Meh rheit der beobachteten Schülerinnen und Schü ler spontan als gültige Modelle für sukzessive Zuwe isungen gewertet werden. Allerdings wird das  erste Modell, bei dem der vorige Wert als ungültig markiert wird, signifikant seltener als korrekt erkannt als die beiden letzten Modelle (exakter Fishe r-Test, p = 0.03 bzw. p = 0.004). 97     n = 154 Dauer der   Animation Entscheidungs zeit (Stdabw.) Als passend  beurteilt von  Konfidenz  (Stdabw.)  1. Als ungültig markieren  (pq_assign_a2_5) 8 s 8.12   (6.71) 102 (66.2 %) 91.7% (23.4%)  2. Ausradieren des vorigen Inhalts   (pq_assign_a2_6) 10 s 9.28 s  (6.22 s) 111 (72.1%) 94.6% (15.6%)  3. Wegsprengen des vorigen Inhalts  (pq_assign_a2_3) 7 s 10.14 s  (11.01) 117 (76.0 %) 89.3% (25.3%)  4. Verlust des vorigen Inhalts  (pq_assign_a2_2) 7 s 9.45 s  (12.45) 120 (77.9%) 91.2% (24.0%)  5. Lösen eines Bezuges  (pq_assign_a2_9) 6 s 7.77 s   (5.88) 125 (81.2%) 93.6% (17.9%)  Tab. 15: Beurteilung von Modellen zur Veranschaulic hung von Zuweisungen.  Berücksichtigt wurden die Antwo rten aus  ersten Spieldurchgängen von 154 Schülerinnen und Sc hülern, die an Workshops mit der PVS teilgenommen h aben.    10.2.2 Sukzessive Zuweisungen ohne Vernichtung  Eine „Fehlvorstellung“ bei der Interpretation von s ukzessiven Zuweisungen ist die Annahme, dass  die vorherigen Werte erhalten bleiben und sozusagen  die Geschichte der Variable aufgezeichnet  wird 11 .  Diese Vorstellung entspricht der Art und Weise, wie Menschen neue Information aufnehmen.  Als aktueller Wert wird dann die neuste Information  übernommen und die alten in den Hintergrund  gedrängt. Man erfährt, wer der der neue Bundeskanzl er ist und speichert den Namen unter der Rubrik  „Bundeskanzler“ ab, vergisst aber nicht die Namen d er vorigen Amtsinhaber. Es ist fraglich, ob man  dieses Zuweisungskonzept unbedingt als fehlerhaft e instufen muss. Denn auch wenn vergangene Wer te zu sehen sind, ist doch der aktuelle („neuste“) Wert erkennbar. Sajaniemis Visualisierungsvorschlag   für Stepper (Streifen mit Werten, von denen einer a ls „aktuell“ markiert ist) bezieht auch vergangene  (und zukünftige) Werte ein (Sajaniemi 2002).   Aufgabe 2 des Python Quiz Modeling assignments  enthält Filme mit den drei oben genannten  Grundmodellen für Variablen, die sukzessive Zuweisu ngen ohne Vernichtung des vorigen Wertes  visualisieren. Zuweisungen führen zu Akkumulation v on Datenentitäten. Beim Notizzettelmodell  (Abb. 47 links) werden Werte untereinander geschrie ben. Der untere Schriftzug ist der aktuelle Wert.  Im Behältermodell wird das neue Datum vor das zulet zt aktuelle gesteckt (Abb. 47 Mitte). Beim Zei germodell entsteht bei jeder Zuweisung ein neuer Ze iger unter dem zuletzt hinzugefügten Zeiger (Abb.  47 rechts).            Abb. 47: Sukzessive Zuweisungen ohne Vernichtung  Die Bewertungsergebnisse aus Tab. 16 zeigen, dass n ur eine Minderheit der beobachteten Schüle rinnen und Schüler vernichtungsfreie Zuweisungsmode lle für geeignet halten. Dabei gibt es einen  signifikanten Unterschied zwischen der Einschätzung  des Notizzettelmodells und des Zeigermodells  (p = 0.028), den man darauf zurückführen könnte, da ss die PVS-Spieler mit dem Notizzettelmodell  vertrauter sind (vgl. Umfrage zu Visualisierungen i m Informatikunterricht Abschnitt 2.6).                                                         11  In mehreren Studien konnte beobachtet werden, dass  Schüler glauben, eine Variable könne gleichzeitig mehre re Werte enthalten (vgl. Putnam et al. 1989, Ben-Ar i 2001). 98     n = 154 Dauer der  Animation Entscheidungs zeit (Stdabw.) Als passend  beurteilt von  Konfidenz  (Stdabw.)  1. Notizzettel   (pq_assign_a2_4) 8 s 10.67 s  (10.80) 40 (26.0%) 8.38 (3.08)  2. Behälter   (pq_assign_a2_1) 6 s 7.92 s  (4.65) 54 (35.1%) 8.70 (2.94)  3. Zeiger   (pq_assign_a2_8) 6 s 11.38 s  (24.53) 59 (38.3 %) 8.81 (2.84)  Tab. 16: Beurteilung von Zuweisungsmodellen ohne Ver nichtung. Berücksichtigt wurden die Antworten aus ers ten Spiel durchgängen von 154 Schülerinnen und Schülern, die an Workshops mit der PVS teilgenommen haben.   10.2.3 Totale Vernichtung   Bei einer Zuweisung geht zwar der vorige Inhalt ein er Variablen verloren, aber der Variablenname  wird nicht zerstört. Für die vollständige Vernichtu ng eines Objektes (Wert einschließlich des zugehö rigen Namens) enthalten Programmiersprachen besonde re Anweisungen. Bei Python z.B. bewirkt die  Anweisung  del a  die Entfernung des Namens a aus dem Namensraum. Die  Folge ist z.B., dass anschließend kein  Zugriff mehr auf a möglich ist und eine Anweisung w ie  print a  zu einem Laufzeitfehler führt. Variablennamen sind also – im Unterschied etwa zu Daten – stabile  Elemente in der Mechanik eines Programmlaufs. Sie e xistieren von der Deklaration oder ersten Zu weisung bis zum Ende des Programmlaufs. Datenflüsse  – nach Pennington (1987) eine wichtige Abs traktion eines Programmtextes – oder das Konzept de r Rollen (Sajaniemi 2002) implizieren die Dau erhaftigkeit von Variablen. Dennoch können sich vie le Menschen vorstellen, dass bei einer Zuweisung   today = "Tuesday"  zuerst das komplette existierende Objekt mit dem Na men today  zerstört und dann ein neues Objekt  mit gleichem Namen geschaffen wird. Im Python Quiz „Modeling assignments“ (Aufgabe 2) akzep tierten 96 von 154 beobachteten Schülerinnen und Sc hülern ein solches Modell. 12  Dieses Ergebnis  zeigt, dass Anfänger häufig nicht deutlich zwischen  dem Namen und dem Wert einer Variablen diffe renzieren, sondern beides als eine Einheit sehen.  10.3 Veränderung (Metamorphose)  Wenn ein Baum wächst, ein Auto neu lackiert oder ei n Pudel frisiert wird, verändern sich Objekte,  aber sie behalten in unserer Vorstellung ihre Ident ität. Es ist immer noch derselbe Baum, dasselbe  Auto und derselbe Pudel, nur einzelne Aspekte der E rscheinung haben sich geändert. Aus dem Alltag  sind uns radikale Wechsel der äußeren Erscheinung b ekannt:  • Aus einer Raupe wird ein Schmetterling (Metamorphos e), aber es bleibt dasselbe Individuum.  • Wenn Wasser verdampft, bleibt es derselbe Stoff. Nu r der Aggregatzustand ändert sich.  • Wenn Eisen und Schwefel chemisch reagieren, entsteh t ein neuer Stoff mit neuen Eigenschaften  (Eisensulfid). Aber die Atome bleiben erhalten. Im Eisensulfid sind die Atome der Ausgangsstoffe  nur anders angeordnet.  Moderne Programmiersprachen unterstützen das Konzep t der Veränderung. Man kann komplexe  Objekte wie z.B. Listen definieren, die veränderbar  sind. Bei einer Liste können z.B. Elemente ent                                                        12  Die Vorstellung einer totalen Vernichtung erwies s ich sogar als besonders hartnäckig. Schüler, die da s Spiel  mehrfach spielten, bewerteten diese Visualisierung  immer wieder als passend, obwohl das System jedes Mal mit  Punktabzug reagierte (Einzelheiten in Anhang 5.3) 99     fernt, ersetzt oder neue Elemente eingefügt werden.  Dabei behalten sie ihre Identität. Aber auch unabhängig von den Konstrukten, die die Programmierspra che bereithält, verwenden wir in intuitiven Mo dellen zur Datenverarbeitung verschiedene Vorstellu ngen von Veränderungen.   10.3.1 Datenumwandlungen  In manchen intuitiven Modellen zum Erklären und Ver stehen von Programmen verändern sich En titäten, die Daten repräsentieren. Abb. 48 zeigt ei n Beispiel. Hier visualiert der 17-jährige Schüler S.  die Java-Anweisung  b = a.toUpperCase()   durch einen Akt der Magie. Nach der Berührung mit e inem Zauberstab verwandelt sich ein Wort  aus Kleinbuchstaben in ein Wort aus Großbuchstaben.  Man könnte sagen, es ist das gleiche Wort  geblieben nur die Schreibweise hat sich geändert. I n dieser Betrachtungsweise erhält man die Kontinu ität der Entität, indem man sich von der Ebene der Daten (Zeichenkette) auf die Ebene des Wissens,  das durch die Daten repräsentiert wird, begibt.   In einer detailgenauen Interpretation dieses Progra mmstücks passiert eigentlich folgendes: Das  Stringobjekt a produziert mit Hilfe seiner Methode toUpperCase()  einen zweiten String der aus a  berechnet wird. Dieser Aspekt, dass das Original ei gentlich unversehrt bleibt und ein zweites, neues  Objekt entsteht, wird bei diesem Beispiel im Konzep t der Umwandlung einfach ignoriert.     Abb. 48: Visualisierung der Ausführung eines Method enaufrufs durch die Metamorphose einer Datenentität   Weitere Beispiele für Umwandlungen von Datenentität en sind (mehr dazu in Anhang 5.4):  • Interpretation von cast-Anweisungen als Verändern d es Typs einer Datenentität.   • Die Vorstellung der „Zerlegung“ einer Zahl in Fakto ren.  • Verändern von Listen (Löschen oder Hinzufügen von E lementen).  10.4 Namenumwandlungen  In Kapitel 6 haben wir Namen als Mechanismus beschr ieben, Entitäten zu identifizieren und zu ad ressieren. Intuitive Modelle zur Arbeitsweise von P rogrammen enthalten manchmal Umbenennungen.  Wenn eine Funktion einen Wert als Parameter übernim mt, ist dies mit einer Umbenennung verbunden.  Stellt man sich die Funktion als Box mit Einund A usgang vor, dann wird der Funktion als Eingabe  ein Objekt übergeben, das im Innenraum der Funktion  unter einem anderen Namen gehandhabt wird  als in der Umgebung (visuelles Beispiel in Anhang 5 .5).  Ein zweiter Zusammenhang, in dem Namensumwandlungen  eine Rolle spielen, sind Rechenproto kolle zur Darstellung der Arbeitsweise einer Funkti on. Ein mathematischer Term oder Funktionsaufruf  kann als Name für einen (noch unbekannten) Wert int erpretiert werden.   Viele Menschen machen sich die Arbeitsweise einer s olchen Funktion klar, indem sie – mit einem  Funktionsaufruf beginnend – eine Folge von Termen a ufschreiben, die ein Rechenprotokoll darstellt.  Beim Übergang von einem Term zum nächsten wird ents prechend den Anweisungen der Funktionsde100     finition ein Subterm durch einen anderen (äquivalen ten) Term ersetzt. Beispiel (rekursive Berechnung  der Fakultät):  fak(4)  4 * fak (4-1)  4 * fak(3)  4 * 3 * fak(3-1)  usw.  Am Ende eines solchen Rechenprotokolls steht ein We rt. Alle vorhergehenden Terme kann man als  Namen dieses Wertes auffassen. Jeder einzelne Umfor mungsschritt ist somit eine Modifikation eines  (indirekten) Namens. Beobachtungen mit der PVS habe n gezeigt, dass viele Menschen Rechenproto kolle gegenüber strukturorientierten Visualisierung en bevorzugen (siehe Anhang 5.5 und 5.6).  10.5 Bewegen   Menschen sind mobile Wesen. In der Entwicklungsgesc hichte der Menschheit war für Jahrmillio nen die Beherrschung von Bewegungsvorgängen (z.B. i m Zusammenhang mit Fliehen, Jagen und  Standortverlegungen) für das Überleben entscheidend . In der Alltagssprache werden Veränderungen  häufig durch Bewegungsmetaphern beschrieben. Man re det vom „Aufstieg in die erste Bundesliga“,  „Höhenflug der Aktienkurse“ oder beobachtet „Bewegu ng auf dem Arbeitsmarkt“. In der Mathema tikdidaktik gibt es eine lange Tradition, arithmeti sche Operationen durch Bewegungen auf der Zahlen geraden darzustellen (Lakoff & Núnez 1997).  Mit Bewegungen werden auch in der Informatik Verarb eitungsprozesse veranschaulicht. In diesem  Abschnitt untersuchen wir Modelle, die Bewegungen v on Daten und Namen verwenden. Vorstellun gen zur Bewegung von Botschaften in der Objektorien tierten Programmierung werden im Zusammen hang mit Objekten in Abschnitt 12.5 behandelt. Mode lle für Funktionsaufrufe können mit einer Bewe gung der Funktionsentität verbunden sein, nämlich d ann, wenn wir uns vorstellen, dass die Funktion  wie ein Werkzeug zu einer zu bearbeitenden Daten-En tität gebracht wird.  10.5.1 Bewegung von Daten  Wenn Daten-Entitäten mit einem Aufenthaltsort assoz iiert werden, können Verarbeitungsprozesse  durch Bewegungen – also Ortswechsel der Daten – dar gestellt werden.   • In einem Venn-Diagramm wird die Zugehörigkeit zu ei ner Menge dadurch festgelegt, dass ein  Element sich innerhalb eines (z.B. durch eine gesch lossene Linie) markierten Bereichs aufhält.  Beispielsweise kann das Entfernen eines Elementes ( Daten-Entität) aus der Menge dann so darge stellt werden, dass es aus diesem Bereich herausgeh olt wird.  • Modelle von Listen oder Arrays, bei denen Items neb eneinander liegen oder in einem Behälter mit  mehreren Fächern aufbewahrt werden, können sortiert  werden, indem die Elemente die Plätze  wechseln.  • Eine Funktion wird aufgerufen, indem eine Daten-Ent ität in eine Box wandert, die die Funktion  (genauer den Prozess, der beim Aufruf einer Funktio n generiert wird) repräsentiert (Datenfluss modell).  • Eine Zuweisung der Form b = a  kann durch Bewegung einer Daten-Entität (oder eine r Kopie)  von Behälter a nach Behälter b visualisiert werden.   • Ein Baum, in dem die Eltern-Kind-Beziehung durch rä umliche Nähe der Knoten dargestellt wird,  kann durch Verschieben der Knoten umstrukturiert we rden.  Obwohl Graphen räumliche Darstellungen sind, können  sie nur in Ausnahmefällen durch (alleini ge) Bewegung der Knoten verändert werden. Da bei ei nem Graphen jeder Knoten mit beliebig vielen  anderen Knoten über Kanten verbunden sein kann, spi elt der Ort des Knoten keine Rolle. Nur in sehr  einfachen Strukturen (Bäume, lineare Strukturen ode r Ringe) lassen sich die Kanten durch räumliche  Nähe (Nachbarschaft) darstellen (s. Abb. 49). Allei n dann kann der Graph durch Datenbewegung um strukturiert werden. 101       Abb. 49: Visualisierung von Graphen (Baum, Ring) oh ne explizite Repräsentation der Kanten  10.5.2 Modellierung von Zuweisungen durch Datenbewe gung  Bewegungsmodelle entstehen, wenn man Materialbewegu ng aus dem Alltag (Transport von Ge genständen, Flüsse) auf die Verarbeitung von Daten überträgt. Ein bekanntes Beispiel ist die Visuali sierung der Zuweisung b = a  durch Transport des Inhalts von a nach b.   In der PVS-Applikation Python Visual Assign  wurden verschiedenen Modelle mit Datenbewegun gen zur Visualisierung der Anweisungsfolge   a = 3  b = a  angeboten (s. Abb. 50).  (1) Naive Bewegung einer Datenentität von a nach b.  (2) Bewegung einer Kopie des Inhalts von a nach b.  (3) Der Behälter b holt sich mit Hilfe eines Greifarms eine Kopie des  Inhalts von Behälter a.           Abb. 50: Modelle mit Datentransport zur Visualisier ung einer Zuweisung: Naiver Transport (pq_assign_a1_4 ), Trans port einer Kopie (pq_assign_a1_5) und Holen einer Kop ie (pq_assign_a1_7)  Das naive Bewegungsmodell wurde von etwa der Hälfte  der Teilnehmer (48.1 %) akzeptiert, aber  die Modelle, die die Bewegung einer Kopie darstellt en, signifikant bevorzugt (Fisher-Test, p = 0.000).   Im dritten Modell ist der Behälter mit Aufschrift b  der Akteur, der den Datentransport bewerkstelligt.   Offenbar können sich die meisten Schüler (81.2%) ei ne Zuweisung auch als „Daten holen“ vorstellen.  Die Beurteilungen der beiden letzten Modelle unters cheiden sich nicht signifikant. Dies lässt sich so  interpretieren, dass die Frage des Akteurs bei der Interpretation von Zuweisungen keine Rolle spielt.  Insbesondere gibt es keinen „kognitiven Vorteil“ (m ehr Intuitivität), wenn man sich eine Zuweisung  so vorstellt, dass eine Entität (Variable der linke n Seite der Zuweisung) sich einen neuen Wert von  einer anderen Entität (Variable der rechten Seite d er Zuweisung) holt. 102     n = 154 Dauer der   Animation Entscheidungs zeit (Stdabw.) Als passend  beurteilt von  Konfidenz  (Stdabw.)  Naïve Bewegung (pq_assign_a1_4) 6 s 12.02 s  (8.19) 74 (48.1%) 81.8% (33.7%)  Bewegung einer Kopie  (pq_assign_a1_5) 6 s 8.81 s  (6.22) 133 (86.4%) 87.7% (27.6%)  Holen einer Kopie (pq_assign_a1_7) 9 s 12.68 s  (11.56) 125 (81.2%) 86.4% (24.4%)  Tab. 17: Beurteilung von Modellen zur Veranschaulic hung von Zuweisungen der Form b = a. Berücksichtigt wurden  die Antworten aus ersten Spieldurchgängen von 154 Sc hülerinnen und Schülern, die an Workshops mit der P VS teilgenom men haben.   Weitere Beispiele für die Bewertung von Modellen mi t Datenbewegungen werden in Anhang 5.7  diskutiert.  10.5.3 Modellierung von Zuweisungen durch Namenbewe gungen  Namenbewegungen finden statt, wenn Daten als unverä nderbare, „inerte“ Entitäten betrachtet wer den und bestimmte Datenentitäten durch Zuordnung ei nes neuen Namens markiert und damit in einen  neuen Sinnzusammenhang gestellt werden.   Namenbewegungen erlauben einfache Modelle für Itera tionen über Sequenzen und Bäumen. Dabei  wandert z.B. der Name des aktuellen Elementes über die Entitäten der Kollektion. Im Modell einer  Suchoperation (z.B. Suche nach einem Minimum in ein er unsortierten Liste) kann der „most-wantedholder“ (bei einer Minimumsuche der kleinste bisher  gefundene Wert, vgl. Sajaniemi 2002) durch  einen weiteren beweglichen Namen gekennzeichnet wer den.   Betrachten wir nun die Rolle von Namenbewegungen be i der Interpretation von Zuweisungen.  Abb. 51 zeigt Screenshots aus Animationen der PVS, die sich auf die beiden Anweisungen  a = 3  b = a  beziehen.  (1) Im ersten Modell (pq_assign_a1_9) schweben Kart en mit Zahlen durch den Raum. Ein Klebezettel mit  Aufschrift a fliegt ins Bild, bewegt sich zur Karte  mit der Zahl 3 und bleibt an ihr kleben ( a = 3). Ein  zweiter Klebezettel mit Aufschrift b erscheint und heftet sich an den Zettel mit Aufsch rift a. Dieses  Modell ist inkonsistent (und wird vom System als un geeignet bewertet), weil einmal der Klebezettel als   Name eines Datums (3) fungiert und das zweite Mal a ls Name eines Namen ( b als Name für a). Dies  ist ein Beispiel einer Kettenbildung (siehe Abschni tt 6.8).  (2) In der zweiten Animation (pq_assign_a1_6) wird das Behältermodell für Variablen verwendet. Zur  Darstellung der zweiten Zuweisung entsteht eine Kop ie des Namensschildes a und bewegt sich in den  Behälter mit Aufschrift b. Dieses Modell ist in sofern ungeeignet (und wird auch vom System als sol ches bewertet), als ein Kasten einmal als Behälter für Daten (Zahlen) und einmal als Behälter für Na men dargestellt wird. Wiederum handelt es sich um e ine Namenskette, die der Semantik des Pro gramms nicht entspricht.  (3) In der dritten Animation (pq_assign_a1_10) wird  die zweite Zuweisung durch Anbringen eines zweiten   Namensschildes ( b) an den Behälter mit Inhalt 3 visualisiert. Dieses Modell ist (im Unterschied zu  den  vorigen Modellen) insofern akzeptabel, als die Schi lder a und b gleichermaßen als Name für die Zahl 3  dargestellt werden. Gleichwohl ist dieses Modell pr oblematisch, wenn man für komplexere Programme  verwenden möchte. Was passiert, wenn anschließend d ie Anweisung a = 3  ausgeführt werden soll?  Das Modell suggeriert die Vorstellung, dass dann in  dem Behälter die 2 durch eine 3 ersetzt würde.  Dies ist aber falsch, da Variable b ihren alten Wert ( 2) behält. Stattdessen müsste man annehmen, dass  ein neuer Behälter entsteht, der das neue Datum 3 aufnimmt und das Namensschild a erhält.   (4) Die vierte Animation (pq_assign_a1_8) schließli ch enthält eine konsistente und korrekte Visualisie  rung von Zuweisungen durch Namenbewegungen. Der Nam e b bewegt sich zunächst in Richtung Kle103     bezettel a und heftet sich dann an die gleiche Datenentität ( Karte mit der Zahl 3), an der sich bereits  der Name a befindet.                 Abb. 51: Modelle mit Namenbewegung zur Visualisierung  einer Zuweisung: Namenskette (pq_assign_a1_9) Transp ort  der Kopie eines Namens (pq_assign_a1_6), zweiter Name f ür Behälter (pq_assign_10) und zweiter Name für Datum   (pq_assign_a1_8)    n = 154 Dauer der   Animation Entscheidungs zeit (Stdabw.) Als passend  beurteilt von  Konfidenz  (Stdabw.)  Namenskette (pq_assign_a1_9) 9 s 13.75 s  (11.58) 78 (50.7%) 78.2% (30.7%)  Transport der Kopie eines Namen  (pq_assign_a1_6) 6 s 10.50 s  (7.75) 98 (63.6%) 87.2% (24.1%)  Zweiter Name für Behälter  (pq_assign_a1_10) 6 s 17.31 s  (18.40) 103 (66.9%) 77.6%  (31.3%)  Zweiter Name (pq_assign_a1_8) 9 s 14.05 s  (12.56) 119 (77.27%) 82.1% (31.1%)  Tab. 18: Beurteilung von Modellen zur Veranschaulic hung von Zuweisungen der Form b = a. Berücksichtigt wurden  die Antworten aus ersten Spieldurchgängen von 154 Sc hülerinnen und Schülern, die an Workshops mit der P VS teilgenom men haben.   Am unproblematischsten gibt das vierte Modell Zuwei sungen durch Namensbewegungen wieder.  Fast vier Fünftel (119) der 154 Schüler, die Python Visual  Assign  gespielt haben, waren bereits beim  ersten Spieldurchgang überzeugt, dass es eine geeig nete Veranschaulichung ist (Tab. 18). Allerdings  schnitt es signifikant schlechter ab als das Behält ermodell (Abb. 50 Mitte), bei dem die Zuweisung  b = a durch Transport einer Kopie des Inhalts von a nach b visualisiert wurde (Fisher-Test,  p = 0.04).  Betrachten wir nun die beiden ersten Animationen, d ie ungeeignete Namenbewegungen mit Ket tenbildung enthalten. Beide Modelle wurden von den meisten der 154 Schülerinnen und Schüler posi tiv bewertet. Doch zeigte sich, dass das falsche Be hältermodell (pq_assign_a1_6) eher als richtig ak zeptiert wurde (63.6 %) als das falsche behälterfre ie Modell (pq_assign_a1_9 mit 50.7%). Der  Unterschied ist signifikant (p = 0.029).   Bei Vielspielern konnte zudem beim behälterfreien M odell ein höherer Lerneffekt beobachtet wer den (Abb. 52 links). Im dritten Spiel haben 90% der  41 Schüler dieses Modell als ungeeignet einge stuft im Vergleich zu nur 76% beim Behältermodell. 104        Abb. 52: Beurteilung unpassender Modelle mit Namenbe wegungen für Zuweisungen. Lernkurven bei Vielspielern  (n =  41) für ein behälterfreies Modell (pq_assign_a1_9, links) und ein Modell mit Behälter (pq_assign_a1_6,  rechts)  Das Behältermodell mit falschen Namenbewegungen ist  persistenter als das behälterfreie Modell.  Trotz Feedback, Reflektion und in der Regel auch Di skussion mit Parallelspielern erkennen ein Viertel  der Vielspieler auch im dritten Durchgang nicht, wa s an dem Modell nicht stimmt. Das wirft ein ge wisses Licht auf das Modell „Variablen sind Behälte r für Daten“ als solches. In diesem Zusammen hang scheint es zu falschen Vorstellungen „zu verfü hren“. Der Fehler der Kettenbildung wird dagegen  im Etikettmodell leichter erkannt und in späteren S pieldurchgängen vermieden.  Zum Schluss dieses Abschnitts vergleichen wir noch verschiedene Zeigermodelle zur Darstellung  von Zuweisungen (Abb. 53). Zeiger sind wie Etikette n bewegliche Namen für Objekte, besitzen aller dings in ihrem Ursprung (breiteres Ende) einen ruhe nden Punkt. Bei Zeigerbewegungen bleibt also der  Ursprung mit der Bezeichnung des Namens (hier: a und b) ortsfest und die Spitze wandert – unter  gleichzeitiger Verformung des Pfeils – zur benannte n Entität.   (1) Das erste Modell ist ein inverses Zeigermodell.  Der Ablauf ist folgender: Zunächst entsteht ein Ze iger  aus der Karte mit der 3, der sich zum Namensschild a hin entwickelt, danach „wächst“ ein zweiter  Zeiger zum Namensschild b. Die Animation bringt damit die Vorstellung zum Au sdruck, dass die Ak tivität bei der Namenszuordnung vom benannten Objek t ausgeht. D.h. das Objekt 3 sucht über den  Pfeil, der aus ihm herauswächst, selbst die Verbind ung zu seinen Namen. Es handelt sich eigentlich  nicht um eine Namenbewegung, eher ähnelt es einer D atenbewegung, da die Datenentität aktiv ist.  (2) Das zweite Modell ist ein Beispiel für eine Ket tenbildung. Aus dem Namensschild b wächst ein Pfeil,  der auf das Namensschild a zeigt. Da in der Semantik des Programmtextes sowoh l a als auch b Namen  für eine Zahl sind, ist dieses Modell unpassend.  (3) Das dritte Modell ist eine plausible Anwendung des Zeigermodells. Aus dem Namensschild a wächst  ein Zeiger zur Karte 3. Bei der Visualisierung der zweiten Zuweisung ist der genaue Bewegungsvor gang von Bedeutung. Die Zeigerspitze von b bewegt sich zuerst zum Namensschild a und „tastet“ sich  am Zeiger von a entlang bis zur Karte 3.           Abb. 53: Modelle mit Zeigerbewegung zur Visualisieru ng von Zuweisungen: Zeiger vom Objekt zum Namen  (pq_assign_a1_13) Zeigerkette (pq_assign_a1_12) und  zwei Zeiger zur Zahl (pq_assign_11).  Fast die Hälfte aller beobachteten Schülerinnen und  Schüler (70 von 154) hielten das inverse Zei germodell (Modell 1) für korrekt. Die Lernkurve von  Vielspielern (Abb. 53 links) indiziert eine hohe  Persistenz dieser Vorstellung. Das inverse Zeigermo dell wurde vom System als unpassend gewertet.  Nur wer sich dieser Einschätzung anschloss, erhielt  Pluspunkte. Trotz „Bestrafung“ durch das System  haben im zweiten Durchgang nur wenig mehr Personen das inverse Zeigermodell als unpassend einge schätzt. Erst im dritten Durchgang stieg ihr Anteil  auf etwa 71% an. 105     Die Verkettung von Zeigern in Modell 2 entspricht d er bereits diskutierten Verkettung von Namen  (Abschnitt 6.8) und ist unpassend. Dennoch wurde es  von mehr als der Hälfte der Schülerinnen und  Schüler (87 von 154) akzeptiert. Im Unterschied zum  inversen Zeigermodell konnte man aber eine  steile Lernkurve beobachten. Bereits in der zweiten  Sitzung bewerten 85% der Vielspieler das Modell  als unpassend (Konfidenz 90%). Dies kann man so deu ten, dass an diesem Modell der „Denkfehler“  einer Namensverkettung besonders leicht erkannt wir d.  Modell 3 ist ein von der Fachgemeinschaft allgemein  akzeptiertes Modell und wurde von den  Schülern in der ersten Sitzung gegenüber den beiden  anderen den beiden anderen Zeigermodellen  signifikant häufiger akzeptiert.    n = 154 Dauer der   Animation Entscheidungs zeit (Stdabw.) Als passend  beurteilt von  Konfidenz  (Stdabw.)  Zeiger vom Objekt zum Namen  (pq_assign_a1_13) 5 s 13.35 s  (13.77) 70 (45.5%) 76.0% (35.8%)  Zeigerkette  (pq_assign_a1_12) 5 s 12.07 s  (13.75) 87 (56.49%) 88.6% (24.6%)  Zwei Zeiger zur Zahl  (pq_assign_a1_11) 6 s 13.36 s  (11.38) 119 (77.27%) 83.1%  (29.8%)  Tab. 19: Beurteilung von Modellen zur Veranschaulic hung von Zuweisungen mit Zeigern.   Berücksichtigt wurden die Antworten aus ersten Spield urchgängen von 154 Schülerinnen und Schülern, die a n Workshops  mit der PVS teilgenommen haben.    Abb. 54: Beurteilung als unpassend eingestufter Mod elle mit Zeigerbewegungen. Lernkurven bei Vielspiele rn (n = 41)  für Zeiger vom Objekt zum Namen (pq_assign_a1_13, li nks) und Zeigerkette (pq_assign_a1_12, rechts)  106       11 Klassen  11.1 Intuitive Modelle in der Objektorientierten Pr ogrammierung  Ein objektorientiertes Programm ist ein System von Objekten, die Botschaften austauschen. Jedes  Objekt besitzt Attribute, die Wissen repräsentieren , und beherrscht Operationen, mit denen das gekap selte Wissen verarbeitet werden kann. Eine Besonder heit der OOP ist, dass das mentale Modell von  interagierenden Entitäten Bestandteil des Paradigma s ist und mit der Begrifflichkeit der Fachsprache  beschrieben wird. Objektorientierte Programme solle n häufig Realitätsausschnitte modellieren (Hub wieser 1999, 2004; Schubert & Schwill 2004) sind ab er in der Regel nicht völlig strukturtreu. Das  Hauptmotiv der informatischen Modellierung ist Denk ökonomie. Das heißt, das Design ist so ange legt, dass möglichst gut verständliche Systeme ents tehen. Nun gibt es einen seltsamen Doppelbezug.  Einerseits soll häufig das informatische System tat sächlich ein Modell eines Realitätsausschnitts sein .  In diesen Fällen ist die Grundlage des Entwurfs ein  Fachkonzept, das sich mit der Realität (z.B. die  Verwaltungsabläufe in einer Bibliothek) beschäftigt  und sie analysiert. In dieser Realität liegt der  praktische Nutzen des Programms (z.B. Verwaltung vo n Büchern in einer Bibliothek). Auf der ande ren Seite aber dienen Teile dieser Realität (Bücher , Leser, ...) als Metaphern für das geschaffene Pro  gramm und helfen, das System übersichtlich und durc hschaubar zu machen. Diese Metaphern unter scheiden sich allerdings erheblich von den realen O bjekten. Sie sind keine Modelle im  naturwissenschaftlichen Sinn.  11.2 Klassenbegriff   Der Begriff Klasse (class) bezeichnet ein allgemein es Muster für Objekte (Instanzen, Inkarnatio nen) mit gemeinsamen Attributen und Methoden. Nach dem Paradigma der OOP besteht Programmie rung letztlich aus der Definition von Klassen. Ein konsequent objektorientiertes Programm besteht aus  einem einzigen Objekt einer Klasse, das aus anderen  Objekten anderer Klassen zusammengesetzt ist.  Je nach Anwendungskontext werden völlig unterschied liche intuitive Modelle für Klassen verwendet,  wie in diesem Abschnitt erläutert werden wird.  Die Idee der Klasse ist sehr alt und kann bis in di e griechische Philosophie der Antike zurückver folgt werden. Aristoteles (384 – 322 v. Chr.) betra chtete es als das Hauptanliegen seiner insgesamt 17 0  Werke, die Dinge der Welt zu klassifizieren (nach T aivalsaari 1996). Objekte gehören zur selben Ka tegorie, wenn sie gemeinsame Eigenschaften besitzen . Die Kategorie selbst wird durch eine Gruppe  von Eigenschaften definiert. Durch Spezifikation ge meinsamer und unterschiedlicher Eigenschaften  können aus bekannten Kategorien neue gewonnen werde n. Der aristotelische Klassenbegriff ist die  philosophische Grundlage für das Klassenkonzept obj ektorientierter Programmiersprachen (Taivalsaa ri 1996).   11.3 Klasse als Bauplan   Wer sich eine Klasse als Bauplan vorstellt, begibt sich in die Rolle eines Architekten, der spezifi ziert, wie ein Objekt einer Kategorie später ausseh en soll. Der Bauplan ist die Dokumentation aber  noch nicht die Sache selbst. Um aus einem Bauplan e in Objekt zu generieren, braucht man einen Ak teur (Konstruktor) und Baumaterial. In OO-Programmi ersprachen wie Java oder Python enthalten  Klassendefinitionen eine besondere Methode zur Init ialisierung eines Objektes, die man als Konstruk tor bezeichnet. Es macht aber keinen Sinn, diese Me thode als Kreationsoperation zu begreifen, mit der  ein Objekt erzeugt wird. Denn wie soll ein Objekt e ine Operation ausführen, wenn es noch gar nicht  existiert? Vielmehr enthalten diese Methoden einen Mechanismus, der variable Teile eines Objektes  mit Anfangswerten belegt (Initialisierung). Die eig entliche Schaffung eines Objektes muss durch einen  Akteur außerhalb des geschaffenen Objektes bewerkst elligt werden. Die Bauplanmetapher spielt eine  große Rolle beim Entwurf der Architektur eines Soft waresystems im Sinne eines SoftwareEngineerings (z.B. Sommerville 1997). Hier werden d ie technischen Komponenten eines Systems  vollständig erfasst und in einen strukturellen Zusa mmenhang gebracht, der z.B. in einem UMLKlassendiagramm dokumentiert wird.  107     11.4 Klasse als Fabrik für Objekte  Bei der Fabrik-Metapher stellt man sich eine Klasse  als Akteur vor, der Objekte bestimmter Art  produzieren kann. Im Unterschied zur Bauplan-Metaph er wird das Augenmerk auf die Instanzierung  von Objekten – also die „Produktion“ – gelegt 13 .   Die Programmiersprache Python unterstützt die Fabri k-Metapher, da Klassen – so wie Funktionen  – aufrufbare Objekte („callable objects“) sind, die  ein Objekt generieren und zurückgeben.   11.5 Klasse als Menge von Objekten  Eine Klasse kann als Menge von Objekten eines besti mmten Typs vorstellen. In der Philosophie  spricht man von der Extension einer Kategorie. So v erbindet man häufig mit numerischen Klassen wie  int  oder float (Python) den Gedanken an die Menge der ganzen Zahle n oder die Menge der  Gleitkommazahlen. Das Mengenkonzept wird auch im Zu sammenhang mit Klassenattributen verwen det. Ein Klassenattribut kann als gemeinsames Attri but aller denkbaren (aber unter Umständen noch  gar nicht existierenden) Objekte der Klasse gesehen  werden.   11.6 Klasse als Prototyp  Im Prototyp-Modell stellt man sich eine Klasse durc h ein konkretes Objekt vor, das gewissermaßen  als Stellvertreter für alle Inkarnationen der Klass e fungiert. Im Grunde gibt es zwei Konzepte für Pro  totypen, nämlich die Vorstellung eines typischen od er eines unfertigen Objektes. In der Begriffspsy chologie (Rosch 1973, 1975; vgl. Anhang 6.4) ist ei n Prototyp ein typisches Exemplar eine Kategorie.  In Anlehnung an dieses Konzept kann man eine Klasse  durch ein typisches Objekt beschreiben, dem  alle Objekte dieser Klasse ähneln. Bei einer Instan zierung werden Abweichungen des neu geschaffe nen Objektes vom (in der Klassendefinition festgele gten) Standard spezifiziert.   Eine Klasse kann man sich auch als unfertiges Objek t – als vereinfachte, vorläufige Version – vor stellen, dem bei der Instanzierung fehlende Teile h inzugefügt werden. Beide Intuitionen können auch  gleichzeitig verwendet werden.   Nun gibt es spezielle Programmiersprachen, bei dene n das Prototyp-Konzept expliziter Bestandteil  des Programmierparadigmas ist (Smith & Ungar 1995; Taivalsaari 1992, 1996, siehe auch Anhang  6.5). Aber auch wenn man in einem Projekt eine der etablierten objektorientierten (und nicht prototyporientierten) Programmiersprachen wie Java oder Pyt hon verwendet, kann das Prototyp-Modell von  Bedeutung sein. Betrachten wir zunächst das „Progra mmieren im Großen“.  Im Software Engineering ist Prototyping eine Method e der Software-Entwicklung (Sommerville  1997, S. 167 ff.). Hier  versteht man unter einem P rototyp eine Software, die ein vereinfachtes Modell   der Zielsoftware darstellt und schnell zu implement ieren ist. Entscheidend ist, dass der Prototyp lauf  fähige Software ist, die evaluiert werden kann, etw a um Schwächen oder Lücken der Systemspezifika tion festzustellen. Eine besondere Rolle spielt das  Prototyp-Konzept beim agilen Programmieren. Hier  ist der Entwicklungsprozess in eine Folge von Itera tionen aufgeteilt, an deren Ende immer ein lauffä higes Programm steht, das mit den Kunden diskutiert  werden kann. Ausgehend von einem minimalen  System wird mit jeder Iteration das Produkt dem Zie lprodukt immer ähnlicher. Man geht davon aus,  dass zu Beginn des Prozesses die genaue Funktionali tät des Zielproduktes noch gar nicht bekannt ist.  Es existiert erst eine vage Vorstellung, die sich i m Laufe der Entwicklung – parallel zur Evolution de r  Software – präzisiert.   Auch auf der Ebene des „Programmierens im Kleinen“ kann die Entwicklung einer Klasse mit ei ner objektorientierten Programmiersprache nahezu vö llig prototyporientiert sein. Anfänger, die in der  Syntax und Semantik einer Programmiersprache noch u nsicher sind, folgen häufig einer experimentel len Strategie, die dem Test Driven Development (TDD ) des Extreme Programming (Beck 2003) äh nelt. Sie definieren in ihrem Programmtext zunächst  eine minimale Klasse und ein paar Zeilen, die  eine Instanzierung beinhalten und dem Testen dieser  Klasse dienen. Damit haben sie einen Prototyp,  ein unfertiges konkretes Objekt, das als Stellvertr eter für alle Objekte der Klasse dient. In der weit eren                                                         13  Schülerzeichnungen mit visuellen Modellen für Klas sen befinden sich in Anhang 6.2 108     Entwicklung wird die Klassendefinition sukzessive e rweitert und alle Zwischenversionen getestet und  debuggt. Obwohl man formal eine Klassendefinition s chreibt, modelliert man doch – aus psychologi scher Sicht – einen Prototyp. Alle kognitiven Aktiv itäten drehen sich um ein einzelnes Objekt, das die   Klasse repräsentiert 14 .  11.7 Klasse als Behälter für Funktionen (Toolbox)  Objektorientierte Programmiersprachen (z.B. Java od er Python) erlauben die Definition statischer  Methoden. Eine statische Methode kann aufgerufen we rden, ohne ein Objekt der Klasse zu instanzie ren. Beispiel (Java):  a = Math.sqrt(2)  Die Klasse Math  stellt hier einen Behälter für Funktionen dar (Too lbox) dar. Statische Methoden  verändern keine Objektzustände, verhalten sich also  wie Funktionen im Sinne des funktionalen Pro grammierparadigmas. Man kann sie sich als eigene En tität – völlig losgelöst von der Klasse – vorstel len. Der Klassenname, der im Funktionsaufruf vorkom mt, wird dann nicht Bezeichnung eines Objek tes, an das eine Botschaft geschickt wird, interpre tiert, sondern eher als Präfix eines Funktionsnamen s.                                                          14  Ein konkretes Beispiel für diesen Prozess findet s ich in Anhang 6.6. 109       12 Objekte   12.1 Zustand eines Objektes – Datenbesitz oder holi stische Befindlich keit  In der objektorientierten Programmierung definiert man den Zustand eines Objektes durch die Be legungen seiner Attribute (Instanzvariablen), sofer n es sich um „einfache Attribute“ handelt, denen ei n  einfacher Wert (Datum) zugeordnet wird. Komplexe Ob jekte (z.B. Aggregate aus mehreren Teilen)  besitzen darüber hinaus Attribute, die selbst wiede r Objekte sind. Hier ergibt sich der Zustand des  komplexen Objektes aus den Zuständen der verbundene n Objekte (Balzert 1999). Letztlich kann man  sich den Zustand eines Objektes als eine Kombinatio n von Daten vorstellen. Sich in einem Zustand  befinden, heißt in dieser Sichtweise: Daten besitze n. Die Veränderung eines einzigen Werts impliziert  die Veränderung des Gesamtzustandes des Objektes.   Neben dieser Vorstellung „Zustand als Datenbesitz“ gibt es noch ein zweites, holistisches Konzept,  mit dem der Zustand eines Objektes als Befindlichkeit begriffen wird. Meist geht man von einer klei nen Menge von Zuständen aus, die in einem Sinnkonte xt von Bedeutung sind und deshalb in irgendei ner Weise mit der Funktionalität des Objektes verkn üpft sind.   Bei einem Objekt, das eine Verkehrsampel modelliert , könnten diese Zustände die Ampelphasen  sein: rot, rot-gelb, grün, gelb. Bei einer realen A mpel gibt es nur diese Zustände. Sie sind jeweils m it  einer verkehrsrechtlichen Bedeutung verknüpft (Sinn kontext). Sie sind insofern mit Funktionalität  verknüpft als nur bestimmte Übergänge von einem Zus tand zum nächsten erlaubt (und sinnvoll) sind.  So hat die Gelbphase die Bedeutung „Achtung, gleich  kommt Rot.“ Autofahrer, die dieses Signal se hen, müssen entscheiden ob sie Gas geben oder anhal ten. Angesichts dieses Sinnkontextes muss der  Folgezustand die Rotphase sein, alles andere wäre s innlos. In einem Ampel-Objekt kann die Folge der  durchlaufenen Zustände durch eine Liste – also ein einziges Attribut – dargestellt werden. Hier wird  das holistische Zustandskonzept verwendet. Alternat iv könnte ein Ampelobjekt für jede der drei  Leuchten (rot, gelb, grün) ein eigenes Attribut bes itzen, das mit den booleschen Werten True  oder  False belegt ist, je nachdem ob die Leuchte einoder aus geschaltet ist. Diese Modellierung orien tiert sich stärker am technischen Aufbau einer real en Verkehrsampel (höhere Strukturtreue). Es sind  nun aber auch Zustände möglich, die in der Realität  nicht vorkommen und denen keine Semantik zu geordnet ist (z.B. gleichzeitiges Aufleuchten von R ot und Grün).  Das holistische Konzept der Befindlichkeit wird in der zustandsorientierten Modellierung (Hub wieser 1999, 2004) und insbesondere in Zustandsüber gangsgraphen für endliche Automaten verwen det (Albert & Ottmann 1983). Hier repräsentiert man  einen Zustand durch einen Knoten in einem ge richteten Graphen. Ein Zustand wird als Ort im Raum  und ein Zustandwechsel als Bewegung zu einem  anderen Ort (über eine Kante des Graphen) visualisi ert. Ein Ort ist eine geschlossene Gestalt. Eine  Entität kann nicht an mehreren Orten gleichzeitig s ein. Sie kann sich nicht mit einem Aspekt ihres  Seins an dem einen und mit einem anderen Aspekt an dem anderen Ort befinden.   Im Unterschied zum Modell des Datenbesitzes werden im Befindlichkeitsmodell Zustände mit aus sagekräftigen Namen versehen. Ein Prozess kann sich  z.B. in den Zuständen „aktiv“ oder „wartend“  befinden. Für ein Objekt, das ein Bankkonto modelli ert, gibt es aber keinen eigenen Namen für den  Zustand, der sich ergibt, wenn der Besitzer „Monika  Gabel“ heißt und sich 1200 EUR auf dem Konto  befinden.   Holland et al. 1997 haben beobachtet, dass Studente n häufig glauben, dass Objekte nur ein einziges  Attribut besitzen dürfen. Sie führen dies auf bloße s Nichtwissen zurück und empfehlen einführende  Beispiele mit mehreren Attributen. Die Ursache für diese Tendenz könnte aber auch im holistischen  Zustandskonzept liegen. Wenn man von einem zustands orientierten Modell für das Verhalten einer  Entität ausgeht, ist es nahe liegender, die möglich en Zustände in einem einzigen Attribut zu speichern .  Eine verfeinerte, weiter gehende Modellierung impli ziert, dass man die Gestalt des Zustandes auf bricht und die Struktur des zu modellierenden Origi nals analysiert. Teilaspekte seiner Beschaffenheit  müssen identifiziert und durch Attribute repräsenti ert werden. 110     12.2 Instanzierung von Objekten – Produktion oder A uswahl  Intuitive Modelle zur Instanzierung von Objekten ko rrespondieren mit Vorstellungen über Klassen.  Vor dem Hintergrund der Ausführungen in Kapitel 11 kann man zwei grundsätzliche Instanzierungs modelle unterscheiden:  • Herstellung eines neuen Objektes (Klasse als Fabrik , Bauplan oder Prototyp). Argumente des  Konstruktoraufrufs werden als Individualmerkmale de s neuen Objektes interpretiert.  • Auswahl eines Objektes aus einem Vorrat (Klasse als  Menge). Argumente des Konstruktoraufrufs  werden als Auswahlkriterien interpretiert. Damit su cht der Konstruktor ein passendes, bereits exis tierendes Objekt heraus.  12.3 Instanzierungsmodelle in der PVS  In der PVS-Applikation Python Quiz „Objects“ werden  verschiedene intuitive Modelle aus dem  Bereich der OOP thematisiert. Grundlage ist folgend e Klassendefinition (Python):  class Container (object):      def __init__(self, max):          self.max = max          self.content = 0        def fill (self, volume):          self.content += volume          if self.content > self.max:              self.content = self.max    # overflow        def empty (self):          volume = self.content          self.content = 0          return volume    Die Klasse Container modelliert Behälter mit einem begrenzten Fassungsve rmögen,  z.B. Fla schen für Flüssigkeiten. Mit  der Methode fill() wird ein Behälter mit einem gewissen Volumen  befüllt und mit empty()  wird er vollständig entleert.  Ein typisches objektorientiertes Programm repräsent iert eine „magische Welt“, in der Objekte agie ren können, die in der Realität völlig passiv sind.  So kann im Programmtext dieses Beispiels sich eine   Flasche selbst befüllen und Materie (Inhalt einer F lasche) aus dem Nichts entstehen. Die Vorstellung  einer Welt aus Flaschen, deren Inhalte umgefüllt we rden, ist eine Analogie, eine anschauliche Konkre tisierung des formalen Programmtextes. Wie wir spät er sehen werden, kann es dabei vorkommen, dass  auf unzulässige Weise Merkmale des modellierten Rea litätsausschnitts in die Interpretation des Pro grammtextes einbezogen werden (siehe Abschnitt 12.4 ).   Alle Aufgaben verwenden diese Klassendefinition. Be i den ersten drei Aufgaben soll der folgende  Programmtext (Zeile für Zeile) interpretiert werden :  bottle = Container (0.7)  bottle.fill(0.4)  bottle.empty()  Bei der vierten und fünften Aufgabe geht es um die beiden letzten Zeilen des folgenden Pro gramms:  bottle = Container (0.7)  vase = Container (1.5) 111     bottle.fill(0.4)  vase.fill(bottle.empty())  Bei jeder Aufgabe ist ein Stück des Programmtextes mit einem gelben Hintergrund versehen und  auf diese Weise optisch herausgehoben. Die angebote nen visuellen Modelle sollen die Arbeitsweise  dieser Programmpassage veranschaulichen. Die nachfo lgend verwendeten Daten zur Bewertung der  Modelle als passend oder unpassend beziehen sich au f 23 erste Sitzungen im Rahmen von Workshops  mit der PVS. Teilnehmer waren 21 Schüler, ein Hochs chulstudent und ein Lehrer, darunter vier weib liche und 19 männliche Personen. Das mittlere Alter  betrug 18,4 Jahre und die wöchentliche Zeit, in  der man sich mit Programmierung beschäftigte, 3,2 S tunden (weitere Details im Anhang 6.8).   Wir vergleichen zunächst einige Modelle, die die In stanzierung eines Objektes der Klasse Contai ner in der Anweisung bottle = Container(0.7) visualisieren.  (1) Das erste Modell (pq_objects_a1_2) visualisiert  die Klasse Container als Tablett mit einem Vorrat  an Flaschen unterschiedlicher Größe dar. Dem Klasse nobjekt wird von oben ein Zettel mit Aufschrift  0.7  übergeben. Ein Manipulatorarm ergreift diesen Zett el, legt ihn ab, sucht eine Karaffe passender  Größe heraus und gibt sie zurück. In diesem Modell produziert die Klasse also kein Objekt, sondern  die Instanzierung wird als Auswahl aus einem Vorrat  dargestellt (Abb. 55 erstes Bild).   (2) Die zweite Animation (pq_objects_a1_3) verwende t die Fabrikmetapher und stellt die Klasse Contai ner als Box mit der Aufschrift Container()  dar. Ein Zettel mit der Zahl 0.7  schwebt ins Bild, aus  der Box kommt ein Manipulatorarm, und ergreift den Zettel. Die Box generiert eine Flasche (Objekt  der Klasse Container ), die die Box verlässt und an die ein Zettel mit d em Namen bottle geheftet  wird.   (3) Das dritte Modell (pq_objects_a1_6) basiert ebe nfalls auf dem Herstellungskonzept. Allerdings wird   die Instanzierung eines Objektes als Ereignis durch  einen Blitz mit Beschriftung Container()  dar gestellt. Die Klasse selbst wird nicht als eigenstä ndige Entität veranschaulicht. Ein Zettel mit Auf schrift 0.7  schwebt ins Bild. Mit einem Blitz verschwindet der  Zettel und stattdessen ist eine Glaska raffe zu sehen. An sie wird ein Zettel mit dem Name n bottle  geheftet. Die Instanzierung wird also  auf die Verarbeitung eines Zahlenwertes (Metamorpho se) reduziert.          Abb. 55: Screenshots aus Animationen zur Veranschau lichung von Instanzierungen (aus Python Quiz Object s)  Tab. 20 kann man entnehmen, dass alle drei Modelle überwiegend als passend beurteilt wurden. Es  lässt sich keine signifikante Bevorzugung des einen  oder anderen Modells feststellen.   n = 23 Dauer der Ani mation Entscheidungs zeit (Stdabw.) Als passend beur teilt von  Konfidenz  (Stdabw.)  1. Auswahl  (pq_objects_a1_2) 6 s 25 s (28) 17 (74%) 74% (40%)  2. Fabrik  (pq_objects_a1_3) 12 s 15 s (11) 18 (78%) 80% (35%)  3. Metamorphose  (pq_objects_a1_6) 6 s 11 s (12) 18 (78%) 83% (24%)  Tab. 20: Beurteilung von Modellen für Instanzierung en. Berücksichtigt wurden die Antworten aus ersten Sp ieldurchgän gen von 23 Personen (darunter 21 Schülerinnen und S chülern), die an Workshops mit der PVS teilgenommen  haben.   Eine weitere Animation (pq_objects_a1_5) ist eine V ariante des oben beschriebenen Fabrikmo dells. Wiederum wird die Klasse Container durch eine Box dargestellt. Der Unterschied zu Mo112     dell pq_objects_a1_3 ist, dass sie neben einem Zett el mit Aufschrift 0.7  noch einen zweiten Zettel  mit dem Objektnamen  bottle  als Eingabe erhält. Anschließend verlässt eine Kar affe (Objekt) mit  Klebezettel bottle  die Box. Hier wird die Instanzierung so interpreti ert, dass die Klasse benannte  Objekte produziert. Das widerspricht insofern der S emantik des Programms, als die Benennung durch  die Zuweisung erfolgt und nicht bei der Initialisie rung eines Objektes in der Klassendefinition. (Das  Objekt kann ja später umbenannt werden.) Immerhin 1 4 Spieler (61 %) hielten im ersten Durchlauf  dieses Modell für passend. Das Ergebnis lässt sich so interpretieren, dass die Fabrikmetapher gewis sermaßen „ausstrahlt“. Sie wird nicht allein zur Be schreibung der Instanzierung verwendet sondern als  Modell für die gesamte Zuweisung (Instanzierung plu s Benennung). Damit verbunden ist auch die  Vorstellung, dass der Name Bestandteil des Objektes  ist.  12.4 Interaktion von Objekten – Verarbeitung von Bo tschaften  In der Objektorientierten Programmierung ist die Vo rstellung interagierender Entitäten expliziter  Bestandteil des Paradigmas. Objekte senden und empf angen Botschaften. Dieser Abschnitt widmet  sich dem Botschaftskonzept. Wir gehen dabei auf fol gende Fragen ein: In welchem Maß wird das  durch eine Botschaft beauftragte Objekt als Akteur gesehen? Wie gelangt eine Botschaft zu ihrem  Adressaten?   12.4.1 Objekte als Verursacher von Aktivität  Nach dem Paradigma der OOP empfängt ein Objekt eine  Botschaft, wertet sie aus und führt die  spezifizierte Operation aus. Der Ursprung der Aktiv ität liegt also im beauftragten Objekt.   Das Python Quiz „Objects“ enthält Animationen, die die Aktivität bei der Ausführung eines Auf trags auf unterschiedliche Weise auf das Objekt und  seine Umgebung verteilt. Wir betrachten Model le, die die Ausführung der Anweisung bottle.fill(0.4) veranschaulichen.   (1) Im ersten Modell wird die Botschaft (Oval mit P rogrammtext bottle.fill(0.4)) an die Karaffe (Objek t  der Klasse Container) gesendet. Anschließend füllt sich die Karaffe auf magische Weise von alleine  (Abb. 56). Dies ist eine passende aber weniger natu ralistische Veranschaulichung des Programmtextes.    Abb. 56: Objekt als Akteur. Screenshots aus der Ani mation pq_objects_a2_4  (2) Das zweite Modell ist naturalistisch und stellt  die Befüllung der Flasche mit einer „Abfüllstation “  (Rohr mit Hebel zum Öffnen und Schließen) dar. Die Botschaft wandert zur Abfüllstation. Diese wird  nun aktiv, das Rohr bewegt sich zur Karaffe und bef üllt sie. Die Karaffe selbst (Objekt der Klasse Con  tainer) bleibt völlig passiv, was dem Paradigma der  OOP widerspricht (Abb. 57).     Abb. 57: Umgebung als Akteur. Screenshots aus der A nimation pq_objects_a2_3 113     (3) In der Animation pq_objects_a2_1 wird die Botsc haft durch zwei Entitäten dargestellt. Ein Oval mit   der Beschriftung fill wird an eine Karaffe gesendet und veranschaulicht d ie Auswahl der Methode.  Nachdem die Karaffe diese Botschaft empfangen hat, bewegt sie sich zu einer Abfüllstation. Nun fliegt  ein Zettel mit Aufschrift 0.4  (Parameter des Methodenaufrufs) zum Schließmechani smus der Abfüll station und löst die Befüllung der Karaffe aus (Abb . 58). Die Aktivität bei der Ausführung der Operati  on wird hier auf das Objekt und seine Umgebung vert eilt.    Abb. 58: Gesplittete Aktivität. Screenshots aus der  Animation pq_objects_a2_1  (4) Im vierten Modell wird wiederum die Botschaft d urch zwei Entitäten (Oval mit Methodenbezeichnung  und Zettel mit Parameterwert) dargestellt. Das Oval  mit der Beschriftung fill  wird an die Karaffe  gesendet. Diese bewegt sich sie zur Abfüllstation u nd bringt mit einem Greifarm das Rohr in die richti  ge Position. Die Karaffe empfängt nun einen Zettel mit Aufschrift 0.4  (Parameter) und betätigt mit ih rem Greifarm den Steuermechanismus der Abfüllvorric htung. Im Unterschied zum letzten Modell ist  hier allein das Container-Objekt aktiv.  Die Ergebnisse in Tab. 21 deuten an, dass alle Mode lle überwiegend akzeptiert werden. Sie wurden  von 70% bis 90% der Teilnehmer mit hoher Konfidenz als passend beurteilt. Dagegen waren Perso nen, die die Modelle ablehnten, eher unsicher (geri ngere Konfidenz). Aufgrund der geringen Teilneh merzahl, können allerdings keine signifikanten Unte rschiede zwischen den Modellen festgestellt wer den (Fisher-Test).   n = 23 Als passend be urteilt  Konfidenz  (Stdabw.) Als unpassend  beurteilt von  Konfidenz  (Stdabw.)  1. Eigenbefüllung (1)  (pq_objects_a2_4) 21 (91%) 81% (34%) 2 (9%) 25% (35%)  2. Naturalistische Befüllung  (pq_objects_a2_3) 16 (70%) 78% (32%) 7 (30%) 76% (37%)  3. Gesplittete Aktivität  (pq_objects_a2_1) 16 (70%) 97% (13%) 7 (30%) 64% (38%)  4. Eigenbefüllung (2)  (pq_objects_a2_2) 20 (87%) 90% (21%) 3 (13%) 0% (0%)  Tab. 21: Beurteilung von Modellen zur Ausführung ei nes Auftrags mit unterschiedlicher Gewichtung der Ei genaktivität  des Objekts. Berücksichtigt wurden die Antworten aus ersten Spieldurchgängen von 23 Personen (darunter 2 1 Schülerinnen  und Schülern), die an Workshops mit der PVS teilgen ommen haben.   Abb. 59 zeigt einen Screenshot aus einer Visualisie rung der Anweisung   bottle.empty()   Aus dem Oval, das die Botschaft repräsentiert, ersc heint ein Greifarm, der die Karaffe auskippt.  Hier geht die Aktivität von der Botschaft aus und d as Objekt bleibt passiv. Dieses Modell wurde von  19 der 23 Workshop-Teilnehmer mit einer mittleren K onfidenz von 87% als passend beurteilt.   114        Abb. 59: Botschaft als Akteur  Die Auswertung der letzten Aufgabe (verschachtelte Botschaften) befindet sich in Anhang 6.9.  12.5 Übermittlung von Botschaften  Die Übermittlung von Botschaften vom Sender zum Emp fänger ist ein Akt der Kommunikation.  Wie gelangt eine Botschaft von Objekt A zu Objekt B ? Wie findet es seinen Adressaten? Die PVS  enthält einige Visualisierungen die man als Beispie le für folgende drei Routingmodelle betrachten  kann.  (1) Der Sender der Botschaft ist für die korrekte Z ustellung zuständig. Im Alltag verwenden wir dieses   Modell z.B., wenn wir jemandem bei einem Gespräch i n die Augen sehen und so signalisieren, dass die  nun folgende Sprachäußerung für ihn bestimmt ist.   (2) Die Botschaft kennt den Adressaten und findet i hn selbsttätig. Dieses Modell wird im Alltag verwen  det, wenn ein Brief von einem Boten transportiert w ird.  (3) Die Botschaft wird wie eine Rundfunksendung aus gestrahlt (Broadcasting). Alle Objekte können sie  empfangen und müssen selbst entscheiden, ob sie für  sie selbst bestimmt ist. Dies entspricht der üblichen Gesprächssituation mit mehreren Personen in ei nem Raum. Jeder kann alles hören und muss  selbst an ihn gerichtete Botschaften erkennen.  In Animationen zur Visualisierung der Anweisung bottle.fill(0.4)  werden diese unter schiedlichen Vorstellungen aufgegriffen.  Zwei Animationen verwenden das Modell der direkten Zustellung durch den Sender. Im Modell  pq_objects_a4_3 wird zunächst ein „Leitstrahl“ (bla ue Linie) auf das Empfänger-Objekt gerichtet.  Über diese Linie wandert anschließend die Botschaft  (Abb. 60 erstes Bild). Im zweiten Modell betätigt  ein Manipulatorarm einen Knopf mit der Beschriftung  fill()  auf einem Kasten, der zur visuellen  Repräsentation des Objektes bottle gehört. Offenbar  wählt die aufrufende Entität zunächst die Metho de aus, die ausgeführt werden soll. Durch diesen Ak t des „Anfassens“ wird das Objekt zum Empfän ger der Botschaft gemacht. Im nächsten Schritt flie gt dann ein Zettel mit dem Parameter 0.4 zum an gesprochenen Objekt (Abb. 60 zweites Bild).  In der Animation pq_objects_a4_2 schwebt ein Oval m it der Beschriftung bottle.fill(0.4)   ins Bild, bewegt sich zunächst zu der Vase und schl ießlich zur Karaffe, verschwindet mit einem Blitz.  Darauf hin füllt sich die Karaffe auf magische Weis e mit einer gewissen Menge Flüssigkeit (Abb. 60  drittes Bild). Hier sucht sich also die Botschaft s elbst ihren Weg zum Empfänger.  Im letzten Modell schließlich schweben von oben vie le Ovale mit der Botschaft über die Bildflä che. Eines davon trifft auf das Objekt bottle und löst die Aktivität (Befüllung) aus (Abb. 60 rec h tes Bild).             Abb. 60: Modelle mit unterschiedlicher Darstellung des Transports einer Botschaft zum Empfänger: Leits trahl, Anfassen,  selbstständige Suche und Broadcasting  115     Die Beurteilungen dieser Modelle durch 23 Teilnehme r von Workshops mit der PVS (Tab. 22) las sen erkennen, dass alle drei intuitiven Modelle ein e gewisse psychische Realität besitzen. Allerdings  wurde das Broadcasting-Modell gegenüber den Modelle n „Anfassen“ und „Eigenständige Suche“  signifikant seltener als passend beurteilt (FisherTest, p = 0.036 bzw. p = 0.006). Die vier Modelle  standen in unmittelbarem zeitlichem Kontext innerha lb einer Aufgabe. Sie wurden innerhalb einer  Minute von den Spielern wahrgenommen, so dass davon  auszugehen ist, dass sie von den Betrachtern  verglichen worden. Vor diesem Hintergrund ist bemer kenswert ist, dass gerade das Modell „Anfas sen“, welches als einziges die Botschaft nicht als eigene Entität modelliert, besonders häufig als pas  send beurteilt akzeptiert wurde.  n = 23 Dauer der Ani mation Entscheidungs zeit (Stdabw.) Als passend beur teilt von Konfidenz  (Stdabw.)  Leitstrahl  (pq_objects_a4_3) 7 s 11.3 s (12.8) 14 (61%) 78% (32%)  Anfassen  (pq_objects_a4_4) 7 s 12.7 s (10.8) 19 (82%) 79% (25%)  Eigenständige Suche  (pq_objects_a4_2) 8 s 11.6 s (12.4) 17 (74%) 91% (26%)  Broadcasting  (pq_objects_a4_1) 8 s 9.6 s (6.8) 9 (39%) 78% (36%)  Tab. 22: Beurteilung von Modellen zum Routing von B otschaften. Berücksichtigt wurden die Antworten aus e rsten Spiel durchgängen von 23 Personen (darunter 21 Schülerinn en und Schülern), die an Workshops mit der PVS teil genommen   haben.   12.6 Schlussfolgerungen  Ziehen wir – mit angemessener Vorsicht – einige Sch lussfolgerungen aus den Beobachtungen mit  der PVS. Anscheinend spielt das Botschaftskonzept i n der Vorstellungswelt von Menschen, die ob jektorientierte Programme zu verstehen versuchen, k eine große Rolle. Veranschaulichende Modelle  der PVS wurden von den Spielern vor allem dahingehe nd beurteilt, ob der Effekt, den die Ausführung  der Programmanweisungen auf den Zustand der Objekte  hat, in der Visualisierung richtig wieder ge geben wird. Aber der „Weg zum Ziel“, die im Paradig ma der OOP festgelegte Mechanik des Entsen dens von Botschaften und deren Interpretation durch  eigenaktive Objekte, scheint (zumindest für die  Spieler der PVS) nur von geringer Bedeutung zu sein . Damit wird die Bedeutung des „objektorientier ten Denkens“, das z.B. von Cecile Crutzen (1995) be tont wird, etwas relativiert. Man beachte jedoch,  dass wir mit der PVS die Konzepte der Objektorienti erung lediglich auf der Ebene der Implementie rung untersucht haben („Programmieren im Kleinen“).  Objektorientierung ist aber auch und vor allem  ein Paradigma für die Analyseund Entwurfsphase ei ner Software-Entwicklung, also des „Program mierens im Großen“ (Balzert 1999; Sommerville 1997,  S. 247 ff). Im Zusammenhang der objektorien tierten Modellierung auf hohem Abstraktionsniveau h at die Botschaftsmetapher einen ganz anderen  Stellenwert.  116       13 Intuitive Modellierung  In Kapitel 3 haben wir vier Anwendungen intuitiver Modelle unterschieden: Verstehen, Erklären,  Problemlösen und Kontrolle. In allen diesen Kontext en spielt das Ringen um Intuitivität eine Rolle. In   diesem Kapitel geht es um die Identifizierung einig er kognitiver Aktivitäten, die bei der intellektuel len  Auseinandersetzung mit Programmtexten eine Rolle sp ielen. Wir bezeichnen als „intuitive Modellie rung“ den Versuch ein gegebenes formales Programm d urch ein Cluster intuitiver Modelle zu reprä sentieren. Dabei gehen wir von folgender Annahme au s:  Das Hauptziel bei einer gedanklichen Modellierung i m Rahmen der Erklärens oder Verstehens ei nes Programms ist die Gewinnung von Intuitivität. B ei der Rekonstruktion eines Programmtextes  durch eine Kombination intuitiver Modelle werden di ese so gewählt, dass die Intuitivität maximal  wird 15 . Dabei steht die Suche nach Gewissheit im Vordergr und.  Querliegend zur informatisch-inhaltlichen Dimension  werden in den folgenden Abschnitten kogni tive Aktivitäten oder Mechanismen beschrieben, die man beim intuitiven Modellieren beobachten  kann. Dazu gehören etwa das Identifizieren von Enti täten, Abstraktion, Gestaltbildung, Animismus  oder das Bemühen um Konsistenz. Diese Aktivitäten d er Intuitionsgewinnung können – je nach Situa tion – eng zusammenhängen (und quasi gleichzeitig s tattfinden) oder aber auch im Konflikt zueinan der stehen. So steht z.B. das Streben nach logische r Konsistenz manchmal im Widerspruch zur Ges taltbildung.  Viele der hier beschriebenen Vorgänge kann man als Metaphorisierung betrachten, weil Konzepte  einer vertrauten Domäne (Source) auf eine noch unve rtraute oder zu erklärende Zieldomäne (Target)  angewendet werden. Es gibt aber auch Prozesse, die keine Metaphorisierung sind. So werden bei einer  Dramatisierung, d.h. der Einbindung eines Programmf ragments in eine sinnvolle Geschichte, Fanta sieelemente hinzugefügt, die keine Entsprechung im modellierten Programmtext (Ziel) haben.   In Anlehnung an Piagets Entwicklungsmodell könnte m an sagen, dass man sich bei Nachbildung  von formalem Programmtext durch intuitive Modelle a uf die Denkstufe konkreter Operationen begibt.  Nach diSessa ist dies ist kein negativ zu bewertend er Rückfall sondern etwas völlig normales, wenn  man sich auf noch unvertrautem Wissenterrain bewegt .  Die hier skizzierten kognitiven Prozesse des intuit iven Modellierens haben letztlich als Ziel, das  Verständnis des Programmtextes zu verbessern. Insof ern sind sie sinnvoll und haben sich zumindest in  der Biographie der Personen, bei denen man diese Pr ozesse beobachten kann, bewährt. Gleichwohl  können sie zu Fehlvorstellungen führen bzw. ihre Er gebnisse lassen sich als Fehlvorstellungen inter pretieren. Damit sind sie aber noch keine „bug gene rators“, die man generell ausmerzen muss. Es sind  normale kognitive Vorgänge, die beim Versuch, die W elt zu verstehen, ihren Stellenwert haben.   13.1 Identifizierung von Entitäten  Bei der intellektuellen Auseinandersetzung mit Prog rammtexten streben Menschen nach gedankli chen Einheiten, die sie beherrschen können. Sie suc hen nach vertrauten Entitäten in einem (zunächst)  undurchschaubaren Ganzen, die im Hinblick auf die G esamtidee des Systems wichtige Rollen spielen.  So wird man beispielsweise bei der Analyse eines it erativen Algorithmus vielleicht folgende Entitäten  identifizieren:  • Ein Container (z.B. eine Liste) mit mehreren Elemen ten.   • Das „aktuelle Element“, das während eines Durchlauf s der Iteration verarbeitet werden soll.  • Eine Funktion, die das aktuelle Element verarbeitet .                                                         15  Hier wird der Begriff Intuitivität in einem steige rungsfähigen Sinn gebraucht. Erläuterungen dazu fin den sich  in Anhang 7.1. 117     Sajaniemi (2002) hat ein System von „Rollen“ entwic kelt, die Variablen in einem Programm spie len können, und gibt für jede Rolle eine Visualisie rung an.   Beispiele für Rollen sind   • Konstante, d.h. eine Variable, die nur einen Wert a nnehmen kann, der niemals geändert wird.  • Stepper: Eine Variable, die mit einem Anfangswert i nitialisiert wird, und die im Laufe einer  Rechnung eine bestimmte Folge von Werten durchlaufe n kann. Ein Zähler, der in einer Schleife  inkrementiert wird, ist ein Beispiel für einen Step per.  • Most-wanted-holder: Eine Variable, die den besten b isher gefundenen Wert enthält. Zum Beispiel  bei der Suche nach dem Minimum in einer Sequenz bra ucht man einen Most-wanted-holder für  das bisher gefundene kleinste Objekt.  Die Rolle definiert ein Verhaltensmuster und Möglic hkeiten der Interaktion mit anderen Entitäten  des Programms. Wenn man einer Variablen eine Rolle zuordnet, bindet man sie an Funktionalität.  Eine Variable kann (wie ein menschliches Individuum ) in verschiedenen Kontexten unterschiedliche  Rollen spielen (das ist freilich schlechter Program mierstil), andererseits können unterschiedliche Var i ablen die gleiche Rolle annehmen.   In fast allen Fällen ist eine Rolle ein intuitives Konzept, das Bestandteil einer Problemlösung ist.  Wenn ich einen Algorithmus für die Suche nach dem M inimum in einer unsortierten Sequenz entwick le und auf die Idee komme, einen Most-wanted-holder  zu verwenden, habe ich bereits einen Teil der  Lösung gefunden. So wie eine Rolle in sozialen Syst em nur Sinn im Kontext komplementärer Rollen  hat. Eine Rollenbeschreibung eines Koordinators in einem Programmierteam, der z.B. Aufgaben ver teilen und Termine festsetzen soll, definiert impli zit auch zu einem großen Teil die Funktionsweise  des gesamten Teams.   Sajaniemi hat auch Programm-Beispiele in Anfänger-B üchern nach dem Vorkommen verschiede ner Konzepte (Rollen) untersucht. Erstaunlich ist, dass etwa 80 bis 90 % der Variablen den drei oben  erwähnten Rollen zuzuordnen sind: Konstante, Steppe r und Most-wanted-holder. Sajaniemi verwendet  sein Rollensystem für Programmvisualisierungen („ro le based program animation“). Variablen (und  ihre Werte) werden je nach ihrer Rolle durch versch iedene Abbildungen dargestellt. Ein Stepper z.B.  wird durch ein Band mit fortlaufenden Nummern reprä sentiert, auf dem die aktuelle Nummer einge rahmt ist. Generell sollen die Visualisierungen typ ische Eigenschaften der Rolle veranschaulichen. Im  Fall des Steppers wird die Vorhersehbarkeit der Var iableninhalte (Vergangenheit und Zukunft) durch  das Nummernband verdeutlicht. Hinter diesem Visuali sierungsansatz steht eine „Verstehensstrategie“:  Untersuche zunächst die Rollen der Variablen um die  Idee des Programms zu verstehen.   13.2 Abstrahieren  Abstraktion (lat. abstrahere: abziehen, entfernen) ist der Gegenbegriff zu Konkretisierung und be zeichnet in der Philosophie das Absehen von bestimm ten Aspekten konkreter Entitäten oder Prozesse  in der Welt. Automatische Visualisierungsversuche –  z.B. mit Sajaniemis Rollenansatz – scheitern  daran, dass sie jede  im System vorkommende Entität darstellen, was zu k omplexen und schwer ver ständlichen Mechaniken führt. 16 Es fehlt die Unterscheidung von Wichtigem und Unwic htigem. Ein  intuitives Modell eines Programmtextes muss einfach  sein. Intuitive Modellierung beinhaltet deshalb  auch Abstraktion im Sinne des Absehens von Unwichti gem:  • Bezeichner (z.B. Variablennamen) aus dem Programmte xt werden weggelassen.  • Entitäten werden nur implizit angedeutet und nicht explizit dargestellt (z.B. Blitz für die Ausfüh rung einer Funktion).  • Daten werden durch figürliche Platzhalter ersetzt. Sie sind einfacher und heben nur die für den  Algorithmus wichtigen Aspekte der repräsentierten D aten hervor. So kann ein Papierstreifen eine  Liste von Daten repräsentieren, wenn es nur auf die  Länge der Liste ankommt.                                                         16  Wie in Abschnitt 6.6 gezeigt wurde werden abstrakt ere Visualisierungen einer Iteration, die auf eine Explizie rung der Laufvariablen verzichten, gegenüber denen mit expliziter Laufvariablen bevorzugt. 118     • Umfangreiche Daten (z.B. Listen) werden unter Verwe ndung von Ellipsen (Auslassungen) darge stellt (Abb. 61). 17     • Determinismus wird durch Nichtdeterminismus ersetzt . Beispielsweise kann man manchmal die  exakte Sequenzialität von Ereignissen vernachlässig en und Aktionen, die nach dem Programmtext  eigentlich nacheinander erfolgen müssten, als neben läufige Prozesse darstellen (vgl. Abschnitt  9.2).    Abb. 61: Verwendung von Auslassungen bei der Darstel lung einer langen Liste  13.3 Gestaltbildung  Ein intuitives Modell ist eine Gestalt, ein einfach es in sich geschlossenes Ganzes. Die gedankliche  Nachbildung eines Programms bei der intuitiven Mode llierung schließt deshalb auch das Streben nach  einer Gestalt ein. Damit verbunden ist oftmals auch  das Weglassen von Details, dennoch ist Gestalt bildung nicht das gleiche wie Abstraktion. Ein wich tiger Aspekt einer Intuition als Gestalt ist die ge  dankliche Vertrautheit. Häufig verwendet man Analog ien aus dem Alltag, z.B. Gegenstände oder Ar rangements von Gegenständen, deren Funktionsweise o der Gebrauchsmöglichkeiten wohl bekannt  sind. Eine Analogie für ein Array ist z.B. ein Kast en mit mehreren Fächern, in den sich beschriftete  Zettel befinden. Mit diesem materiellen Arrangement  sind eine Reihe von möglichen Operationen  verbunden: Man kann Zettel nacheinander herausnehme n, sie lesen oder neu beschreiben etc. Alles  zusammen ergibt eine kohärente Gestalt. Das Modell des Kastens ist komplexer und besitzt einen ge ringeren Abstraktionsgrad als z.B. ein Arrangement von nebeneinander liegenden Zetteln. Es hat aber  eher Gestaltcharakter.   Um eine Gestalt „abzurunden“ kann ein intuitives Mo dell auch strukturelle Elemente enthalten, die  im Zielprogramm nicht explizit vorkommen. In Abschn itt 9.4 wurde z.B. eine Visualisierung des InPlace-Sortierens durch direkte Auswahl beschrieben,  bei der ein Glaskasten den bereits sortierten Teil   der Liste bedeckt. Damit wurde für die Hauptidee di eses Sortierverfahrens – der erste Teil der Liste i st  fertig und wird nicht mehr verändert – eine holisti sche Vorstellung gefunden, die im Programmtext  nicht einmal anklingt.  13.4 Animieren  Gestaltbildung kann auch mit Animismus verbunden se in. Animismus ist die Vorstellung, dass alle  Dinge beseelt (lat. animus: Seele) und lebendig sin d. Sie haben einen Willen und können sich ohne  Außensteuerung aus sich heraus verhalten. Nach Piag et ist Animismus eine typische Denkweise von  Kindern in der präoperationalen Stufe (z.B. Flavell  1963).   In der PVS ist eine häufig vorkommende Animation ei n fliegender Zettel, der selbst seinen Weg  findet. Die Eigenaktivität des Objektes macht die V orstellung eines steuernden Mechanismus über flüssig und vereinfacht das Modell.   Animismus ist ein Feature des objektorientierten Pr ogrammierparadigmas. Ein Objekt im Sinne der  OOP ist eine Entität, in der Daten und Operationen auf diesen Daten zu einer Gestalt zusammengefasst  sind. Das Objekt verwaltet seine Daten selbst und i nteragiert eigenständig mit seiner Umgebung. Es                                                         17  In Texten werden Auslassungen unwichtiger oder nah e liegender Passagen durch Ellipsen dargestellt. Da s sind  im Deutschen, Englischen und in den meisten anderen  Sprachen drei aufeinander folgende Punkte.   Beispiele: „Montag, Dienstag, …, Sonntag“,  A =  {1 , …, 10}. Die Ellipse ist also eine Möglichkeit, ei nen Text  zu kürzen ohne seine Aussagekraft zu verringern.  119     gibt – zumindest auf konzeptioneller Ebene – keine übergeordnete Verwaltung. Dies kann zu einfache ren und deshalb intuitiveren Modellen führen.  Objektorientiert kann man sich den Algorithmus „Sor tieren durch Vertauschen“ („Bubblesort“)  folgendermaßen vorstellen: Wir haben eine Liste von  Objekten. Jedes Objekt prüft, ob es größer als  sein linker Nachbar ist. Wenn das nicht der Fall is t, tauscht es mit ihm den Platz. Dies macht das Objekt so lange, bis keine Vertauschungen mehr notwen dig sind. Wenn sich alle Objekte der Liste so  verhalten, ist sie irgendwann sortiert. Die Idee de s gesamten Algorithmus kommt in der relativ einfa chen Gestalt eines einzelnen Objektes zum Ausdruck.    Ein Spezialfall von Animismus ist Anthropomorphismu s, d.h. die Übertragung spezifisch mensch licher Merkmale auf Elemente des Zielbereichs. Die Verwendung von Anthropomorphismen in wis senschaftlichen Erklärungen wird in der Didaktik ko ntrovers diskutiert (vgl. z.B. Kattmann 2005). In  der Anthropologie existiert die Vermutung, dass die  Fähigkeit, soziale Ereignisse (in irgendeiner frühen Form) sprachlich zu beschreiben und auf andere Phänomene anzuwenden, biologisch determiniert  ist. Mithen und Boyer (1996) sind der Auffassung, d ass die Fähigkeit zu anthropomorphem Denken  etwa vor 100 000 bis 40 000 Jahren sich gegenüber a nderen frühen Menschformen (z.B. Neandertaler)  als evolutionärer Vorteil herausgestellt hat. Erste  archäologische Hinweise auf anthropomorphes Den ken sind z.B. Abbildungen von Menschen mit Tierköpf en aus der Zeit vor 30 000 Jahren.    Abb. 62: Anthopomorphes Modell aus der PVS für die Ausführung einer rekursiven Funktion   Der informatische Fachjargon ist voller anthropomor pher Redewendungen, die zwischenmenschli che Interaktionen wiedergeben: Eine Funktion „übern immt Argumente“ und „gibt etwas zurück“, ein  Prozess „schläft“ oder wird „geweckt“. Da Menschen erheblich komplexer sind als die Komponenten  einfacher Computerprogramme, bedeutet derartige Mod ellierung durch Anthropomorphismen keine  strukturelle Vereinfachung. Der Vorteil von anthrop omorphen Modellen liegt vermutlich darin, dass  sie aus einer sehr vertrauten (und für das Überlebe n wichtigen) Erfahrungssphäre stammen und mit  einem hohen Maß an Gewissheit verknüpft sind. Jeder  hat eine ziemlich präzise Vorstellung, was es  heißt zu schlafen, obwohl dies – bei genauerer Betr achtung – ein relativ komplexes Phänomen ist  (man lebt noch, aber man ist inaktiv, bis man wiede r aufwacht). Abb. 62 zeigt einen Screenshot aus  einer Animation der PVS, in der die Ausführung eine r rekursiven Funktion auf anthropomorphe Weise  durch soziale Ereignisse, nämlich als Wechselspiel von Fragen und Antworten, modelliert wird.  13.5 Clusterbildung und Fokussierung  Intuitive Modelle sind einfach. Das hat zur Folge, dass ein Modell das Original nur unvollständig  abbildet. Dieses Problem der Begrenztheit von Intui tion löst man dadurch, dass man ein Cluster von  Modellen verwendet. Insbesondere wenn es darum geht , (anderen) ein Programm zu erklären, fokus sieren die verwendeten Modelle auf bestimmte Aspekt e. Das Verständnis des Gesamten ergibt sich  gewissermaßen aus der Summe der herangezogenen Intu itionen.   Die folgende Abbildung zeigt einen Cluster von Intu itionen zur Repräsentation einer Liste.   120     1031 liste  131013 10 110  1031 a b  Abb. 63: Cluster intuitiver Modelle für eine Liste  Oben wird die Liste als Behälter, dargestellt, der Zettel enthält. Die Zettel kann man herausnehmen  oder ersetzen. Dieses Modell fokussiert folgende As pekte einer Liste:  • Behälter: Die Liste enthält Elemente (Items)  • Entität: Die Liste ist eine eigene Entität, sie ist  mehr als die enthaltenen Elemente  • Iterierbarkeit: Man kann die Elemente nacheinander herausnehmen, um sie zu verarbeiten  • Direkter Zugriff: Man kann ein Element über das Fac h, in dem es sich befindet, erreichen.  In der Mitte wird eine Liste durch eine lineare Ano rdnung der enthaltenen Elemente dargestellt.  Deren Zusammengehörigkeit wird allein durch räumlic he Nähe dargestellt. Hier liegt der Fokus auf:  • Lückenlosigkeit: Eine Liste hat keine Leerstellen. Wenn ich ein Element entferne, wird die entste hende Lücke sofort geschlossen.  • Dynamische Länge: Die Länge einer Liste kann sich w ährend der Verarbeitung ändern.  Die untere Darstellung betont, dass (bei Python) di e Liste ein änderbares Objekt ist. Für ein und  dasselbe Objekt können mehrere Namen existieren. Ma n beachte, dass die Modelle eines Clusters in  logischem Widerspruch zueinander stehen können. So kann in der Behälterdarstellung der Liste sehr  wohl eine Lücke (leeres Fach) entstehen.  Clusterbildung tritt manchmal „blitzschnell“ und ka um wahrnehmbar auf. Ein Spezialfall von  Clusterbildung ist die Verwendung von Kontrollmodel len. Wenn man z.B. versucht sich die Arbeits weise eines Sortierprogramms klar zu machen, zieht man in Gedanken viele Intuitionen heran und  prüft sie wechselseitig auf Übereinstimmung und Wid ersprüchlichkeit:  • Die sortierte Liste muss genauso lang sein wie die unsortierte Liste.  • Das erste Element einer aufsteigend sortierten List e ist immer das kleinste.  • Eine Liste mit einem Element ist immer sortiert.  Die Intuitionen eines Clusters brauchen nicht konsi stent zu sein und sind es häufig auch nicht. Di Sessa verwendet den Begriff „scattered knowledge“ z ur Beschreibung von Wissenstrukturen aus lo cker verbundenen Ideen. Sein Ansatz des „knowledge in pieces“ (1988) ist gewissermaßen eine Ge genposition zu Theorien, die von einer konsistenten  in sich widerspruchsfreien kognitiven Struktur  ausgehen. Die Animationen der PVS repräsentieren in  der Regel nicht einzelne geschlossene Intuitio nen sondern jeweils Cluster. Für ein einzelnes intu itives Modell sind sie häufig zu komplex. In ein un d  derselben Animation können z.B. unterschiedliche Mo delle für die Benennung von Objekten vor kommen.  121     13.6 Überstrukturierung  Überstrukturierung liegt vor, wenn ein gegebenes Sy stem feiner strukturiert wird, als es eigentlich  notwendig oder zulässig ist. Durch Überstrukturieru ng können z.B. logische Implikationen atomarer  Programmelemente verdeutlicht werden.  So kann eine Animation mit einem Behältermodell für  Variablen den atomaren Vorgang einer Zu weisung der Art x = 2  in die Zerstörung des vorigen Inhalt und das Einfü llen eines neuen Inhalts  aufteilen. Mit der visuellen Explizierung der Zerst örung (z.B. durch eine Explosion) wird hervorgeho ben, dass jede Zuweisung den Verlust der vorigen Va riablenbelegung impliziert. Dies ist eine rein  logische Überlegung, die nichts mit der technischen  Realisierung in einem realen Computer zu tun  hat 18 .   Ein Funktionsaufruf innerhalb einer Zuweisung der F orm  x = f(y)  kann folgendermaßen visualisiert werden. Zuerst wir d ein Name  x  generiert, der für ein neues Objekt  bestimmt ist („wartender Name“). Dann startet die F unktion f und erzeugt ein Objekt, dem schließlich  der Name x zugewiesen wird. Der auf sein Objekt war tende Name ist eigentlich überflüssig. Er wurde  hinzu erfunden, um die Rückgabe des Objektes zu ver deutlichen. Er veranschaulicht, dass der aufru fende Prozess darauf wartet, dass die Funktion ein Objekt zurückgibt, für das dieser Name vorgesehen  ist.  Die Interpretation von Zuweisungen als Eingabe, die  bei Anfängern gelegentlich beobachtet wird,  kann als Überstülpen des EVA-Prinzips (also Hinzufü gen zusätzlicher Struktur) verstanden werden  (eine Schülervisualisierung als Beispiel findet sic h in Anhang 7.2).   Manchmal ist es für das Verständnis der Semantik ei ner Anweisung sinnvoll, wenn man in die Tie fe der Programmiersprache dringt und implizite tech nische Aspekte, die mit der Ausführung der An weisung zusammenhängen, expliziert. Hierzu einige B eispiele:  Viele Programmiersprachen verwenden implizites Cast ing bei Operationen mit Objekten unter schiedlicher Typen. Die Ausführung der Operation 1*2.3  kann man sich z.B. so vorstellen, dass  zuerst das Objekt 1 vom Typ integer  in ein Objekt vom Typ float „umgewandelt“ wird, bevor  die Multiplikation ausgeführt wird.   Bei Python kann man Iterationen über Container-Obje kte (z.B. Listen, Mengen oder Dictionaries),  der Form  for i in container:      Anweisungsfolge   besser verstehen, wenn man sich klar macht, dass be i der Ausführung „hinter den Kulissen“ ein Itera tor ins Leben gerufen wird, der bei jedem Durchlauf  das nächste Element des Containers heraussucht  und eine Ausnahme auslöst (und damit das Ende der I teration bewirkt), wenn alle Items besucht wor den sind. Dieser Iterator ist implizit, das heißt, er tritt im Programmtext nicht in Erscheinung, aber  er  könnte bei einer erklärenden Animation visualisiert  werden.   13.7 Einbeziehung der Umgebung  Gelegentlich werden nicht sichtbare Teile der Umgeb ung des zu erklärenden oder zu verstehenden  Programmtextes in die intuitive Modellierung einbez ogen. Zur Umgebung eines Programms gehören  z.B. das Betriebssystem, Compiler und Interpreter. Betrachten wir folgendes Python-Programm, das  ein Fenster mit zwei Labeln darstellt.  from Tkinter import *  fenster = Tk()  label1 = Label(fenster, text="Oben")                                                         18  Beispielsweise beim Überschreiben einer Speicherze lle im Arbeitsspeicher, wird diese nicht zuerst gelöscht  und bleibt dann für einen kurzen Moment „leer“, bev or der neue Inhalt kommt. 122     label2 = Label(fenster, text="Unten")  label1.pack()  label2.pack()  fenster.mainloop()  Formal ist die Methode pack()  eine Operation der Klasse  Label . In einer strukturtreuen Erklä rung würde man sagen, dass das Label-Objekt sich selbst  in bestimmter Weise im Anwendungsfenster  positioniert. Doch bei Erklärungen eines solchen Pr ogramms (z.B. in Sprachreferenzen) wird meist  das Konzept des Layout-Managers herangezogen. Man s agt z.B., dass durch den Methodenaufruf  pack()  der Packer – einer von mehreren verfügbaren Layout -Managern – aktiviert wird, der in die sem Fall dafür sorgt, dass die beiden Labels untere inander stehen. Mit dem Packer wird ein Akteur  herangezogen, der im Programmtext nicht sichtbar is t. Ein Layout-Manager ist Teil der Systemumge bung, die zur Laufzeit die geometrische Anordnung v on Elementen der grafischen Oberfläche des  Programms auf dem Bildschirm verwaltet. Die Einbezi ehung der Umgebung kann auch als Möglich keit der Gestaltbildung gesehen werden. Ein unvolls tändiges Stück wird durch die Hinzunahme eines  Teils zu einem abgerundeten und leichter vorstellba ren Ganzen.   13.8 Dekorieren und Dramatisieren  Als Dekorierungen bezeichnen wir gestalterische Ele mente, die nicht in dem abzubildenden Pro grammtext aber auch nicht in seiner technischen Umg ebung vorkommen. Solche kreativen Add-ons  können den Charakter von Kommentaren haben, die die  Verständlichkeit durch Hinzunahme zusätzli cher Information erhöhen. Sie können sogar dazu die nen aus einem Programmtext eine Geschichte zu  machen (Dramatisierung). In der Visualisierung in A bb. 64 unterhalten sich zwei Variablen und erklä ren dadurch ihren Zustand nach einer Zuweisung.    Abb. 64: Dramatisierung einer Zuweisung. Visualisier ung einer 17-jährigen Schülerin   Im Unterschied zur „Einbeziehung der Umgebung“ habe n die hinzugefügten Elemente nichts mit  dem Kontext des Programmfragments in der Zieldomäne  zu tun. Die technische Umgebung, in der das  Programm läuft, das in Abb. 64 visualisiert wird, h at z.B. keinen Mechanismus, über den eine Variab le über ihre Belegung berichten könnte.  13.9 Rückmodellierung  Unter Rückmodellierung verstehen wir den Versuch, z u einem Programmtext (oder Programmtext fragment) einen Wirklichkeitsausschnitt oder eine p raktische Problemstellung zu finden, für die das  Programm ein Modell oder eine Lösung darstellt. Abb . 66 zeigt eine Visualisierung der JavaAnweisungsfolge  String wort;  wort = "Hallo";  Hier hat der Schüler mit viel Fantasie eine Begrüßu ngssituation erfunden, in der ein Computer auf  dem Monitor ein Gesicht zeigt und über Lautsprecher  den Gruß „Hallo“ ausgibt. Das Programm, das  eine solche Aufgabe bewältigt, enthält sicherlich d ie beiden obigen Anweisungen – aber noch viele  mehr. 123        Abb. 65: Visualisierung als Rückmodellierung (Zeich nung eines 17-jährigen Schülers der Jahrgangsstufe 11)  Rückmodellierung kann dem Dramatisieren und Dekorie ren ähneln, wenn Erfundenes hinzugefügt  wird. Die hinzugefügten Elemente entstammen jedoch einem Realitätsausschnitt, der vom Programm  modelliert wird. Dabei wird angenommen, dass in dem  Programm (wie bei jeder Modellierung) ge wisse Aspekte der Realität weggelassen worden sind.  Diese werden beim Rückmodellieren wieder  hinzugefügt. Als Motiv für Rückmodellierung kann ma n in erster Linie Sinnschaffung annehmen.  Nackter Programmtext wird als sinnvolles Modell ged eutet.   Program m verm uteter Ausschni tt aus Real wel tR□ckm odel l i erenAusschni tt aus Real wel tm odel l i eren =  program m i eren   Abb. 66: Rückmodellieren  Rückmodellierung heißt, zu einem gegebenen Programm  die Funktionalität herauszufinden. Wozu  dient das Programm? Was leistet es? Bei diesen Frag en verwendet man den Funktionsbegriff der Sys temtheorie, betrachtet das Programm als System und sucht nach dem Nutzen im Hinblick auf Ziele,  die selbst außerhalb des Systems liegen. Wer die Fu nktion (im Sinne eines Zwecks) eines gegebenen  Programms beschreibt, muss deshalb kreativ werden u nd einen Kontext erfinden, innerhalb dessen es  sinnvoll verwendet werden könnte.   Nach der Theorie von Pennington (1987) ist die Such e nach Funktionalität (neben der Auseinan dersetzung mit Kontrollmechanismen, Datenflüssen un d den Zuständen, die bei der Ausführung des  Programms durchlaufen werden) einer von mehreren ko gnitiven Prozessen („Abstraktionen“), die zum  Verstehen eines Programmtextes führen. Beim funktio nalen Verstehen werden Programmstücke Zie len zugeordnet. Es entsteht ein Baum mit dem global en Ziel des gesamten Programms als Wurzel und  darunter immer weiter ausdifferenzierten Teilzielen .   Nach den Ergebnissen von Davies (2000) ist das schn elle Erkennen von Funktionalität mit Experti se verbunden. In einem Experiment zeigte er 16 Anfä ngern und 16 Programmierexperten für kurze  Zeit (entweder 2 Sekunden oder 10 Sekunden lang) kl eine C++-Programme und stellte anschließend  Verständnisfragen. Im Fall der Zwei-SekundenPräse ntationen schienen die Experten einen Schwer punkt auf die Erkennung der Funktionalität zu legen . Sie konnten signifikant mehr Fragen zur Funkti onalität (54%) als zu Kontrollund Datenfluss (26%  bzw. 23%) beantworten. Novizen dagegen hatten  eher Schwierigkeiten.  13.10 Exhaurierung  In der Wissenschaftstheorie versteht man unter Exha ustion folgendes: Wenn sich mit einer Hypo these Beobachtungen nicht erklären lassen, verwirft  man sie nicht sofort, sondern „schöpft sie aus“ 124     (exhauriert sie), indem man versucht mit geeigneten  Zusatzannahmen die widersprechenden Daten  hypothesengemäß zu deuten (Dingler 1913). Ein bekan ntes Beispiel für die Anwendung dieses Ver fahrens stammt aus der Frühzeit der Chemie. Der deu tsche Alchemist Georg Ernst Stahl stellte zu  Beginn des 18. Jahrhunderts die Phlogistonhypothese  zur Erklärung von Verbrennungsvorgängen auf  (Ströker 1967, S. 115 ff.). Danach ist die Verbrenn ung ein Vorgang, bei dem der Brennstoff einen  „Feuerstoff“ abgibt, den Stahl Phlogiston nannte. N ach dieser Hypothese mussten alle brennbaren  Stoffe Phlogiston enthalten. Nun konnte man aber be obachten, dass die Verbrennungsprodukte (Oxi de) schwerer waren als die Ausgangsstoffe der Verbr ennung. Die Exhaustion der Phlogistonhypothese  bestand darin, dass Stahl ihr ein negatives Gewicht  zuschrieb. Wie das Beispiel zeigt, kann Exhaurie rung zu einer Komplizierung des Erklärungsmodells f ühren.  Bei der intuitiven Modellierung von Programmtexten werden Verfahren angewendet, die der Ex haustion entsprechen. Ein Beispiel ist die Exhaurie rung des Behältermodells, das Zuweisungen der  Form  a = b  als Kopieren von Daten interpretiert. Wenn man die ses Modell auf änderbare Objekte  (z.B. Python-Listen) anwendet, so steht man vor fol gendem Problem: Eine Änderung des Objektes in  Behälter a wirkt sich gleichzeitig auf das Objekt in Behälter  b aus. Eine Exhaurierung kann nun darin  bestehen, dass man das Objekt in Behälter a nicht als eigenständige Entität sondern als „Geist “, als  zweite Erscheinung des Objektes in Behälter b betrachtet. Eine Veränderung des Objektes in Behäl ter  b wird dann auch in seinem Geist sichtbar.  Eine Funktion kann man sich als geschlossene Maschi ne mit Einund Ausgang vorstellen. Die Ma schine nimmt über den Eingang Daten auf, verarbeite t sie und gibt über den Ausgang das Ergebnis  aus. Probleme gibt es mit diesem Modell, wenn die F unktion andere Funktionen aufruft. Eine mögli che Exhaurierung ist die Annahme, dass die Funktion sbox eine Seitentür besitzt, über die sie Daten an  andere Funktionen senden und die Ergebnisse empfang en kann (vgl. Abschnitt 8.8.2).   13.11 Konsistenzwahrung   Für die Auswahl der Modelle eines Clusters zur Erkl ärung eines Programmtextes kann deren Kon sistenz ein Kriterium sein. Konsistent sind z.B. da s Behältermodell für Variablen und das Modell einer   Funktion als Box, die über ihren Eingang Daten aufn immt, sie verarbeitet und über einen Ausgang das  Ergebnis zurückgibt. Ein Cluster konsistenter intui tiver Modelle ist gedanklich einfacher zu handha ben als ein gleich großes nichtkonsistentes Cluster . Denn wenn es Widersprüche enthält, muss man  sich jeden Widerspruch vergegenwärtigen oder bei Er klärungen seinen Kommunikationspartnern mit teilen. Wer bei Erklärungen konsistente Intuitionen  verwendet, versucht „im Bild zu bleiben“. D.h. sie   oder er sucht nach Metaphern, die dieselbe Quelldom äne besitzen. In der Mathematikdidaktik gibt es  regelrechte Systeme konsistenter Metaphern, die als  Lernhilfen für Unterrichtsreihen eingesetzt wer den (vgl. z.B. Lakoff & Núnez 1997).  Konsistenz wird andererseits oft durch höhere Kompl exität erkauft. So kann man Programme einer  objektorientierten Programmiersprache strikt objekt orientiert deuten und sich alle Objekte als Akteure   vorstellen, die Botschaften senden und entgegen neh men können. Die arithmetische Operation  2*(b + 1)  muss man dann ungefähr so beschreiben: „Das Objekt,  das die Zahl 2 repräsentiert, erhält die Bot schaft, eine Multiplikation mit einer Zahl durchzuf ühren, die durch ein anderes (anonymes) Objekt  repräsentiert wird. Dieses Objekt wird folgendermaß en ermittelt: Das Integer-Objekt mit dem Namen  b erhält die Botschaft zu seinem Wert die Zahl 1 zu  addieren. Zurückgegeben wird ein Objekt, das die  Summe repräsentiert“. Das ist ein sehr komplexer Ge danke. Cluster von intuitiven Modellen zur Er klärung eines Programmtextes sind deshalb häufig in konsistent, um einfach zu bleiben. Ein großer  Teil der intuitiven Modellierkunst besteht darin, I nkonsistenzen zu handhaben. Dazu gehört, sich ihrer   bewusst zu sein, um Fehlvorstellungen zu vermeiden.   125       14 Von der Intuition zum Programm  Im Zusammenhang mit Programmierung kann man zwische n zwei Typen von Problemlösungen  unterscheiden:   • Bei Problemlösungen erster Art ist allein die Probl emstellung bekannt. Das Subjekt verwendet  einen großen Teil seiner Aktivität darauf, zunächst  eine unformale intuitive Lösung zu finden, von  deren Korrektheit er oder sie überzeugt ist. Im zwe iten Schritt wird die intuitive Lösung zu einem  lauffähigen Programm formalisiert.   • Bei einer Problemlösung zweiter Art ist die intuiti ve Lösung bereits bestens bekannt. Die Haupt aktivität liegt in der Programmierung. Das heißt, m it bekannten oder zu recherchierenden syntakti schen Mitteln der Programmiersprache wird das intui tive Modell nachgebildet und ein lauffähiges  und korrektes Programm generiert.   Beispiele für Probleme, die zu Problemlösungen zwei ter Art führen, sind:  • „Nimm alle roten Gummibärchen aus der Tüte.“  • „Suche im Telefonbuch die Nummer von Monika.“  • „Sortiere Karten mit Namen und Telefonnummern in ei nem Karteikasten aufsteigend nach den  Nachnamen.“  Im Schulalltag spielen Problemlösungen der zweiten Art die größere Rolle. Man kann davon aus gehen, dass Schüler Aufgaben wie in den obigen Beis pielen intuitiv lösen können. Aber selbst Schü ler, die die notwendigen Elemente der Programmiersp rache kennen und über Programmiererfahrung  verfügen, haben Schwierigkeiten ein entsprechendes Programm zu formulieren und scheitern häufig  sogar. Auf dem Weg von der Intuition zum Programm g ibt es einige kognitive Barrieren, die zu über winden sind (vgl. Weigend 2006d).  14.1 Prozedurale Intuition und fehlendes deklarativ es Wissen  Im schlimmsten Fall kann die Vorgehensweise bei der  intuitiven Lösung vollkommen unbewusst  sein (prozedurale Intuition, vgl. Abschnitt 1.2). Z ur Überwindung dieser Barriere muss der Programm entwickler sich selbst bei der intuitiven Problemlö sung beobachten oder sie sich in Gedanken verge genwärtigen, um zu deklarativem Wissen über eine Vo rgehensweise (einem antizipatorischen oder  paradigmatischen Modell) zu gelangen. 19   14.2 Aufbrechen der Gestalt  Eine zweite Hürde ist das Aufbrechen der Gestalt ei nes paradigmatischen oder antizipatorischem  Modells („Lösungsidee“). Im Modell des GAP-Trees vo n Spohrer, Soloway und Pope (1989) muss ein  gestaltartiger Plan in Ziele aufgeteilt werden (sie he Abschnitt 3.3.2). Nachdem das erste Stück heraus  gelöst ist, hat aber der Gesamtplan seine Intuitivi tät verloren. Man ist sich zwar sicher, dass der Pl an  irgendwie realisierbar ist, aber bei der Festlegung  der Ziele wird man spezifischer und unsicher, ob d ie  aufgelisteten Ziele in ihrer Summe den übergeordnet en Plan wirklich vollständig beschreiben. Viel leicht hat man ein Detail vergessen. Bonar und Solw ay (1985) beobachteten bei programmierenden  Schülern Explizierungslücken. Sie verwendeten bei P rogrammierübungen die Programmiersprache als  wäre sie natürliche Sprache. Ein Beispiel ist die V erwendung einer Anweisung der Art   sum = sum + i  in einer for -Schleife als Realisierung der umgangssprachlichen Anweisung „Addiere den nächsten  Wert zur Summe“. Dabei wurde unterschlagen, dass de r „nächste Wert“ erst noch gelesen werden                                                         19  Moser (2003) beschreibt Workshops, in denen über e ine Analyse von Metaphern (wie z.B. „Wissen als Bib lio thek“ oder „Wissen als umkämpfter Schatz“) in Grupp endiskussionen implizites (unbewusstes) Wissen der Teil nehmer über eine Domäne expliziert und bewusst gema cht wird. 126     muss. Die Variable  i  wird einfach als Behälter für den nächsten Wert ge sehen. Die umgangssprachli che Darstellung „verkürzt“ das Procedere um das Ein lesen.   Werfen wir einen genaueren Blick auf die kognitiven  Prozesse bei der Analyse einer antizipatori schen Lösungsidee. Eine wesentliche Aktivität ist d abei die Suche nach Elementen, die man mit pro grammiersprachlichen Mitteln beschreiben kann. Ein einzelner Punkt dabei ist die Identifikation und  Benennung von Entitäten. Das Problem ist, dass das intuitive Modell als Gestalt einfach ist und auf  explizite Benennung der enthaltenen Entitäten verzi chtet. Nehmen wir als Beispiel die Suche nach  einer Telefonnummer in einer Liste, die auf ein Bla tt Papier geschrieben ist. Jede Zeile enthält ein P aar  im Format ( Name , Telefonnummer ). Um nach der Nummer zu suchen, geht man mit dem F inger von  oben nach unten die Namensspalte hinunter und kontr olliert in jeder Zeile ob der aufgeführte Name  mit dem gesuchten übereinstimmt. Falls dies der Fal l ist, geht man mit dem Finger nach rechts und  liest die zugehörige Telefonnummer. Eine Schwierigk eit liegt darin zu erkennen, dass das Zeigen mit  dem Finger eine Benennung ist. Für die Zeile, auf d ie der Finger zeigt, müsste im Programmtext ein  Name eingeführt werden, über den der Zugriff auf da s Paar ( Name , Telefonnummer ) ermöglicht wird.  14.3 Fehlende Verbindungen zwischen intuitiven Vors tellungen und  Programmkonstrukten  Das letzte Beispiel verweist bereits auf eine dritt e Barriere, nämlich fehlende Verbindungen zwi schen intuitiven Vorstellungen und Programmierkonze pten. Es kann z.B. sein, dass jemand auf der  einen Seite Alltagsaktivitäten wie das Zeigen auf e in Objekt oder das Aufschlagen von Seite 20 in  einem Buch beherrscht und auf der anderen (programm technischen) Seite Zuweisungen und den  Zugriff auf ein Item eines Arrays kennt, aber diese  Konzepte aus zwei verschiedenen Domänen nicht  verbinden kann. Dieser Person kommt dann nicht in d en Sinn, dass das Zeigen auf ein Objekt einer  Benennung bzw. einer Zuweisung der Art x = objekt  entspricht.  Diese Art von Wissen wird durch Programmiererfahrun g erworben, d.h. durch viele Programmier experimente, in denen intuitive Modelle zu Programm text in Beziehung gesetzt werden (vgl. auch  Weigend 2006c). Perkins et al. (1989) beobachteten,  dass erfolgreiche Programmentwickler die Fä higkeit besitzen, genau zu erklären bzw. nachzuvoll ziehen, was jede Zeile eines Programmtextes be wirkt. Sie nennen das „close tracking of code“. Sie  untersuchten auch, welche Arten von Unterstüt zungsmaßnahmen helfen, Blockaden im Problemlösungsp rozess zu überwinden. Als besonders  wirksam stellte sich heraus, Schüler, die nicht wei terkommen, aufzufordern, Zeile für Zeile zu erklä ren, was ihr (bisher geschriebener) Programmtext le istet. Dabei stießen sie von allein auf ihre Proble  me und fanden Ansätze, ihren Programmtext weiterzue ntwickeln. Python Puzzles der PVS enthalten  als Hilfemechanismus Animationen, die die Arbeitswe ise einer zu definierenden Funktion darstellen.  Die Nutzung dieser visuellen Modelle kann eine beso nders intensive Art des „close trackings“ sein,  nämlich dann wenn man die einzelnen Entitäten und A ktivitäten mit Elementen des Programmtextes  in Beziehung setzt. 20    14.4 Schwierige intuitive Modelle  Eine vierte Barriere bei Problemlösungen sind schwi erige intuitive Modelle. Eine Lösungsidee  kann grundsätzlich für eine direkte Implementierung  ungeeignet sein. Genauer gesagt, sie kann Aspek te enthalten, zu deren Implementierung der Person d ie programmiersprachlichen Konzepte fehlen. Als  Beispiel betrachten wir einen Ansatz zur Lösung des  Sortierproblems. Als Einstieg in einer Unter richtsreihe könnten Schüler die Aufgabe erhalten, s ich der Größe nach in einer Reihe an der Wand  aufzustellen. Eine intuitive Lösungsgestalt (Bubble sort) ist:   „Jeder sorgt dafür, dass links neben ihm niemand st eht, der kleiner ist.“                                                          20  Fehlende Verbindungen von Programmkonstrukten und intuitiven Modellen in Problemlösungssituationen  sollten eigentlich mit der PVS  untersucht werden. Manche Python Puzzles enthalten als Hilfesystem ein e Reihe  von visuellen Modellen, die auf die Prüfung (und Sc haffung) solcher Assoziationen abzielen. Leider gab  es in  den bisherigen Workshops mit der PVS zu wenige Sitz ungen mit Python Puzzles und darin eine zu geringe Nut zung der Hinweise um zu dieser Thematik irgendwelch e Erkenntnisse zu gewinnen. 127     Es ist unmittelbar einleuchtend, dass eine Gruppe v on Personen auf diese Weise nach der Körper größe sortiert werden kann. Angenommen, jemand verw endet diese Lösungsidee als paradigmatisches  Modell für die Sortierung einer Liste von Zahlen, s o stieße er oder sie auf massive Probleme. Jede  Zahl müsste durch einen eigenen Prozess repräsentie rt werden, der mit den anderen Prozessen kom muniziert. Es müssten relativ komplexe Protokolle e rarbeitet und obendrein beachtet werden, dass das  System nicht in Deadlocks oder Endloswiederholungen  gerät. Die intuitive Lösungsidee ist also (zu mindest für Anfänger) für eine direkte Umsetzung un geeignet. Die Kunst liegt darin, das zu erkennen  und entweder nach einem völlig neuen Ansatz zu such en oder aber die Lösungsgestalt als abstraktes  (das heißt von einer Implementierung weit entfernte s) Modell zu begreifen, die nur auf nichtnaheliegende Weise implementiert werden kann (siehe  Abschnitt 15.2).  14.5 Fehlvorstellungen  Fehlvorstellungen über die Bedeutung von Programmte xt sind das fünfte und letzte in diesem Ab schnitt betrachtete Hindernis auf dem Weg vom intui tiven Modell zum Programmtext. Eine Fehlvor stellung kann man in diesem Zusammenhang als falsch e Verbindung zwischen einer intuitiven Vor stellung und einem Programmkonstrukt betrachten.   Verschiedene Mechanismen machen Fehlvorstellungen z ur Barriere. Erstens können sie zu heimtü ckischen semantischen Fehlern im Programmtext führe n, da sie nicht durch Inspektion zu finden sind.  Fehlersuche durch Inspektion setzt voraus, dass man  die Semantik der Programmiersprache vollstän dig beherrscht. Logische Fehler, die auf Fehlvorste llungen basieren, können nur durch systematisches  Eingrenzen in Programmierexperimenten (Tracing, Tes ten, Experimente mit vereinfachten Pro grammversionen etc.) gefunden werden. Um dabei erfo lgreich zu sein, braucht man ein generelles  Misstrauen gegenüber der eigenen Intuition. Man mus s die Möglichkeit in Betracht ziehen, dass –  gegen die eigene Überzeugung – jedes Programmstück falsch sein kann.  Heimtückischer noch ist der zweite Mechanismus. Wen n man eine falsche Vorstellung über ein  Programmkonstrukt hat, kommt man vielleicht gar nic ht auf die Idee es zu benutzen, weil man es irr tümlicherweise für untauglich hält.   Interessant ist in diesem Zusammenhang auch das Phä nomen, dass Fehlvorstellungen häufig keine  Behinderung von Problemlösungen und speziell Progra mmentwicklungen darstellen. Fehlvorstellun gen sind ja kognitive Konzepte, die sich in der Bew ältigung des Alltags bewährt haben. Jahrtausende lang kam die Menschheit problemlos mit der Fehlvors tellung zurecht, dass sich die Sonne um die Erde  dreht. Auch heute verwenden naturwissenschaftlich g ebildete Menschen Formulierungen wie „Die  Sonne steht hoch am Himmel“ und denken bei der Betr achtung eines Sonnenuntergangs nicht daran,  dass sich eigentlich die Erde dreht. Beobachtungen mit der PVS haben gezeigt, dass die meisten beo bachteten Informatikschüler/innen für Zuweisungen d er Art a = b  unkorrekte intuitive Modelle ver wenden (siehe Abschnitt 10.5). Geht man davon aus, dass diese Personen in der Lage sind, korrekte  einfache Programme mit Zuweisungen der beschriebene n Art zu formulieren, so scheinen diese Fehl vorstellungen keine kognitiven Barrieren darzustell en. 128       15 Pädagogische Implikationen  15.1 Intuitive Modelle und Lernen formaler Programm ierkonzepte  Programmiersprachen sind so konzipiert, dass sie be stimmte Denkmuster (Paradigmen) unterstüt zen. Die Programmierparadigmen korrespondieren mit bestimmten „Leitintuitionen“. Wie bereits an  verschiedenen Beispielen erläutert worden ist, determiniert  die Programmiersprache jedoch nicht  die  gedanklichen Vorstellungen, die man bei einer Progr ammentwicklung verwendet. Das imperative  Programmierparadigma etwa unterstützt die Vorstellu ng, dass ein Programm aus „Befehlen“ besteht,  die von einem einzigen Akteur ausgeführt werden. Ei ne im Programmtext definierte Funktion wird in  diesem Denkmuster als komplexer Befehl gesehen, der  nicht im vorgegebenen Repertoire des Akteurs  vorrätig ist, sondern zunächst „gelernt“ werden mus s. Auf der anderen Seite stellen sich viele Anwen der einer imperativen Programmiersprache eine Funkt ion als eigenen Akteur vor, der durch einen  Funktionsaufruf aktiviert wird.  Intuitive Modelle der Informatik können hinsichtlic h ihres Abstraktionsgrades oberhalb, auf glei chem Niveau oder unterhalb einer Programmiersprache  liegen. Man kann sie sie in Anlehnung an die  Redeweise in der Chemie molekulare, atomare und sub atomare Modelle nennen.  15.1.1 Molekulare Modelle  Programmierer verwenden intuitive Modelle, die ganz e Programme oder Programmabschnitte – al so größere logische Einheitenin einer kohärenten Gestalt zusammenfassen. Ein Beispiel ist das Mo dell eines Behälters mit mehreren Fächern und sprin gender Markierung zur Darstellung der Verarbei tung einer Liste in einer Iteration (zur psychische n Realität siehe Abschnitte 6.6 und 9.4). Solch ein   Modell lässt Details der Implementierung weg und br ingt Denken „oberhalb der Programmiersprache“  zum Ausdruck. In didaktischer Hinsicht sind Modelle  oberhalb der Programmiersprache z.B. wichtig,  um algorithmische fundamentale Ideen der Informatik  (Schwill 1993) zu verstehen, zu behalten, zu  kommunizieren und als antizipatorische Intuitionen für Problemlösungen zu verwenden. Die Abstrak tion, die mit der Gestaltbildung verbunden ist, bri ngt eine Entfernung von den Konstrukten der Pro grammiersprache mit sich. Die Kunst (und Schwierigk eit) der Implementierung liegt vor allem im  Aufbrechen der Gestalt in Fragmente, denen man Prog rammkonstrukte zuordnen kann. Beispielsweise  muss man wissen, dass eine „springende Markierung a uf einem Behälter mit Fächern“ eine Laufvari able in einer Iteration repräsentieren kann.   15.1.2 Atomare Modelle  Betrachten wir als nächstes intuitive Modelle, dere n Abstraktheit in etwa auf dem Niveau einer  Programmiersprache liegen und die deshalb mehr oder  weniger unmittelbar formale Programmkon strukte abbilden können. Eine Vielfalt von Ausdruck sformen zur Veranschaulichung von Programm konstrukten kann im Hinblick auf kreatives Probleml ösen nützlich sein. Wer weiß, dass man eine Zu weisung der Form x = 2 auch als Markierung eines Objektes interpretieren k ann, dem sollte es  leichter fallen, ein abstrakteres intuitives Modell  für eine Iteration über eine Liste, das Markierung en  verwendet („springende Markierung auf einem Behälte r mit Fächern“), „aufzubrechen“. Diese Person  kommt dann eher auf die Idee, für die Markierung ei ne Variable (Name für einen Listenindex) einzu führen.  Atomare Modelle auf gleichem Abstraktionsniveau wie  das modellierte Konstrukt sind die Basis  von „didaktisch durchdachten“ Quelldomänen für Meta phern, die in der Mathematik bereits eine lange  Tradition haben (siehe Abschnitt 2.3.2). Automatisc he Visualisierungssysteme wie die Jeliot-Familie  (Moreno & Myller 2003) verwenden zusammenpassende S ets atomarer Modelle, um die Arbeitsweise  von Programmen zu veranschaulichen. Ein Visualisier ungssystem ist von Fachdidaktikern designt.  Den verwendeten Modellen liegt eine von der Fachgem einschaft akzeptierte Interpretation von Kon strukten der Bezugs-Programmiersprache zugrunde. Ty pische Aktivitäten im Klassenraum sind: 129     • Lernen neuer Sprachelemente: Die Lehrperson demonst riert die Wirkungsweise eines neu einge führten Programmkonstrukts. Die Ausführung des Prog rammtextes kann mit Hilfe des Modells  nachvollzogen werden.  • Debugging: Wenn ein Programm semantische Fehler ent hält, kann eine kritische Passage  Schritt  für Schritt nachvollzogen werden. Die Funktion atom arer Modelle ist dann, die (ansonsten un sichtbare) Wirkung eines atomaren Programmschritts zu visualisieren und der kritischen Überprü fung (Vergleich mit dem erwarteten Effekt) zugängli ch zu machen.  Bei derartigen Aktivitäten ist die 1:1-Beziehung – die direkte Zuordnung von Elementen der  Quelldomäne (visuelle Komponenten auf dem Bildschir m) zu Elementen der Zieldomäne (sprachliche  Einheiten des Programmtextes) – von Bedeutung.   Automatische Visualisierungsysteme haben jedoch pri nzipiell zwei Einschränkungen. Zum einen  enthalten sie keine Repräsentationen für typische f alsche intuitive Modelle, die in den Köpfen der  Lernenden existieren können. Sie liefern naturgemäß  nur richtige Interpretationen vor Programmtex ten und können nicht die Konsequenzen einer ungeeig neten Intuition vor Augen führen. Zum zweiten  kanalisieren sie die Vielfalt möglicher (im gegeben en Kontext ebenfalls akzeptabler) Modelle auf  jeweils ein einziges. Dabei ist es erstens fraglich , ob im Hinblick auf den Lernkontext (algorithmisch e  Idee, Vorkenntnisse der Lernenden) die beste Darste llungsform gewählt worden ist. Zweitens können  in einem abstrakteren, molekularen Modell für eine algorithmische Idee, die in dem gegebenen Pro gramm implementiert werden soll, verschiedene Typen  atomarer Modelle gemischt sein (z.B. Behäl termodelle und Referenzierungsmodelle).  Zusammenfassend kann man sagen, dass atomare Modell e vor allem dem Erlernen und Einüben ei ner Programmiersprache dienen. Die Auswahl geeignet er Modelle für Unterrichtsgespräche ist eine  didaktische Entscheidung, die nur schlecht automati siert werden kann, da viele Faktoren berücksich tigt werden müssen. Die Beherrschung einer Vielfalt  atomarer Modelle für Elemente einer Program miersprache erleichtert die Implementierung einer a lgorithmischen Idee.  15.1.3 Subatomare Modelle  Für das Verstehen von elementaren Programmkonstrukt en ist es oft hilfreich und notwendig menta le Vorstellungen zu verwenden, deren Abstraktionsgr ad unterhalb dem Niveau der Programmierspra che liegt. Wir sprechen dann von subatomaren Modell en. In Abschnitt 13.6 wurden sie bereits unter  dem Stichwort „Überstrukturierung“ diskutiert.   Wie im Zusammenhang mit Verarbeitungskonzepten disk utiert worden ist (vgl. Kapitel 10) spielen  bei der Interpretation elementarer Programmanweisun gen häufig mehrere grundlegende Intuitionen,  die auch im Alltag verwendet werden, zusammen. Beis pielsweise enthalten Modelle für Zuweisungen  Vorstellungen über Entstehung, Vernichtung, Transpo rt und Metamorphose von Entitäten. In der Re gel sind die Modelle, die man zur Abbildung formale r Programmkonstrukte heranzieht, nicht hundert prozentig passend. Um jedoch die Unterschiede und G renzen der Anwendbarkeit herauszufinden und  zu explizieren, muss man sie genauer analysieren un d auf subatomare Komponenten zurückgreifen.   15.2 Kompetenzen im Umgang mit intuitiven Modelle  Die Beherrschung intuitiver Modelle der Informatik ist eine Form von Fachwissen, weil die Model le Fachwissen repräsentieren. Wie in Kapitel 3 hera usgearbeitet worden ist, dienen intuitive Modelle  dem Verstehen, Erklären (z.B. in Dokumentationen un d Diskussionen) und Kreieren informatischer  Systeme – formal repräsentiert meist durch Programm text. Über das Fachliche hinaus gibt es eine  Reihe von metakognitiven Kompetenzen, die sich auf den Umgang mit intuitiven Modellen beziehen.  Nun könnte man einwenden, dass metakognitive Kompet enzen unabhängig von einem inhaltlichen  Bezug sind, also in den anderen Wissenschaften wie Chemie oder Mathematik ebenso wichtig sind  und deshalb in diesem Informatik-orientierten Zusam menhang nicht diskutiert zu werden brauchen.  Dem muss man aber entgegen halten, dass Modellierun g in der Informatik einen besonderen Stellen wert hat. Denn ein wesentlicher Teil der Informatik  dreht sich um Techniken, neue Systeme zu erfin den und ihre Komplexität zu beherrschen. Pointiert gesprochen geht es in den anderen Wissenschaften 130     vor allem darum Modelle für Realitätsausschnitte zu  finden. In der Informatik wird der Modellie rungsprozess selbst thematisiert (vgl. z.B. Hubwies er 1999, 2004).  15.2.1 Abstraktionsgrad erkennen  In Abschnitt 15.1 wurde herausgearbeitet, dass intu itive Modelle für Programmtexte sich im Abs traktionsgrad unterscheiden können. Der Abstraktion sgrad eines Modells muss aber erkannt werden,  damit es nicht zu Fehlvorstellungen und Blockaden b ei Problemlösungen kommt. So ist es eine wich tige Einsicht für Schüler/innen, dass Computerprogr amme in der Feinstruktur oft ganz anders funktio nieren als die anschauliche (holistische) Vorstellu ng einer Problemlösung, die man im Kopf hat. Da mit verbunden ist die Erkenntnis, dass es für ein u nd dieselbe antizipatorische Intuition  unterschiedliche Implementierungen geben kann. Das heißt, man muss den Abstand sehen, den ein  abstraktes Modell zu möglichen Implementierungen ha t. Wenn man z.B. die Abstraktheit der  Lösungsidee für Bubblesort („Jedes Element prüft, o b der linke Nachbar kleiner ist, und tauscht  gegebenenfalls mit ihm den Platz“) verkennt, versuc ht man vielleicht die Elemente der Liste als  konkurrent agierende Objekte zu implementieren und scheitert an dieser komplexen Aufgabe.  Am unteren Ende der Abstraktionsskala stehen subato mare Modelle, die eine bloße logische Facet te einer Programmanweisung zum Ausdruck bringen. Au ch sie müssen als solche erkannt werden.  Anderenfalls sucht man überflüssigerweise nach Prog rammkonstrukten, die gar nicht notwendig sind  oder gar nicht existieren. Wer nicht merkt, dass be i einer Zuweisung im Behältermodell die Zerstörung  des vorigen Inhaltes nur eine Bedeutungsfacette ist , kommt vielleicht auf die Idee, in einem Programm  müsse vor einer neuen Zuweisung der Art x = 2  zuerst eine spezielle Löschoperation ausgeführt  werden.  15.2.2 Fokus und Grenzen wahrnehmen   Intuitive Modelle der Informatik sind in der Regel ungenau und geben ein informatisches Konzept  nur unzureichend wieder. Sie fokussieren auf bestim mte Features des modellierten Konzeptes und  lassen andere außer Acht. In der Fokussierung und d er damit verbundenen Einfachheit liegt die Ein gängigkeit und Ausdrucksstärke eines Modells. Wer d ies nicht würdigt und deshalb keinen Mut zur  Vereinfachung hat, ist nicht in der Lage, selbst Mo delle für Erklärungen zu erfinden.  Andererseits muss man sich der mit der Fokussierung  verbundenen Grenzen der Anwendbarkeit  bewusst sein und sie auch explizieren können (z.B. wenn man das Modell in einer Diskussion verwen det). Das impliziert zweierlei: Die Grenze der Anwe ndbarkeit eines Modells kennt man nur, wenn man  Kontexte benennen kann, in denen es untauglich ist.  Zum zweiten kann man das fokussierende Modell  trotz aller Ungenauigkeiten nur dann als tauglich a kzeptieren, wenn man es als Teil eines Clusters von   Modellen zur gleichen Thematik sieht. Man muss sich  klar machen, dass die Genauigkeit und Schärfe  einer Erklärung sich erst aus der Zusammenschau meh rerer Modelle ergibt.   15.2.3 Medienund Kommunikationskompetenz  Intuitive Modelle müssen in irgendeiner Weise (verb al oder visuell) dokumentiert („materialisiert“)  sein, um sie sich selbst ins Bewusstsein zu rufen u nd anderen mitzuteilen. Solche Repräsentationen  sind also Medien und spielen eine zentrale Rolle im  „situated learning“ in einer „community of practice“ (vgl. z.B. Ben-Ari 2004). Zu den Kompetenzen, d ie sich primär auf den Aspekt der Mediengestal tung beziehen, gehören:  • Dekorative Elemente eines Modells erkennen (und erf inden), die die Gestalt des Analogons ab runden aber kein Element des abgebildeten Konzepts repräsentieren.   • Den (kognitiven) Nutzen eines Modells für das eigen e Verstehen beurteilen.  • Für eine Zielgruppe (z.B. Kunden in einem Softwarep rojekt oder Kollegen in einem Entwick lungsteam) und einen sozialen Kontext (z.B. Dokumen tation einer Software, Vorstellen einer Idee  in der Entwurfsphase eines Projekts) geeignete Mode llrepräsentationen auswählen. 131     15.3 Intuitive Modelle und Scaffolding   Eine typische Lehraktivität im Informatikunterricht  ist die Unterstützung einer eigenständigen  Problemlösungsaktivität (Scaffolding) 21 . Wenn ein Schüler mit einer Programmieraufgabe nic ht wei terkommt oder einen semantischen Fehler nicht finde n kann, erhält er oder sie einen Tipp, der eine  Barriere überwinden helfen soll, aber nicht die Lös ung vorwegnimmt. Würde eine Lehrperson die  Lösung verraten, sabotiert sie damit den ursprüngli ch geplanten Lernprozess. Wenn die betroffenen  Schüler/innen nicht in der Lage sind, das Problem z u lösen, es also zu schwierig für sie ist, ist offe nbar  an dieser Stelle besonders intensives Lernen notwen dig. Durch ein Verraten der Lösung wird die ge samte Anbahnung des Lernprozesses (Auseinandersetzu ng mit der Aufgabenstellung, Ausprobieren  verschiedener Ansätze etc.) zunichte gemacht und di e Lernenden des Erfolgserlebnisses einer eigen ständigen Lösung beraubt.   Ein geeigneter Tipp kann an intuitive Modelle anknü pfen, die Schüler verstehen. Um gute Tipps  gestalten zu können, braucht man Wissen über mental e Modelle von Anfängern zur Interpretation von  Programmtexten und typische fehlerhafte Anwendungen  dieser Modelle.  Hierzu einige Beispiele:   • Wenn die Lernenden „Startschwierigkeiten“ haben und  nicht in der Lage sind, auch nur einen  Ansatz für das Programm zu finden, könnte zunächst eine eingängige metaphorische Beschrei bung einer Problemlösung unter Verwendung von Model len erarbeitet werden.   • Möglicherweise können Schüler/innen einen Algorithm us beschreiben, aber es gelingt ihnen die  Implementierung nicht, weil die gedankliche Verbind ung zwischen Komponenten ihres mentalen  Modells und formalen Programmkonstrukten fehlen. In  diesem Fall kann eine Hilfestellung darin  bestehen, diese Verbindung herzustellen.  • Ein semantischer Fehler in einem Programmtext, den die Schüler alleine nicht entdecken, kann  verdeutlicht werden, indem man die kritische Progra mmpassage an einem Modell durchspielt.  Hierbei können Fehlvorstellungen (bzw. unangemessen e Verwendungen des Modells) entdeckt  und expliziert werden.   15.4 Diskussion und Reflektion intuitiver Modelle  Es gibt viele Möglichkeiten, die Explikation und Re flektion intuitiver Modelle in den Informatik unterricht einzubringen. Darunter sind Visualisieru ngsübungen, Rollenspiele und Aktivitäten mit neu en Medien wie Mikround Nanowelten. Das Grundmuste r einer solchen Lerneinheit besteht aus den  drei Schritten Hinführung, Schüleraktivität und Ref lektion.  15.4.1 Visualisierungsübungen  In einer Visualisierungsübung erhalten Schüler/inne n die Aufgabe, ein Programmstück zu visuali sieren. In der Hinführungsphase wird klargestellt, dass die Visualisierung anderen Personen die Ar beitsweise des Programms erklären soll. Es geht als o um Kommunikation. Eventuell kann sogar die  Zielgruppe spezifiziert werden (Fachleute, erwachse ne Nichtfachleute wie z.B. Kunden in einem  Softwareprojekt, Kinder). Hinsichtlich des geforder ten Ergebnisses sind verschiedene Varianten denk bar:  • Storyboard mit Bleistift und Papier    • Trickfilm z.B. mit Modellen aus Lego  • Animationen z.B. mit Adobe Flash, Mediator oder Prä sentationssoftware   • Minidrama unter Verwendung eines Sets vorgegebener Requisiten („Szenokasten“) wie z.B. Kar ten und Behälter.                                                         21  Die Unterstützung problemlösender Aktivitäten durc h Tipps wird z.B. im pädagogischen Ansatz des cogni tive  apprenticeship kultiviert. Vgl. dazu Collins et al.  1989. 132     In der Hinführungsphase sollte ein (potentieller od er realer) Anwendungskontext für das Produkt  umrissen werden. Beispielsweise könnte eine Animati on Teil der Schul-Website werden. Ein Trick film könnte in eine Datenbank für Unterrichtsmateri alien eingespeist werden. Ein Storyboard kann die  Grundlage für eine spätere Implementierung mit Flas h sein.  Die von den Schülern eigenaktiv entwickelten Produk te werden von ihnen präsentiert und erläutert.  Die Präsentationen sind Anlässe für anschließende D iskussionen über die verwendeten intuitiven Mo delle (Reflektionsphase). Sie können auf verschiede ne Aspekte fokussieren und durch entsprechende  Fragen der Lehrperson eingeleitet werden:  • Welche Elemente des Modells sind frei erfunden?  • Was macht das Modell anschaulich und gut verständli ch?  • An welchen Stellen weicht die Visualisierung von in formatischen Konzepten ab?  15.4.2 Rollenspiele und Regelspiele  Bell et al. (1998) beschreiben Spiele mit Requisite n (z.B. Behälter mit einer Balkenwaage nach ih rem Gewicht sortieren) und Rollenspiele (z.B. das „ Orange Game“, in dem es um Fragen der Daten kommunikation geht), die im Informatikunterricht du rchgeführt werden können und dazu dienen, be stimmte Konzepte der Informatik auf enaktive Weise zu präfigurieren.  Für den Bereich der objektorientierten Programmieru ng gibt es Rollenspiele, bei denen die Teil nehmer in die Rolle eines Objektes schlüpfen und di e Übergabe und Verarbeitung von Botschaften  nachspielen (Adrianoff & Levine 2002; Jimenez-Diaz et al. 2005). Der Unterschied zu Dramen im  Rahmen von Visualisierungsübungen (siehe voriger Ab schnitt) liegt darin, das hier das Szenario pro fessionell gestaltet ist und die Aktivitäten durch Regeln und Rollenbeschreibungen weitgehend festge legt sind. Es geht hier nicht um die spontane Kreat ion von Darstellungsformen und Externalisierung  interner mentaler Modelle sondern um das Nachvollzi ehen vorgegebenen Gedankenguts und körperli ches Erleben mit allen Sinnen. Ben-Ari (1997) besch reibt mehrere Übungen, bei denen die Schüler  „Roboter spielen“ und umgangssprachlich formulierte  rekursive Algorithmen nachspielen (z.B. Scho kolade essen). Adrianoff & Levine (2002) schlagen e in Spiel vor, bei dem Schüler sich in die Rolle  eines Akrobaten (Objekt der Klasse Akrobat ) versetzen, der auf Zuruf bestimmte Dinge tut. Wen n  ein „Akrobat“ z.B. die Botschaft „Clap“ gefolgt von  einer ganzen Zahl n erhält, soll er n Mal in die  Hände klatschen. Wichtig ist, dass diese Aktivitäte n tatsächlich (physisch) ausgeführt werden und so  das Rollenspiel zu einem Erlebnis wird, das man nic ht vergisst. In der Reflektionsphase („Debrie fing“) geht nach Empfehlung von Adrianoff & Levine (2002) die Lehrperson einen vorgegebenen  Katalog von informatischen Konzepten durch (Objekt,  Klasse, Botschaft, Parameter usw.), auf die das  Rollenspiel zugeschnitten ist, und klärt mit den Te ilnehmern, wie diese Konzepte im Spiel zum Aus druck gekommen sind und wo die Grenzen und Schwäche n dieser Modellierung lagen.  15.4.3 Gestaltete Medien und Mikrowelten   Intuitive Modelle bilden den Hintergrund für bildha fte Darstellungen in Büchern, Unterrichtsfilmen  und gegenständlichen Modellen zum Anfassen. Für die  Designer solcher Medien ist folglich Wissen  über geeignete und ungeeignete intuitive Vorstellun gen wichtig. Die (professionell gestaltete) Explika  tion einer typischen Fehlvorstellung kann genauso l ehrreich sein wie eine fachlich korrekte Darstel lung.  Auch Abbildungen auf der Basis einer standardisiert en Modellbeschreibungssprache (z.B. UML)  fußen auf intuitiven Vorstellungen. Ein Zustandsübe rgangsgraph etwa beschreibt einen Zustandswech sel als Bewegung. In der Industrie werden solche Di agramme zur Dokumentation von SoftwareEntwürfen oder Analyse-Ergebnissen verwendet. Im Un terrichtsbereich besitzen sie einen gewissen  „Eigenwert“ und werden für das Erlernen von Konzept en – unabhängig von einem Software-Projekt – 133     eingesetzt. So hält Hubwieser die Modellierung durc h UML-Diagramme auch ohne Implementierung  für lehrreich 22 .   Eine besonders weit entwickelte Form medialer Lernh ilfen sind Mikrowelten wie die verschiede nen Implementierungen des Turtle-Konzeptes oder „Ka rel the Robot“ 23 .   Ein Medium ist noch kein Unterricht. Damit es zu Le rnprozessen kommt, muss das Medium in ela borierende Aktivitäten eingebunden sein, die üblich erweise von der Lehrperson im Unterricht (z.B.  durch geeignete Aufgabenstellungen) initiiert werde n. Teil einer solchen Unterrichtssequenz kann und  sollte auch eine kritische Reflektion der im medial en Material enthaltenen oder sogar thematisierten  intuitiven Modelle sein 24 .    15.5 Informatik im Kontext  Die Belegung der Sitze in einem Auto kann durch ein e Multiliste beschrieben werden. Ein Beispiel  in Python-Syntax ist:  auto = [["Anna", "Karl"], ["Tim", "Sandra"]]  Dabei repräsentiert jede Unterliste eine Sitzreihe.  Nun ist die Vorstellung der Sitze in einem Auto  einerseits ein prototypisches Beispiel einer Multil iste und hat den Charakter eines intuitiven Modells   für ein abstraktes Konzept. Andererseits ist die Mu ltiliste ein informatisches Modell eines Realitätsausschnitts. Informatische Modellierung und Rekonst ruktion abstrakt-formaler Konzepte durch intui tive Modelle sind also ganz ähnliche kognitive Proz esse. Lediglich die Zielsetzung ist unterschiedlich :  Generieren eines neuen Programms versus Verstehen o der Erklären eines Programms. In der Tat ten dieren Schüler beim Versuch, Programmtexte zu erklä ren, zur „Rückmodellierung“, d.h. sie erfinden  zum Programmtext passende Realitätsausschnitte (sie he Abschnitt 13.9).  Wer ein gewisses Repertoire intuitiver Modelle zum Verstehen und Erklären von Programmkon strukten erworben hat, dem müsste eigentlich in vie len Fällen auch umgekehrt die Modellierung von  Realitätsausschnitten besser gelingen, weil er oder  sie Ähnlichkeiten der neuen Situation mit gespei cherten Prototypen in Betracht ziehen kann.   In der Naturwissenschaftsdidaktik ist seit Mitte de r 1980iger Jahre ein Unterrichtsmodell entwi ckelt worden, das unter dem Namen „Science in Conte xt“ oder „Salters Approach“ bekannt geworden  ist (vgl. z.B. Bennet et al. 2002; Bennet & Lubben 2006; Huntemann et al. 1999). Kontexte sind all tagsrelevante und lebensweltbezogene Fragestellunge n, die Sachstrukturen erkennen lassen und fach wissenschaftliche Inhalte in einen für Schüler eins ichtigen Sinnzusammenhang stellen. Kontexte für  die Chemie der Kohlenwasserstoffe (fachliches Konze pt) sind z.B. die Gegenstände „Autokraftstoffe“  oder „Fleckenentferner“. In Lehrbüchern und Kurscur ricula, die diesem Ansatz folgen, sind Kontexte  mit zugehörigen (systematisch eingeführten) fachwis senschaftlichen Konzepten verbunden.  Alltagsrelevante Kontexte in der Informatik sind ab er nicht nur Anwendungsbereiche für abstrakte  Konzepte sondern auch Quelldomänen für intuitive Mo delle. Wer etwa in einem Programmierprojekt  sich mit der Modellierung von Sitzbelegungen in ein em Auto beschäftigt, verwendet diesen Wirklich keitsausschnitt als Domäne für metaphorische intuit ive Vorstellungen zum informatischen Konzept  der Liste. Beispiel: Ein Auto mit drei Sitzreihen, in dem sich nur Susanne als Fahrerin befindet, läss t  sich durch die Multiliste [["Susanne"], [], []]  modellieren. Eine leere Sitzreihe wird hier  durch eine leere Liste modelliert. Das ist etwas an deres als eine nicht vorhandene Liste (Sitzreihe). Bei  der Auswahl der Lebensweltbereiche, die in einem ko ntext-orientierten Informatikunterricht aufgegrif fen werden, sollte ihre Eignung als „Materialbasis“  für intuitive Modelle beachtet werden.                                                          22  „Im Hinblick auf die Allgemeinbildung kommt es uns  dabei hauptsächlich auf die Modellierung an. Die o jek torientierte Programmierung bietet lediglich eine e infache und effiziente Möglichkeit, die erarbeitete n Modelle  zu implementieren, liefert aber für sich genommen k aum Beiträge zur Allgemeinbildung.“ (Hubwieser 2004 ,  S. 94)  23  Eine Übersicht über gängige informatische Mikrowel ten liefern z.B. Henriksen & Kölling (2004).  24  Beispiele für Animationen aus dem Bereich der Chem ie mit Explorationsaufgaben, die auf den Modellie rungsaspekt abzielen,  findet man in der Website „D ie Welt der kleinsten Teilchen“ (Weigend 2004)  134     15.6 Schluss und Ausblick  Unterricht an allgemeinbildenden Schulen richtet si ch an junge Menschen, die sich in einem wich tigen Abschnitt ihrer Persönlichkeitsentwicklung be finden. In der Schule bilden sich nicht nur kogniti  ve und soziale Kompetenzen sondern auch persönliche  Interessen und Einstellungen zu beruflichen  Perspektiven. Intuitive Modelle der Informatik repr äsentieren Wissen, das ein Individuum beherrscht.  Weil sie mit einem Gefühl der subjektiven Sicherhei t verbunden sind, inspirieren sie zum Weiterden ken (einschließlich einer kritischen Revision), bef lügeln die Fantasie und motivieren junge Menschen,  sich mit der Informatik zu beschäftigen. „Je mehr W issen jemand in seiner Entwicklung erwirbt, desto  neugieriger wird er.“ (Oerter, Montada 1995, S. 769 ). Motivierender Unterricht knüpft deshalb an  vorhandenes (intuitives) Wissen an und schafft so Z ugänge zu neuem Wissen.   Als Medien materialisierte intuitive Modelle, ansch auliche und leicht verständliche Abbilder  (schwieriger) informatischer Konzepte werden in Sch ulbüchern, Museen, Zeitschriften und Fernseh sendungen verbreitet. Sie sind damit „Aushängeschil der“, die das Bild der Informatik in der Öffent lichkeit prägen. Eine Aufgabe der Fachdidaktik ist es, solche Vermittlungsmodelle zu schaffen, um  einem breiten Publikum den Zugang zur Informatik zu  ermöglichen. Zu den konkreten Zielen in dieser  Richtung gehört, den Katalog identifizierter (geeig neter und ungeeigneter) intuitiver Modelle zu  erweitern, zu verfeinern, auf komplexere Themen aus zudehnen und neue Medien und dazu passende  Unterrichtsformen zu entwickeln, in denen diese Mod elle elaboriert werden. 135       Literatur  Andrianoff, Steven K.; Levine, David B. (2002): Rol e playing in an object-oriented world. In: ACM  SIGCSE Bulletin  2002 S. 121–125.  Aharoni, Dan (2000): Cogito, Ergo Sum! Cognitive Pr ocesses of Students Dealing with Data Struc tures. In: ACM SIGCSE Bulletin , S. 26–30.  Albert, Jürgen; Ottmann, Thomas (1983): Automaten, Sprachen und Maschinen für Anwender . Mann heim Wien Zürich (BI).  Anderson, John R. (1996): Kognitive Psychologie . Heidelberg Berlin Oxford (Spektrum Akademi scher Verlag).  Anderson, John R. (1996a): ACT – A Simple Theory of  Complex Cognition. In: American Psycholo gist , 51/4, S. 355–365.  Anderson, John R.; Jeffries, Robin (1985): Novice L ISP Errors: Undetected Losses of Information  from Working Memory. In: Human-Computer Interaction , 1, S. 107–131.  Anderson, John R.; Piroll, Peter; Farell Robert (19 88): Learning to Program Recursive Functions. In:  Chi, M.; Glaser, R., Farr, M. (Hrsg.): The Nature of Expertise . Hilsdale, USA, S. 153–184.  Anderson, John R.; Bothell, Daniel; Byrne, Michael D. (2004): An Integrated Theory of the Mind. In:  Psychological Review , 111/4, S. 1036–1060.  Anjaneyulu, K. S. R.; Anderson, John R (1992): The Advantages of Data Flow Diagrams for Begin ning Programming. In: Intelligent Tutoring Systems , S. 585–592  Arnheim, Rudolph (1972): Anschauliches Denken . Köln (DuMont Schaumberg)   Anzai, Y.; Uesato, Y. (1982): Learning Recursive Pr ocedures by Middleschool Children. In: Proceed ings of the Fourth Annual Conference of the Cogniti ve Science Society , Ann Arbor, Michigan.  Aschwanden, Christoph; Crosby, Martha (2006): Code Scanning Patterns in Program Comprehension.  In: Symposium on Skilled Human-Intelligent Agent Perfor mance. Mesurement, Application and  Symbiosis. Hawaii International Conference on Syste ms Science , Januar 2006, Kauai, Hawaii.  Balzert, Heide (1999): Lehrbuch der Objektmodellierung: Analyse und Entwur f . Spektrum Akademi scher Verlag, Heidelberg Berlin.  Baumann, Rüdeger (1990): Didaktik der Informatik . Stuttgart 1990.  Baumann, Rüdeger (1994): Der Weg vom Konkreten zum Abstrakten. In: LOG IN  14 (1994) Heft 1,  S. 10 ff.   Baumgarten, Hans (2005): Compendium Rhetoricum . 2. Aufl. Göttingen (Vandenhoeck und Rup recht).  Beck, Kent (2003): Test Driven Development . Boston u.a. (Addison Wesley) 2003.  Beck, Kent (1999): Extreme Programming Explained . Boston u.a. (Addison Wesley).  Ben-Ari, Mordechai (1997): Recursion: From Drama to  Program. In: Journal of Computer Science  Education  11/3, S. 9–12.  Blackwell, Alan Frank (1998): Metaphor in Diagrams . Dissertation University of Cambridge.  Ben-Ari, Mordechai (2001): Constructivism in Comput er Science Education. In: Journal of Com puters in Mathematics and Science Teaching , 20 /1, S. 45–73.  Ben-Ari, Mordechai (2004): Situated Learning in Com puter Science Education. In: Computer Science  Education , 14/2, S. 85-100.  Bennet, Judith; Holman, John; Lubben, Fred; Nicolso n, Peter; Prior, Christine (2002): Science in Con text: The Salters Approach . Contribution to the 2 nd  IPN-YSEG-Symposium. 136     Bennett, Judith; Lubben, Fred (2006): Context-based  Chemistry: The Salters Approach. In: Interna tional Journal of Science Education , 28/9, S. 999–1015.  Bell, Tim; Witten, Ian H.; Fellows, Mike (1998): Computer Science Unplugged … off-line activities  and games for all ages . 1998. http://unplugged.canterbury.ac.nz, Zugriff am 15. 3. 2005.  Bernitzke, Fred Heinz (1987): Mastery-Learning-Strategie als Unterrichtsalternati ve . Frankfurt a.M.  Bern New York Paris (Lang).  Bhuiyan, Shawkat; Greer, Jim E.; McCalla, Gordon I.  (1994): Suppporting the Learning of Recursive  Problem Solving. In: Interactive Learning Environments , 4/2, S. 115–139.  Blackwell, Alan F.; Whitley, Kirsten N.; Good, Judi th; Petre Marian (2001): Cognitive Factors in Pro gramming with Diagrams. In: Artificial Intelligence Review  15/1-2, Springer Netherlands, S. 95– 114.  du Boulay, Benedict (1989): Some difficulties of le arning to program. In: Soloway & Spohrer 1989, S.  283–301.  Bonar, Jeffrey; Soloway, Elliot (1985): Preprogramm ing Knowledge: A Major Source of Misconcep tions in Novice Programmers. In: Human–Computer Interaction , Bd. 1 Nr. 2, S. 133 -161.  Bower, G.H.; Black, J.B.; Turner, T.J. (1979): Scri pts in memory for texts. In: Cognitive Psychology ,  11, S. 177–220.  Brewer, W.F.; Treyens,. J.C. (1981): Role of schema ta in memory for places. In: Cognitive Psychol ogy , 13, S. 207–230.  Brown, D.E. (1992): Using examples and analogies to  remediate misconceptions in physics: Factors  influencing conceptual change. In: Journal of Research in Teaching Science , 29 (1992) S. 17–34.  Byrnes, James P. (1996): Cognitive Development and Learning in Instructional  Contexts . Boston  London Toronto Sydney Tokyo Singapur.  Chiu, Ming Ming (1996): Exploring the origins, uses  and interactions of students intuitions. In: Jour nal for Research in Mathematical Education , 27, S. 478–504  Chiu, Ming Ming (2000): Metaphoric Reasoning: Origi ns, uses, development and interactions in  mathematics. In: Educational Journal  28/1, S. 13–46.  Chiu, Ming Ming (2001): Using Metaphors to understa nd and solve arithmetic problems: Novices and  experts working with negative numbers. In: Mathematical Thinking and Learning , 3/3, S. 93–124.  Clement, John (1982): Students preconceptions in in troductory mechanics. In: American Journal of  Physics  50 S. 60–71.  Clement, John; Lochhead, John; Monk, George (1981):  Translation difficulties in Learning Mathemat ics. American Mathematical Monthly,  88 (April 1981), S. 286–290.  Close, John; Dicheva, Darina (1997): Misconceptions  in Recursion: Diagnostic Teaching. In: Pro ceedngs of the Sixth Eurologo Conference “Learning and Exploring with Logo” . Budapest, Un garn 1997, S. 132–140.  Coenen, Hans Georg (2002): Analogie und Metapher. Grundlegung einer Theorie de r bildlichen Rede.   Berlin New York (Walter de Gruyter).  Collins, A. M. & Qulian, M. R. (1969): Retrieval ti me from semantic memory. In: Journal of verbal  Learning and Verbal Behaviour , 8, S. 240–247.  Collins, A; Brown, J. S.; Newman, S.E. (1989): Cogn itive apprenticeship: Teaching the crafts of read ing, writing and mathematics. In: Resnick, L. B. (H rsg.): Knowing, learning and instruction: Es says in honor of Robert Glaser , Hilsdale, NJ, S. 453–494  Collins, Allan; Brown, John Seely; Holum, Ann (1991 ): Cognitive apprenticeship: Making thinking  visible. In: American Educator , 6/11, S. 38-46.  Craik, Kenneth (1943): The nature of explanation . Cambridge. 137     Crowley, Lillie; Thomas, Michael; Tall, David (1994 ): Algebra, Symbols and Translation of Meaning.  In: Proceedings of the 18 th  International Conference for the Psychology of Mat hematics Education   (PME) , S. 240–247.  Crutzen, Cecile K.M.; Hein, Hans-Werner (1995): Obj ektorientiertes Denken als didaktische Basis der  Informatik. In: Sigrid Schubert (Hrsg.): Innovative Konzepte für die Ausbildung/ 6. GI-Facht agung  Informatik und SchuleINFOS ´95, Chemnitz, 25. – 2 8. September 1995 . Berlin Heidelberg New  York London Paris Tokyo Hong Kong; Barcelona Budape st (Springer).  Dicheva, Darina; Close, John (1996): Mental Models of Recursion. In: Journal of Educational Com puting Research , 14/1, S. 1–23.  Dewdney, A.K. (1995): Der Turing Omnibus. Eine Reise durch die Informatik  mit 66 Stationen . Berlin  Heidelberg New York.  Dingler, H. (1913): Die Grundlagen der Naturphilosphie , Leibzig.  diSessa, Andrea A.(1988): Knowledge in Pieces. In: George Forman & Peter B. Pufall (Hrsg.): Con structivism in the Computer Age.  Hillsdale (Lawrence Erlbaum), S. 49–70.  diSessa, Andrea A. (1993): Toward an Epistemology o f Physics. In: Cognition and Instruction  10/3,  S. 105-225.  diSessa, Andrea A.: Changing Minds. Computers, Learning, and Literacy . Cambridge, Massachusetts  (MIT Press) 2001.   Duell, M. (1997): Non-Software Examples of Software  Design Patterns. In: Object,  7/5.   Du Boulay, Benedict (1989): Some difficulties of le arning to program. In: Soloway & Spohrer 1989,  S. 283–301.  Eckes, Thomas (1991: Psychologie der Begriffe. Strukturen des Wissens un d Prozesse der Kategori sierung . Göttingen Toronto Zürich.  English, Lyn D. (1997) (Hrsg.): Mathematical Reasoning. Analogies, Metaphors, and I mages . Mah wah New Jersey, London (Lawrence Erlbaum Associates , Publishers) 1997.  English, Lyn D. (2004): Mathematical and Analogical  Reasoning of Young Learners. Mahwah (Law rence Erlbaum).  Fach, Peter W.; Strothotte, Thomas (1994): Cognitiv e Maps: A Basis for Designing User Manuals for  Direct Manipulation Interfaces. In: Tauber, M. J.; Mahling, D.E.; Arefi, F. (Hrsg.): Cognitive As pects of Visual Languages and Visual Interfaces . Amsterdam London New York Tokyo (NorthHolland) 1994, S. 133 ff.  Fischbein, Efraim (1987): Intuition in Science and Mathematics . Dordrecht Boston Lancaster Tokio  (Reidel).  Flavell, John H. (1963): Developmental Psychology of Jean Piaget . Princeton (D. Van Nostrand).  Fothe, Michael (2005): Rekursion und Iteration: Vor untersuchung zu einem Test. In: Friedrich, Stef fen: Unterrichtskonzepte für informatische Bildung. Proc eedings der INFOS 2005 in Dresden ,  LNI – Proceedings, Bonn 2005, S. 207–218.  George, Carlisle E. (2000): EROSIVisualising Recu rsion and Discovering New Errors. In: ACM  SIGCSE 2000 , S. 305–309.  Gamma, E.; Helm, R.; Johnson, R.; Vlissides, J. (19 95): Design Patterns -Elements of Resuable Ob ject-Oriented Software . Reading, MA (Addison Wesley).  Ginat, David (2001): Misleading Intuition in Algori thmic Problem Solving. In: ACM SIGCSE Bulletin  2001 , S. 21–25.  Götschi, Tina (2003): Mental Models of Recursion . Masterarbeit an der Faculty of Science der Univer  sity of the Witwatersrand, Johannisburg.  Griffith, A.K.; Preston, K.P. (1992): Grade-12-stud ents‘ misconceptions relating to fundamental char acteristics of atoms and Molecules. In: Journal of Research in Science Teaching , 29, S. 611–628. 138     Greening, Tony (1997): Examining Student Learning o f Computer Science. In: ACM SIGCSE 1997,  S.  63-66  Grudin, J. (1989): The case against user interface consistency. In: Communications of the ACM, 32/  10, 1989, S. 1164–1173.  Haberlandt, Karl (1994): Cognitive Psychology . Boston London Toronto Sydney Tokyo, Singapore  (Allyn and Bacon).  Hammer, David (1996): Misconceptions or P-Prims – H ow May Alternative Perspectives of Cognitive  Structures Influence Instructional Perceptions and Intentions? In: Journal of the Learning Sci ences , 5/2, S. 97 – 128  Henriksen, Poul; Kölling, Michael (2004): Greenfoot : Combining Object Visualization with Interac tion. In: Companion to the 19 th  annual ACM SIGPLAN conference on Object-orented pr ogram ming systems, languages and applications (OOPSLA)  Vancouver, Kanada, November 2004, S. 7382.  Hershkowitz, R. und Vinner, Sh. (1982): Basic geome tric concepts – definitions and images. In:  Vermandel, A. (Hrsg.): Proceedings of the Sixth International Conference f or the Psychology of  Mathematics Education . Antwerpen (Universitaire Instelling) 1982, S. 18– 23.  Holland, Simon; Griffiths, Robert; Woodman, Mark (1 997): Avoiding Object Misconceptions. In:  Proceedings ACM SIGCSE 1997 , S. 131–134.  Holmboe, Christian; McIver, Linda; George, Carlisle  (2001): Research Agenda for Computer Science  Education. In Kadoda, G. (Hrsg.): PPIG 13, Bournemo uth, UK, April 2001.  Hubwieser, Peter (1999): Modellierung in der Schuli nformatik. In: Log In 19/1  (1999), S. 24 –29.  Hubwieser, Peter (2004): Didaktik der Informatik. Grundlagen, Konzepte, Beis piele . 2. Aufl. Berlin  u.a. (Springer) 2004.  Huntemann, Heike; Paschmann, Antje; Parchmann, Ilka ; Ralle, Bernd (1999): Chemie im Kontext –  ein neues Konzept für den Chemieunterricht? In: Chemikon 6/4 , S. 191-196.  Jeong, Allan; Lee, Mihwa; Lehrer, Richard (1999): R eflective Teaching of Logo. In: Journal of the  Learning Sciences , 8/2 S. 245-288.  Jimenez-Diaz, Guillermo; Gomez-Albarran, Mercedes; Gomez-Martin, Marco A.; Gonzalez-Calero,  Pedro A. (2005): Understanding Object-Oriented Soft ware through Virtual Role-Play. In: Fifths  International Conference on Advanced Learning Techn ologies (ICALT ’05) , S. 875-877.  Johnson, W. Lewis (1990): Understanding and Debuggi ng Novice Programs. In: Artificial Intelli gence , 42, S. 51-97.  Johnson-Laird, Philip N. (1983): Mental Models: Toward a Cognitive Science of Langua ge, Inference  and Consciousness . Cambridge, MA (Harvard University Press).  Johnson-Laird, Philip N. (1996): Der Computer im Kopf. Formen und Verfahren der Erke nntnis.   München (dtv).  Johnson-Laird, Philip N.; Girotto, Vittorio; Legren zi, Paopo (1998): Mental models: a gentle guide for  outsiders . URL: http://www.si.umich.edu/ICOS/gentleintro.htm l, Zugriff am 20.2.2007.  Kahneman, D.; Tversky, A. (1982): Subjective probab ility: A judgement of representativeness. In:  Kahneman, D.; Slovic, P.; Tversky, A. (Hrsg.): Judgement under Uncertainty: Heuristics and Bi ases . Cambridge (Cambridge University Press) 1982, S. 3 2–47.  Kahney, Hank (1984): Modeling novice programmer beh aviour. In: Yazdani, M.: New horizons in  educational computing . EllisHorwood Ltd. 1984, S. 101–118.  Kahney, Hank (1989): What do novice programmers kno w about recursion? In: Soloway & Spohrer  1989, S. 209–228. 139     Karlgren, Klas; Ramberg, Robert (1996): Language Us e & Conceptual Change in Learning. In: Paul  Brna, Ana Paiva & John Self (Hrsg.): The European Conference on Artificial Intelligence in Edu cation  (EuroAIED)  Lissabon, S. 45–51.  Kattmann, Ulrich (2005): Lernen mit anthropomorphen  Vorstellungen? – Ergebnisse von Untersu chungen zur Didaktischen Rekonstruktion in der Biol ogie. In: Zeitschrift für Didaktik der Natur wissenschaften  11 (2005), S. 165–174.  Kessler, Claudius M.; Anderson, John R. (1989): Lea rning Flow of Control: Recursive and Iterative  Procedures. In: Soloway & Spohrer 1989, S. 229–260.   Knuth, Eric J.; Stephens, Ana C.; McNeil, Nicole M. ; Alibali, Martha W. (2006): Does Understanding  the Equal Sign Matter? Evidence from Solving Equati ons. In: Journal for Research in Mathemat ics Education , 37/4, S. 297–312.  Kurland, D. Midian; Pea, Roy D. (1985): Children’s mental models of recursive Logo programs. In:  Journal of Educational Computing Research , Vol. 1(2), 1985, S. 235–243.  Lakoff, G. (1987): Women, fire and dangerous things: what categories r eveal about the mind . Univer sity of Chicago Press.  Lakoff, George; Núnez, Rafael E. (1997): The Metaph orical Structure of Mathematics: Sketching Out  Cognitive Foundations for a Mind-Based Mathematics.  In: English, Lyn D. (Hrsg.): Mathematical  Reasoning. Analogies, Metaphors, and Images . Mahwah New Jersey, London (Lawrence Erlbaum  Associates, Publishers) S. 21–92.  Lehotská, Daniela (2006): Visual fractions in teach er training. In: Deryn Watson & David Benzie  (Hrsg.): IFIP WG 3.1, 3.3 & 3.5 Joint Conference , Alesund, Norwegen 2006 Proceedings.  Lakoff, G.; Johnson, M. (1980): The metaphors we live by . Chicago (The University of Chicago  Press).   Levy, Dalit; Lapidot, Tami (2000): Recursively Spea king: Analyzing Students’ Discourse of Recur sive Phenomena. In: Proceedings of the ACM SIGCSE 2000, Austin, Texas, USA S. 31–319.  Levy, Dalit; Lapidot, Tami; Paz, Tamar (2001): „It’ s just like the whole picture, but smaller“: Expres  sions of gradualism, self-similarity, and othe preconceptions while classifying recursive phenom ena. In: Kadoda, G. (Hrsg.): Proc. PPIG 13 , Bournemouth UK, April 2001, S. 249–262  Ley, R.G. (1983): Cerebral laterality and imagery. In A. A. Sheikh (Hrsg.): Imagery: Current theory,  research and application . New York (Wiley).  Linn, Marcia C.; Dalbey, John (1989): Cognitive Con sequences of Programming Instruction. In: So loway & Spohrer 1989, S.58 ff.  Logo Computer Systems Inc. (2004): Microworlds JR . Ressource Book with Extended Reference  Guide.  Madison, Sandra; Gifford, James (2002): Modular Pro gramming: Novive Misconceptions. In: Journal  of Research on Technology in Education . 34, 3 S. 217ff.  Manis, V. & Little, J. (1995): The Schematics of Computation . Prentice Hall.  Mayrhauser, A. von; Vans, A. M. (1994): Program Understanding – A Survey . Technical Report CS94-120, Department of Computer Science, Colorado St ate University USA.  Mayer, Richard E. (1989): The Psychology of How Nov ices Learn Computer Programming. In: Solo way & Spohrer, 1989, S. 129–159.  McCloskey, M. (1983): Naïve theories of motion. In:  Gentner, D. und Stevens, A. (Hrsg.): Mental  models . Hillsdale, NJ (Lawrence Erlbaum Associates, Inc.) , S. 299–324.  Messaris, Paul (1993): Analog, Not Digital: Roots o f Visual Literacy and Visual Intelligence. In:  Beauchamp, Darell G. et al. (Hrsg.): Selected readings of the IVLA Annual Conference “Vi sual  Literacy in the Digital Age” . Rochester New York 1993, S. 307–315. 140     Metzler, J. und Shepard R.N. (1974): Transformation  Studies of the Internal Representations of Three  Dimensional Objects. In: R.L. Solso (Hrsg.) Theories of Cognitiv Psychology: The Loyola Sym posium . Hillsdale 1974, S. 147–201.  Miller, John Alexander (2004): Promoting Computer Literacy through Programming Pyt hon . Disser tation University of Michigan.  Mithen, Stephen; Boyer, Pascal (1996): Anthropomorp hism and the evolution of cognition. In: Jour nal of the Royal Anthropological Institute , 2/4 S. 717 ff.  Moreno, Andrés & Myller, Niko (2003): Producing an Educationally Effective and Usable Tool for  Learning, The Case of the Jeliot Family. In: Proceedings of the International Conference on Networked e-learning for European Universities , Granada, Spain.  Mosconi, Mauro, Porta; Marco (1999): Testing the Us ability of Visual Languages: A Web-Based  Methodology. In: Hans-Jörg Bullinger & Jürgen Ziegl er (Hrsg.): Proceedings of the 8 th  Interna tional Conference on Human-Computer Interaction (HC I’99) , Band 1, München, S.1053–1057.  Mosconi, Mauro; Ottelli, Davide; Porta, Marco (2003 ): Alligator, a Web-based Distributed Visual  Programminp Environment. In: Proceedings WWW 2003 , Budapest, Ungarn, 20-24. Mai 2003,  Poster.  Moser, Karin S. (2003): Mentale Modelle und ihre Be deutung – kognitionspsychologische Grundlagen  des (Miss-)Verstehens. In: U. Ganz-Blättler & P. Mi chel (Hrsg.) Sinnbildlich schief: Missgriffe bei  Symbolgenese und Symbolgebrauch . Schriften zur Symbolforschung, Vol. 13), Bern (Pe ter Lang),  S. 181–205.  Nakamura, T. (1974): The learning of motion and for ce. In: Takahashi, K. und Hosoya, K. (Hrsg.):  Introduction to methods of Kyokuchi: Modern science  education . Tokio.  Navarro-Prieto, Raquel; Can as, Jose J. (2001): Are visual programming language s better? The role of  imagery in program comprehension. In: Journal Human -Computer Studies (2001) 54, S. 799–829.  Odell, James J. (1994): Six Different Kinds of Comp osition. In: JOOP  5/8.  Oerter, Montada (1994) (Hrsg.) Entwicklungspsychologie . Weinheim (Beltz).  Oviedo, Maria Cecilia Núnez; Clement, John (2003): Model Competition: A Strategy Based on Model  Based Teaching and Learning Theory. In: Procedings of NARST , Philadelphia 23-26. März 2003.  Paivio, Allan (1971): Imagery and language: In: S. J. Seagl (Hrsg.): Imagery: Current cognitive ap proaches . New York (Holt, Rinehardt & Winston), S. 7-32.  Paivio, Allan (1986): Mental representations – a dual coding approach . Oxford (Oxford University  Press).  Papert, Seymour (1980): Teaching Children Thinking.  In: R. Taylor (Hrsg.): The Computer in School:  Tutor, Tool, Tutee . New York (College Press), S. 161–176.   Parikh, Jadhish (1994): Intuition: the new frontier of management . Oxford (Blackwell).  Pennington, Nancy (1987): Stimulus Structures and M ental Representations in Expert Comprehension  of Computer Programs. In Cognitive Psychology  19, S. 295–341.  Perkins, D.N.; Hancock, Chris; Hobbs, Renee; Martin , Fay (1989): Conditions of learning in novice  programmers. Educational Technology Center, Harvard  University. In: Soloway & Spohrer 1989.  Piaget, Jean (2003): Meine Theorie der geistigen Entwicklung . Herausgegeben von Reinhard Fatke.  Weinheim, Basel, Berlin (Beltz).  Poincaré, Henri (1905): Science and Hypothesis . London (Walter Scott Publishing).  Popper, Karl R. (1934): Logik der Forschung . Wien (Verlag Julius Springer).  Putnam, Ralph T.; Sleeman, D.; Baxter Juliet A.; Ku spa, Laiani, K. (1989): A summary of misconcep tions of high school basic programmers. In: Soloway  & Spohrer, 1989, S. 301–314. 141     Riehle, D.; Züllighoven, H. (1996): Understanding a nd Using Patterns in Software Development, In:  Karl Lieberherr & Roberto Zicari (Hrsg.): Theory and Practice of Object Systems , Band 2, Nr. 1,  S. 3-13, 1996.  Roger, J.M.; Cisero, C.A.; Carlo, M.S. (1993): Tech niques amd Procedures for Assessing Cognitive  Skills. In: Review of Educational Research , 63/2, S. 201–243.  Reed, David (1998): Incorporating Problem-solving P atterns in CS1. In: Proc. ACM SIGCSE , S. 6-9.  Rosch, Eleonor (1973): On the internal structure of  perceptual and semantic categories. In: T.H.  Moore (Hrsg.): Cognitive development and the acquisition of langua ge . New York (Academic  Press).  Rosch, Eleonor (1975): Cognitive representations of  semantic categories. In:  Journal of Experimental  Psychology , 104, S. 192–223.  Rosnick, Peter (1981): Some Misconceptions Concerni ng the Concept of Variable. Are you careful  about defining your variables? In: The Mathematics Teacher , 74 (6), September 1981, S. 418–420,  450.  Samurçay, R. (1989): The concept of variable in pro gramming: Its meaning and use in problemsolving by novice programmers. In: Soloway & Spohre r, 1989, S. 161–178.  Sanner, M. F.; Stoffler, D.; Olson, A.J. (2002): Vi PEr, a visual programming environment for Python.  In: Proceedings of the 10 th  international Python Conference , Februar 2002, S. 103–115.  Sasse, Martina Angela (1997): Eliciting and Describing Users’ Models of Computer Systems .  Dissertation. Birmingham (University of Birmingham) .  Schank, R.C.; Abelson, R. (1977): Scripts, plans, g oals and understanding. Hillsdale.  Sajaniemi, Jorma (2002): Visualizing Roles of Varia bles to Novice Programmers. In: Kuljis, J.; Bald win, L.; Scoble, R. (Hrsg.): Proc PPIG  14, Brunel University.  Sleeman, D.; Putman, D.; Baxter, R.T.; Kuspa, L. (1 989): A summary of misconceptions of high  school Basic programmers. In: Soloway & Spohrer 198 9, S. 301–314.  Schubert, Sigrid; Schwill, Andreas (2004): Didaktik der Informatik . Heidelberg Berlin (Spektrum).  Schulmeister, Rolf (2002): Grundlagen hypermedialer Lernsysteme . Oldenbourg Verlag, München  u.a.   Schwank, Inge (2003): Einführung in prädikatives un d funktionales Denken. In: Zeitschrift für Didak tik der Mathematik , 35/3, S. 70–78.  Schwank, Inge (2005): Maschinenintelligenz: ein Erg ebnis der Mathematisierung von Vorgängen –  Zur Idee und Geschichte der Dynamischen Labyrinthe.  In C. Kaune, I. Schwank & J. Sjuts: Ma thematikdidaktik im Wissenschaftsgefüge: Zum Verste hen und Unterrichten mathematischen Den kens . Osnabrück (Forschungsinstitut für Mathematikdidak tik).  Schwill, Andreas (1993): Fundamentale Ideen der Inf ormatik. In: Zentralblatt der Mathematik 20  (1993) S. 20–31.  Schwill, Andreas (2001): Ab wann kann man mit Kinde rn Informatik machen? Eine Studie über in formatische Fähigkeiten von Kindern. In: Reinhard K eil-Slawik; Johannes Magenheim (Hrsg.): In formatikunterricht und Medienbildung, INFOS 2001, 9 . GI-Fachtagung Informatik und Schule,  17.-20. September 2001 in Paderborn . LNI 8 GI 2001, S. 13–30.  Smith, John P.; diSessa, Andrea A.; Roschelle, Jere my (1994): Misconceptions Reconceived: A Con structivist Analysis of Knowledge in Transition. In : Journal of the Learning Sciences , Vol. 3  (1993/94) Nr. 2.  Soloway, E.; Spohrer, J. C. (1989) (Hrsg.): Studying the novice programmer . Hilsdale (Lawrence Erl baum Associates).  Sommerville, Ian (1997): Software Engineerung . 5. Auflage, Harlow, England (Addison-Wesley). 142     Spohrer, James C., Soloway, Elliot, Pope, Edgar (19 89): A Goal/Plan Analysis of Buggy Pascal Pro grams. In: Soloway & Spohrer, 1989, 355–399.  Stary, Joachim (1997): Visualisieren: eine Studienund Praxisbuch . Berlin.  Stern, Linda; Naish, Lee (2002): Visual Representat ions for Recursive Algorithms. In: Proceedings of  the SIGCSE 2002 , Covington, Kentucky, USA 2002, S. 196–200.  Storey, M.-A. D.; Wong, K.; Müller, H. A. (1997): H ow Do Program Understanding Tools Affect  How Programmers Understand Programs? In: Proceedings of the Fourth Working Conference on  Reverse Engineering , S. 12–21.  Ströker, Elisabeth (1967): Denkwege der Chemie . Freiburg München.  Sutcliffe, Alistair G.; Darzentas, Jenny S. (1994):  Use of Visual Media in Explanation. In: Tauber, M.   J.; Mahling, D.E.; Arefi, F. (Hrsg.): Cognitive Aspects of Visual Languages and Visual In terfaces .  Amsterdam London New York Tokio (North-Holland). 19 94, S.105 ff.  Smith, Randall B.; Ungar, David (1995): Programming  as an Experience: The Inspiration for Self. In:  Proceedings of ECOOP ’95 , Lecture Notes on Computer Science 952 (Springer).   Taivalsaari, Antero (1992): Kevo – a prototype-base d object-oriented language based on concatenation  and module operations. Technical report DCS-197-IR,  University of Victoria,B.C., Kanada, Juni  1992.  Taivalsaari, Antero (1997): Classes vs. Prototypes.  Some Philosphical and Historical Observations. In:   JOOP 10(7) 1997, S. 44–50.  Temple, David M.; Guest, Stece P. (1994): Diagramma tic Techniques for the Visualisation of Object  Oriented Programming. In: Tauber, M. J.; Mahling, D .E.; Arefi, F. (Hrsg.): Cognitive Aspects of  Visual Languages and Visual Interfaces . Amsterdam London New York Tokyo (North-Holland)  1994, S.259 ff.  Thomas, Marco (2003): Informatische Modelle zur Str ukturierung von Anfangsunterricht. In: Peter  Hubwieser (Hrsg.): Informatische Fachkonzepte im Unterricht, INFOS 200 3, GI-Fachtagung In formatik und Schule , 17.-19.September 2003 in Garching bei München. LN I 32 GI, S. 155–164.  Tuzova, Olga; Katz, Yekuda (2001): Logo Art Gallery .  http://www.geocities.com/CollegePark/Lab/2276/ 2001 . Zugriff am 1. Juli 2006.  Ueno, Naok (1993): Reconsidering P-Prims Theory Fro m the Viewpoint of Situated Cognition. In:  Cognition and Instruction. 10, 3, S. 239 ff.  Ueding, Gert (2005): Klassische Rhetorik . 4. Aufl. München (Beck).  Uitenbroek, Daan (2000): SISA Fisher , Hilversum, http://home.clara.net/sisa/fisher.htm.   Van der Veer, Gerrit C. (1994): Mental Models of Co mputer Systems: Visual Languages in the Mind.  In: Tauber, M. J.; Mahling, D.E.; Arefi, F. (Hrsg.) : Cognitive Aspects of Visual Languages and  Visual Interfaces. Amsterdam London New York Tokyo (North-Holland), S. 3 ff.  Vossenkuhl, Wilhelm (1998): „Verstehen“ verstehen. In: Kanitschneider & Wetz (Hrsg.): Hermeneu tik und Naturalismus . Tübingen.  Van Rossum, Guido; Yee, Ka-Ping (2001): Iterators  (PEP 234), 30.1.2001.  http://www.python.org/peps/pep-0234.html. Zugriff a m 1. Mai 2006.  Weigend, Michael (1999): Roboter im Internet (1). I n: Informatik betrifft uns , 1999/4.  Weigend, Michael (2005): Intuitive Modelle in der I nformatik. In: Friedrich, Steffen (Hrsg.) Unter richtskonzepte für informatische Bildung. INFOS 200 5 . Lecture Notes in Informatics (LNI) – Pro ceedings. Bonn (GI) 2005 S. 275–284.  Weigend, Michael (2005a): Objektorientierte Program mierung. In: Markus Nix (Hrsg.); Martin  Grimme; Torsten Marek; Michael Weigend; Wolfgang We itz: Exploring Python . Frankfurt (ent wickler.press).  Weigend, Michael (2006): Python-Gepackt . Dritte Auflage. Heidelberg (Redline) 2006 143     Weigend, Michael (2006a): Objektorientierte Programmierung mit Python . Dritte Auflage. Heidelberg  (Redline).  Weigend, Michael (2006b): Experimental Programming.  In: Deryn Watson & David Benzie (Hrsg.):  IFIP WG 3.1, 3.3 & 3.5 Joint Conference , Alesund, Norwegen 2006 Proceedings.  Weigend, Michael (2006c): Design of web-based educa tional games for informatics classes – some  insights from workshops with the Python Visual Sand box. In: Workshop „GML – Grundfragen  multimedialer Lehre“ , Potsdam 14. – 15.3.2006, im Druck.  Weigend, Michael (2006d): From Intuition to Program me. In: Roland T. Mittermeir (Hrsg.): Informat ics Education – The Bridge between Using and Unders tanding Computers . ISSEP 2006 Vilnius,  Litauen Proceedings, Berlin Heidelberg (Springer), S. 117–126.  Wertheimer, Max (1925): Über Gestalttheorie. In: Philosopgische Zeitschrift für Forschung und Aus sprache , 1, S. 39-60.  Wittgenstein, Ludwig (1953): Philosophische Untersuchungen . 3. Auflage, Frankfurt a.M. 1982 (zu erst erschienen 1953).  Wu, Cheng-Chih; Dale, Neil B.; Bethel, Lowell J. (1 998): Conceptual Models and Cognitive Learning  Styles in Teaching Recursion. In: Proceedings of the 29 th  SIGCSE technical symposium on com puter science education , Atlanta Georgia, USA S. 223-227.  Zachary, Joseph L. (1997): The Gestalt of Scientifi c Programming: Problem, Model, Method, Imple mentation, Assessment. In: ACM SIGCSE 1997 , S. 238-242.  Zietsman, Aletta; Clement, John (1997): The Role of  Extreme Case Reasoning in Instruction for Con ceptual Change. In: Journal of the Learning Sciences , 6/1, S. 61-89.   144       Anhang 145     Abbildungsverzeichnis  Abb. 1: Gestalt eines Quadrats 18  Abb. 2: Problemlösen mit dem p-Prim „Auslöschen“ 24  Abb. 3: Visualisierung der Idee eines Rechenalgorit hmus zur Berechnung der Summe von Gliedern einer  Zahlenfolge 24  Abb. 4: Entscheidungsbaum für die binäre Suche 28  Abb. 5: Ergebnis einer Umfrage zur Häufigkeit der V erwendung von Visualisierungen im  Informatikunterricht (n = 20) 28  Abb. 6: Intuitive Modellierung einer Iteration über  eine Liste durch Entnahme von Items 32  Abb. 7: Suchbaum und geschachtelte antizipatorische  Intuitionen 34  Abb. 8: Aufbau eine GAP-Trees und eines Lösungsbaum s (dunkel) 35  Abb. 9: Aufbau der Python Visual Sandbox 42  Abb. 10: Screenshots aus dem Python Visual Multilists  43  Abb. 11: Auszug aus der Evaluation der Antworten zu m Python Visual „Changing lists“ 44  Abb. 12: Screenshots aus einem Python Puzzle 44  Abb. 13: Zwei Screenshots aus dm „Tipp“ des Python Puzzles Multilists  48  Abb. 14: Screenshot aus einem Python Quiz 49  Abb. 15: Ein Objekt als Akteur zur Veranschaulichun g der Idee eines nicht objektorientierten  Programms. 54  Abb. 16: Modelle für Mehrfachnamen 56  Abb. 17: Ungeeignetes visuelles Modell für das Prog ramm 56  Abb. 18: Behältermodell für die Veränderung einer L iste mit zwei Namen (Erscheinungsmodell). 57  Abb. 19: Modell einer Liste mit zwei Namen 57  Abb. 20: Konsistentes Zeigermodell für die Veränder ung einer Liste mit zwei Namen 57  Abb. 21: Etikettenmodell 58  Abb. 22: Zahl als aktive Entität, die ihre Namen ko ntrolliert 59  Abb. 23: Modelle für eine Iteration über eine Liste  von Paaren 59  Abb. 24: Modelle für die Sortierung einer Liste nac h dem Algorithmus straight selection (Screenshots) 61  Abb. 25: Illustration des 17-jährigen Schülers T. ( Jahrgangsstufe 11) 64  Abb. 26: Illustration der 17-Jährigen Schülerin J. zur Visualisierung der Unterordnung eines Objektes  unter einen Namen 65  Abb. 27: Figuren als Platzhalter für Zahlen 67  Abb. 28: Geeignete und ungeeignete intuitive Modell e zur Darstellung einer leeren Liste 67  Abb. 29: Screenshots aus drei Animationen zur Visua lisierung von Zuweisungen. Entität-Modell),  Zustand-Modelle 69  Abb. 30: Zuweisung b = a als Manipulation des Zusta ndes von Objekt b durch Objekt a. 70  Abb. 31: Funktion (eigentlich statische Methode ein er Klasse) als Materialverarbeitungseinheit mit Ein  und Ausgang. Visualisierung der 17-jährigen C. 72  Abb. 32: Funktion (eigentlich Aufruf einer Methode)  als „magischer Becher“, der Objekte „verwandelt“.   Visualisierung des 17-jährigen Schülers M. 72  Abb. 33: Visualisierung einer Prozedur als Box mit Einund Ausgang 73  Abb. 34: Eingabe über Sensoren (PVS) 73  Abb. 35: Verknüpfung von Operatoren (Funktionen) un d Objekten bei Logotron (aus Lehotská 2006) 74  Abb. 36: Modelle mit unterschiedlichen Eingabemecha nismen zur Visualisierung   eines Funktionsaufrufs 75  Abb. 37: Visuelle Modelle für die Rückgabe einer Re ferenz auf ein Objekt 77  Abb. 38: Vergleich zweier Zahlen als steuerndes Ere ignis. Screenshots aus dem   Python Quiz Modeling a group  78  Abb. 39: Modelle für Funktionen mit offener Systemg renze 80  Abb. 40: Offene und geschlossene Modelle zur Visual isierung der Ausführung   einer rekursiven Funktion 80  Abb. 41: Funktionen als Boxen mit Ein/Ausgang und S eitentüren (PVS) 82  Abb. 42: Visualisierung der Ausführung einer Sequen z durch konkurrente Prozesse 85  Abb. 43: Visualisierung einer Iteration. Screenshot s aus dem Python Visual „Iteration“ 88  Abb. 44: Nassi-Shneiderman-Diagramm und Modell eine s Steuerungsakteurs 89  Abb. 45: Screenshot aus einer Sitzung mit Microworl d EX 92  Abb. 46: Darstellung von Zuweisungen mit unterschie dlichen Vernichtungsmodellen. 96  Abb. 47: Sukzessive Zuweisungen ohne Vernichtung 97 146     Abb. 48: Visualisierung der Ausführung eines Method enaufrufs durch die Metamorphose einer  Datenentität 99  Abb. 49: Visualisierung von Graphen (Baum, Ring) oh ne explizite Repräsentation der Kanten 101  Abb. 50: Modelle mit Datentransport zur Visualisier ung einer Zuweisung. Naiver Transport,   Transport einer Kopie und Holen einer Kopie 101  Abb. 51: Modelle mit Namenbewegung zur Visualisieru ng einer Zuweisung: Namenskette, Transport der  Kopie eines Namens, zweiter Name für Behälter und z weiter Name für Datum 103  Abb. 52: Beurteilung unpassender Modelle mit Namenb ewegungen für Zuweisungen. Lernkurven bei  Vielspielern (n = 41) 104  Abb. 53: Modelle mit Zeigerbewegung zur Visualisier ung von Zuweisungen 104  Abb. 54: Beurteilung als unpassend eingestufter Mod elle mit Zeigerbewegungen. Lernkurven bei  Vielspielern (n = 41) 105  Abb. 55: Screenshots aus Animationen zur Veranschau lichung von Instanzierungen   (aus Python Quiz Objects ) 111  Abb. 56: Objekt als Akteur. Screenshots aus der Ani mation pq_objects_a2_4 112  Abb. 57: Umgebung als Akteur. Screenshots aus der A nimation pq_objects_a2_3 112  Abb. 58: Gesplittete Aktivität. Screenshots aus der  Animation pq_objects_a2_1 113  Abb. 59: Botschaft als Akteur 114  Abb. 60: Modelle mit unterschiedlicher Darstellung des Transports einer Botschaft zum Empfänger:  Leitstrahl, Anfassen, selbstständige Suche und Broa dcasting 114  Abb. 61: Verwendung von Auslassungen bei der Darste llung einer langen Liste 118  Abb. 62: Anthopomorphes Modell aus der PVS für die Ausführung einer rekursiven Funktion 119  Abb. 63: Cluster intuitiver Modelle für eine Liste 120  Abb. 64: Dramatisierung einer Zuweisung 122  Abb. 65: Visualisierung als Rückmodellierung (Zeich nung eines 17-jährigen Schülers    der Jahrgangsstufe 11) 123  Abb. 66: Rückmodellieren 123  Abb. 67: Dynamisches Labyrinth (Schwank 2005), das eine Subtraktion ( 6-4) repräsentiert 154  Abb. 68: Beispiel für die Spezifikation eines Kalen dereintrags bei site@school 155  Abb. 69: Ansicht des Kalenderblattes nach Spezifika tion wie im Beispiel aus Abb. 68 155  Abb. 70: Formel in einer Kalkulationstabelle 156  Abb. 71: Binärbaum, der durch eine Turtle-Prozedur generiert worden ist 157  Abb. 72: Ein Kasten mit Schild repräsentiert eine V ariable als Behälter für Daten. 158  Abb. 73: Kasten mit mehreren Fächern zur Darstellun g einer Python-Liste 159  Abb. 74: Beschriftete Zettel repräsentieren Daten 159  Abb. 75: Bewegliches Oval, das eine Botschaft an da s Objekt bottle repräsentiert 159  Abb. 76: Haftzettel als Namen für Objekte 159  Abb. 77: Stecknadeln mit Schildern repräsentieren R eferenzen auf Elemente einer Liste 160  Abb. 78: Zeiger 160  Abb. 79: Namensschild 160  Abb. 80: Greifer repräsentieren Aktivität einer Ent ität 161  Abb. 81: Darstellung einer Funktion als Box mit Ein gang (oben) und Ausgang (unten). 161  Abb. 82: Fragebogen zur Verwendung von Visualisieru ngen (1) 162  Abb. 83: Fragebogen zur Verwendung von Visualisieru ngen (2) 163  Abb. 84: Fragebogen zur Verwendung von Visualisieru ngen (3) 163  Abb. 85: Verteilung der gewählten Beispiele für reg uläre Ausdrücke und ihre Sprachen (n=29) 168  Abb. 86: Häufigkeitsverteilung der ausprobierten vo llständigen Beispiele. (n=29) 171  Abb. 87: Häufigkeitsverteilung der insgesamt auspro bierten Beispiele (n=29) 171  Abb. 88: Regulärer Ausdruck als Sieb, das bestimmte  Zeichenketten „ausfiltert“ 172  Abb. 89: Regulärer Ausdruck als „Produzent“ von Zei chenketten 172  Abb. 90: Regulärer Ausdruck als Muster, das auf bes timmte Zeichenketten „passt“ 172  Abb. 91: Programmflussgraph für die Quicksort-Funkt ion 177  Abb. 92: Dialogseite für Coaches 187  Abb. 93: Actvity Report der Testentität test_hans  188  Abb. 94: Auszug aus einem Highscore-Bericht 188  Abb. 95: Gruppenbezogene Auswertung eines Python-Vi suals (Ausschnitt) 189  Abb. 96: Problemkontext (links) und Editorseite (re chts). 214  Abb. 97: Feedback zu einem Testlauf des Programms ( links) und Kurzreferenz zur den vorkommenden  Python-Sprachelementen. 214 147     Abb. 98: Ein datenflussorientiertes visuelles Progr amm mit DRLP 285  Abb. 99: Fetch-execute-Schleife eines interaktiven Systems. Nach Sommerville 1997, S. 287 286  Abb. 100: Visualisierung der Arbeitsweise rekursive r Funktionen 289  Abb. 101: Zuweisung mit totaler Vernichtung der Var iablen 291  Abb. 102: Beurteilung eines Zuweisungsmodells mit t otaler Vernichtung. Lernkurve (links) und  Antilernkurve (rechts) bei Vielspielern (n = 41) 292  Abb. 103: „Verschmelzen“ von zwei Datenentitäten. D rei Screenshots aus einer Animation der PVS  (Python Puzzle Assert First Steps ) 292  Abb. 104: Konkatenation von Listen. Drei Screenshot s aus einer Animation der PVS (Python Puzzle  Multilists ) 293  Abb. 105: Abstrakte Darstellung der Abspaltung eine s Pivot-Elementes aus einer unsortierten Liste im  Rahmen des Quicksort-Algorithmus. 293  Abb. 106: Illustration des 17-jährigen Schülers M. zur Visualisierung der statischen Methode (Java)  Math.sqrt(2)  293  Abb. 107: Umbenennungen bei der Ausführung einer Fu nktion. Sechs Screenshots aus einer Animation  der PVS (Python Puzzle Assert First Steps ) 294  Abb. 108: Veranschaulichung der Arbeitsweise einer rekursiven Funktion zur Berechnung der Fakultät  unter Verwendung von Execution Frames. Screenshot a us der PVS (Python Visual Factorial ) 296  Abb. 109: Veranschaulichung der Arbeitsweise einer rekursiven Funktion durch sukzessive  Umbenennung. Drei Screenshots aus einer Animation d er PVS (Python Visual Factorial ) 296  Abb. 110: Screenshots aus Animationen der PVS-Appli kation Python Quiz List 297  Abb. 111: Modelle mit Namenbewegung zur Visualisier ung einer Iteration 298  Abb. 112: Schüler-Visualisierungen mit Fabrik-Metap hern 299  Abb. 113: Modell einer Klasse als Menge von Objekte n 299  Abb. 114: Illustration einer Klassendefinition und Instanzierung eines Objektes   (17-jährige Schülerin J.) 300  Abb. 115: Abspalten einer Botschaft aus einer versc hachtelten Botschaft (pq_objects_a5_3) 304  Abb. 116: Vermischen von passivem und aktivem Model l für Objekte (pq_objects_a5_3) 304  Abb. 117: Auflösung einer verschachtelten Botschaft  durch das Laufzeitsystem (pq_objects_a5_6) 304  Abb. 118: Unplausibles Modell mit (pq_objects_a5_1)  305  Abb. 119: Verschachtelte Botschaft als eigener Akte ur, der Botschaften senden kann 305  Abb. 120: Modelle, die der Semantik der Anweisung bottle.empty()  widersprechen 306    148     Tabellenverzeichnis  Tab. 1: Zusicherungen für eine Implementierung von Quicksort.  39  Tab. 2: Verwendung korrekter Programmzeilen in Pyth on Puzzle Modeling a group  46  Tab. 3: Verwendung falscher Programmzeilen in Pytho n Puzzle Modeling a group  47  Tab. 4: Wahl verschiedener Modelle zur Veranschauli chung eines Programms  58  Tab. 5: Beurteilung von Modellen zur Veranschaulich ung von Zuweisungen  60  Tab. 6: Wahl verschiedener Modelle zur Veranschauli chung eines Programms 62  Tab. 7: Beurteilung von Modellen zur Darstellung ei ner leeren Liste 68  Tab. 8: Beurteilung von Modellen zur Veranschaulich ung von Zuweisungen 69  Tab. 9: Beurteilung von Modellen mit unterschiedlic hen Eingabemechanismen für Funktionen 76  Tab. 10: Wahl verschiedener Modelle zur Veranschaul ichung der Rückgabe einer Referenz 78  Tab. 11: Beurteilung von Modellen für Testfunktione n, deren Ausgabe als Signal interpretiert wird 79  Tab. 12: Wahl verschiedener Modelle zur Veranschaul ichung der Rückgabe einer Referenz 81  Tab. 13: Wahl verschiedener Modelle zur Veranschaul ichung einer rekursiven Funktion 83  Tab. 14: Wahl verschiedener Modelle zur Veranschaul ichung einer Iteration 88  Tab. 15: Beurteilung von Modellen zur Veranschaulic hung von Zuweisungen   97  Tab. 16: Beurteilung von Zuweisungsmodellen ohne Ve rnichtung 98  Tab. 17: Beurteilung von Modellen zur Veranschaulic hung von Zuweisungen der Form b = a 102  Tab. 18: Beurteilung von Modellen zur Veranschaulic hung von Zuweisungen der Form b = a 103  Tab. 19: Beurteilung von Modellen zur Veranschaulic hung von Zuweisungen mit Zeigern  105  Tab. 20: Beurteilung von Modellen für Instanzierung en 111  Tab. 21: Beurteilung von Modellen zur Ausführung ei nes Auftrags mit unterschiedlicher Gewichtung der  Eigenaktivität des Objekts 113  Tab. 22: Beurteilung von Modellen zum Routing von B otschaften. 115  Tab. 23: Python-Kurzreferenz von O’Reilly 151  Tab. 24: Verwendete Ausdrucksmittel bei Teach-backVersuchen (van der Veer 1994) 151  Tab. 25: Merkmale naher und entfernter Visualisieru ngen von Programmen 158  Tab. 26: Ergebnis der Umfrage zur Verwendung von Vi sualisierungen 164  Tab. 27: Anzahlen der ausprobierten Beispiele (n=29 ) 170  Tab. 28: Tabelle person  181  Tab. 29: Tabelle person_group  181  Tab. 30: Tabelle pvsgroup  182  Tab. 31: Tabelle coach  182  Tab. 32: Tabelle model  182  Tab. 33: Tabelle protocol_pv  183  Tab. 34: Tabelle description_pv  184  Tab. 35: Tabelle protocol_pv_person  184  Tab. 36: Tabelle description_pp  184  Tab. 37: Tabelle protocol_pp  184  Tab. 38: Tabelle protocol_pp_task  185  Tab. 39: Tabelle protocol_pp_model  185  Tab. 40: Tabelle description_pq  186  Tab. 41: Tabelle description_pq  186  Tab. 42: Tabelle protocol_pq  186  Tab. 43: Tabelle protocol_pq_model  187  Tab. 44: Rekursive Logo-Prozedur mit einer korrekte n und zwei falschen Bildschirmausgaben  beim  Aufruf von pattern3 "LEGO  288  Tab. 45: Ergebnisse von ersten Sessions zweier Pyth on Visuals 290  Tab. 46: Beurteilung eines Zuweisungsmodells mit to taler Vernichtung der Variablen 291  Tab. 47: Wahl verschiedener Modelle zur Veranschaul ichung der Arbeitsweise einer rekursiven Funktion  (Fakultät) 296  Tab. 48: Beurteilung von Modellen zur Veranschaulic hung von Zuweisungen   im Rahmen einer Iteration. 297  Tab. 49: Beurteilung von Modellen zur Veranschaulic hung von Iterationen durch Namenbewegungen 298  149       Abkürzungsverzeichnis    ACM Association for Computing Machinery  DL Dynamisches Labyrinth  GI Gesellschaft für Informatik  ICOS   IFIP International Federation for Information Proce ssing  IVLA International Visual Literacy Association  JOOP Journal of Object Oriented Programming  LNI Lecture Notes in Informatics  OOP Objektorientierte Programmierung  PPIG   p-Prim phänomenologisches Primitiv (diSessa)  PVS Python Visual Sandbox  SIGCSE Special Interest Group Computer Science Educ ation  SIGPLAN  Special Interest Group   UML Uniform Modeling Language      150     1 Ergänzungen zur Repräsentation intuitiver Modelle   1.1 Verwendung unterschiedlicher Metaphern beim mat hematischen  Problemlösen   Chiu (2001) ging in einer Untersuchung mit 12 Erwac hsenen (18 bis 25 Jahre) und 12 Kindern (1213 Jahre) der Frage nach, in welchem Umfang Metaphe rn bei Problemlösungen und zur Erklärung  arithmetischer Operationen verwendet werden. Die Un tersuchung bestand aus zwei Teilen. Im ersten  Teil sollten die Probanden Profite aus einem Börsen handel berechnen und anschließend ihre Rechnung  begründen. Die Rechnungen bestanden aus Additionen und Multiplikationen mit positiven und negati ven Zahlen. Im zweiten Teil sollten die Versuchsper sonen Fragen der Art „How do you make sense of  -5+8 ?“ beantworten. Alle schriftlichen, mündlichen und gestischen Äußerungen wurden protokolliert  und analysiert. In den Antworten wurde nach metapho rischen Erklärungen mit Konzepten aus ver schiedenen Bereichen (Quell-Domänen) gesucht 25 , unter anderem  (1) Bewegung („arithmetic is motion along a line“):  In dieser Domäne werden positive Zahlen durch  Schritte nach rechts und negative Zahlen durch Schr itte nach links vom Ursprung dargestellt. Die  Rechnung -5+8  wird so interpretiert, dass man zuerst 5 Schritte nach links und dann 8 Schritte nach  rechts geht. Dabei wird der Weg, den man zuerst nac h links gegangen ist, gewissermaßen annulliert.  (2) Manipulation von Objekten („arithmetic is manip ulating objects”): Natürliche Zahlen werden durch  eine entsprechende Anzahl von Objekten repräsentier t, negative ganze Zahlen durch Löcher, die man  mit Objekten füllen („auslöschen“) kann, oder Objek te aus Antimaterie.  (3) Soziale Transaktionen (“arithmetic is a social transaction”). Positive Zahlen stellt man sich als Besitz  vor und negative Zahlen als Schulden.   Die Probanden äußerten die Metaphern spontan. Wenn im ersten Teil keine spontane Erklärung  kam, sondern nur das Ergebnis genannt wurde, fragte  der Interviewer nur ein einziges Mal nach. Be merkenswert sind folgende Ergebnisse:  Erwachsene verwendeten bei den Erklärungen im zweit en Teil deutlich mehr Metaphern (Mittel wert 7.0, Standardabweichung 2.7) als Kinder (Mitte lwert 2.25, Standardabweichung 0.35). Erwach sene verwendeten außerdem mehr unterschiedliche Met aphern und bevorzugten die beiden ersten  Quelldomänen, während die Kinder fast ausschließlic h auf die Bewegungsdomäne zurückgriffen.  Zur Erklärung der Problemlösungen im ersten Teil de r Untersuchung verwendeten (genauer: äußer ten) dagegen die Kinder mehr Metaphern (Mittelwert 3.67) als Erwachsene (Mittelwert 0.25).  Die Verwendung multipler Intuitionen zeigte auch ei ne frühere Untersuchung von Chiu (1996). Er  stellte 16 Schülerinnen und Schülern im Alter von 1 2 bis 14 Jahren die Aufgabe, die Längen verschie den geformter Wege zwischen zwei Punkten abzuschätz en. Er interviewte sie während der Problemlö sung und registrierte die Intuitionen, die sie in i hren Erklärungen verwendeten. Es zeigte sich, dass  eine Person im Schnitt 2.63 unterschiedliche Intuit ionen erwähnte. Insgesamt verwendete sie 5.31  intuitive Vorstellungen. Vielfalt und Häufigkeiten sanken nur unwesentlich, nachdem der Person ein  Algorithmus zur Lösung der Aufgabe beigebracht word en ist (4.94 Äußerungen 2.18 verschiedenen  Intuitionen).  1.2 Repräsentation von Sprachkonzepten durch eine B eispielkollektion  – die Python-Kurzreferenz von O’Reilly  Tab. 23 zeigt einen Auszug aus einer Kurzreferenz f ür Python von O’Reilly, die auf ein Lesezei chen passt. Jedes Beispiel verdeutlicht unterschied liche Aspekte von Tupeln. Kurzreferenzen dienen in  der Regel als Erinnerungshilfe für Leute, die die P rogrammiersprache bereits beherrschen. Aber auch                                                         25  Eine systematische Übersicht über Metaphern für ar ithmetische Operationen findet man in La koff et al. 1997   151     erfahrene Programmierer, die die betreffende Sprach e nicht kennen, gewinnen bereits einen Einblick.  Beides deutet darauf hin, dass Menschen auch intern  Programmiersprachenkonzepte durch Beispiel kollektionen repräsentieren können.    Operation Interpretation  ()  t1 = (0,)  t2 = (0, 'Ni', 1.2, 3)  t[i]  t[i:j]  An empty tuple  A one-item-tuple (not an expression)  A four-item tuple  Indexing  Slicing  Tab. 23: In der Python-Kurzreferenz von O’Reilly wird  allein durch Beispiele erklärt, was ein Tupel ist.  Effiziente Beispielkollektionen enthalten meist Pro totypen mit besonders hoher Repräsentativität  und Sonderfälle. Die ersten drei Beispiele in Tab. 23 stellen einen Prototyp (Beispiel 3) und zwei Son  derfälle (die ersten beiden Beispiele) dar. In die Sonderfälle kann auch Wissen über andere Konzepte  einfließen. So wird im Beispiel des Python-Tupels ( 0,) zum Ausdruck gebracht, dass sich durch das  Komma ein einelementiges Tupel von einem Klammeraus druck unterscheidet (vgl. Tab. 23). Derartige  Abgrenzungen können auch durch Gegenbeispiele expli ziert werden. So ist das Literal (1) kein Tupel,  sondern ein Ausdruck und das Statement t[0] = 2  ist nicht erlaubt, wenn t ein Tupel ist. Denn bei  Python sind Tupel unveränderbare Objekte.  1.3 Von der Schwierigkeit intuitive Modelle zu visu alisieren  In einer umfangreichen Untersuchung von van der Vee r (1994) mit 607 Personen aus drei europäi schen Ländern wurde versucht, mentale Modelle über die Arbeitsweise von Computersystemen zu  ermitteln. Die Aufgabe war, mit Hilfe beliebiger Au sdrucksmittel (Text, Zeichnungen etc.) auf einem  Blatt Papier zu erklären, wie man einen gespeichert en Text sucht, ihn auf dem Bildschirm darstellt,  eine Kopie speichert und ihn ausdruckt („teach back “). Aus den Ergebnissen erhoffte man sich Er kenntnisse über verwendete Modellvorstellungen. Wie  die Analyse der abgelieferten Erklärungsversu che zeigte, wurden zwar häufig mehrere Darstellungs formen kombiniert, aber es dominierten eindeu tig verbale Repräsentationen (Tab. 24). Bildhafte o der ikonische Darstellungen spielten eine  untergeordnete Rolle.   Ausdrucksmittel  Anteil   Text 91%  Bild 25%  Ikonische Darstellung 28%  Regeln („Wenn…, dann..“) 6%  Programmtext („Pseudocode“) 34%  Tab. 24: Verwendete Ausdrucksmittel bei Teach-back-V ersuchen (van der Veer 1994)  Um das Problem mangelnder Darstellungsfähigkeit zu umgehen, werden in der Python Visual  Sandbox (PVS) deshalb nicht spontane Visualisierung sversuche der Teilnehmer gesammelt, sondern  stattdessen eine Vielzahl von bildlichen Darstellun gen vorgegeben. Sie sollen mit Programmtexten in  Beziehung gesetzt und beurteilt werden (Python Visu al und Python Quiz) oder können als Hilfe abge rufen werden und müssen dann im Hinblick auf ihre B rauchbarkeit mit einer dreistufigen Skala bewer tet werden (Python Puzzle). Teilnehmer von Workshop s mit der PVS äußerten tatsächlich, dass sie in  einigen Visualisierungen eigene Vorstellungen treff end wiederentdeckt hätten. Gleichzeitig räumten  sie ein, dass sie wahrscheinlich selbst nicht in de r Lage gewesen wären, spontan eine derartige Repräsentation zu erfinden. 152     1.4 Beispiele für Tropen in der Informatik  Metaphern  • Bauplan (für Klasse)  • Absturz (für den Übergang eines Prozesses in einen irregulären Zustand)  • Verzweigung (für bedingte Anweisung, if-Anweisung)  • Schleife (für Iteration, foroder while-Anweisung)   • Botschaft (für Aufruf einer Methode eines Objektes)   • Inhalt (für Wert, der einem Variablennamen zugewies en ist)  Metonymien  • Tabelle (für Relation in einer relationalen Datenba nk)  • Zeile (für Tupel einer Relation in einer RDB)  Katachresen  • zurückgeben (eine Funktion gibt das Ergebnis zurück )  • Objekt   • Anweisung  Allegorien  • Divide and conquer (rekursiver Algorithmus, bei dem  ein Objekt aufgeteilt und rekursiv zunächst  die Teile bearbeitet werden)  • Tiefensuche (Algorithmus für das Durchlaufen eines Baumes, bei dem man zuerst in die Tiefe  geht)  • Sweep (Verfahren in der Algorithmischen Geometrie, das von der Vorstellung eines Scheibenwi schers ausgeht, der Regentropfen von der Windschutz scheibe wegwischt)  Vergleiche  • Instanzen einer Klasse sind wie Häuser, die nach de m gleichen Bauplan gebaut worden sind.   1.5 Mikrowelten als einheitliche Domänen für konzep tionelle Meta phern   Vorstellungswelten können detailliert gestaltet und  z.B. als multimediale Software oder mechani sches Spielzeug implementiert werden. Man spricht d ann von Mikrowelten (microworlds). Mikrowel ten sind explorative Lernumgebungen (Schulmeister 2 002). Es sind künstliche Welten mit sehr einfa chen Regeln, in denen die Benutzer sich frei bewege n und eigenaktiv vom Designer (Pädagogen)  „verstecktes“ Wissen entdecken können.   Das wohl bekannteste und historisch erste Beispiel einer computerbasierten Mikrowelt ist die Turt le-Grafik der Programmiersprache Logo (Papert 1973,  1980). Die Firma Logo Computer Systems Inc.  (LCSI) bietet verschiedene Mikrowelten für verschie dene Altergruppen an, die jeweils die LogoTurtle enthalten. Die Turtle (Schildkröte) ist ein virtuelles Wesen, das wenige „angeborene“ Operationen beherrscht (auf der Stelle um einen bestimmten Winkel nach rechts drehen, eine gewisse Anzahl  von Schritten nach vorne gehen). Bei ihrer Bewegung  hinterlässt sie auf dem Untergrund eine Spur, so  dass man durch Steuern der Turtle Bilder malen kann . Weitere Aktionsmöglichkeiten kann sie durch  Kombination bereits beherrschter Operationen lernen . Insofern kann man das Steuern und Trainieren  der Schildkröte als Metapher für prozedurales Progr ammieren bezeichnen.   Ist die Turtle eine Metapher, wie es gelegentlich u nterstellt wird (z.B. Clements & Samara 1997)?  Sie ist primär ein künstliches Wesen, das für sich selbst steht. Zwar könnte man sie aus Sicht der Informatik grob als Metapher für ein Objekt im Sinne der Objektorientierten Programmierung bezeich153     nen, also eine abstrakte Entität, die sich in einem  Zustand befindet und Methoden beherrscht 26 . Aus  Sicht der Kinder, die mit Logo arbeiten, ist dieser  Aspekt jedoch weitgehend irrelevant.   Die Turtle ist aber eine geschlossene Gestalt, die man sich gut vorstellen kann. Ihre Bewegungs möglichkeiten (gehen und drehen) und das Zeichnen v on Linien durch Bewegung eines Stiftes sind  einzelne getrennte Konzepte, die bereits Kindern im  Vorschulalter vertraut sind. Die Kombination  dieser Merkmale zu einer Einheit ist jedoch rein kü nstlich und existiert nicht in der Realität und ers t  recht nicht in der Erfahrungswelt der Kinder, die z um ersten Mal mit ihr arbeiten. Bei genauerem Hin sehen stellt man fest, dass die Komponenten des Kon zeptes „Turtle“ aus unterschiedlichen Erfah rungsbereichen kommen. So können sich echte Schildk röten und andere Tiere (einigermaßen) gerade aus durch den Sand bewegen und dabei eine Spur hint erlassen. Sie können auch die Richtung ändern,  machen dies aber typischerweise kontinuierlich und bewegen sich dabei in Kurven. Drehungen auf der  Stelle beobachtet man eher bei völlig anderen Objek ten, die auf einer Achse angebracht sind (Wasser hahn, Kamera auf einem Stativ, Klavierhocker etc.).  Das Konzept des Schrittes passt eher zu Wesen,  die auf zwei Beinen laufen. Bei einem Vierfüßer – w ie einer echten Schildkröte – ist der Schritt eines   einzelnen Beins nicht unbedingt mit einer Vorwärtsb ewegung verbunden. Der Schritt selbst ist eine  Metapher für eine diskrete Längeneinheit.   Das Erfolgsgeheimnis der Mikrowelt liegt darin, das s sie ein kohärentes Set von Repräsentationen  für unterschiedliche intuitive Modelle bereitstellt . Jedes für sich könnte auch auf andere Weise reprä  sentiert werden. Aber durch das kohärente Design en tsteht eine künstliche Welt, eine Domäne, in der  man sinnvolle zielgerichtete Aktivitäten ausführen kann. So erlaubt die Turtle-Welt Aktionen, die  innerhalb dieser Welt Sinn machen aber die es in de r Realwelt im Grunde nicht gibt:  Gehe 10 Schritte nach vorne  Drehe dich um 90 ° nach rechts  Setze einen Stift auf den Untergrund  Gehe 20 Schritte nach vorne  ist ein Bewegungsablauf, der in keinem realen Konte xt ausgeführt wird. Innerhalb der Turtle-Welt  ist das jedoch eine sinnvolle zielgerichtete Aktion , die eine bestimmte antizipierbare Wirkung hat.  Diese Möglichkeit des zielgerichteten Handelns ging e verloren, wenn man bei Bewegungsspuren an  Schildkröten im Sand, bei Schritten an eine Wanderu ng und bei Drehbewegungen an einen Wasser hahn denken würde. Beobachtungen haben gezeigt, das s die Logik der Turtle nicht intuitiv ist, sondern  von den Kindern erst gelernt und geübt werden muss (Clements & Samara 1997). Zum Beispiel wird  die Anweisung „drehe nach rechts“ mit „gehe nach re chts“ verwechselt. Manchmal vollziehen die  Kinder einzelne Bewegungsabläufe mit dem eigenen Kö rper nach, um sie sich besser vorstellen zu  können.   Die Turtle ist selbst im Wesentlichen keine Metaphe r. Erst durch die Aktivitäten in der LogoMikrowelt entstehen die konzeptionellen Metaphern i m Sinne Lakoffs, die den Lerneffekt bringen. Im  Falle der Turtle-Grafik sind das vor allem Konzepte  der Geometrie der Ebene (vgl. z.B. Clements und  Samara 1997). Wenn ein Kind eine Folge von Logo-Anw eisungen (oder gar eine Prozedur) schreibt,  die die Turtle ein Rechteck auf den Bildschirm zeic hnen lässt, bringt es damit ein mentales Modell  eines Rechtecks zum Ausdruck. Dieses Modell basiert  auf Bewegung. Ein Rechteck entsteht nämlich,  wenn man x Schritte vorwärts, dann sich um 90° nach  rechts dreht, dann y Schritte vorwärts geht,  dann sich um 90° nach rechts dreht usw. Kritische P unkte sind der Drehwinkel von 90° und die Tatsa che, dass die erste und die dritte sowie die zweite  und vierte Vorwärtsbewegung (also die gegenüber  liegenden Seiten) gleich lang sein müssen. Sonst si eht das Ergebnis nicht wie ein Rechteck aus. (Wenn  man dagegen ein Rechteck mit einem Geodreieck konst ruiert, verwendet man andere Intuitionen. Hier  ist vor allem von Bedeutung, dass gegenüber liegend e Seiten parallel sind.)                                                         26  In manchen Details weicht die Turtle jedoch vom Ob jektkonzept ab. Insbesondere das „Dazulernen“ ist u nty pisch für Objekte im Sinne des OOP. Hier sind Objek te in der Regel Instanzen von Klassen, in denen die  Metho den bereits vollständig beschrieben sind (Balzert 1 999) 154     Als Beispiel einer Mikrowelt, die primär nicht comp uterbasiert ist, sei auf die dynamischen Laby rinthe (DL) von Inge Schwank hingewiesen (Schwank 2 003, 2005). Die Bezeichnung Labyrinth ist  allerdings etwas irreführend, denn es gibt keine We gegabelungen mit Entscheidungsfreiheit und man  kann man sich nicht verlaufen. Im Gegenteil: Es ist  sogar ein wichtiges Strukturmerkmal, dass der  Weg von Start zum Ziel determiniert ist. In einem D L werden verschiedene informatische Intuitionen  verwendet.     Abb. 67: Dynamisches Labyrinth (Schwank 2005), das e ine Subtraktion ( 6-4) repräsentiert. Quelle: www.ikm.uniosnabrueck.de/aktivitaeten/dl/dynamische-labyrinthe .htm  Abb. 67 stellt eine Maschine dar, die von einer grö ßeren Zahl eine kleinere abziehen kann. Ihre Ar beitsweise kann durch folgendes Python-Programm bes chrieben werden:  x = 6  y = 4  while y > 0:      y -= 1      x -= 1  print x  Zuerst stellt der Spieler an den beiden Zählern die  Operanden der Subtraktion ein. Das Display des  oberen Zählers zeigt den Wert des Subtrahenden x un d das Display des unteren Zählers den Subtrak tor. Dann setzt er oder sie einen Stab auf die Star tposition und führt ihn solange – stets in der glei chen  Richtung – durch die Rinne bis das Ziel erreicht is t. Die runden Nuten und Federn der Rinnenbaustei ne sind als Richtungspfeile zu interpretieren. Imme r, wenn der Stab einen Zähler passiert, wird er um  eins herabgesetzt. Die Zähler sind mit einer Weiche  gekoppelt. Sie wird nach links gestellt, wenn der  zugehörige Zähler auf null steht. In diesem Fall du rchläuft der Führungsstab eine Schleife bis y gleic h  null ist und gelangt dann zum Ziel.  Dieses DL repräsentiert eine Reihe von intuitiven M odellen der Informatik. Am augenfälligsten ist  die Bahn, die zusammen mit der Weiche die Intuition  des Kontrollflusses eines Programmlaufs visua lisiert. Die Bahn determiniert, in welcher Reihenfo lge Anweisungen ausgeführt werden.   Das Zähler-Bauteil repräsentiert in Kombination gle ich mehrere intuitive Konzepte. Es stellt eine  Variable dar, deren Wert modulo n inkrementiert ode r dekrementiert werden kann – je nachdem wel ches der beiden Rinnensegmente verwendet wird (link s dekrementieren, rechts inkrementieren). Das  linke Rinnensegment enthält eine Weiche, die den We g nach links führt, wenn der Zähler null anzeigt.  Der Charme des DL liegt darin, dass die mechanische n Bauteile in ihrer Arbeitsweise vollkommen  transparent sind und bis auf den Grund durchschaut werden können. Dagegen enthalten Mikrowelten  in Form multimedialer Software „magische Elemente“,  deren Arbeitsweise versteckt ist. 155     1.6 Prototypische Beispiele  Es gibt Fälle, in denen bereits ein einziges Beispi el zur Repräsentation eines Konzeptes ausreicht.  In site@school, einem Content-Management-System für  Grundschulen, wird in einem einzigen Bei spiel erklärt, wie man einen Kalendereintrag vornim mt. Auf jede abstrakte Erklärung im Sinne einer  Gebrauchsanweisung wird verzichtet.      Abb. 68: Beispiel für die Spezifikation eines Kalend ereintrags bei site@school    Abb. 69: Ansicht des Kalenderblattes nach Spezifikat ion wie im Beispiel aus Abb. 68  Probiert man das Beispiel aus und betrachtet die Wi rkung auf das Kalenderblatt (Monatsübersicht),  wird die Bedeutung offensichtlich. Das Beispiel hat  den Charakter eines Prototyps. Die Abstraktion zu  einer allgemeingültigen Anleitung kann vom Leser vo rgenommen werden. Sie lautet in diesem Fall  etwa folgendermaßen:  Die erste Zahl vor dem Unterstrich repräsentiert de n Tag des Monats. Die anschließende Zeichen kette bis zum Komma ist der Text, der in der Monats übersicht (Kalenderblatt) erscheint, und der dann  folgende Text wird in einer Box sichtbar, wenn man mit der Maus den Cursor auf das Feld im Kalen derblatt bewegt. Dieser Text ist erheblich komplexe r und vermutlich schlechter zu behalten, als das  prototypische Beispiel.  Eine besondere Rolle spielen Beispiele in der Tabel lenkalkulation. Nehmen wir an, wir haben eine  Kalkulationstabelle mit drei Spalten. Die ersten be iden Spalten enthalten irgendwelche Zahlen. Die  dritte Spalte soll in jeder Zeile die Summe der der  beiden links daneben stehenden Zahlen enthalten. 156     Dazu gibt ein geübter Anwender der Tabellenkalkulat ion in die oberste Zelle der Summenspalte eine  Formel ein – in diesem Fall in Zelle C2 die Formel   = A2 + B2.  Diese Formel kopiert sie oder er anschließend in di e anderen Zellen der Summenspalte. In der Kal kulationstabelle erscheint jeweils das Ergebnis der  Rechnung. Mit A2  und B2  werden die Zellen refe riert, die die Summanden enthalten. Der Clou der Ta bellenkalkulation ist nun, dass die Namen A2  und  B2  relative Adressen spezifizieren. Gemeint sind eige ntlich nicht die Zellen mit diesen Namen son dern die beiden Zellen links neben C2 , also der Zelle mit der Formel. Die Bedeutung der Formel ist  eigentlich:  Addiere zum Inhalt der Zelle, die sich in der gleic hen Zeile und zwei Spalten links neben der aktu ellen Zelle befindet, den Inhalt der Zelle, die sic h in der gleichen Zeile und eine Spalte links neben  der  aktuellen Zelle befindet.      Abb. 70: Formel in einer Kalkulationstabelle  Beim Kopieren wird diese abstrakte Version der Form el übertragen und dann in der Zielzelle wie der mit konkreten Referenzen wiedergegeben. In der Zelle C3 erscheint z.B.   = A3 + B3  Der entscheidende Punkt ist, dass ein Anwender die Formel mit relativen Adressen nicht abstrakt,  sondern als Beispiel mit konkreten Zellennamen defi niert. Nun hat man bei jeder Beispielbildung im  üblichen Sinne die Freiheit, aus mehreren (eventuel l unendlich vielen) Konkretisierungsmöglichkeiten  eine auszuwählen. Im Fall der Tabellenkalkulation l iegt die Freiheit allein darin, aus der Menge von  Zellen, in denen eine gleichartige Rechnung ausgefü hrt werden soll, eine einzige für die exemplari sche Formulierung der Formel auszuwählen. In die an deren Zellen wird dann die Formel (in ihrer abs trakten Bedeutung) kopiert.  1.7 Beispiele für ablauforientierte Repräsentatione n  Grafiken, die durch eine rekursive Prozedur erzeugt  worden sind, können selbst als Protokoll des  Programmlaufs interpretiert werden und ein Modell d er Prozedur darstellen. Abb. 71 zeigt die Bild schirmausgabe des folgenden Python-Programms, das T urtle-Funktionen verwendet:  from turtle import *    def baum (n):      if n >1:          forward (n)          left (60)          baum(n/2)           right (120)           baum (n/2)          left (60)    157             backward(n)    baum(100)    Abb. 71: Binärbaum, der durch eine Turtle-Prozedur generiert worden ist  Aus der Grafik kann die Idee der rekursiven Prozedu r „abgelesen“ werden. Der Baum besteht aus  einem Stamm an dessen oberem Ende je ein etwas klei nerer Baum nach schräg links und schräg rechts  abgeht. Die Turtle muss also zuerst den Stamm (Lini e) zeichnen, sich dann z.B. nach links drehen,  einen kleineren Baum zeichnen (rekursiver Aufruf), dann nach rechts drehen wieder einen kleineren  Baum zeichnen (zweiter rekursiver Aufruf) und schli eßlich wieder an den Ausgangspunkt zurückkeh ren. Der Baum ist sozusagen eine „Spur“ der rekursi ven Prozeduraufrufe und dokumentiert die Ar beitsweise des Programms.  1.8 Darstellung intuitiver Modelle in der Python Vi sual Sandbox  1.8.1 Warum Animationen?   Oft ist ein statisches Bild wenig aussagekräftig. B estimmte Features eines Modells werden erst  sichtbar, wenn man das Modell in Aktion sieht. Zum Beispiel darf im Behältermodell für Variablen  ein Behälter nur einen einzigen Zettel mit einer zu sammenhängenden Dateneinheit (z.B. Zahl) enthal ten. Dieser Aspekt kann durch die Abarbeitung zweie r Anweisungen der Form  a = 1  a = 2  sichtbar gemacht werden. Bei der zweiten Zuweisung wird der vorige Inhalt des Behälters zerstört.   Ziel der PVS ist, Detailaspekte intuitiver Vorstell ungen sichtbar zu machen. Ein Problem jeder A nalogie oder Metapher ist, dass nur einige Aspekte auf den Zielbereich („das Gemeinte“) übertragen  werden können und andere nicht. Fehlvorstellungen e ntstehen häufig wenn die Grenze der Anwend barkeit überschritten wird bzw. Einschränkungen nic ht erkannt werden. So ist das Behältermodell nur  unter der Einschränkung brauchbar, dass der Behälte r nur ein Objekt enthalten kann. Reale Behälter  können dagegen können viele Objekte enthalten. Um V orstellungen über die Grenzen besser ausloten  zu können, werden Visualisierungen intuitiver Model le in einem detailreichen Kontext verwendet.   Somit ist eine Animation der PVS in der Regel nicht  die Repräsentation einer Intuition sondern sie  enthält häufig mehrere solche Repräsentationen in e inem relativ kleinen mehr oder weniger abge schlossenen Sinnzusammenhang.   1.8.2 Entfernung und Nähe  Die Animationen der PVS beziehen sich auf Programmt exte. Im Python Puzzle stellen sie die Ar beitsweise des zu erstellenden Programms dar. In Py thon Visual und Python Quiz beziehen sie sich  auf gegebene Programme oder Programmfragmente. 158     Ein äußerliches Merkmal einer Visualisierung in der  PVS ist die Nähe zum Bezugsprogrammtext.  Eine programmnahe Visualisierung enthält viele expl izite Bezüge zum Programmtext. Tab. 25 führt  einige Merkmale auf.  Kriterium nah fern  Daten Die konkreten Daten des Programms  (z.B. Zahlen) tauchen auch in der  Visualisierung auf (z.B. Zettel mit  Zahlen) Daten werden abstrakt dargestellt z.B.  zu sortierende Objekte durch Kästen  oder gegenständliche Objekte  Namen Namen aus dem Programmtextes (z.B.  Variablennamen) werden auch in der  Visualisierung verwendet (z.B. Etiket ten) Namen aus dem Programmtextes tau chen nicht auf  Struktur Die Visualisierung hat die gleiche  Struktur wie das Programm.   Die Visualisierung stellt nur die Kern idee des Programms dar und lässt  unwichtige Details weg.  Tab. 25: Merkmale naher und entfernter Visualisieru ngen von Programmen  Als Maß für die Entfernung verwenden wir in der Dok umentation der Modelle den Anteil an Na men aus dem Bezugsprogramm in Prozent. Zu den Namen  werden Namen von Funktionen (ein schließlich Operatorsymbole), Klassen, Objekten, Va riablen gezählt, nicht aber Schlüsselwörter wie  if , else  oder Literale.  1.8.3 Grafische Elemente der Python Visual Sandbox  Nun sind die Möglichkeiten einen Sachverhalt bildha ft darzustellen praktisch unbegrenzt, weil es  keine allgemeinverbindliche Syntax gibt. Um die Ver ständlichkeit zu verbessern, wurde für die PVS  eine Art Bildersprache entwickelt und die Visualisi erung zu einem großen Teil normiert. Die Animati onen enthalten wieder kehrende grafische Elemente, deren Bedeutung zum Teil aus dem Alltag be kannt ist oder aus dem Zusammenhang erschlossen wer den kann. Einheitliche Formen und Farben  erleichtern das Wiedererkennen. Bei Workshops mit d er PVS erklärten Teilnehmer allerdings, dass sie  etwas Zeit brauchten, um die Bedeutung der Abbildun gen zu verstehen und zu lernen.   Behälter (dreidimensionaler Kasten)  Ein einfacher dreidimensionaler Kasten stellt eine Variable als Behälter dar, die Daten aufnehmen  kann. Inhalt ist meist ein beschrifteter Zettel.   Lange Kästen mit mehreren Fächern repräsentieren Li sten. Manchmal sind die Fächer mit Num mern (0, 1, 2, …) beschriftet (Listenindexe). Sonde rfälle sind Kästen mit einem Fach für einelementi ge Listen, die mit normalen Variablen verwechselt w erden können, sowie Darstellungen leerer Listen.  Eine leere Liste kann durch ein einfaches Brett vis ualisiert werden, auf dessen Schmalseite man blickt   (Kasten mit null Fächern).    Abb. 72: Ein Kasten mit Schild repräsentiert eine Va riable als Behälter für Daten. 159        Abb. 73: Kasten mit mehreren Fächern zur Darstellung  einer Python-Liste  Karten (Zettel)  Auf weißen beweglichen Zetteln werden Daten (Zahlen  oder Zeichenketten) mit schwarzer Schrift  wiedergegeben. Sie bewegen sich manchmal von allein e oder werden durch Greifarme transportiert.     Abb. 74: Beschriftete Zettel repräsentieren Daten  Ovale für Botschaften  Beschriftete Ovale repräsentieren Botschaften, die an Objekte geschickt werden und Aktionen aus lösen. Im Unterschied zu Zetteln enthalten sie zumi ndest die Angabe der Methode, die vom Empfän ger ausgeführt werden soll.      Abb. 75: Bewegliches Oval, das eine Botschaft an das  Objekt bottle repräsentiert  Namenszettel  Namen für Objekte werden gelegentlich durch Klebeze ttel (Zettel mit einem Stück Klebeband) an  die benannten Objekte geheftet. Bei dieser Zuordnun g eines Namens zu einem Objekt fehlt dann kom plett der Behälter. Es kommt aber auch vor, dass ei n Namenszettel an einen Behälter für ein Objekt  geklebt wird. Inkonsistent ist, wenn ein Namenszett el an einem anderen Namenszettel befestigt wird.  Denn ein Name ist kein Objekt.    Abb. 76: Haftzettel als Namen für Objekte  Stecknadeln  Iterationen werden manchmal in der Weise visualisie rt, dass eine Stecknadel von Fach zu Fach ei nes Behälters mit mehreren Fächern fliegt. Die Stec knadel markiert dann das aktuelle Element der 160     Iteration über eine Sequenz. Stecknadeln repräsenti eren also Namen für Objekte. Manchmal hängt an  ihnen ein kleiner Zettel mit einer konkreten Namens bezeichnung (z.B. i oder person ).    Abb. 77: Stecknadeln mit Schildern repräsentieren R eferenzen auf Elemente einer Liste  Zeiger  Graue, transparente sich zu einem Endpunkt verjünge nde Linien, stellen den Bezug zwischen ei nem Namen und dem benannten Objekt her (Zeiger). De r Name befindet sich am dickeren Ende der  Linie. Die Zeiger sind häufig an der Spitze bewegli ch und können zunächst auf ein Objekt und dann  auf ein anderes zeigen. Es stellte sich heraus, das s einige Nutzer der PVS diese Linie zunächst nicht  als Pfeil mit Start und Endpunkt sondern als Linie in dreidimensionaler Darstellung interpretierten.  Das dickere Ende befindet sich im Vordergrund und d as dünnere im Hintergrund.     Abb. 78: Zeiger  Namensschilder  Behälter in den Animationen der PVS tragen meist Na mensschilder. Sie sehen immer gleich aus:  Graue Rechtecke mit abgerundeten Seiten und Bohrlöc hern zum Festschrauben. Sie sind optisch leicht  von Daten (Zetteln) zu unterscheiden. Manchmal bewe gen sich auch Namensschilder. Zum Beispiel  kann an einen Behälter ein zweites Namensschild ang ebracht werden um eine Zuweisung der Form a  = b  zu erklären. Dagegen ist es inkonsistent, wenn ein  Behälter ein Namensschild als Inhalt auf nimmt.    Abb. 79: Namensschild  Bretter  Sequenzen werden häufig durch flache Quader dargest ellt (Bretter). Auf ihrer Oberfläche sind helle  Bereiche aufgetragen, die die Listenelemente visual isieren. In diesen Bereichen befinden sich Zettel  mit Daten oder graue Punkte, von denen ein Zeiger a usgeht.   Greifer, Manipulatoren 161     In manchen Animationen wird die Frage thematisiert,  welche Entitäten in der Maschinerie eines  laufenden Programms eigentlich aktiv sind. Aktivitä t wird durch Greifarme mit Gelenken visualisiert,  die andere Entitäten (meist Zettel mit Daten) beweg en.    Abb. 80: Greifer repräsentieren Aktivität einer Ent ität  Funktionsboxen mit Einund Ausgang  Ein Ein/Ausgabe-orientiertes Modell einer Funktion wird in der PVS durch einen hohlen Pyrami denstumpf mit quadratischem Querschnitt dargestellt , der sich nach unten verjüngt (Funktionsbox).  Die obere (größere) Öffnung ist der Eingang. Sobald  dieses Gerät genügend Daten empfangen hat,  wackelt es ein paar Mal (um interne Aktivität anzud euten) und gibt dann über die untere Öffnung ein  Ergebnis aus. In einigen Fällen (bei rekursiven Fun ktionen) besitzen die Funktionsboxen seitliche  Öffnungen, um die Datenübergabe in internen Funktio nsaufrufen darstellen zu können.       Abb. 81: Darstellung einer Funktion als Box mit Ein gang (oben) und Ausgang (unten).   Blitze  Ereignisse wie die Ausführung einer Operation werde n manchmal durch „Explosionen“ mit einer  Art Blitzerscheinung (heller, sich rasch ausbreiten der und dann wieder verschwindender Lichtfleck)  visualisiert. Der Blitz tritt an einer oder mehrere n Entitäten (meist Zettel) auf und führt zu einer V er änderung. Manchmal sind die Blitze mit dem Namen de r ausgeführten Operation beschriftet. Beispiel:  Zwei Zettel mit Zahlen fliegen aufeinander zu, bis sie sich berühren. Es erscheint ein Blitz mit einem   Pluszeichen. Anschließend sind die beiden Zettel ve rschwunden und statt dessen sieht man einen neu en Zettel mit der Summe der beiden Zahlen.  Weitere grafische Elemente   Nicht alle grafischen Elemente der PVS sind standar disiert. So sind Boxen ein relativ universelles  grafisches Element und werden zur Darstellung unter schiedlicher Arten von Entitäten verwendet. Eine  Box kann einen Konstruktor repräsentieren, der ein Objekt generiert. Boxen stellen manchmal Funkti onen dar, die Werte über „Sensoren“ abtasten und ei n Ergebnis liefern.  Sensoren werden meist durch keilartige sich zu eine r Seite verjüngende Linien (wie Zeiger) darge stellt. Sie tasten Werte ab und blinken manchmal, w enn sie aktiv sind. Gelegentlich werden aber auch  Greifer mit Gelenken und andere Bilder zur Darstell ung von Sensoren verwendet.  Darüber hinaus gibt es eine Reihe naturalistische B ildelemente wie Gummibärchen, Drehscheiben  mit Zahlen, Vasen oder Gesichter.  1.9 Verwendung von Visualisierungen im Informatikun terricht  Im Zeitraum von Oktober 2005 bis zum August 2006 wu rden 3 Lehrerinnen und 17 Lehrer zur  Verwendung von Visualisierungen im Informatikunterr icht befragt. Die befragten Personen hatten im 162     Mittel 7.5 Jahre Unterrichtserfahrung im Fach Infor matik (Standardabweichung 7.44 Jahre, Median  5.5 Jahre). Zehn Personen besaßen eine staatlich ko ntrollierte Zusatzqualifikation (außer Staatsex amen) und neun Personen ein Staatsexamen im Fach In formatik. Eine Person war Autodidakt.  Die folgenden Abbildungen zeigen den Fragebogen.        Abb. 82: Fragebogen zur Verwendung von Visualisierun gen (1)         163     Abb. 83: Fragebogen zur Verwendung von Visualisierun gen (2)        Abb. 84: Fragebogen zur Verwendung von Visualisierun gen (3) 164       n = 20 nie selten gelegentlich  häufig immer Mittelwert  Behälter mit Etikett 17 0 3 2 3 1,20  Kästchen mit variablem Inhalt  4 2 6 3 5 2,15  Wertetabellen 1 2 3 5 9 2,95  Liste als Behälter mit Fächern 15 0 1 2 2 0,80  Zeiger  4 0 5 8 3 2,30  Box mit Einund Ausgang für Funktion 13 1 3 0 3 0,9 5  Aktive Entitäten 6 5 5 1 3 1,50  Bewegliche Zettel für Daten 12 2 4 0 2 0,90  Bewegliche Zettel für Botschaften 19 0 1 0 0 0,10  Haftzettel zur Benennung 13 3 3 1 0 0,60  UML-Klassendiagramme 5 1 4 3 7 2,30  UML-Objektdiagramme 8 0 3 3 6 1,95  UML-Interaktionsdiagramme 16 0 4 0 0 0,40  Nassi-Schneidermann-Diagramme 4 4 7 3 2 1,75  Flussdiagramme 2 6 11 0 1 1,60  Zustandsübergangsdiagramme 13 2 1 2 2 0,90  Tab. 26: Ergebnis der Umfrage zur Verwendung von Vis ualisierungen  2 Ergänzungen zur Verwendung intuitiver Modelle  2.1 Verstehen  2.1.1 Textformen in informatischer Fachliteratur  Die klassische Hermeneutik bezieht sich vor allem a uf die Interpretation theologischer oder philo sophischer Texte. Im Bereich der Informatik haben w ir es vor allem mit Gebrauchstexten zu tun, die  Konzepte technischer Systeme erklären. Ein typische s Beispiel sind Beschreibungen in einer Sprachre ferenz, z.B. die Darstellung der Wirkungsweise eine r Standardfunktion. Form und Abstraktionsgrad  informatischer Texte können sehr unterschiedlich se in.   Nehmen wir als Beispiel verschiedene Darstellungen der Wirkungsweise der Python-Funktion  len() , die wir hier der Einfachheit halber auf Listen ei nschränken.  Definition durch einen erklärenden Text  Die Funktion len()  akzeptiert eine beliebige Liste als Argument und g ibt deren Länge d.h. die  Anzahl der enthaltenen Elemente zurück.   Definition durch Axiome  (4) len([]) == 0  (5) Sei a ein beliebiges Objekt. Dann ist len([a]) == 1 .  (6) Wenn s1  und s2  beliebige Listen sind, dann ist   len(s1+s2) = len(s1) + len(s2) . Dabei ist s1+s2 die Konkatenation der beiden Listen  s1 und s2 .  Definition durch einen Programmtext  def len(s):      if s == []: 165             return 0      else:          return len(s[1:])+1  Definition durch Beispiele  Seien a1, a2, ... beliebige Objekte. Dann gilt  len([]) == 0  len([a1]) == 1  len ([a1, a2]) == 2  len ([a2, a2, a3]) == 3  usw.  Visuelle Darstellung  a0a1a2 an-1... L□ nge = n  2.1.2 Experimente zur Beantwortung erkenntnisgewinn ender Fragen   Verständnisfragen zu einem Text können häufig durch  kleine Experimente am Computer beantwor tet werden. Python unterstützt durch den interaktiv en Modus diese Art der „Erkundung von Bedeu tung“. Zur Illustration folgt eine denkbare Fragese quenz zum Thema Listen:  Textgrundlage: Die Funktion len() liefert die Länge  einer Liste, d.h. die Anzahl der enthaltenen Ele mente.  Frage 1: Ist bei verschachtelten Listen (Listen von  Listen) die Länge die Anzahl der insgesamt vor kommenden Objekte?   Experiment 1.1: Wie groß ist z.B. die Länge der Lis te [[1, 2], [3, 4, 5]] ?  >>> len ([[1, 2], [3, 4, 5]])    2    Experiment 1.2: Wie groß ist z.B. die Länge der Lis te [[]] ? Sie enthält doch eigentlich nichts.  >>> len ([[]])  1  Frage 2: Vergleicht der Operator > die Längen zweier Listen?   Experiment 2:   Ist eine Liste mit drei Elementen immer „größer“ al s eine Liste mit zwei Elementen?  >>> [1, 2, 3] > [4, 2]  False  Frage 3: Wie kann ich zwei Listen hinsichtlich ihre r Länge vergleichen?  Experiment 3: Man könnte die Längenfunktion verwend en.  >>> len([1, 2, 3]) > len ([4, 2])  True  Frage 4: Kann ich bei einem Aufruf der Längenfunkti on auch einen Ausdruck mit der Konkatenation  zweier Listen als Argument übergeben?  Experiment 4:  >>> len ([1, 2] + [3, 4])  4 166     Frage 5: Kann man die Längenfunktion auch zur Analy se von Texten mit regulären Ausdrücken ver wenden?  Experiment 5: Vorkommenshäufigkeit als Länge einer Liste   >>> len (re.findall("[aeiou]", "Die Sonne scheint") )  6    Fragen heißt immer, die im Text mitgeteilten neuen Konzepte mit bereits gelernten Konzepten in  Beziehung zu setzen. Die gefundenen Antworten auf F ragen an den Text können als Grundlage für  intuitive Modelle dienen. Antworten auf selbst gest ellte Fragen sind mit großer subjektiver Gewissheit   verbunden, vor allem dann, wenn sie durch Experimen te gewonnen wurden.  2.2 Das Bemühen um Verstehen bei der Vorbereitung a uf einen Test   Es gibt viele Situationen, in denen selbstgesteuert e Verständnisgewinnung stattfindet. Eine Stan dardsituation im Schulalltag ist die Vorbereitung a uf einen Test. In diesem Abschnitt werden die Er gebnisse einer Befragung von 29 Schülerinnen und Sc hülern eines Informatikkurses der Jahrgangsstu fe 12 diskutiert.   Es geht um folgende Fragen:  • Welche Art von Beispielen wählen Schüler als intuit ive Modelle, um sich ein abstraktes Konzept  zu merken?  • Welche Rolle spielt das praktische Ausprobieren von  Beispielen am Computer?  • Welche Merkmale haben Metaphern, die zur Veranschau lichung eines abstrakten Konzeptes von  Schülern gewählt werden?  Die Schülerinnen und Schüler erhielten ein vierseit iges „Selbstlernmaterial“ zum Thema „reguläre  Ausdrücke“ mit Texten, Animationen und Anregungen z um Ausprobieren am Computer. Für die Be arbeitung hatten sie 90 Minuten Zeit. Wie sie mit d em Material umgingen war ihnen freigestellt. Es  wurde aber deutlich gemacht, dass der Sinn der Übun g eine Vorbereitung auf den nächsten Test sein  sollte.  Zusammen mit dem Selbstlernmaterial bekame n die Schüler einen Fragebogen, in dem nachge fragt wurde, in welcher Weise sie die in dem Text v orkommenden Beispiele verwendet haben.   Das Lernmaterial zu regulären Ausdrücken enthält fo lgende Komponenten:  • Erklärende Texte wie in einer Sprachreferenz und ei ne Concept Map, in der wichtige Begriffe im  Zusammenhang dargestellt werden. Sie beschreiben da s Wissen, das im Test geprüft werden soll.  • Vollständige Beispiele, die in Gedanken nachvollzog en aber nicht am Computer ausprobiert wer den können. Dazu gehören Beispiele für Sprachen reg ulärer Ausdrücke:  L("a") = {"a"}   • L(".aus") = {"Maus", "Laus", "Haus", ...}   • Vollständige Beispiele, die in Gedanken nachvollzog en und am Computer ausprobiert werden  können. Dazu gehören Aufrufe der Python-Funktion fi ndall() mit verschiedenen Parametern. Der artige Beispiele beschreiben die Semantik sowohl de r Funktion findall() als auch der verwendeten  regulären Ausdrücken.  • Unvollständige Beispiele, die durch Nachdenken oder  eigenes Ausprobieren vervollständigt wer den können. Von dieser Art sind Aufrufe der PythonFunktion findall() mit verschiedenen Argu menten, wobei die zurückgegebenen Werte jedoch nich t verraten werden. Diese kann man sich  selbst überlegen oder durch Ausprobieren im interak tiven Modus des Python-Interpreters heraus finden.   • Animationen, die das zentrale Konzept (z.B. regulär e Ausdrücke) durch unterschiedliche Meta phern veranschaulichen. 167     2.2.1 Auswahl repräsentativer Beispiele  Bezugnehmend auf den Abschnitt über Sprachen regulä rer Ausdrücke im Lernmaterial wurde den  Schülern folgende Frage gestellt:  „Welche der folgenden Beispiele des Arbeitsmaterial s werden Sie sich besonders gut merken, um  in Erinnerung zu behalten, was die Sprache eines re gulären Ausdrucks ist?“  L1  L("a") = {"a"}  L2 L("Haus") = {"Haus"}  L3 L("a.") = {"aa", "ab", "ac", ...}  L4 L(".aus") = {"Haus", "Maus", "Laus", ...}  L5 L("a+") = {"a", "aa", "aaa", ...}  L6 L("Mu+h") = {"Muh", "Muuh", "Muuuh", ...}  L7 L("a*") = {"", "a", "aa", "aaa", ...}  L8 L("0*1") = {"1", "01", "001", "0001", ...}  L9 L("G[lr]as") = {"Glas", "Gras"}  L10  L("Glas|Gras") = {"Glas", "Gras"}  L11 L("In.*") = {"In", "Indianer", "Insel","Intuiti on", ... }  L12 L(".*\d.*") = {"0", "1000 EUR", "456", ... }  L13 L(".*[Bb]all") = {"ball", "Ball", "Handball", . .. }  Analysieren wir zunächst die Beispiele. Sie untersc heiden sich in mehrfacher Hinsicht:   Konkretisierungsgrad.  Unter Konkretisierungsgrad verstehen wir das Ausmaß , in dem Beispiele  Objekte oder sensorisch erfahrbare Situationen die Realität wiedergeben. Manche Beispiele verwen den sowohl im regulären Ausdruck re  als auch bei der Darstellung der Menge L(re), die durch  den regulären Ausdruck definiert wird, sinnvolle Te xte. In den Beispielen L2  und L10  sind (abgese hen von Metazeichen) alle vorkommenden Zeichenkette n sinnvolle Begriffe (Haus, Gras, Glas). Bei  anderen Beispielen ( L4 , L11 , L13 ) sind zumindest die in L(re)  aufgeführten Zeichenketten Wör ter der deutschen Sprache. All diese Beispiele sind  also relativ konkret. In einigen Fällen kommt hinzu, dass das Beispiel so interpretiert werden kann,  dass es eine Situation wiedergibt, die aus dem All  tag bekannt ist. Im Falle von regulären Ausdrücken handelt es sich um Situationen, in denen es um  Sprache geht. So stellt L5  eine Menge von Wörtern dar, die sich aufeinander r eimen. Das „Thema“  von  L8  ist die korrekte Schreibweise der Zahl 1 mit beliebiger Anzahl führender Nullen.   Abstrakten Beispielen dagegen fehlt der Bezug zur R ealwelt. In den Mengen von L3 , L5 , L7  wer den Zeichenketten aufgezählt, ohne dass ein Zusamme nhang zu realen „Spracherlebnissen“ erkennbar  ist.  Definitorischer Charakter.  Einige Beispiele sind quasi Definitionen für Aspekt e der Semantik  regulärer Ausdrücke. L5  und L7  stellen die Wirkungsweise des Plusund Sternopera tors dar. Die  Elemente von L(re)  werden systematisch nach einem bestimmten Verfahre n (Wiederholung des  Zeichens vor dem Operator) aufgezählt. Die Punkte i n den Mengenklammern repräsentierten eine  „Fortsetzung“ und signalisieren, dass die gesamte ( unendliche) Menge nach dem angedeuteten Verfah ren konstruiert werden kann. Das Zeichen a kann auc h als Metabezeichner für einen beliebigen regulä ren Ausdruck interpretiert werden.  In anderen Fällen ist der definitorische Charakter des Beispiels geringer ausgeprägt. In L4  werden  in der Beispielmenge für den Punkt des regulären Au sdrucks ".aus"  irgendwelche Buchstaben ein gesetzt, so dass sich ein sinnvolles Wort ergibt ( "Maus" , "Laus"  usw.) Die Auswahl des Zeichens  geschieht aber nicht systematisch sondern willkürli ch. Die drei Punkte in den Mengenklammern sym bolisieren keine „Fortsetzung“ sondern nur die Auss age, dass die Menge noch weitere Elemente ent hält, die aber aus Platzgründen nicht aufgeführt we rden.  Komplexität.  Als Maß für die Komplexität regulärer Ausdrücke bet rachten wir folgende Merkmale: 168     • Anzahl der vorkommenden Zeichen. "Haus" ist komplexer als "a" .  • Anzahl der vorkommenden Sonderzeichen ( *, +, ., |, [, ], \d, \w).   "G[lr]as"  ist komplexer als "Haus" .  • Verschiedenartigkeit der vorkommenden Sonderzeichen . ".*a.+"  ist komplexer als ".*a.*"    Offensichtlich unterscheiden sich die regulären Aus drücke in den Beispielen hinsichtlich der Kom plexität.   Ergebnisse  Im Mittel entschieden sich die Kursteilnehmer für 4 .7 Beispiele. Am häufigsten (7 Teilnehmer)  wurden vier Beispiele ausgewählt. Zwei Schüler/inne n gaben an, sich alle 13 Beispiele merken zu  wollen. Werfen wir einen Blick auf die Auswahl der „Merkbeispiele“ (Abb. 85).    Abb. 85: Verteilung der gewählten Beispiele für regu läre Ausdrücke und ihre Sprachen (n=29)  Es zeigt sich, dass konkrete Beispiele gegenüber ab strakten Beispielen bevorzugt werden. Die vier  am häufigsten gewählten Merkbeispiele kann man als konkret bezeichnen. Das konkrete Beispiel L4   wurde fast doppelt so häufig gewählt wie das prakti sch strukturgleiche abstrakte Beispiel  L3 . Dabei  ist L3  weniger komplex und hat einen stärkeren definitori schen Charakter. Beispiel L6  weist aller dings die gleiche Häufigkeit auf wie sein abstrakte s Pendant L5 .  Die auffällige Dominanz des letzten Beispiels L(".*[Bb]all") kann eventuell damit zusam menhängen, dass die Animationen (s.u.) genau dieses  Beispiel aufgegriffen haben.  2.2.2 Beispiele ausprobieren – Streben nach Gewissh eit   Bei der Programmierung mit Python werden reguläre A usdrücke als erstes Argument in einem  Aufruf der Funktion findall()  verwendet, um einen Text zu analysieren, der als z weites Argument  übergeben wird. Der Aufruf findall(re, text)  liefert eine Liste mit nicht überlappenden  Teilstücken der Zeichenkette text, die auf den regu lären Ausdruck re passen. Das Material zum Fra gebogen enthielt vier Beispiele für Funktionsaufruf e zusammen mit dem Ergebnis, das die Funktion  findall()  liefert und 11 Beispiele ohne das Ergebnis. Außerd em gab es noch zwei kurze interakti ve Programme, in denen eine Benutzereingabe mit Hil fe von findall()  ausgewertet wurde.  2.2.3 Beispiele für die Verwendung regulärer Ausdrü cke  Vollständige Beispiele für Funktionsaufrufe  F1  >>> findall("u", "Hallo")  [] 169     F2  >>> findall ("ab", "Aber abends habe ich Hunger")  ['ab', 'ab']  F3  >>> findall ("G.as", "Ein Glas liegt im Gras.")  ['Glas', 'Gras']  F4  >>> findall ("[Bb]\w*", "Bring mir bitte eine Birne .")  ['Bring', 'bitte', 'Birne']  Unvollständige Beispiele für Funktionsaufrufe  W1  >>> findall("l", "Hallo")  W2  >>> findall("\d", "Notruf ist 110")  W3  >>> findall(".t", "Er hat Fett an den Fingern")  W4  >>> findall(".. ", "Wo ist mein Kuli?")  W5  >>> findall("", "Hallo")  W6  >>> findall(".+", "Meine Orange")  W7  >>> findall("B.*", "Die Birne ist durchgebrannt!")  W8  >>> findall("\d", "1, 2, 3 und 4")[0]  W9  >>> for i in findall("\d", "1, 2, 3 und 4"):   print i  W10  >>> findall("te", "Er hatte Tee".lower())  W11  >>> len (findall("[l]", "hell"))    Skripte, in denen reguläre Ausdrücke verwendet werd en   A1  eingabe = raw_input ("Noch Tee? ")  if findall("[jJ]", eingabe)!= []:      print "Hier ist der Tee!"  A2  eingabe = raw_input (" :")  while findall ("cu|see you|bye", eingabe) == []:      eingabe = raw_input (" :")      if findall ("cu|see you|bye", eingabe) == []:          print "Aha. Tell me more about it!" 170         else:          print "Good bye"    2.2.4 Ergebnisse  Tab. 27 gibt einen Überblick, in wie vielen Fällen die Beispiele ausprobiert wurden.   Art des ausprobierten Beispiels Mittelwert Std.-Abwe ichung  Funktionsaufruf mit bekanntem Ergebnis   (4 Beispiele) 1.4815 1.76222  Funktionsaufruf mit unbekanntem Ergebnis (11  Beispiele) 7.3704 3.97248  Interaktives Skript (2 Beispiele) .8889 .80064  Selbst ausgedachtes Beispiele 1.0741 1.81714  Insgesamt ausprobiert 10.8148 4.99259  Tab. 27: Anzahlen der ausprobierten Beispiele (n=29 )  Bemerkenswert sind folgende Beobachtungen:  • Etwa zwei Drittel der Funktionsaufrufe mit unbekann tem Ergebnis wurden am Computer auspro biert (und so das Ergebnis gefunden). Dagegen wurde n die interaktiven Skripte in erheblich gerin gerem Ausmaß getestet.   • Mehr als ein Drittel der vollständigen Beispiele (F unktionsaufruf mit bekanntem Ergebnis) wur den ausprobiert.   Offenbar spielte das praktische Ausprobieren eine g roße Rolle beim Bemühen um das sichere Ver stehen regulärer Ausdrücke. Selbst Funktionsaufrufe , deren Ergebnisse bereits bekannt waren, wurden  „nachgespielt“. In diesem Fall war das Bild, das de r Python-Interpreter beim Test lieferte, mit dem  identisch, was im Text des Selbstlernmaterials stan d. Es gab keinerlei zusätzliche Information.   Dieses Verhalten kann man als „Streben nach Gewissh eit“ interpretieren. Subjektive Gewissheit ist  nach Fischbein ein zentrales Merkmal von Intuitione n. Der Test am Computer ist eine echte, Gewiss heit spendende Erfahrung in der Wirklichkeit, vergl eichbar mit einem naturwissenschaftlichen Expe riment. Das Beispiel im Arbeitsblatt dagegen ist nu r ein Medium, das ein bloßes Abbild der Realität  liefert.   In der Untersuchung wurde nicht eruiert, wie die Sc hülerinnen und Schüler beim Ausprobieren der  Beispiele mit unbekanntem Ergebnis ( W1  bis W11 ) vorgingen. Ein sinnvolles Verfahren ist sicherlic h  folgendes: Zuerst versucht man das Ergebnis eines F unktionsaufrufs in Gedanken zu ermitteln, und  dann prüft man durch ein Experiment am Computer nac h, ob man mit der Vermutung richtig liegt. Das  Entwickeln einer Lösung in Gedanken kann als Beispi el einer Textinterpretation gesehen werden.  Denn es geschieht vor dem Hintergrund erklärender T exte zu regulären Ausdrücken und hat das Ziel  das eigene Textverständnis zu prüfen („Habe ich ric htig verstanden, was der Sternoperator bedeu tet?“).   Derartiges „fragendes Experimentieren“ ist etwas an deres als Problemlösen (auf das wir später zu  sprechen kommen). Beim echten Problemlösen steht ei n reales als relevant betrachtetes Problem im  Vordergrund. Welchen Weg man beschreitet, um das Pr oblem zu lösen (z.B. welche Programmierkon zepte man verwendet) ist zu Beginn des Problemlösun gsprozesses völlig offen. Hier jedoch sind die  Aufgabenstellungen der Beispiele von der inhaltlich en Thematik her irrelevant und austauschbar. Ziel  ist, ein Konzept (reguläre Ausdrücke) zu verstehen.  Die Zahlen in Tab. 27 belegen, dass es den Schü lern mehr um das direkte und schnelle Ausprobieren einfacher Funktionsaufrufe ( W1  bis W11 ) mit  regulären Ausdrücken ging (im Mittel wurden 7.37 vo n 11 Beispielen ausgeführt). Die beiden Skripte,  die praxisnahe Anwendungen – also „echte Problemlös ungen“ – darstellten ( A1  und A2 ), wurden nur  in erheblich geringerem Ausmaß getestet (0.89 von 2 ). 171     4,0 3,0 2,0 1,0 0,014 12 10 8 6 4 2 0   Abb. 86: Häufigkeitsverteilung der ausprobierten vo llständigen Beispiele. (n=29)  17,0015,00 13,0012,00 11,0010,00 9,007,00 6,004,00 3,002,00 1,00MissingCount6 5 4 3 2 1 0   Abb. 87: Häufigkeitsverteilung der insgesamt auspro bierten Beispiele (n=29)  Die relativ großen Standardabweichungen und die Häu figkeitsverteilungen der ausprobierten Bei spiele (Abb. 87 und Abb. 87) deuten an, dass man di e Teilnehmer der Befragung grob in zwei Grup pen aufteilen kann: Personen, die sehr viele, und s olche, die nur wenige Beispiele getestet haben. Besonders krass ist dieses Phänomen bei vollständigen  Beispielen ( F1  bis F4 ). Dieses kann man  folgendermaßen erklären. Wer wenig ausprobiert, bes itzt bereits ein sicheres Verständnis der Funkti onsweise regulärer Ausdrücke. Er oder sie kann die Beispiele in Gedanken nachvollziehen und ist sich  sicher, dass das Ergebnis richtig ist. Nachprüfen a m Computer wäre Zeitverschwendung. Nur wer sich  unsicher ist, wem die Verständnis liefernde Intuiti on noch fehlt, sammelt Erfahrung durch Computer experimente.  2.2.5 Verwendung von visuellen Modellen als Versteh enshilfe   Zum Selbstlernmaterial gehörten drei Animationen (F lash-Filme), die Metaphern für reguläre Aus drücke darstellten. Im Begleittext wurden die Schül er aufgefordert, zu jeder Animation in einem Satz  die dahinter steckende Idee zu beschreiben. Damit s ollte eine Elaboration des Materials angeregt wer den. Später sollten die Teilnehmer angeben, welche Animation ihre persönliche Vorstellung von ei nem regulären Ausdruck am besten wiedergibt. Die Ab bildungen Abb. 88 bis Abb. 90 zeigen Screens hots der Flash-Filme.  Die erste Animation visualisiert einen regulären Au sdruck als Sieb, das aus herunterfallenden Kar ten mit Zeichenketten diejenigen herausfiltert, die  auf den regulären Ausdruck passen, also zu L(re)   gehören. Nicht passende Strings gehen durch das Sie b hindurch. Hier wird also allein der Aspekt des  „Herausfilterns“, der Trennung von passenden und un passenden Strings thematisiert. Wie diese Tren nung funktioniert oder funktionieren könnte, wird n icht beschrieben. 172        Abb. 88: Regulärer Ausdruck als Sieb, das bestimmte  Zeichenketten „ausfiltert“  Der zweite Film veranschaulicht einen regulären Aus druck als Maschine, die Zettel mit passenden  Zeichenketten produziert. Hier wird also die formal e Definition der Semantik eines regulären Aus drucks re über seine Sprache L(re)  visualisiert.    Abb. 89: Regulärer Ausdruck als „Produzent“ von Zei chenketten  Die dritte Animation verwendet die Metapher des Sch loss-Schlüssel-Prinzips. Man sieht man „Kar ten“ mit aufgedruckten Zeichenketten, die über den Bildschirm wandern. Jede Karte besitzt an der  Oberkante ein markantes Profil. Es ist der Form der  Buchstaben der Zeichenkette nachgebildet (siehe  Abb. 90). Der reguläre Ausdruck ist durch ein Gegen profil visualisiert, das genau auf die Karten mit  Strings aus L(re)  passt. Ähnlich wie ein Magnetkran holt nun der reg uläre Ausdruck alle passenden  Strings aus dem vorbeiziehen Strom von Karten herau s. Wie bei der ersten Animation (Sieb) wird also  das Konzept der Trennung passender und nicht passen der Strings zusätzlich aber auch das Konzept  des „Passens“ (Schloss-Schlüssel-Prinzip) quasi als  Wirkungsmechanismus veranschaulicht.     Abb. 90: Regulärer Ausdruck als Muster, das auf bes timmte Zeichenketten „passt“   Schüler der Jahrgangsstufe 12 wurden gefragt, welch e der drei Animationen am ehesten ihre Vor stellung von der „Idee“ eines regulären Ausdrucks w iedergibt. Von den 27 Personen, die zu diesem  Punkt Angaben machten, nannten jeweils 12 die erste  (Sieb) und dritte Animation (Magnetkran). Nur  drei Personen fanden, dass die zweite Animation (Wö rter-produzierende Maschine) ihre Vorstellung  am treffendsten wiedergab. 173     Vermutlich haben die Schüler vorzugsweise solche in tuitiven Modelle gewählt, die in ihrer  Vorstellungswelt bereits fest verankert sind. Das P rinzip der Trennung mit einem Sieb dürfte seit dem  Kindergartenalter (Spielen im Sandkasten) vertraut sein (Sand von Kieselsteinen mit einem Sieb tren nen). Auch das Schloss-Schlüssel-Prinzip gehört zum  Alltag: Ein Schlüssel „erkennt“ aufgrund seiner  Form bestimmte Schlösser, zu denen er passt. Ein Le gostein passt nur an bestimmte Stellen eines Le go-Bauwerks, ein Teller passt nur an bestimmte Stel len einer Spülmaschine etc.   Die Vorstellung, dass durch reguläre Ausdrücke eine  (eventuell unendliche) Menge von Zeichen ketten definiert wird (Mengenkonzept), erlaubt eine  elegante Definition der Semantik regulärer Aus drücke. Die zweite Animation ist eine Visualisierun g dieses Modells. Die Produktion einer im Prinzip  unendlichen Vielfalt von Dingen nach einem bestimmt en Muster ist grundsätzlich ein Konzept, das  auch im Alltag vorkommt (Ostereier färben, Mandelas  ausmalen etc.). Dennoch wurde diese Intuition  nur von wenigen Schülern auf reguläre Ausdrücke ang ewendet. Möglicherweise liegt es daran, dass  das Mengenkonzept für Problemlösungen mit regulären  Ausdrücken keine Rolle spielt. Bei prakti schen Anwendungen regulärer Ausdrücke – etwa bei de r Verarbeitung natürlichsprachlicher Eingaben  oder der Analyse von Texten – geht es allein um das  Erkennen von Zeichenketten und nicht um die  Produktion.  2.3 Problemlösen  2.3.1 Fallstudie: Das Iterator-Pattern und seine Im plementierung in Python  Das Iterator-Konzept gehört zu den klassischen 23 D esign-Patterns, die in dem grundlegenden  Werk von Gamma et al. (1995) beschrieben werden. Es  fällt in die Kategorie Verhaltensmuster (beha vioural pattern).   Der Begriff Iteration leitet sich von dem lateinisc hen Wort iter ab, was so viel wie Gang oder  Marsch bedeutet. Dahinter steckt die Metapher, dass  man von vorne nach hinten »durch eine Folge  von Objekten marschiert« und z.B. auf jedes Objekt bestimmte Operationen anwendet.   Ein Iterator ist nun ein Objekt, das die in einem C ontainer enthaltenen Objekte nach und nach her vorholt. Ein Iterator beherrscht allein die Methode  next() , die das nächste Element einer Iteration  über den Container liefert.   Duell (1997) beschreibt einige Alltagsbeispiele für  Iteratoren:  • In einer Arztpraxis entscheidet die Sprechstundenhi lfe der Rezeption, wer der nächste Patient ist,  der vom Arzt behandelt wird. Aus der Art und Weise,  wie die Patienten im Wartezimmer sitzen,  geht die Behandlungsreihenfolge nicht hervor. Die A rzthelferin an der Rezeption ist also ein Itera tor für den Container „Wartezimmer“.  • Ein modernes Autoradio besitzt eine Taste, mit der man zum nächsten Sender springen kann. Der  Benutzer braucht sich keine Gedanken zu machen, auf  welchen Frequenzen die Radiostationen  senden. Dieser Mechanismus ist ein Iterator für die  Menge der Radiosender, die empfangen wer den können.   Die Programmiersprache Python enthält seit der Vers ion 2.2 (2002) eine Implementierung des Ite rator-Patterns. Container-Klassen wie z.B. Sequenze n sind iterierbar. D.h. ihre Klassendefinition enthält eine Methode __iter__() , die zu einem Objekt dieser Klasse ein Iterator-Ob jekt liefert. Dieser  Iterator ist dann an das Container-Objekt gekoppelt  und besitzt als einzige Methode die Methode  next() , die das »nächste Element« liefert, das nach einem  bestimmten Mechanismus ausgewählt  wird Der Iterator merkt sich das „aktuelle Element“  und liefert beim nächsten next() -Aufruf den  Nachfolger, sofern einer existiert. Falls der Conta iner kein weiteres Element enthält, gibt es eine  StopIteration -Ausnahme. Dem Iterator ist es nicht möglich, ein b ereits geliefertes Element des  Containers noch einmal zu referieren. Wenn die Iter ation noch einmal von vorne beginnen soll, muss  ein neues Iterator-Objekt generiert werden. Beispie l:  >>> liste = [1, 'Fisch']   # generiere Container (L iste)  >>> i = iter(liste)        # erzeuge Iterator   >>> i.next()               # naechstes Element der Liste 174     1  >>> i.next()  'Fisch'  >>> i.next()  Traceback (most recent call last):    File "<pyshell#6>", line 1, in ?      i.next()  StopIteration  Es gibt keine explizit spezifizierte Klasse für Ite ratoren. Vielmehr kann das Iterator-Pattern ein  Merkmal einer (Container-)Klasse sein. Eine iterier bare Klasse enthält in ihrer Definition eine »magische« Methode __iter__()  und eine Methode next() . Damit ist die Standardfunktion iter() be fähigt, ein passendes Iteratorobjekt zu generieren (Überladen der Funktion iter()). In der PythonDokumentation (van Rossum, Yee, 2001) spricht man v on einem Iterator-Protokoll , dem alle iterier baren Objekte folgen.  Iteratoren werden (in allen imperativen Programmier sprachen) implizit in Iterationen über Sequen zen (for-Schleifen) verwendet.  In C/ C++ oder Java-Programmen gibt es Anweisungen der Art:  for (i=0, i< 5, i++) {     A nweisungsfolge   }  Hier wird durch den Ausdruck (i=0, i< 5, i++)  eine Folge von Werten definiert, die die  Laufvariable i nacheinander einnimmt. In der Python-Syntax wird ei ne solche Wiederholungsanwei sung folgendermaßen formuliert.  for i in [0, 1, 2, 3, 4]:      Anweisungsfolge  oder   for i in range(5):      Anweisungsfolge   Dabei liefert die Funktion range(n)  eine Liste mit ganzen Zahlen zwischen 0 und einschließlich  4.  Das Konzept des Iterators ist elementarer und abstr akter als das Konzept der Iteration über eine Se quenz in einer Wiederholungsanweisung (for-Schleife ). Denn bei einer Sequenz ist die Reihenfolge  der Elemente sichtbar, beim Iterator nicht. Hier wi rd von der Reihenfolge abstrahiert, sie ist Sache d es  Iterators.   Nun stützt sich das for-Statement bei Python auf It eratoren. Der Unterschied kommt dann zum  Ausdruck, wenn man Iterationen über Container-Objek te durchführt, in denen die Reihenfolge der  enthaltenen Elemente irrelevant und unsichtbar ist.  Dazu gehören bei Python Abbildungen (mappings)  wie z.B. Dictionaries. In einem Dictionary werden S chlüsseln Werte zugeordnet. Der Zugriff auf einen  Wert erfolgt wie in folgendem Beispiel über den zuh örigen Schlüssel:  >>> dict = {'Sonne':'sun', 'Mond':'moon'}  >>> dict['Sonne']  'sun'  Die Reihenfolge der Schlüssel-Wert-Paare in einem D ictionary ist irrelevant. Angenommen wir  wollen in einer Iteration sämtliche Werte eines Dic tionaries ausgeben. Bei dieser Aufgabenstellung ist   die Reihenfolge, mit der die Einträge des Dictionar ys bearbeitet werden, völlig unerheblich. Hauptsa che es werden tatsächlich alle  Elemente erfasst. Nun haben wir zwei Möglichkeiten :   • Iteration über die Liste aller Schlüssel. Diese Lis te wird von der Methode keys()  geliefert.  Technisch verwendet das Python-Laufzeitsystem dann den Iterator des Listen objektes, das die  Schlüssel enthält. 175     • Iteration mit Hilfe des Iterators des Dictionary-Ob jektes. Hier wird also keine Liste (oder sonstige  Sequenz) verwendet.   Im folgenden Skript-Beispiel werden die beiden Mögl ichkeiten realisiert:  dict = {'Sonne':'sun', 'Mond':'moon', 'Erde':'earth '}  for key in dict.keys():  # Iteration ueber Liste       print dict[key]    for key in dict:         # Iteration ueber Dictiona ry      print dict[key]  Das Iterator-Pattern hat folgende Vorteile (vgl. va n Rossum, Yee, 2001):  • Kürzere und besser lesbare Programmtexte. Auf inter mediäre Listen, die eigens für die Iteration  erstellt werden (z.B. mit der keys() -Methode bei Dictionaries), kann verzichtet werden.   • Bessere Performanz. Durch die Verwendung des abstra kteren Iterators werden überflüssige Verar beitungsprozesse vermieden. Es wird sozusagen nur d as notwendigste getan. Wenn eine Iteration  (wie im letzten Beispiel) von einer vorgegebenen Se quenz losgelöst wird, kann der Iterator selbst  eine Reihenfolge unter dem Gesichtspunkt optimaler Rechenzeit wählen. Die Python-Liste ist ein  sehr »kostenintensiver« Datentyp. Sie ist keine lin eare Liste im üblichen Sinne sondern erlaubt di rekten Zugriff auf einzelne Elemente über ihren Ind ex. Diese Möglichkeit wird bei Iterationen  nicht genutzt und muss aber dennoch (mit Performanz verlusten) »bezahlt« werden.  Fraglich ist, ob die Verwendung des Iterators an St elle einer Liste mit einem Verlust an Anschu lichkeit bzw. Intuitivität verbunden ist. Eine Pyth on-Liste kann man sich z.B. als lange Kiste mit vie  len Fächern vorstellen. Jedes Fach ist mit dem Inde x des dort enthaltenen Elementes beschriftet. Ein  Container-Objekt mit Iterator (ohne offenkundige Re ihenfolge der Elemente) kann man nicht so ohne  weiteres visualisieren. Man müsste ja die enthalten en Elemente in irgendeiner Weise darstellen, ohne  dass die Darstellung eine bestimmte Reihenfolge sug geriert. Nun ist es natürlich legitim, als Modell   eine listenähnliche Darstellung zu verwenden. Nur m uss man sich dann im Klaren sein, dass die Rei henfolge der Elemente der Modell-Liste kein Merkmal  des modellierten Original-Konzeptes ist.  2.4 Kontrolle  2.4.1 Intuitive Modelle und Testen  Inwiefern werden beim Testen eines Programms intuit ive Modelle über dessen Arbeitsweise ver wendet? Wir beschränken unsere Überlegungen auf das  Testen kleiner Systemkomponenten, wie z.B.  einzelne Funktionen. Als Beispiel betrachten wir da s Testen der Quicksort-Funktion. Man testet eine  Funktion, indem man sie mit verschiedenen Argumente n aufruft und das erwartete Ergebnis mit dem  tatsächlich gelieferten vergleicht.   Im Software-Engineering unterscheidet man zwischen Black-Box-Testen und White-Box-Testen.  Im ersten Fall ist der Programmtext unbekannt und m an orientiert sich bei der Auswahl von Testdaten  allein an den Anforderungen, die an das Programm ge stellt werden (Sommerville 1997, S. 463 ff.).   Beim White-Box-Testen (oder strukturellem Testen) b ezieht man Wissen über das Programm bei  der Auswahl der Test-Werte mit ein. Das heißt verwe ndet spezifische Modelle zur Arbeitsweise des  Programms. Dies sind Kontrollmodelle im engeren Sin ne. Die Vereinfachung liegt darin, dass man die  nur die Arbeitsweise bei bestimmten Eingabewerten b etrachtet. Nehmen wir als Beispiel folgende  Quicksort-Implementierung:  def qsort (liste):      s = liste[:]             # s ist eine Kopie von  liste      if s == []:          return s      else:          x = s[0]          s.remove(x)          # entferne x aus der L iste s 176             s1 = []          s2 = []          for i in s:              if i <= x:                  s1.append(i)              else:                  s2.append(i)          return ergebnis   Dann treffen folgende Überlegungen zu:  1 Bei trivialen Eingabesequenzen (leere Liste) gibt  die Quicksort-Funktion die Eingabesequenz als  Ergebnis zurück.  2 Komplexere Eingabesequenzen werden  in drei Stück e s1 , [x] , s2  zerlegt. Die mittlere Se quenz [x] enthält immer genau ein Element. Dabei kann man meh rere Fälle unterscheiden:   2.1  s1  und s2  sind leer  2.2  s1  ist leer und s2  enthält mindestens ein Element,  2.3  s2  ist leer und s1  enthält mindestens ein Element,  2.4  s1  und s2  enthalten mindestens ein Element.  Weitere Fälle gibt es nicht. Sofern man dieses Mode ll im Sinn hat, wird man bei der Wahl von  Testsequenzen darauf achten, dass alle diese Situat ionen durchlaufen werden. Das ist die Idee des  Pfadtestens (siehe folgender Abschnitt). Das folgen de Set von Testaufrufen ist so konstruiert, dass  beim ersten Durchlauf  einer dieser fünf Fälle eintritt.  print qsort ([])              # 1  print qsort ([1])             # 2.1  print qsort ([1, 3])          # 2.2   print qsort ([3, 1])          # 2.3    print qsort ([2, 3, 1])       # 2.4     2.4.2 Paradigmatische Modelle beim Testen  Beim Testen eines Programms können Intuitionen eine  Rolle spielen, die man zur Gruppe der pa radigmatischen Modelle zählen kann. Denn sie beschr eiben eigentlich eine allgemeine Strategie des  Testens. Sie sind damit keine vereinfachten Modelle  des zu testenden Programms, bieten aber ein  Grundlage zur systematischen Konstruktion von Tests zenarios (hier: Eingabesequenzen).   Modell der vollständigen Induktion  Nach dem Modell der vollständigen Induktion arbeite t die Funktion f unter folgenden Bedingungen  korrekt.   • Sie liefert für die kleinsten denkbaren Eingabeobje kte (hier: leere und einelementige Sequenzen)  korrekte Ergebnisse.   • Sei f(s)  ein Funktionsaufruf mit Argument s. Unter der Voraussetzung, dass die in der Funkti onsdefinition spezifizierten rekursiven Funktionsau frufe f(s1), ... , f(sn)  korrekte Er gebnisse liefern, liefert auch f(s)  ein richtiges Ergebnis.  Wenn man sich an diesem Modell orientiert, wird man  die Testargumente  folgendermaßen wählen:  Man testet die Trivialfälle, die zum sofortigen Abb ruch der Rekursion führen. Dann testet man mit  Argumenten, die zu verschiedenen rekursiven Aufrufe n mit einfacheren Argumenten führen. Im Un terschied zum Modell des „Härtetests“ (s.u.) reicht  es, möglichst einfache nicht triviale Testargument e  zu verwenden. Man schließt dann induktiv, dass es a uch mit komplexeren Werten klappt.   Pfadtesten  Beim so genannten Pfadtesten (path testing) achtet man bei den Testläufen darauf, dass sämtliche  unabhängigen Ausführungspfade durchlaufen werden. D as bedeutet insbesondere, dass jede im Pro177     grammtext vorkommende Anweisung in der Summe der Te stläufe mindestens einmal ausgeführt wird  (Sommerville 1997, S.471 ff).  Ausgangspunkt für das Pfadtesten ist ein Programmfl ussgraph. Das ist ein gerichteter Graph, der  ein auf vorkommende Kontrollstrukturen reduziertes Modell des zu testenden Programms darstellt.  Darin werden if-else-Anweisungen als Verzweigungen und whileund for-Anweisungen als Schleifen  dargestellt. Zwei unabhängige Ausführungspfade sind  Pfade vom Startzum Zielknoten, die sich zu mindest in einer Kante unterscheiden. Abb. 91zeigt einen Programmflussgraphen für die QuicksortFunktion.    Abb. 91: Programmflussgraph für die Quicksort-Funkt ion    Belastungstest  Das intuitive Modell des Belastungstests basiert au f folgender Annahme: Wenn die Funktion  „schwierige Argumente“ (z.B. lange Sequenzen mit gr oßen Zufallszahlen) korrekt verarbeitet, dann  wird sie erst recht für „einfache Argumente“ (kurze  Sequenzen mit kleineren Zahlen) richtige Ergeb nisse liefern.   Belastungstests zur Überprüfung korrekter Arbeitswe ise sind aus dem Alltag bekannt:  • Beim Test eines Autos beobachtet man sein Fahrverha lten auf einer sehr holprigen Teststrecke  („Marterstrecke“). Wenn es unter diesen Bedingungen  verkehrstauglich ist – so schließt man -,  dann ist es das erst recht auf einer normalen Straß e.  • Ein Hersteller von Haushaltsgeräten ließ einen Tell er mit einer kompletten Sahnetorte von einer  Spülmaschine reinigen. Wenn die Spülmaschine diesen  Teller in einem Spülgang säubern kann –  so das Verkaufsargument -, dann erst recht normal v erschmutztes Geschirr.  Zu beachten ist, dass wir hier über Korrektheitstes ts reden. Im Software-Engineering gibt es auch  das Konzept des Stress-Tests (Sommerville 1997, S. 457 f). Stress-Tests werden nicht mit Einzelkom ponenten sondern mit ganzen Systemen durchgeführt, die für eine bestimmte Belastung ausgelegt sind  (Anzahl der Transaktionen pro Sekunde, Anzahl anges chlossener Rechner etc.). Beim Stress-Testen  wird das System mit Absicht überlastet, um zu prüfe n, wie das System mit der Situation fertig wird  (Zusammenbruch oder kontrollierte Handhabung der Sy stemüberlastung).  Bewährung in Extremsituationen  Wenn die Funktion für  „extreme“ Eingabewerte (Gren zfälle, Extremsituationen) das richtige Er gebnis liefert, wird sie auch bei normalen Argument en, die man sich als „Mischung“ aus Extremsitua tionen vorstellen kann,  korrekt arbeiten. Zum Beis piel bei einer Sortierfunktion könnten folgende  Listen als Extreme verstanden werden:  []      leere Liste  [1]      einelementige Liste 178     [1, 2, 3]    aufsteigend sortierte Liste  [3, 2, 1]    absteigend sortierte Liste  [1, 2, 1, 2, 1, 2]  Liste mit Duplikaten  [1, 1, 1]    Liste mit lauter gleichen Elementen  Im Unterschied zu den Belastungstests sind die hier  gemeinten Extremsituationen nicht unbedingt  „schwierig“. So ist eine leere Liste als Testargume nt für eine Sortierfunktion ein sehr einfacher Ex tremfall.  3 Materialien zu den empirischen Untersuchungen  3.1 Visualisierungsübungen  Im Juni 2006 habe ich mit Schülerinnen und Schülern  der Holzkamp Gesamtschule Witten Visuali sierungsübungen zu Java-Programmen durchgeführt. Da bei wurden die folgenden beiden Aufgaben blätter verwendet.  3.1.1 Aufgabenblatt 1  Informatik visuell  "Ein Bild sagt mehr als tausend  Worte"  public class Soccer  {   private String[] team = {"Asamoah", "Ballack", "Kl ose", "Lahm",  "Schneider"};   public Soccer()   {   }     public void print (int n)   // Druckt die ersten n Teammitglieder aus   {    for(int i=0; i<n; i++)    {        System.out.println(team[i]);    }   }     public String get (String anfang)   // Gibt vollständigen Namen zurück   {       String name = "unbekannt";       String spieler;       for(int i=0; i<team.length; i++)       {           spieler = team[i];           if (spieler.startsWith(anfang))           {               name = spieler;           }       }       return name;       }  } 179     Übung 1  Zeichnen Sie ein Storyboard aus mehreren Bildern, d as die Ausführung folgender Anweisungen  veranschaulicht (Sie können zu jeder Anweisung mehr ere Bilder zeichnen):  wmteam = new Soccer();             // 1  wmteam.print(3)                    // 2     spieler = wmteam.get("Ba")         // 3  Übung 2  Die Klasse Soccer soll um eine Methode getBin()  erweitert werden, die den gleichen Effekt hat  wie die Methode get() . Allerdings soll der Spielername nach dem Verfahre n „binäre Suche“ ermit telt werden. Zeichnen Sie ein Storyboard, das die A usführung dieser neuen Methode bei folgendem  Aufruf veranschaulicht:  spieler = wmteam.getBin("La")  Storyboard  Ein Storyboard besteht aus mehreren Bildern. Sie kö nnen Symbole wie Pfeile, Linien, Rechtecke  etc. oder auch Abbildungen von konkreten Dingen aus  dem Alltag verwenden. Haben Sie Mut zur  Fantasie! Jedes Bild ist mit einem kurzen Kommentar  versehen, in dem erklärt wird, was passiert.      3.1.2 Aufgabenblatt 2  Informatik visuell (2)  Übung 3  Die Java-Klasse Math  enthält statische Methoden, die aufgerufen werden können, ohne zuvor ein  Objekt der Klasse zu instanzieren. Der Aufruf Math.sqrt()  liefert die Quadratwurzel einer Zahl  als Gleitpunktzahl vom Typ double. Beispiel:  Math.sqrt(2)  liefert 1.41421356237   Zeichnen Sie ein Storyboard aus mehreren Bildern, d as die Ausführung folgender Anweisungen  veranschaulicht:  double a;  a = Math.sqrt(2);  Übung 4  Objekte der Klasse String beherrschen die Methode toUpperCase() . Der Aufruf  a.toUpperCase()  liefert einen String aus Großbuchstaben.  Beispiel: Wenn w die Zeichenkette "klein"  darstellt, dann gibt w.toUpperCase()  die Zei chenkette  "KLEIN" zurück. Das Objekt w selbst bleibt dabei unverändert.  Zeichnen Sie ein Storyboard aus mehreren Bildern, d as die Ausführung folgender Anweisungen  veranschaulicht: 180     String a;  String b;  a = "informatik";  b = a.toUpperCase();     181     3.2 Aufbau der Datenbank der PVS  3.2.1 Allgemeine Tabellen  person  Die Relation person  enthält die Daten eines Spielers der Python Visual  Sandbox.  Attribut Datentyp Erläuterung  id varchar(20) Primärschlüssel. Er enthält das Pseudonym (Nickname ), das Personen bei der  Registrierung angeben. Damit wird sie oder er währen d einer Session angeredet  und es erscheint (falls gewünscht) in Highscore-Lis ten. Außerdem können Leh rer/innen Nicknames verwenden, wenn sie Gruppen def inieren. (Die Passwörter  dagegen bleiben geheim.)  age smallint Alter des Spielers bzw. der Spielerin  gender char(1) Geschlecht (f: weiblich, m: männlich )  country varchar(10) Kürzel für das Land, aus dem de r Spieler kommt.  pass varchar(20) Passwort, das ein Spieler bei der Registrierung ange geben hat. Es muss vor dem  Start eines Spiels eingegeben werden. Leider kann e s sein, dass bei einer Regist rierung ein Spieler per Zufall auf ein bereits verw endetes Passwort stößt. Er oder  sie muss dann ein neues wählen, weiß dann aber das bereits verwendete Passwort.  Dieses wird zu Gunsten einer möglichst einfachen Ha ndhabung in Kauf genom men. (Wenn das Passwort kein Schlüssel wäre, müsste n bei jedem Spielstart  Name und Passwort eingegeben werden.)  date int(20) Datum der Registrierung als Anzahl der Sekunden seit  Beginn der "Epoche"  (1.1.1970).  profession varchar(15) Beruf des Spielers:  "school": Schüler, "university": Student, "teacher" : Lehrer, "professor": Professor,  "professional": Software-Entwickler oder ähnliches,   "other": anderer Beruf.  progtime smallint Stundenzahl pro Woche, die man pr ogrammiert.   Tab. 28: Tabelle person  person_group   Die Tabelle realisiert die n:m-Beziehung zwischen d en Relationen person und group.  Attribut Datentyp Erläuterung  person_id varchar(20) Fremdschlüssel mit ID der Per son  group_id varchar(20) Fremdschlüssel mit ID der Gruppe, in der sich die P erson befindet . Das Feld bleibt  leer, falls die Person zu keiner Gruppe gehört.   Tab. 29: Tabelle person_group   pvsgroup   Die Tabelle modelliert eine Gruppen (z.B. Informati kkurse) mit Gruppenleiter (Coach). Sie enthält  gruppenbezogene Daten, mit denen die Validität von Daten der Tabelle person  (in gewissen Gren zen) geprüft werden kann.  Attribut Datentyp Erläuterung  id varchar(20) ID der Gruppe  date int(20) Datum der Registrierung als Anzahl der Sekunden seit  Beginn der "Epoche"  (1.1.1970).  coach_id varchar(20) ID des Coaches  minage smallint Mindestalter 182     maxage smallint Höchstalter  experience smallint Tage Programmiererfahrung mit P ython  lessons smallint Unterrichtsstunden pro Woche   female smallint Anzahl weiblicher Personen  country varchar(10) Kürzel für das Land  institution varchar(10) Art der Institution (univer sity, school, other)  description varchar(250) Kurzbeschreibung der Grupp e  townsize smallint Größe der Stadt, in der die Grupp e unterrichtet wird.  Einwohnerzahl bis 10 000, 50 000, 100 000, 500 000,  1000 000, mehr)  Tab. 30: Tabelle pvsgroup   Die Daten einer Gruppe werden in einem Online-Frage bogen erfasst, den der Gruppenleiter (coach)  ausfüllen muss.   coach  Die Tabelle enthält die Daten von Gruppenleitern (z .B. Informatiklehrer/in). Ein Coach kann eine  Gruppe definieren und die PVS-Sitzungen seiner Grup pen auswerten.  Attribut Datentyp Erläuterung  id varchar(20) ID des Coaches (Loginname)  pw varchar(20) Passwort  date int(20) Datum der Registrierung als Anzahl der Sekunden seit  Beginn der "Epoche"  (1.1.1970).  address varchar(250) Adresse der Institution, für d ie die Person arbeitet  email varchar(100) E-Mail-Adresse  institution varchar(20) Art der Institution (university, school, software c ompany, other), an der die Person  hauptsächlich beschäftigt ist  Tab. 31: Tabelle coach  model  Die Tabelle enthält Beschreibungen der verwendeten Modelle (Animationen).  Attribut Datentyp Erläuterung  id varchar(20) Primärschlüssel. Er enthält den Flas h-Symbolnamen der Animation.  description varchar(200) Verbale Kurzbeschreibung d es Modells  complexity smallint Anzahl der enthaltenen Elemente  (grafische Elemente, Textelemente)  time smallint Dauer der Animation in Sekunden (0 be i statischen Modellen)  names smallint Prozent der Namen eines zugehörigen Programmtextes,  die in diesem Modell zur  Bezeichnung analoger Modellteile verwendet werden. D ies ist nur bei korrekten  Animationen, die Programmtext illustrieren, relevan t. Der Wert dieses Attributs ist  ein Maß für die Abstraktheit eines Modells. 0 bedeu tet: sehr abstrakt, 100 bedeutet  sehr konkret.   a1 smallint Zusätzliches Attribut für etwaige späte re Verwendung  a2 smallint Zusätzliches Attribut für etwaige späte re Verwendung  a3 smallint Zusätzliches Attribut für etwaige späte re Verwendung  Tab. 32: Tabelle model 183     Regeln für die Bestimmung der Komplexität (complexi ty)  Gezählt werden alle Elemente des Modells, die eine in sich zusammenhängende Entität darstellen.  Meist ist es ein einzelner Gegenstand (z.B. Zettel oder Box), manchmal auch mehrere Gegenstände,  die irgendwie zusammengehören und sich nicht separa t bewegen können (z.B. alle Zettel in einer Kis te, wenn die Zettel sich nicht bewegen oder verände rn, oder Blitze, wenn diese immer gleichzeitig  auftreten). In der Regel wird ein solches Element i n einer eigenen Ebene im Flash-Film dargestellt.  Programmtexte und das animierte Highlighting von Pr ogrammzeilen werden nicht zum Modell ge zählt, wenn sie sich außerhalb des Modellszenariums  befinden.  Regeln für die Bestimmung der Abstraktheit (names)  Wir beschränken uns auf Namen. Literale, die im Pro grammtext vorkommen (Zahlen, Zeichenket ten) werden nicht gezählt. (Sie sind oft nur exempl arisch). Zu den Namen zählen alle Namen für Ob jekte: Variablennamen, Namen von Funktionen, Operat oren, Klassennamen, alle vorkommenden Na men für Listenelemente (z.B. s[i] ). Letztere werden separat gezählt. D.h. wenn die N amen s und i  schon gezählt worden sind, wird s[i]  als weiterer Name gewertet.  Nicht gezählt werden def, = (Zuweisung),  return , for , if , while .  3.2.2 Tabellen für Python Visual  protocol_pv  Die Tabelle modelliert Sessions mit einer Python Visual -Applikation ohne das Befragungsergebnis.  Jedes Tupel enthält zwischen drei und fünf Modellen , die bewertet werden können. Es können ein  oder zwei Spieler teilnehmen.    Attribut Datentyp Erläuterung  id varchar(20) Primärschlüssel. Er enthält einen String folgenden Formats:   <Nickname des ersten Spielers><Zeitstempel>  game varchar(20) Fremdschlüssel. Enthält id der Spi elbeschreibung.  time int(20) Zeitstempel (Sekunden seit Beginn der E poche).  time1 smallint Betrachtungszeit erstes Modell   time2 smallint Betrachtungszeit zweites Modell   time3 smallint Betrachtungszeit drittes Modell (0, w enn Modell nicht existiert)  time4 smallint Betrachtungszeit viertes Modell (0, w enn Modell nicht existiert)  time5 smallint Betrachtungszeit fünftes Modell (0, w enn Modell nicht existiert)  Tab. 33: Tabelle protocol_pv   description_pv  Die Relation enthält Beschreibungen von „Python Vis ual“-Applikationen.  Attribut Datentyp Erläuterung  id varchar(20) Primärschlüssel. Er enthält den Name n des Spiels (Dateiname ohne Extension).  description varchar(200) Kurzbeschreibung  models smallint Anzahl der enthaltenen Modelle.  mod1 varchar(20) Fremdschlüssel. Er enthält die id des 1. Modells  mod2 varchar(20) Fremdschlüssel. Er enthält die id des 2. Modells  mod3 varchar(20) Fremdschlüssel. Er enthält die id des 3. Modells  mod4 varchar(20) Fremdschlüssel. Er enthält die id des 4. Modells, f alls es existiert. Sonst leerer  String.  mod5 varchar(20) Fremdschlüssel. Er enthält die id des 1. Modells 184     question1 varchar(100) Erste Frage (ev. Kurzform)  question2 varchar(100) Zweite Frage (ev. Kurzform)  question3 varchar(100) Dritte Frage (ev. Kurzform)  a1 varchar(10) Weiteres Attribut (Reserve)  Tab. 34: Tabelle description_pv   protocol_pv_person  Die Relation verbindet die Relationen protocol_pv  und person . Wenn ein Spieler eine Ap plikation vom Typ „Python Visual“ bearbeitet, wird hier ein Tupel eingetragen. Damit wird die Teil nahme einer Person an einer Sitzung – also eine Bez iehung zwischen einer person -Entität und einer  protocol_pv -Entität – modelliert.  Attribut Datentyp Erläuterung  id_person varchar(20) Fremdschlüssel mit id des Spi elers.  id_protocol_pv varchar(20) Fremdschlüssel mit id de r Session.  a1 smallint Antwort Frage 1 (Modellnummer)  a2 smallint Antwort Frage 2 (Modellnummer)  a3 smallint Antwort Frage 3 (Modellnummer)  Tab. 35: Tabelle protocol_pv_person   3.2.3 Tabellen für Python Puzzle  description_pp  Die Relation enthält Beschreibungen von „Python Puz zle“-Applikationen.  Attribut Datentyp Erläuterung  id varchar(20) Primärschlüssel. Er enthält den Name n des Spiels (Dateiname ohne Extension).  description varchar(200) Kurzbeschreibung  time smallint Maximale Gesamtzeit des Spiels  a1 varchar(10) Weiteres Attribut (Reserve)  Tab. 36: Tabelle description_pp   protocol_pp  Die Tabelle modelliert Sessions mit einer "Python P uzzle"-Applikation. An einer Session können  ein oder zwei Spieler teilnehmen. Die Tabelle besch reibt allgemeine – nicht aufgabenbezogene Daten  der Session.   Attribut Datentyp Erläuterung  id varchar(20) Primärschlüssel. Er enthält einen String folgenden Formats:   <id des Spiels><Zufallszahl>  game varchar(20) Fremdschlüssel. Enthält id der Spi elbeschreibung.  time int(20) Zeitstempel (Sekunden seit Beginn der E poche) für Spielstart  gametime smallint tatsächliche Spieldauer in Sekund en  points smallint erreichte Punkte (-200, falls Sessi on abgebrochen wurde)  players smallint Anzahl der Spieler (1 oder 2)  player1 varchar(20) Fremdschlüssel. Enthält id des ersten Spielers.  player2 varchar(20) Fremdschlüssel. Enthält id des zweiten Spielers (falls vorhanden)  Tab. 37: Tabelle protocol_pp  185     Zu Beginn einer Session wird ein Datensatz mit Punk tzahl -200 angelegt. Am Ende der Session  wird die Punktzahl aktualisiert.  protocol_pp_task  Jede Zeile der Tabelle beschreibt einen erfolgreich en Python Puzzle Testlauf eines selbst zusam mengesetzten Programms.  Attribut Datentyp Erläuterung  id varchar(20) Primärschlüssel  task smallint Nummer der Aufgabe  session_id varchar(20) Fremdschlüssel. Enthält ID der Session (protocol_pp ). Darin sind die  z.B.Spieler-IDs enthalten.  runs smallint Anzahl der Testlaeufe  time smallint Zeitbedarf zur Lösung der Aufgabe  points smallint erreichte Punktzahl  c1 ... c10 varchar(60) Programmzeile des korrekten Programmtextes  e1 ... e8 varchar(60) Falsche Programmzeile, die be i einem Testlauf einmal verwendet worden ist  Tab. 38: Tabelle protocol_pp_task   Ein Tupel der Relation wird angelegt, sobald ein Te stlauf erfolgreich war. Die Attribute c1, ..., c10  enthalten Programmzeilen, die zur korrekten Lösung gehören und zwar in der Reihenfolge, in der sie  verwendet worden sind (c1 enthält die erste verwend ete Programmzeile). Somit kann man später z.B.  feststellen, an welchen Aspekt der Problemlösung di e Teilnehmer zuerst oder zuletzt dachten.   Die Attribute e1, ..., e8 enthalten falsche verwend ete Programmzeilen, also Chips, die irgendwann  einmal während der Lösung der Aufgabe in das Editor feld gezogen worden sind – wiederum in der  Reihenfolge der Verwendung. Es kann sein, dass eine n Spieler einen falschen Chip „anfasst“, ihm der  Fehler aber sofort bewusst wurde und er den Chip wi eder heraus zieht, so dass diese Anweisung nie mals bei einem Testlauf zum Einsatz kam und deshalb  auch nicht registriert wurde.  protocol_pp_model  Die Relation modelliert die Bewertung der betrachte ten Modelle auf den Hinweiskarten. Sie reali siert eine Beziehung zwischen Modell (model) und Pr otokoll eines erfolgreichen Python-PuzzleTestlaufs (protocol_pp_task).  Attribut Datentyp Erläuterung  model_id varchar(20) Fremdschlüssel. Er enthält einen String mit ID des Modells (model) auf der Cue  Card  task_id varchar(20) Fremdschlüssel. Enthält ID des Protokolls zu einer Aufgabenlösung (proto col_pp)  players smallint Anzahl der Spieler, die hinter der  Bewertung stehen  score smallint Bewertung des Modells  time smallint Betrachtungszeit des Modells  Tab. 39: Tabelle protocol_pp_model  186     3.2.4 Tabellen für Python Quiz  description_pq  Beschreibung einer Python Quiz Applikation.   Attribut Datentyp Erläuterung  id varchar(20) Primärschlüssel. Er enthält den Name n des Spiels (Dateiname ohne Extension).  description varchar(200) Kurzbeschreibung auf Engli sch  a1 varchar(10) Weiteres Attribut (Reserve)  Tab. 40: Tabelle description_pq   description_pq_task  Jede Zeile der Tabelle beschreibt eine Aufgabe eine s Python Quiz. Eine Aufgabe besteht grund sätzlich darin, für verschiedene Modelle zu entsche iden ob sie zu einem Programmfragment passen.  Die Korrektheit eines Modells (zum Programmtext pas send, akzeptabel oder nicht passend) wird nicht  modelliert.   Attribut Datentyp Erläuterung  id varchar(20) Primärschlüssel (wird zusammengesetzt aus ID des Sp iels und Nummer der  Aufgabe)  task smallint Nummer der Aufgabe  game varchar(20) Fremdschlüssel. Enthält ID des Spiels (description_ pq), zu dem diese Aufgabe  gehört.  program varchar(250) Programmtext oder verbale Beschreibung des Programmt extes, der durch Mo delle interpretiert wird.  Tab. 41: Tabelle description_pq   protocol_pq  Die Tabelle modelliert eine Session mit einer "Pyth on Quiz"-Applikation. Es können ein oder zwei  Spieler teilnehmen. Die Tabelle beschreibt allgemei ne – nicht aufgabenbezogene Daten der Session.  Diese Tabelle wird automatisch von den Dienstprogra mmen pq_service.py  und  pq_startservice  aktualisiert.  Attribut Datentyp Erläuterung  id varchar(20) Primärschlüssel. Er enthält einen String folgenden Formats:   <id des Spiels><Zufallszahl>  game varchar(20) Fremdschlüssel. Enthält id der Spi elbeschreibung.  time int(20) Zeitstempel (Sekunden seit Beginn der E poche) für Spielstart  gametime smallint tatsächliche Spieldauer in Sekund en  points smallint erreichte Punkte (-200, falls Sessi on abgebrochen wurde)  players smallint Anzahl der Spieler (1 oder 2)  player1 varchar(20) Fremdschlüssel. Enthält id des ersten Spielers.  player2 varchar(20) Fremdschlüssel. Enthält id des zweiten Spielers (falls vorhanden)  Tab. 42: Tabelle protocol_pq   Zu Beginn einer Session wird ein Datensatz angelegt . Am Ende der Session wird die Punktzahl ak tualisiert. 187     protocol_pq_model  Die Relation modelliert die Bewertung eines Modells  in einem Quiz. Diese Tabelle wird automa tisch vom Dienstprogramm pq_service.py  aktualisiert.    Attribut Datentyp Erläuterung  protocol_id varchar(20) Fremdschlüssel. Enthält ID des Protokolls zu einer Quiz-Session (protocol_pq).    task_id varchar(20) Fremdschlüssel. Enthält ID der Beschreibung einer Aufgabe  players smallint Anzahl der Spieler, die hinter der  Bewertung stehen  model varchar(20) ID des bewerteten Modells (in der  Reihenfolge der Bewertung)  fits smallint Bewertung des Modells (0: unpassend, 1 : passend)  time smallint Betrachtungszeit des Modells  points smallint gesetzte Punktzahl  Tab. 43: Tabelle protocol_pq_model   3.3 Gruppen einrichten  Lehrerinnen und Lehrern bietet die PVS die Möglichk eit, Schülergruppen zu definieren. Dazu ge ben sie auf einer interaktiven Webseite verschieden e Daten zu ihrer Gruppe an (Schule, minimales und  maximales Alter der Gruppenmitglieder, Größe der St adt, Programmiererfahrung ...) und zählen die  Loginnamen (Pseudonyme) der Mitglieder ihrer Gruppe  auf. Sie haben dann die Möglichkeit, statisti sche Daten zu ihrer Gruppe abzufragen. Zum Beispiel  kann man die statistische Verteilung der Ant worten zu einem Python Visual–Spiel als Aufhänger f ür ein Unterrichtsgespräch verwenden.     Abb. 92: Dialogseite für Coaches   3.4 Auswertung der Datenbank  Mit verschiedenen über das Internet zugänglichen We rkzeugen kann die Datenbank der PVS aus gewertet werden. Die Datenbank auch Daten von Teste ntitäten, die keine realen Personen repräsentie ren und in keiner Auswertung berücksichtigt werden.  Der Name einer Testentität beginnt mit der Zei chenkette test_ . Testentitäten sind notwendig, um die Funktionalit ät der PVS zu prüfen und etwaige  Fehler zu entdecken.  Die Auswertungswerkzeuge sind entweder öffentlich ( Usage), involvierten Spielern zugänglich  (z.B. Activity Reports, Highscore-Listen) oder komp lett abgeschirmt (wissenschaftliche Auswertung). 188     3.4.1 Auswertungsmöglichkeiten für Spieler und Zusc hauer  Völlig öffentlich ist der Usage-Bericht, der von de r Startseite der PVS aus abgerufen werden kann.  Er enthält globale Angaben über Anzahl der Sitzunge n bei den verschiedenen Applikationstypen, Be ruf und mittleres Alter der Teilnehmer und ähnliche s.  Jeder Spieler der PVS kann (nach Eingabe seines Pas swortes) einen Activity Report abrufen. Er  enthält die bisher erreichte Gesamtpunktzahl und ei ne Auflistung aller Sitzungen.    Abb. 93: Actvity Report der Testentität test_hans   Jeder Spieler kann nach Eingabe seines Passwortes d ie Highscore-Listen aller Spiele abrufen, die  sie oder er selbst durchgeführt hat. Jede Hisghscor e-Liste zeigt Punktzahl, Nicknames der Spieler,  Herkunftsland und Datum der besten zehn Sessions ei nes Spiels. Dies motiviert dazu, an vielen Spie len teilzunehmen und bei einem Spiel ein möglichst gutes Resultat zu erzielen.    Abb. 94: Auszug aus einem Highscore-Bericht  Für Python-Visual-Applikationen gibt es ein Auswert ungswerkzeug, das die Antworten der Teil nehmer einer Gruppe wiedergibt (siehe Abb. 95). Es ist nur dem Coach einer Gruppe zugänglich. Der 189     Coach wählt eine Gruppe und eine Applikation aus un d fordert einen Evaluationsbericht an. Dieser  enthält zu jedem Modell der Aufgabe einen Screensho t, die zeitliche Länge und die durchschnittliche  Betrachtungszeit. Aus letzterer kann man schließen,  wie ernsthaft sich die Spieler mit dem jeweiligen  Modell auseinandergesetzt haben. Außerdem werden di e Fragen (in Kurzform) und zu jeder Frage der  Anteil der Spieler, die das jeweilige Modell zu die ser Frage ausgewählt haben, dargestellt. In  Workshops mit der PVS kann eine solche Evaluation a ls Anlass für eine Plenumsdiskussion über die  dargestellten Modelle verwendet werden. Typischerwe ise werden in einer solchen Diskussion folgen de Punkte angesprochen:  • Warum wird Modell X von den meisten abgelehnt? Inwi efern ist dieses Modell X ungeeignet oder  gar falsch?  • Die meisten würden Modell X oder Modell Y verwenden , um die Arbeitsweise des Programms zu  erklären. Vergleichen wir diese beiden Modelle. Was  unterscheidet sie? Was spricht jeweils für  das eine oder das andere Modell?  • Warum können sich die meisten an Modell X besonders  gut erinnern? Warum kann man sich be stimmte Modelle besonders gut merken?  In einer solchen Diskussion reflektieren die Teilne hmer die Verwendung intuitiver Modell zur Er klärung und zum Verstehen von Programmtexten.    Abb. 95: Gruppenbezogene Auswertung eines Python-Vis uals (Ausschnitt)  3.4.2 Wissenschaftliche Auswertung  Zur statistischen Auswertung enthält die PVS für je den Typ (Python Visual, Python Puzzle und  Python Quiz) ein Auswertungswerkzeug, das über das Internet erreichbar ist (Anklicken einer ver steckten Stelle auf der PVS-Startseite und Eingabe eines Passworts). Diese Programme liefern jeweils  eine Webseite mit statistischen Daten, die folgende rmaßen aufgebaut ist.   Für jede der folgenden Personengruppen gibt es getr ennt einen statistischen Überblick:  • Alle Teilnehmer.  • Alle Teilnehmer, die an einem Workshop mit der PVS teilgenommen haben.  • Schülerinnen und Schüler, die an einem Workshop tei lgenommen haben. 190     Art und Darstellung der Daten zu der jeweiligen Per sonengruppe hängen von der PVS-Applikation  ab. Bei Python Visuals werden Betrachtungszeiten fü r die Modelle und die Verteilung der Antworten  auf die Fragen wiedergegeben. Besonders komplex ist  die Auswertung der Python Puzzles. Hier wird  die mittlere Reihenfolge, in der richtige und falsc he Puzzlestücke verwendet worden sind, dargestellt.   Außerdem enthält das Auswertungsdokument Angaben üb er die Benutzung und Bewertung der visuel len Modelle, die als Hilfe angeboten worden sind. D ie Auswertung der Python-Quiz-Sitzungen kon zentriert sich auf Entscheidungszeiten, Bewertung u nd Konfidenz der Bewertung von visuellen  Modellen.  Jedes Spiel der PVS kann von einer oder zwei Person en gespielt werden. Damit wird die übliche  Ausstattung von Rechnerräumen an Schulen berücksich tigt, die häufig nur einen Computer für zwei  Personen vorsehen. In der statistischen Auswertung wird deshalb zwischen subjektiven und objektiven  Sitzungen unterschieden. Wenn zwei Personen zusamme n spielen, entstehen eine objektive und zwei  subjektive Sitzungen. Allerdings wurden auf den Wor kshops mit der PVS in fast 90% der Fälle Ein zelsitzungen beobachtet.  Nun kann ja eine Person eine PVS-Applikation belieb ig oft spielen. In den Statistiken werden in  der Regel nur die ersten (subjektiven) Sitzungen au sgewertet. Insbesondere Python-QuizApplikationen wurden jedoch von einigen Schülerinne n und Schülern gerne mehrfach gespielt. Des halb gibt es im Auswertungsdokument für Python Quiz  für diese „Vielspieler“ zusätzliche Statistiken,  die die Beobachtungen der ersten drei subjektiven S itzungen darstellen.  3.5 Python Visual  3.5.1 Dokumentation einer Session  Die Merkmale eines Python Visuals (IDs der Modelle,  Fragen zu den Modellen etc.) sind in der  Datenbank gespeichert (Relation description_pv). In  der Relation protocol_pv werden für jede Session  die Betrachtungszeiten der einzelnen Modelle festge halten. In der Relation protocol_pv_person   sind für jeden Spieler die Antworten niedergelegt.   Am Ende einer Session wird ein XML-Paket an das Ser vice-Programm pv_service.py  ge schickt. Es ist folgendermaßen aufgebaut:  <answers>  <person a3="zahl3" a2="zahl2" a1="zahl1" id="Nickna me des Spielers" />  …  <times z5="zeit5" z4=" zeit4" z3=" zeit3" z2="40" z 1="28" z0="21" />  <game game="pv_mirror" />  </answers>  Beispiel:  <answers>  <person a3="1" a2="2" a1="2" id="test_juli" />  <times z5="0" z4="22" z3="34" z2="40" z1="28" z0="2 1" />  <game game="pv_mirror" />  </answers>  3.5.2 Auszug aus der automatisch erstellten Auswert ung  Der folgende gekürzte Auszug aus dem Ergebnis der a utomatischen Auswertung liefert einen  statistischen Überblick über die Antworten von Schü lerinnen und Schülern, die an einem Workshop  mit der PVS teilgenommen haben. Betrachtet werden n ur die ersten  Sitzungen mit dem der jeweiligen  Python-Visual-Applikation. Es hat also keine Auswir kungen auf das Ergebnis, wenn Teilnehmer ein  Spiel mehrfach durchführen. 191     Regular expressions  Some general information about the players of this category, who played the game at least once .   Professions 18 highschool students, 0 university students,   0 teachers, 0 professors and 0 others   Gender 5 female and 13 male persons  Hours a week spent on programming (standard de viation) 1.67 hours (1.78)  Roughly estimated experience in Python program ming(standard deviation) 201.17 days (166.35)  Age (standard deviation) 19.17 years (4.85)  Population of the town, where the workshop took  place Less than 100 000: 1, 100 000 to 500 000: 13, more  than 500 000: 4  Country Germany: 18 other country: 0     Model 1     Description: Visualizes the effect of a regular  expression by a sieve.     Duration: 8 seconds   Concreteness: 0 percent  Average watchtime (standard deviation): 23.78  seconds (12.60)        This model was evaluated in 18 first subjective ses sions. The following table shows the results.  Question votes percentage  ... would you use to explain 8  44.44  ... do you remember best 7 38.89  ... when you imagine the use of a regular expressio n 9 50.00   192     Model 2     Description: Visualizes the effect of a regular  expression by a machine which generates  matching strings.     Duration: 12 seconds   Concreteness: 0 percent  Average watchtime (standard deviation): 22.61  seconds (14.65)        This model was evaluated in 18 first subjective ses sions. The following table shows the results.  Question votes percentage  ... would you use to explain 1  5.56  ... do you remember best 3 16.67  ... when you imagine the use of a regular expressio n 2 11.11    Model 3     Description: Crane that selects maching string  applying key-lock principle.     Duration: 21 seconds   Concreteness: 0 percent  Average watchtime (standard deviation): 23.39  seconds (9.20)        This model was evaluated in 18 first subjective ses sions. The following table shows the results.  Question votes percentage  ... would you use to explain 9  50.00  ... do you remember best 8 44.44  ... when you imagine the use of a regular expressio n 7 38.89   193     Straight selection  Some general information about the players of this category, who played the game at least once .   Professions 15 highschool students, 0 university students,   0 teachers, 0 professors and 0 others   Gender 3 female and 12 male persons  Hours a week spent on programming (standard de viation) 2.33 hours (2.44)  Roughly estimated experience in Python program ming(standard deviation) 223.00 days (164.75)  Age (standard deviation) 18.20 years (1.21)  Population of the town, where the workshop took  place Less than 100 000: 4, 100 000 to 500 000: 8, more  than 500 000: 3  Country Germany: 15 other country: 0     Model 1     Description: Sorting by straight selection  and exchanging places, actual elements of  the list are marked by lifting.     Duration: 23 seconds   Concreteness: 9 percent  Average watchtime (standard deviation):  40.27 seconds (21.86)        This model was evaluated in 15 first subjective ses sions. The following table shows the results.  Question votes percentage  ... would you use to explain 9  60.00  ... do you remember best 5 33.33  ...when you imagine the execution of the script 7 4 6.67   194     Model 2     Description: Sorting by straight selection and  exchanging places, actual elements of the list  are marked by post-its i, j .     Duration: 21 seconds   Concreteness: 27 percent  Average watchtime (standard deviation): 31.53  seconds (43.67)        This model was evaluated in 15 first subjective ses sions. The following table shows the results.  Question votes percentage  ... would you use to explain 4  26.67  ... do you remember best 7 46.67  ...when you imagine the execution of the script 4 2 6.67    Model 3     Description: Sorting by straight selection and  exchanging places. The actual elements of the  list are marked by arrows named i and j.     Duration: 21 seconds   Concreteness: 27 percent  Average watchtime (standard deviation): 18.40  seconds (15.44)        This model was evaluated in 15 first subjective ses sions. The following table shows the results.    Question votes percentage  ... would you use to explain 0  0.00  ... do you remember best 2 13.33  ...when you imagine the execution of the script 3 2 0.00   195     Model 4     Description: Sorting by straight selection and  exchanging places. Indices of the actual ele ments of the list are represented by frames on  strips with numbers.     Duration: 21 seconds   Concreteness: 27 percent  Average watchtime (standard deviation): 43.47  seconds (110.10)        This model was evaluated in 15 first subjective ses sions. The following table shows the results.    Question votes percentage  ... would you use to explain 2  13.33  ... do you remember best 1 6.67  ...when you imagine the execution of the script 1 6 .67   196     Changing lists  Some general information about the players of this category, who played the game at least once .   Professions 70 highschool students, 0 university students,   0 teachers, 0 professors and 0 others   Gender 14 female and 56 male persons  Hours a week spent on programming (standard de viation) 3.94 hours (5.91)  Roughly estimated experience in Python program ming(standard deviation) 184.67 days (160.58)  Age (standard deviation) 17.01 years (1.59)  Population of the town, where the workshop took  place Less than 100 000: 21, 100 000 to 500 000: 20,  more than 500 000: 29  Country Germany: 70 other country: 0     Model 1     Description: Wrong visualization of changing  lists. Lists are represented by boxes with cards.  Assign statement is interpreted as copy. Only  one copy of the list is changed.     Duration: 6 seconds   Concreteness: 66 percent  Average watchtime (standard deviation): 24.47  seconds (14.09)        This model was evaluated in 70 first subjective ses sions. The following table shows the results.    Question votes percentage  ... would you use to explain 15  21.43  ... do you remember best 12 17.14  ...when you imagine the execution of the script 10 14.29   197     Model 2     Description: Model of changing lists. Lists are  represented by boxes with cards. Assign state ment is interpreted as copy (ghost). Both copies  of the list are changed.     Duration: 7 seconds   Concreteness: 66 percent  Average watchtime (standard deviation): 14.99  seconds (10.07)        This model was evaluated in 70 first subjective ses sions. The following table shows the results.    Question votes percentage  ... would you use to explain 40  57.14  ... do you remember best 23 32.86  ...when you imagine the execution of the script 34 48.57    Model 3     Description: Model of changing lists. Lists are  represented by boxes with cards. Assign state ment is interpreted as adding a second label to  the box.     Duration: 5 seconds   Concreteness: 66 percent  Average watchtime (standard deviation): 14.46  seconds (15.19)        This model was evaluated in 70 first subjective ses sions. The following table shows the results.    Question votes percentage  ... would you use to explain 11  15.71  ... do you remember best 16 22.86  ...when you imagine the execution of the script 17 24.29   198     Model 4     Description: Model of changing lists. Lists are  represented by boards and arrows. Assign  statement is interpreted as adding a new arrow.     Duration: 7 seconds   Concreteness: 66 percent  Average watchtime (standard deviation): 25.39  seconds (84.62)        This model was evaluated in 70 first subjective ses sions. The following table shows the results.    Question votes percentage  ... would you use to explain 4  5.71  ... do you remember best 19 27.14  ...when you imagine the execution of the script 9 1 2.86    Recursive function that mirrors a string.  Some general information about the players of this category, who played the game at least once .   Professions 22 highschool students, 0 university students,   0 teachers, 0 professors and 0 others   Gender 2 female and 20 male persons  Hours a week spent on programming (standard de viation) 4.23 hours (3.22)  Roughly estimated experience in Python program ming(standard deviation) 83.59 days (110.33)  Age (standard deviation) 17.36 years (1.43)  Population of the town, where the workshop took  place Less than 100 000: 10, 100 000 to 500 000: 7, more  than 500 000: 5  Country Germany: 22 other country: 0    199     Model 1     Description: Function call is represented by an  active element with grabs. Only one recursive  call is visualized.     Duration: 22 seconds   Concreteness: 14 percent  Average watchtime (standard deviation): 31.86  seconds (16.29)        This model was evaluated in 22 first subjective ses sions. The following table shows the results.    Question votes percentage  ... would you use to explain 3  13.64  ... represents the idea of a recursive function 2 9 .09  ... most difficult to follow 8 36.36    Model 2     Description: Function call is represented by an  active element with grabs. Full recursion depth.     Duration: 38 seconds   Concreteness: 14 percent  Average watchtime (standard deviation): 83.91  seconds (159.39)     200       This model was evaluated in 22 first subjective ses sions. The following table shows the results.    Question votes percentage  ... would you use to explain 7  31.82  ... represents the idea of a recursive function 7 3 1.82  ... most difficult to follow 4 18.18    Model 3     Description: Recursive function calls are repre sented by nested boxes. Full recursion depth.     Duration: 31 seconds   Concreteness: 28 percent  Average watchtime (standard deviation): 32.32  seconds (17.90)        This model was evaluated in 22 first subjective ses sions. The following table shows the results.    Question votes percentage  ... would you use to explain 8  36.36  ... represents the idea of a recursive function 10 45.45  ... most difficult to follow 4 18.18    Model 4     Description: Recursive function calls are repre sented by nested boxes. Only one recursive call  is shown.     Duration: 17 seconds   Concreteness: 28 percent  Average watchtime (standard deviation): 76.73  seconds (152.29)     201       This model was evaluated in 22 first subjective ses sions. The following table shows the results.    Question votes percentage  ... would you use to explain 4  18.18  ... represents the idea of a recursive function 3 1 3.64  ... most difficult to follow 6 27.27    Analogies for iterations  Some general information about the players of this category, who played the game at least once .   Professions 66 highschool students, 0 university students,   0 teachers, 0 professors and 0 others   Gender 12 female and 54 male persons  Hours a week spent on programming (standard de viation) 5.09 hours (6.25)  Roughly estimated experience in Python program ming(standard deviation) 130.23 days (158.32)  Age (standard deviation) 16.64 years (1.28)  Population of the town, where the workshop took  place Less than 100 000: 20, 100 000 to 500 000: 6, more  than 500 000: 40  Country Germany: 52 other country: 14     Model 1     Description: Iteration over a list visualized  as box. Elements are taken from the box one  by one     Duration: 16 seconds   Concreteness: 0 percent  Average watchtime (standard deviation):  29.32 seconds (11.54)        This model was evaluated in 66 first subjective ses sions. The following table shows the results.    Question votes percentage  ... would you use to explain 6  9.09  ... do you remember best 8 12.12  ... when you imagine the execution of the script 9 13.64   202     Model 2    Description: Iteration over a list visualized as  box. Elements are copied and the copies are  processed.     Duration: 16 seconds   Concreteness: 0 percent  Average watchtime (standard deviation): 22.92  seconds (9.30)        This model was evaluated in 66 first subjective ses sions. The following table shows the results.    Question votes percentage  ... would you use to explain 13  19.70  ... do you remember best 8 12.12  ... when you imagine the execution of the script 7 10.61    Model 3     Description: Iteration over a list visualized as  box. Elements are copied and the copies are  processed. Additionally a red point marks the  actual element.     Duration: 16 seconds   Concreteness: 0 percent  Average watchtime (standard deviation): 22.47  seconds (14.53)        This model was evaluated in 66 first subjective ses sions. The following table shows the results.    Question votes percentage  ... would you use to explain 30  45.45  ... do you remember best 20 30.30  ... when you imagine the execution of the script 30  45.45   203     Model 4     Description: Iteration over a list visualized as a  column of numbers on a piece of paper. Num bers are copied and processed. Copied numbers  are marked.     Duration: 10 seconds   Concreteness: 0 percent  Average watchtime (standard deviation): 17.55  seconds (13.92)        This model was evaluated in 66 first subjective ses sions. The following table shows the results.    Question votes percentage  ... would you use to explain 17  25.76  ... do you remember best 30 45.45  ... when you imagine the execution of the script 20  30.30    Multilists  Some general information about the players of this category, who played the game at least once .   Professions 6 highschool students, 0 university students,   0 teachers, 0 professors and 0 others   Gender 1 female and 5 male persons  Hours a week spent on programming (standard de viation) 3.00 hours (2.10)  Roughly estimated experience in Python program ming(standard deviation) 240.50 days (121.79)  Age (standard deviation) 16.33 years (0.82)  Population of the town, where the workshop took  place Less than 100 000: 0, 100 000 to 500 000: 1, more  than 500 000: 5  Country Germany: 6 other country: 0    204     Model 1     Description: Iteration over a multilist. Ghost  model with several ghosts of one original.  Changes take place at the same time at all  ghosts.     Duration: 11 seconds   Concreteness: 33 percent  Average watchtime (standard deviation): 24.83  seconds (10.72)        This model was evaluated in 6 first subjective sess ions. The following table shows the results.  Question votes percentage  ... would you use to explain? 2  33.33  ... do you remember best? 1 16.67  ... when you imagine the execution? 2 33.33    Model 2     Description: Iteration over a multilist. Ghost  model with several ghosts of one original.  Changes take place at the same time at all  ghosts. Original is highlighted as the origin  of all change.     Duration: 11 seconds   Concreteness: 33 percent  Average watchtime (standard deviation):  28.67 seconds (17.19)        This model was evaluated in 6 first subjective sess ions. The following table shows the results.  Question votes percentage  ... would you use to explain? 0  0.00  ... do you remember best? 2 33.33  ... when you imagine the execution? 1 16.67   205     Model 3     Description: Iteration over a multilist. Mixture  of container and pointer model. Top level ist is  container with pointers to sublists.     Duration: 11 seconds   Concreteness: 33 percent  Average watchtime (standard deviation): 13.17  seconds (11.00)        This model was evaluated in 6 first subjective sess ions. The following table shows the results.  Question votes percentage  ... would you use to explain? 2  33.33  ... do you remember best? 1 16.67  ... when you imagine the execution? 2 33.33    Model 4     Description: Iteration over a multilist.  Consistent pointer model. Top level ist is con tainer with pointers to sublists containing  pointers to numbers.     Duration: 11 seconds   Concreteness: 33 percent  Average watchtime (standard deviation): 24.33  seconds (13.49)        This model was evaluated in 6 first subjective sess ions. The following table shows the results.  Question votes percentage  ... would you use to explain? 2  33.33  ... do you remember best? 2 33.33  ... when you imagine the execution? 1 16.67   206     Recursive computation of factorial  Some general information about the players of this category, who played the game at least once .   Professions 28 highschool students, 0 university students,   0 teachers, 0 professors and 0 others   Gender 5 female and 23 male persons  Hours a week spent on programming (standard de viation) 2.25 hours (2.72)  Roughly estimated experience in Python program ming(standard deviation) 79.29 days (122.83)  Age (standard deviation) 17.39 years (0.74)  Population of the town, where the workshop took  place Less than 100 000: 19, 100 000 to 500 000: 1, more  than 500 000: 8  Country Germany: 28 other country: 0     Model 1     Description: Berechnung Fakultaet, voll staendige Rekursion (bis zum Abbruch),  Execution Frames, white box     Duration: 28 seconds   Concreteness: 80 percent  Average watchtime (standard deviation):  93.25 seconds (42.36)        This model was evaluated in 28 first subjective ses sions. The following table shows the results.    Question votes percentage  ... would you use to explain 11  39.29  ... represents the idea of a recursive function bes t 9 32.14  ... most difficult to follow 1 3.57   207     Model 2     Description: Recursive computation of fac torial. Processes are represented by execu tion frames. Only one recursive call.     Duration: 9 seconds   Concreteness: 80 percent  Average watchtime (standard deviation):  38.61 seconds (25.62)        This model was evaluated in 28 first subjective ses sions. The following table shows the results.    Question votes percentage  ... would you use to explain 5  17.86  ... represents the idea of a recursive function bes t 7 25.00  ... most difficult to follow 10 35.71    Model 3     Description: Recursive computation of fac torial. Record of computation process, func tion calls are replaced by results. Full recur sion depth.     Duration: 23 seconds   Concreteness: 80 percent  Average watchtime (standard deviation):  45.96 seconds (22.78)        This model was evaluated in 28 first subjective ses sions. The following table shows the results.    Question votes percentage  ... would you use to explain 11  39.29  ... represents the idea of a recursive function bes t 10 35.71  ... most difficult to follow 5 17.86   208     Model 4     Description: Recursive computation of fac torial. Record of computation process, func tion calls are replaced by results. Only one  recursive call is visualized.     Duration: 8 seconds   Concreteness: 80 percent  Average watchtime (standard deviation):  22.07 seconds (11.71)        This model was evaluated in 28 first subjective ses sions. The following table shows the results.    Question votes percentage  ... would you use to explain 1  3.57  ... represents the idea of a recursive function bes t 2 7.14  ... most difficult to follow 12 42.86    Fibonacci numbers  Some general information about the players of this category, who played the game at least once .   Professions 19 highschool students, 0 university students,   0 teachers, 0 professors and 0 others   Gender 5 female and 14 male persons  Hours a week spent on programming (standard de viation) 1.58 hours (1.64)  Roughly estimated experience in Python program ming(standard deviation) 59.21 days (111.83)  Age (standard deviation) 17.42 years (0.61)  Population of the town, where the workshop took  place Less than 100 000: 15, 100 000 to 500 000: 0, more  than 500 000: 4  Country Germany: 19 other country: 0    209     Model 1     Description: Recursive function that com putes Fibonacci numbers. Process is repre sented by box with side exit. Full recursion  depth. New boxes are generated serially.     Duration: 23 seconds   Concreteness: 33 percent  Average watchtime (standard deviation):  50.89 seconds (48.68)        This model was evaluated in 19 first subjective ses sions. The following table shows the results.    Question votes percentage  ... would you use to explain 4  21.05  ... represents the idea of a recursive function bes t 8 42.11  ... most difficult to follow 4 21.05    Model 2     Description: Recursive function that computes  Fibonacci numbers. Process is represented by  only one box with side exit. Full recursion  depth. On top of the box (entrance) values are  accumulated.     Duration: 21 seconds   Concreteness: 33 percent  Average watchtime (standard deviation): 28.84  seconds (14.42)        This model was evaluated in 19 first subjective ses sions. The following table shows the results.    Question votes percentage  ... would you use to explain 3  15.79  ... represents the idea of a recursive function bes t 2 10.53  ... most difficult to follow 6 31.58   210     Model 3     Description: Recursive function that com putes Fibonacci numbers. Processes are  represented by four static boxes with side  exit, which are already visible at the begin ning. Full recursion depth.     Duration: 19 seconds   Concreteness: 33 percent  Average watchtime (standard deviation):  33.11 seconds (19.78)        This model was evaluated in 19 first subjective ses sions. The following table shows the results.    Question votes percentage  ... would you use to explain 3  15.79  ... represents the idea of a recursive function bes t 3 15.79  ... most difficult to follow 7 36.84    Model 4     Description: Recursive function that com putes Fibonacci numbers. Processes are  represented by five dynamic boxes with side  exit. Parallel execution of function calls.  Full recursion depth.     Duration: 15 seconds   Concreteness: 33 percent  Average watchtime (standard deviation):  21.79 seconds (19.68)        This model was evaluated in 19 first subjective ses sions. The following table shows the results.    Question votes percentage  ... would you use to explain 9  47.37  ... represents the idea of a recursive function bes t 6 31.58  ... most difficult to follow 2 10.53   211     What happens, when a function returns something?  Some general information about the players of this category, who played the game at least once .   Professions 16 highschool students, 0 university students,   0 teachers, 0 professors and 0 others   Gender 1 female and 15 male persons  Hours a week spent on programming (standard de viation) 6.50 hours (10.84)  Roughly estimated experience in Python program ming(standard deviation) 92.06 days (124.06)  Age (standard deviation) 16.38 years (1.41)  Population of the town, where the workshop took  place Less than 100 000: 8, 100 000 to 500 000: 3, more  than 500 000: 5  Country Germany: 16 other country: 0     Model 1     Description: Function is represented by a box,  searches for the minimal element of a list and  puts a pin named with an x at this element     Duration: 8 seconds   Concreteness: 75 percent  Average watchtime (standard deviation): 36.00  seconds (23.34)        This model was evaluated in 16 first subjective ses sions. The following table shows the results.    Question votes percentage  ... would you use to explain 3  18.75  ... do you remember best 2 12.50  ... explains worst 10 62.50   212     Model 2     Description: Function is represented by a box,  searches for the minimal element of a list and  returns a copy of this element (ghost). Assign ment x=10 is done twice with x and the origi nal in the list.     Duration: 10 seconds   Concreteness: 75 percent  Average watchtime (standard deviation): 24.44  seconds (12.21)        This model was evaluated in 16 first subjective ses sions. The following table shows the results.    Question votes percentage  ... would you use to explain 4  25.00  ... do you remember best 5 31.25  ... explains worst 2 12.50    Model 3     Description: Function is represented by a box.  Before the function appears, the name x and a  pointer enters the scene. The funnction finds  the minimal element of a list and moves the  pointer x to it.     Duration: 12 seconds   Concreteness: 75 percent  Average watchtime (standard deviation):  25.06 seconds (12.01)        This model was evaluated in 16 first subjective ses sions. The following table shows the results.    Question votes percentage  ... would you use to explain 6  37.50  ... do you remember best 4 25.00  ... explains worst 3 18.75   213     Model 4     Description: Function is represented by a box.  Before the function appears, the name x (with out object) enters the scene. The function finds  the minimal element of a list and puts name x  on it.     Duration: 11 seconds   Concreteness: 75 percent  Average watchtime (standard deviation): 19.56  seconds (4.38)        This model was evaluated in 16 first subjective ses sions. The following table shows the results.    Question votes percentage  ... would you use to explain 3  18.75  ... do you remember best 5 31.25  ... explains worst 1 6.25   214     3.6 Python Puzzle  3.6.1 Screenshots aus einer Sitzung mit dem Python Puzzle „Modeling a  group“        Abb. 96: Problemkontext (links) und Editorseite (re chts).        Abb. 97: Feedback zu einem Testlauf des Programms ( links) und Kurzreferenz zur den vorkommenden PythonSprachelementen (erscheint nach Klick auf „Semantics “).   3.6.2 Dokumentation einer Session mit XML  Zu Beginn einer Session wird ein XML-Paket an das S ervice-Programm pp_startservice.py ge schickt. Es enthält u.a. die IDs (Passwörter) der S pieler und hat folgendes Format:  <log>      <session game="gameId" id ="SessionID" />      <person id="id1"  />      <person id ="id2" />  </log>  Vom Serviceprogramm wird ein Datensatz (Tupel der R elation protocol_pp )  für die Beschrei bung der Session angelegt , als Spieldauer 0 Sekund en und als erreichte Punktzahl –200  eingetragen.   Am Ende einer Session wird ein XML-Paket mit dem Se ssionprotokoll an das Service-Programm  pp_service.py  geschickt. Es ist folgendermaßen aufgebaut:  <log>     <task id = "Nummer" time="Bearbeitungsbeginn der  Aufgabe">         <model id="Primärschlüssel des Modells"                 time="Zeitpunkt der Betrachtung"                watchtime="Dauer der Betrachtung"                eval="Bewertung (1 bis 3)" />   215            <correct time = "zeitpunkt"> Programmzeile < /correct>         …         <error time = "zeitpunkt"> Programmzeile </e rror>         …         <time>Bearbeitungszeit</time>         <points>erreichte Punktzahl</points>         <runs>Anzahl der Testläufe</runs>     </task>     …     <session id = "SessionID"           game= "gameID"           time="Spieldauer in Sekunden"            points="erreichte Punktzahl"/>  </log>  Für jede gelöste Aufgabe gibt es einen task-Knoten (mit Nummer der Aufgabe und Bearbeitungs beginn als Attribut). Er erhält Unterknoten mit Inf ormationen zu folgenden Punkten:  • Eine Beschreibung der Modelle, die verwendet worden  sind: Primärschlüssel (id), Zeitpunkt der  Betrachtung, Dauer, Bewertung (1= "hat nicht geholf en", 3= "hat geholfen"). Jedes Mal, wenn die  Hint-Schaltfläche angeklickt worden ist, wird ein s olcher model-Knoten erzeugt.   • Eine Beschreibung der verwendeten Programmzeilen (" Bausteine"). Die correct-Knoten enthalten  Beschreibungen der Programmzeilen des korrekten, ge testeten Programms (Programmzeile und  Zeitpunkt, wann der Baustein mit dieser Zeile zum e rsten Mal bewegt worden ist). Die errorKnoten enthalten entsprechende Beschreibungen von f ehlerhaften Zeilen. Eine Zeile wird als feh lerhaft gewertet, wenn sie nicht zum korrekten Prog ramm gehört und dennoch irgendwann einmal  während der Bearbeitung der Aufgabe in das Programm feld bewegt worden ist. In diesem kann  man davon ausgehen, dass der Spieler zu irgendeinem  Zeitpunkt glaubte, die Zeile müsse in den  Programmtext eingebaut werden. Es kann sein, dass i hm oder ihr der Fehler sofort aufgefallen ist  oder vielleicht auch erst nach einem misslungenen T estlauf. Auf jeden Fall ist der Fehler später  korrigiert worden.   • Bearbeitungszeit für diese Aufgabe in Sekunden.  • Erreichte Punktzahl (entspricht dem Schwierigkeitsg rad).  • Anzahl der Testläufe, bis das Programm fehlerfrei w ar.  Nach den task-Knotengibt es noch einen session-Knot en mit dem Primärschlüssel der Session in  der entsprechenden Tabelle der Datenbank, der gesam ten Spieldauer und der insgesamt erreichten  Punktzahl. Beispiel für ein XML-Dokument:  <log>  <task id="1" time="50">  <model id="group1_task1" time="46" watchtime="1" ev al="2" />  <model id="group1_task1" time="44" watchtime="1" ev al="3" />  <correct time="28">return result</correct>  <correct time="37">result = []</correct>  <correct time="32">result.append(person[0])</correc t>  <correct time="34">for person in persons:</correct>   <time>25</time>  <points>60</points>  <runs>1</runs>  </task>  <session id = "pp_group1508063" game="pp_group1" ti me="600"            points="60" />  </log>   216     3.6.3 Beispiel für eine automatisch generierte stat istische Auswertung  Kontext  Der nachfolgende Auszug aus dem Bericht des Auswert ungsdienstes für Python Puzzles zeigt die  Ergebnisse für Aufgabe 1 aus dem Puzzle Modeling a group . Der Aufgabenkontext lautet:  Wir modellieren eine Personengruppe durch eine List e von Listen.  Beispiel:   p = [['Anna', 22], ['Tim', 21], ['Sarah', 19]]  Definieren Sie verschiedene Funktionen, in denen ei ne solche Liste verarbeitet wir d.  In Aufgabe 1 soll eine Funktion definiert werden, d ie eine Liste mit den Namen der Gruppenmit glieder liefert. Zu dieser Funktionsdefinition ist nur der Funktionskopf vorgegeben:  def getNames(persons):  Die Anweisungen des Funktionskörpers müssen eingefü gt werden. Angeboten werden Puzzlestü cke mit korrekten und falschen Anweisungen. Die kor rekte Lösung lautet:  def getNames(persons):     result = []     for person in persons:         result.append(person[0])     return result  Zu dieser Aufgabe wurde nur eine einzige Animation angeboten, die auch als nonverbale Beschrei bung der erwarteten Funktionalität gesehen werden k ann.   Auszug aus der automatisch erstellten Auswertung  Modeling a group (pp_group1)   Maximal time: 600 seconds  Objective number of sessions 54 sessions  Subjective number of sessions   (taking into accout that there are sometimes two  players working together) 69 sessions  Average number of times (canceled and uncanceled  sessions) a player played this game  (standard deviation)  1.23 sessions (0.50)  Average number of players in all objective sessions   (standard deviation) 1.28 (0.45) players  Objective number of uncancelled sessions (includ ing sessions, in which no task was solved)  33 sessions  Subjective number of uncancelled sessions (includ ing sessions, in which no task was solved) 40 sessions  Average number of points in all objective uncan celed sessions (standard deviation) 84.94 (94.68) points   217     Task 1  Successful solutions  Number of successful subjective solutions of task 2 4 solutions  Average number of test runs (standard deviation) 3. 30 runs (3.21)  Average solution time (standard deviation) 319.91 s econds (191.84)    Some general information about the players of this category, who solved this task.  Professions 20 highschool students, 4 university students,   0 teachers, 0 professors and 0 others   Gender 4 female and 20 male persons  Hours a week spent on programming (standard de viation) 5.29 hours (5.77)  Age (standard deviation) 17.54 years (4.51)  Country DEU: 22 USA: 2     Use of correct lines of code (pieces) in task 1. Th e rank of a piece indicates the time, when it was p ut  into the program. We consider only successful solut ions.  Correct line of code Usage (percent) Rank (standard  deviation)  result = [] 24 (100.00 percent)  1.38 (0.88)   return result 24 (100.00 percent)  2.96 (0.95)   for person in persons: 24 (100.00 percent)  2.67 (1.05)   result.append(person[0]) 24 (100.00 percent)  3.00 (0.78)     Use of wrong lines of code (errors) in task 1. The rank of an error indicates the time, when a player  tried to insert it into the program.  Error Usage (percent) Rank (standard deviation)  for all in persons: 8 (33.33 percent)  2.62 (1.69)   for persons in person: 11 (45.83 percent)  2.82 (1.66)   result.append(name) 7 (29.17 percent)  2.14 (1.35)   result.append(person) 14 (58.33 percent)  1.71 (1.14)   result.append(person[1]) 6 (25.00 percent)  3.33 (1.03)   result= "" 5 (20.83 percent)  2.60 (1.82)     Use of visual models in successful solutions  The following tables show, how visual models are us ed while solving this task. We only consider  subjective sessions, in which the task was actually  solved.  218     Model group1_task1  Python Puzzle: Modeling a group   Task: 1   Description of model: Iteration over a list  containing three lists, represented by a  box containing three boxes. The actual  element is marked by a pin.     Level of concreteness (percentage of  names): 60 percent   Duration: 17 seconds         In how many subjective sessions this task was  solved?  24 sessions   How often was this model watched altogether (suc cessful task solutions only)?  26 times   In how many subjective sessions was this model  used (successful task solutions only)?  16 sessions   We consider the players, who have actually used  this model. How often did such a player watch this  model in a session?  (standard deviation) 1.62 times (0.96)  For how long did a player watch this model alto gether during a session?  (standard deviation) 40.44 seconds (21.56)  How useful was this model (average of all ratings  in a session)?   3 = very useful, 2 = a bit useful, 1 = not useful  (standard deviation) 2.27 (0.79)  How useful was this model (best of all ratings in a   session)?   3 = very useful, 2 = a bit useful, 1 = not useful  (standard deviation) 2.38 (0.81)  3.7 Python Quiz  3.7.1 Dokumentation einer Session  Zu Beginn einer Session wird ein XML-Paket an das S ervice-Programm  pq_startservice.py  geschickt. Es enthält unter anderem die Passwörter  der Spieler und hat  folgendes Format:  <log>     <session game="gameId" id ="SessionID" />     <person id = "id1"  />     <person id = "id2" />  </log> 219     Vom Serviceprogramm wird ein Datensatz (Tupel der R elation protocol_pq )  für die Beschrei bung der Session angelegt, als Spieldauer 0 Sekunden und als erreichte Punktzahl –200  eingetragen.  Bei einem vorzeitigen Abbruch der Session, erhalten  somit die Spieler Minuspunkte und der Sessio nabbruch wird "bestraft". Am Ende einer Session wir d ein XML-Paket mit dem Sessionprotokoll an  das Service-Programm pq_service.py  geschickt. Es ist folgendermaßen aufgebaut:  <log>       <task id = "ID der Aufgabenbeschreibung">         <model id="ID des Modells"                 watchtime="Dauer der Betrachtung"                points="gesetzte Punkte"                eval="Bewertung (0 oder 1)" />         ...     </task>     ...     <session id = "SessionID"           time="Spieldauer in Sekunden"            points="erreichte Punktzahl">     </log>  Für jede gelöste Aufgabe gibt es einen task-Knoten mit der ID der Aufgabenbeschreibung (Primär schlüsselattribut der Relation description_pq_task  ) als Attribut. Er erhält als Unterknoten  Beschreibungen der Modelle und ihre Bewertung. Der session -Knoten enthält Daten des Sitzungs protokolls, die nach dem Spiel in der Relation protocol_pq  geändert werden müssen.  3.7.2 Auszug aus der automatisch erstellten Auswert ung  Dieser Auszug aus der automatisch erstellten Auswer tung beschränkt sich auf die ersten, nicht vor zeitig abgebrochenen, subjektiven Sitzungen von Sch ülerinnen und Schülern, die an einem Workshop  teilgenommen haben. Wenn es Schüler gab, die ein Qu iz drei Mal oder häufiger durchgeführt haben,  wurde eine Übersicht über die Ergebnisse der ersten  drei (nicht abgebrochenen) Sitzungen generiert.   Modeling a group using a list of tuples.  This game contains 5 tasks. I n each task the playe r has to judge several models, whether or not  they are appropriate to explain the execution of so me program statement.  Task 1  result=[]  Task 2  for (n, a) in persons:  Task 3  a > age  Task 4  result.append(n)  Task 5  olderThan(group, 19) 220       The following table provides some general informati on about the usage of this game (pq_list).   Number of objective sessions   (not  taking into account that there are sometimes  two players working together) 106 sessions  Number of subjective sessions   (taking into account that there are sometimes two  players working together) 116 sessions  Number of subjective uncanceled sessions   (taking into account that there are sometimes two  players working together) 77 sessions  Number of subjective first uncanceled sessions   (taking into account that there are sometimes two  players working together and some people play this  game several times) 68 sessions  Number of persons, who played three times or more 2  persons    Some general information about the players of this category, who played the game at least once .   Professions 68 highschool students, 0 university students,   0 teachers, 0 professors and 0 others   Gender 12 female and 56 male persons  Hours a week spent on programming (standard de viation) 3.81 hours (5.96)  Roughly estimated experience in Python program ming (standard deviation) 91.63 days (138.80)  Age (standard deviation) 17.15 years (2.12)  Population of the town, where the workshop took  place Less than 100 000: 13, 100 000 to 500 000: 9, more  than 500 000: 46  Country Germany: 41 other country: 27       Some general information about the players of this category, who played the game at least three times .  Professions 2 highschool students, 0 university students,   0 teachers, 0 professors and 0 others   Gender 1 female and 1 male persons  Hours a week spent on programming (standard de viation) 1.50 hours (2.12)  Roughly estimated experience in Python program ming(standard deviation) 136.50 days (188.80)  Age (standard deviation) 17.00 years (1.41)  Population of the town, where the workshop took  place Less than 100 000: 0, 100 000 to 500 000: 0, more  than 500 000: 2  Country Germany: 1 other country: 1    221     Task 1  Judging Model pq_list_a1_1  Associated program:  result=[]     Description: Visualization of an empty list by  a box containing an empty card    Time: 0 seconds  Concreteness: 100 percent of names are used  in the model        Total number of first judgements 68   Average bet points (0 to 10) representing the  player's confidence (standard deviation) 6.40 (4.04)   Average watch time (standard deviation) 17.25 secon ds (21.64)   Number and percentage of players, who declared  that the model is appropriate ("good"-judgements).  41 players, 60.29 percent   Average confidence in "good"-judgement (standard  deviation) 6.10 (3.95)   Number and percentage of players, who declared  that the model is not  appropriate ("bad"judgements) 27 players, 39.71 percent   Average confidence in "bad" judgement (standard  deviation) 6.85 (4.19)     Judging Model pq_list_a1_2   Associated program:  result=[]     Description: Visualization of an empty list  by a box with five empty compartments.    Time: 0 seconds  Concreteness: 100 percent of names are  used in the model   222       Total number of first judgements 68   Average bet points (0 to 10) representing the playe r's  confidence (standard deviation) 5.81 (4.46)   Average watch time (standard deviation) 25.12 secon ds (74.37)   Number and percentage of players, who declared that   the model is appropriate ("good"-judgements).  47 players, 69.12 percent   Average confidence in "good"-judgement (standard  deviation) 6.17 (4.45)   Number and percentage of players, who declared that   the model is not  appropriate ("bad"-judgements) 21 players, 30.88 percent   Average confidence in "bad" judgement (standard  deviation) 5.00 (4.47)     Judging Model pq_list_a1_3   Associated program:  result=[]     Description: Visualization of an empty list  named result by a box containing a card with  result written on it.    Time: 0 seconds  Concreteness: 100 percent of names are used in  the model        Total number of first judgements 68   Average bet points (0 to 10) representing the playe r's  confidence (standard deviation) 6.84 (4.04)   Average watch time (standard deviation) 18.82 secon ds (27.59)   Number and percentage of players, who declared that   the model is appropriate ("good"-judgements).  34 players, 50.00 percent   Average confidence in "good"-judgement (standard  deviation) 5.74 (4.11)   Number and percentage of players, who declared that   the model is not  appropriate ("bad"-judgements) 34 players, 50.00 percent   Average confidence in "bad" judgement (standard  deviation) 7.94 (3.72)    223     Judging Model pq_list_a1_4  Associated program:  result=[]     Description: Visualization of an empty list by a  bord (box with zero compartments).    Time: 0 seconds  Concreteness: 100 percent of names are used in  the model        Total number of first judgements 68   Average bet points (0 to 10) representing the playe r's  confidence (standard deviation) 5.51 (4.50)   Average watch time (standard deviation) 17.40 secon ds (17.32)   Number and percentage of players, who declared that   the model is appropriate ("good"-judgements).  41 players, 60.29 percent   Average confidence in "good"-judgement (standard  deviation) 5.61 (4.50)   Number and percentage of players, who declared that   the model is not  appropriate ("bad"-judgements) 27 players, 39.71 percent   Average confidence in "bad" judgement (standard  deviation) 5.37 (4.58)     Judging Model pq_list_a1_5   Associated program:  result=[]     Description: Visualization of an empty list by a  pointer pointing to nothing.    Time: 0 seconds  Concreteness: 100 percent of names are used in  the model   224       Total number of first judgements 68   Average bet points (0 to 10) representing the playe r's  confidence (standard deviation) 5.96 (4.43)   Average watch time (standard deviation) 19.99 secon ds (27.56)   Number and percentage of players, who declared that   the model is appropriate ("good"-judgements).  44 players, 64.71 percent   Average confidence in "good"-judgement (standard  deviation) 5.23 (4.57)   Number and percentage of players, who declared that   the model is not  appropriate ("bad"-judgements) 24 players, 35.29 percent   Average confidence in "bad" judgement (standard  deviation) 7.29 (3.90)     Judging Model pq_list_a1_6   Associated program:  result=[]     Description: Visualization of an empty list by a  pointer pointing to an empty card.    Time: 0 seconds  Concreteness: 100 percent of names are used in  the model        Total number of first judgements 68   Average bet points (0 to 10) representing the playe r's  confidence (standard deviation) 6.32 (4.11)   Average watch time (standard deviation) 14.01 secon ds (17.25)   Number and percentage of players, who declared that   the model is appropriate ("good"-judgements).  44 players, 64.71 percent   Average confidence in "good"-judgement (standard  deviation) 6.59 (4.14)   Number and percentage of players, who declared that   the model is not  appropriate ("bad"-judgements) 24 players, 35.29 percent   Average confidence in "bad" judgement (standard  deviation) 5.83 (4.08)    225     Judging Model pq_list_a1_7   Associated program:  result=[]     Description: Visualization of an empty list  named result by a pointer pointing to the word  result.    Time: 0 seconds  Concreteness: 100 percent of names are used in  the model        Total number of first judgements 68   Average bet points (0 to 10) representing the playe r's  confidence (standard deviation) 6.18 (4.15)   Average watch time (standard deviation) 16.50 secon ds (21.98)   Number and percentage of players, who declared that   the model is appropriate ("good"-judgements).  29 players, 42.65 percent   Average confidence in "good"-judgement (standard  deviation) 5.34 (4.21)   Number and percentage of players, who declared that   the model is not  appropriate ("bad"-judgements) 39 players, 57.35 percent   Average confidence in "bad" judgement (standard  deviation) 6.79 (4.05)     Task 2  Judging Model pq_list_a2_8  Associated program:  for (n, a) in persons:     Description: Visualization of an iteration using  a cointainer to represent a list and pointers for  iteration variables.    Time: 7 seconds  Concreteness: 100 percent of names are used in  the model   226         Total number of first judgements 68   Average bet points (0 to 10) representing the  player's confidence (standard deviation) 7.35 (3.71)   Average watch time (standard deviation) 10.28 secon ds (11.09)   Number and percentage of players, who declared  that the model is appropriate ("good"-judgements).  54 players, 79.41 percent   Average confidence in "good"-judgement (standard  deviation) 7.96 (3.30)   Number and percentage of players, who declared  that the model is not  appropriate ("bad"judgements) 14 players, 20.59 percent   Average confidence in "bad" judgement (standard  deviation) 5.00 (4.39)     Judging Model pq_list_a2_7   Associated program:  for (n, a) in persons:     Description: Visualization of an iteration. Postits with the names of the iteration variables are  moving from item to item in the list    Time: 9 seconds  Concreteness: 100 percent of names are used in  the model        Total number of first judgements 68   Average bet points (0 to 10) representing the playe r's  confidence (standard deviation) 7.35 (3.71)   Average watch time (standard deviation) 12.40 secon ds (17.74)   Number and percentage of players, who declared that   the model is appropriate ("good"-judgements).  54 players, 79.41 percent   Average confidence in "good"-judgement (standard  deviation) 7.59 (3.60)   Number and percentage of players, who declared that   the model is not  appropriate ("bad"-judgements) 14 players, 20.59 percent   Average confidence in "bad" judgement (standard  deviation) 6.43 (4.13)    227     Judging Model pq_list_a2_6   Associated program:  for (n, a) in persons:     Description: Visualization of an iteration. Con tains an unappropriate model of assignment.  Cards (representing values) accumulate in a con tainer.    Time: 10 seconds  Concreteness: 100 percent of names are used in  the model        Total number of first judgements 68   Average bet points (0 to 10) representing the playe r's  confidence (standard deviation) 7.57 (3.81)   Average watch time (standard deviation) 9.78 second s (5.97)   Number and percentage of players, who declared that   the model is appropriate ("good"-judgements).  35 players, 51.47 percent   Average confidence in "good"-judgement (standard  deviation) 7.29 (3.90)   Number and percentage of players, who declared that   the model is not  appropriate ("bad"-judgements) 33 players, 48.53 percent   Average confidence in "bad" judgement (standard  deviation) 7.88 (3.76)     Judging Model pq_list_a2_5   Associated program:  for (n, a) in persons:     Description: Visualization of an iteration  using a pointer model for the list and the  iteration variable. The pointer of the iteration  variable moves.    Time: 4 seconds  Concreteness: 100 percent of names are used  in the model   228         Total number of first judgements 68   Average bet points (0 to 10) representing the playe r's  confidence (standard deviation) 6.03 (4.19)   Average watch time (standard deviation) 27.22 secon ds (93.78)   Number and percentage of players, who declared that   the model is appropriate ("good"-judgements).  42 players, 61.76 percent   Average confidence in "good"-judgement (standard  deviation) 6.19 (4.25)   Number and percentage of players, who declared that   the model is not  appropriate ("bad"-judgements) 26 players, 38.24 percent   Average confidence in "bad" judgement (standard  deviation) 5.77 (4.17)     Judging Model pq_list_a2_4   Associated program:  for (n, a) in persons:     Description: Visualization of an iteration  using a container model for the list and the  iteration variable. Copies of cards with tuples  move out of the list-container.    Time: 10 seconds  Concreteness: 100 percent of names are used  in the model        Total number of first judgements 68   Average bet points (0 to 10) representing the playe r's  confidence (standard deviation) 7.50 (3.72)   Average watch time (standard deviation) 9.06 second s (7.43)   Number and percentage of players, who declared that   the model is appropriate ("good"-judgements).  43 players, 63.24 percent   Average confidence in "good"-judgement (standard  deviation) 6.86 (4.09)   Number and percentage of players, who declared that   the model is not  appropriate ("bad"-judgements) 25 players, 36.76 percent   Average confidence in "bad" judgement (standard  deviation) 8.60 (2.71)    229     Judging Model pq_list_a2_3   Associated program:  for (n, a) in persons:     Description: Visualization of an iteration  using a pointer model for the list and the  iteration variable. The pointers of the itera tion  variable move.    Time: 4 seconds  Concreteness: 100 percent of names are used  in the model        Total number of first judgements 68   Average bet points (0 to 10) representing the  player's confidence (standard deviation) 7.50 (3.91)   Average watch time (standard deviation) 19.40 secon ds (65.88)   Number and percentage of players, who declared  that the model is appropriate ("good"-judgements).  57 players, 83.82 percent   Average confidence in "good"-judgement (standard  deviation) 7.46 (3.91)   Number and percentage of players, who declared  that the model is not  appropriate ("bad"judgements) 11 players, 16.18 percent   Average confidence in "bad" judgement (standard  deviation) 7.73 (4.10)     Judging Model pq_list_a2_2   Associated program:  for (n, a) in persons:     Description: Visualization of an iteration  using a con tainer model for the list and the  iteration variable. The cards in the listcontainer are removed.    Time: 10 seconds  Concreteness: 100 percent of names are  used in the model   230         Total number of first judgements 68   Average bet points (0 to 10) representing the  player's confidence (standard deviation) 7.72 (3.81)   Average watch time (standard deviation) 8.81 second s (6.22)   Number and percentage of players, who declared  that the model is appropriate ("good"-judgements).  40 players, 58.82 percent   Average confidence in "good"-judgement (standard  deviation) 7.50 (3.92)   Number and percentage of players, who declared  that the model is not  appropriate ("bad"judgements) 28 players, 41.18 percent   Average confidence in "bad" judgement (standard  deviation) 8.04 (3.69)     Judging Model pq_list_a2_1   Associated program:  for (n, a) in persons:     Description: Visualization of an iteration  using a container model for the list and the  iteration variable. Copies of the cards in the  list-container move.    Time: 10 seconds  Concreteness: 100 percent of names are used  in the model        Total number of first judgements 68   Average bet points (0 to 10) representing the playe r's  confidence (standard deviation) 7.35 (3.91)   Average watch time (standard deviation) 11.18 secon ds (10.50)   Number and percentage of players, who declared that   the model is appropriate ("good"-judgements).  49 players, 72.06 percent   Average confidence in "good"-judgement (standard  deviation) 7.45 (3.97)   Number and percentage of players, who declared that   the model is not  appropriate ("bad"-judgements) 19 players, 27.94 percent   Average confidence in "bad" judgement (standard  deviation) 7.11 (3.84)    231     Task 3  Judging Model pq_list_a3_4   Associated program:  a > age     Description: Visualization of a greater-thanfunction by a box with sensors for the input  values.    Time: 8 seconds  Concreteness: 100 percent of names are used  in the model      Total number of first judgements 68   Average bet points (0 to 10) representing the playe r's  confidence (standard deviation) 7.13 (3.70)   Average watch time (standard deviation) 10.65 secon ds (7.18)   Number and percentage of players, who declared that   the model is appropriate ("good"-judgements).  58 players, 85.29 percent   Average confidence in "good"-judgement (standard  deviation) 7.41 (3.66)   Number and percentage of players, who declared that   the model is not  appropriate ("bad"-judgements) 10 players, 14.71 percent   Average confidence in "bad" judgement (standard  deviation) 5.50 (3.69)     Judging Model pq_list_a3_2   Associated program:  a > age     Description: Visualization of the greater-than  operation using a flash for the function call  and a cointainer model for the compared  variables.    Time: 7 seconds  Concreteness: 100 percent of names are used  in the model   232         Total number of first judgements 68   Average bet points (0 to 10) representing the  player's confidence (standard deviation) 6.99 (4.06)   Average watch time (standard deviation) 7.88 second s (5.58)   Number and percentage of players, who declared  that the model is appropriate ("good"-judgements).  58 players, 85.29 percent   Average confidence in "good"-judgement (standard  deviation) 7.67 (3.77)   Number and percentage of players, who declared  that the model is not  appropriate ("bad"judgements) 10 players, 14.71 percent   Average confidence in "bad" judgement (standard  deviation) 3.00 (3.50)     Judging Model pq_list_a3_3   Associated program:  a > age     Description: Shows an input-output model for  the greater-than operator and a unappropriate  container model for the compared variables  (name and content mixed-up).    Time: 9 seconds  Concreteness: 100 percent of names are used  in the model      Total number of first judgements 68   Average bet points (0 to 10) representing the playe r's  confidence (standard deviation) 6.69 (4.29)   Average watch time (standard deviation) 27.18 secon ds (95.74)   Number and percentage of players, who declared that   the model is appropriate ("good"-judgements).  43 players, 63.24 percent   Average confidence in "good"-judgement (standard  deviation) 6.86 (4.37)   Number and percentage of players, who declared that   the model is not  appropriate ("bad"-judgements) 25 players, 36.76 percent   Average confidence in "bad" judgement (standard  deviation) 6.40 (4.21)    233     Judging Model pq_list_a3_1   Associated program:  a > age     Description: Visualization of the greater-than  operation using an input-output model for the  operator and a cointainer model for the com pared variables.    Time: 9 seconds  Concreteness: 100 percent of names are used  in the model      Total number of first judgements 68   Average bet points (0 to 10) representing the  player's confidence (standard deviation) 6.69 (4.29)   Average watch time (standard deviation) 14.84 secon ds (25.25)   Number and percentage of players, who declared  that the model is appropriate ("good"-judgements).  56 players, 82.35 percent   Average confidence in "good"-judgement (standard  deviation) 7.23 (4.04)   Number and percentage of players, who declared  that the model is not  appropriate ("bad"judgements) 12 players, 17.65 percent   Average confidence in "bad" judgement (standard  deviation) 4.17 (4.69)     Task 4  Judging Model pq_list_a4_5   Associated program:  result.append(n)     Description: Unappropiate visualization of a  list extension (append) that mixes-up name  and value of variables. The list is represented  by a container model.    Time: 5 seconds  Concreteness: 67 percent of names are used  in the model   234         Total number of first judgements 68   Average bet points (0 to 10) representing the playe r's  confidence (standard deviation) 6.18 (4.24)   Average watch time (standard deviation) 9.24 second s (6.09)   Number and percentage of players, who declared that   the model is appropriate ("good"-judgements).  43 players, 63.24 percent   Average confidence in "good"-judgement (standard  deviation) 5.81 (4.22)   Number and percentage of players, who declared that   the model is not  appropriate ("bad"-judgements) 25 players, 36.76 percent   Average confidence in "bad" judgement (standard  deviation) 6.80 (4.30)     Judging Model pq_list_a4_4   Associated program:  result.append(n)     Description: Visualization of a list extension  (append). Two lists are represented by boards  with cards. A card moves from the 1st to the  2nd list which gets longer.    Time: 5 seconds  Concreteness: 67 percent of names are used  in the model      Total number of first judgements 68   Average bet points (0 to 10) representing the playe r's  confidence (standard deviation) 6.69 (4.02)   Average watch time (standard deviation) 11.44 secon ds (12.78)   Number and percentage of players, who declared that   the model is appropriate ("good"-judgements).  54 players, 79.41 percent   Average confidence in "good"-judgement (standard  deviation) 6.85 (4.04)   Number and percentage of players, who declared that   the model is not  appropriate ("bad"-judgements) 14 players, 20.59 percent   Average confidence in "bad" judgement (standard  deviation) 6.07 (4.01)    235     Judging Model pq_list_a4_6   Associated program:  result.append(n)     Description: Visualization of a list extension  (append) using a consistent pointer model for  the lists. Lists are represented by boards with  pointers.    Time: 5 seconds  Concreteness: 67 percent of names are used  in the model      Total number of first judgements 68   Average bet points (0 to 10) representing the  player's confidence (standard deviation) 4.85 (4.57)   Average watch time (standard deviation) 9.62 second s (7.51)   Number and percentage of players, who declared  that the model is appropriate ("good"-judgements).  40 players, 58.82 percent   Average confidence in "good"-judgement (standard  deviation) 5.62 (4.56)   Number and percentage of players, who declared  that the model is not  appropriate ("bad"judgements) 28 players, 41.18 percent   Average confidence in "bad" judgement (standard  deviation) 3.75 (4.44)     Judging Model pq_list_a4_1   Associated program:  result.append(n)     Description: Visualization of a list extension  (call of append()-method). The list is repre sented by a box with a constant number of  compartments.    Time: 5 seconds  Concreteness: 67 percent of names are used  in the model   236         Total number of first judgements 68   Average bet points (0 to 10) representing the  player's confidence (standard deviation) 6.03 (4.28)   Average watch time (standard deviation) 9.66 second s (7.28)   Number and percentage of players, who declared  that the model is appropriate ("good"-judgements).  48 players, 70.59 percent   Average confidence in "good"-judgement (standard  deviation) 6.67 (4.17)   Number and percentage of players, who declared  that the model is not  appropriate ("bad"judgements) 20 players, 29.41 percent   Average confidence in "bad" judgement (standard  deviation) 4.50 (4.26)     Judging Model pq_list_a4_3   Associated program:  result.append(n)     Description: Visualization of a list extension  (call of append()-method). There are two list  models, a card moves from one list to the other.    Time: 4 seconds  Concreteness: 33 percent of names are used in  the model      Total number of first judgements 68   Average bet points (0 to 10) representing the playe r's  confidence (standard deviation) 6.47 (3.96)   Average watch time (standard deviation) 10.01 secon ds (10.24)   Number and percentage of players, who declared that   the model is appropriate ("good"-judgements).  39 players, 57.35 percent   Average confidence in "good"-judgement (standard  deviation) 6.54 (4.16)   Number and percentage of players, who declared that   the model is not  appropriate ("bad"-judgements) 29 players, 42.65 percent   Average confidence in "bad" judgement (standard  deviation) 6.38 (3.76)    237     Judging Model pq_list_a4_2   Associated program:  result.append(n)     Description: Visualization of a list extension  (call of append()-method). The list is repre sented by a box with increasing number of  compartments.    Time: 5 seconds  Concreteness: 67 percent of names are used  in the model      Total number of first judgements 68   Average bet points (0 to 10) representing the playe r's  confidence (standard deviation) 5.59 (4.36)   Average watch time (standard deviation) 7.94 second s (5.71)   Number and percentage of players, who declared that   the model is appropriate ("good"-judgements).  51 players, 75.00 percent   Average confidence in "good"-judgement (standard  deviation) 5.78 (4.40)   Number and percentage of players, who declared that   the model is not  appropriate ("bad"-judgements) 17 players, 25.00 percent   Average confidence in "bad" judgement (standard  deviation) 5.00 (4.33)     Task 5  Judging Model pq_list_a5_4   Associated program:  olderThan(group, 19)     Description: Visualization of a function call.  The function is represented by a box with  sensors.    Time: 9 seconds  Concreteness: 100 percent of names are used  in the model   238         Total number of first judgements 68   Average bet points (0 to 10) representing the  player's confidence (standard deviation) 6.69 (3.92)   Average watch time (standard deviation) 7.75 second s (6.09)   Number and percentage of players, who de clared that the model is appropriate ("good"judgements).  48 players, 70.59 percent   Average confidence in "good"-judgement  (standard deviation) 7.19 (3.85)   Number and percentage of players, who de clared that the model is not  appropriate ("bad"judgements) 20 players, 29.41 percent   Average confidence in "bad" judgement (stan dard deviation) 5.50 (3.94)     Judging Model pq_list_a5_5   Associated program:  olderThan(group, 19)     Description: Visualization of a function call.  The function call is represented by a flash  (event model).    Time: 6 seconds  Concreteness: 100 percent of names are used  in the model      Total number of first judgements 68   Average bet points (0 to 10) representing the playe r's  confidence (standard deviation) 6.76 (4.03)   Average watch time (standard deviation) 8.09 second s (6.32)   Number and percentage of players, who declared that   the model is appropriate ("good"-judgements).  49 players, 72.06 percent   Average confidence in "good"-judgement (standard  deviation) 6.73 (4.02)   Number and percentage of players, who declared that   the model is not  appropriate ("bad"-judgements) 19 players, 27.94 percent   Average confidence in "bad" judgement (standard  deviation) 6.84 (4.15)    239     Judging Model pq_list_a5_6   Associated program:  olderThan(group, 19)     Description: Visualization of a function call.  The function (input-output model) receives  copies of all cards of a list (container) and a  card with a number.    Time: 9 seconds  Concreteness: 100 percent of names are used  in the model        First Judgements   Total number of first judgements 68   Average bet points (0 to 10) representing the playe r's  confidence (standard deviation) 6.91 (4.05)   Average watch time (standard deviation) 10.37 secon ds (9.02)   Number and percentage of players, who declared that   the model is appropriate ("good"-judgements).  46 players, 67.65 percent   Average confidence in "good"-judgement (standard  deviation) 7.28 (4.04)   Number and percentage of players, who declared that   the model is not  appropriate ("bad"-judgements) 22 players, 32.35 percent   Average confidence in "bad" judgement (standard  deviation) 6.14 (4.06)     Judging Model pq_list_a5_1   Associated program:  olderThan(group, 19)     Description: Visualization of a function call. The  Function is represented by a box with a manipu lator arm, that graps input values.    Time: 14 seconds  Concreteness: 100 percent of names are used in  the model         240     Total number of first judgements 68   Average bet points (0 to 10) representing the playe r's  confidence (standard deviation) 7.13 (3.99)   Average watch time (standard deviation) 12.75 secon ds (12.56)   Number and percentage of players, who declared that   the model is appropriate ("good"-judgements).  55 players, 80.88 percent   Average confidence in "good"-judgement (standard  deviation) 7.55 (3.71)   Number and percentage of players, who declared that   the model is not  appropriate ("bad"-judgements) 13 players, 19.12 percent   Average confidence in "bad" judgement (standard  deviation) 5.38 (4.77)     Judging Model pq_list_a5_2   Associated program:  olderThan(group, 19)     Description: Visualization of a function call.  The function (input-output model) accepts a  list model(container) and a card with a num ber.    Time: 9 seconds  Concreteness: 100 percent of names are used  in the model      Total number of first judgements 68   Average bet points (0 to 10) representing the playe r's  confidence (standard deviation) 6.62 (3.91)   Average watch time (standard deviation) 10.59 secon ds (19.34)   Number and percentage of players, who declared that   the model is appropriate ("good"-judgements).  40 players, 58.82 percent   Average confidence in "good"-judgement (standard  deviation) 6.25 (3.88)   Number and percentage of players, who declared that   the model is not  appropriate ("bad"-judgements) 28 players, 41.18 percent   Average confidence in "bad" judgement (standard  deviation) 7.14 (3.95)    241     Judging Model pq_list_a5_3   Associated program:  olderThan(group, 19)     Description: Unappropriate visualization of a  function call. The function (input-output  model) receives cards with names of formal  parameters as input.    Time: 9 seconds  Concreteness: 100 percent of names are used  in the model        Total number of first judgements 68   Average bet points (0 to 10) representing the playe r's  confidence (standard deviation) 6.40 (4.13)   Average watch time (standard deviation) 27.81 secon ds (86.31)   Number and percentage of players, who declared that   the model is appropriate ("good"-judgements).  35 players, 51.47 percent   Average confidence in "good"-judgement (standard  deviation) 6.14 (4.22)   Number and percentage of players, who declared that   the model is not  appropriate ("bad"-judgements) 33 players, 48.53 percent   Average confidence in "bad" judgement (standard  deviation) 6.67 (4.08)     Modeling assignments.  This game contains 2 tasks. I n each task the playe r has to judge several models, whether or not  they are appropriate to explain the execution of so me program statement.  Task 1  a = 3  b = a  Task 2  today = "Monday"  today = "Tuesday"  today = "Wednesday" 242         The following table provides some general informati on about the usage of this game (pq_assign).   Number of objective sessions   (not  taking into account that there are sometimes  two players working together) 332 sessions  Number of subjective sessions   (taking into account that there are sometimes two  players working together) 388 sessions  Number of subjective uncanceled sessions   (taking into account that there are sometimes two  players working together) 313 sessions  Number of subjective first uncanceled sessions   (taking into account that there are sometimes two  players working together and some people play this  game several times) 154 sessions  Number of persons, who played three times or more 4 1 persons    Some general information about the players of this category, who played the game at least once .   Professions 154 highschool students, 0 university students,   0 teachers, 0 professors and 0 others   Gender 34 female and 120 male persons  Hours a week spent on programming (standard de viation) 3.23 hours (3.23)  Roughly estimated experience in Python program ming(standard deviation) 94.95 days (130.39)  Age (standard deviation) 17.21 years (2.04)  Population of the town, where the workshop took  place Less than 100 000: 42, 100 000 to 500 000: 28,  more than 500 000: 84  Country Germany: 110 other country: 44  243         Some general information about the players of this category, who played the game at least three times .  Professions 41 highschool students, 0 university students,   0 teachers, 0 professors and 0 others   Gender 13 female and 28 male persons  Hours a week spent on programming (standard de viation) 3.44 hours (2.27)  Roughly estimated experience in Python program ming(standard deviation) 189.37 days (127.68)  Age (standard deviation) 16.80 years (1.23)  Population of the town, where the workshop took  place Less than 100 000: 4, 100 000 to 500 000: 13, more  than 500 000: 24  Country Germany: 39 other country: 2    244     Task 1  Judging Model pq_assign_a1_9   Associated program:  a = 3  b = a     Description: Names are represented by postits. A post-it a is attached to a floating card  with number 3. A second post-it b is attached  to post-it a.    Time: 9 seconds  Concreteness: 100 percent of names are used  in the model      Total number of first judgements 154   Average bet points (0 to 10) representing the playe r's  confidence (standard deviation) 7.82 (3.07)   Average watch time (standard deviation) 13.75 secon ds (11.58)   Number and percentage of players, who declared that   the model is appropriate ("good"-judgements).  78 players, 50.65 percent   Average confidence in "good"-judgement (standard  deviation) 7.37 (3.09)   Number and percentage of players, who declared that   the model is not  appropriate ("bad"-judgements) 76 players, 49.35 percent   Average confidence in "bad" judgement (standard  deviation) 8.29 (3.01)     Total number of persons, who played this game at  least three times 41    First session Second session Third session  Average bet points (0 to 10) representing the  player's confidence (standard deviation) 7.56 (3.38)  9.39 (2.00)  8.90 (3.06)   Average watch time (standard deviation) 8.98 second s  (4.61)  7.20 seconds  (4.59)  4.85 seconds  (3.18)   Percentage of players, who declared that the model  is appropriate ("good"-judgements).  34.15 percent  17.07 percent  9.76 percent   Average confidence in "good"-judgement (standard  deviation) 6.43 (3.06)  9.29 (1.89)  10.00 (0.00)   Percentage of players, who declared that the model  is not  appropriate ("bad"-judgements) 65.85 percent  82.93 percent  90.24 percent   Average confidence in "bad" judgement (standard  deviation) 8.15 (3.44)  9.41 (2.05)  8.78 (3.21)    245     Judging Model pq_assign_a1_8   Associated program:  a = 3  b = a     Description: Names are represented by postits. A post-it a is attached to a floating card  with number 3. A second post-it b is attached  to the same card.    Time: 9 seconds  Concreteness: 100 percent of names are used  in the model      Total number of first judgements 154   Average bet points (0 to 10) representing the  player's confidence (standard deviation) 8.21 (3.11)   Average watch time (standard deviation) 14.05 secon ds (12.56)   Number and percentage of players, who declared  that the model is appropriate ("good"-judgements).  119 players, 77.27 percent   Average confidence in "good"-judgement (standard  deviation) 8.49 (2.88)   Number and percentage of players, who declared  that the model is not  appropriate  35 players, 22.73 percent   Average confidence in "bad" judgement (standard  deviation) 7.29 (3.71)     Total number of persons, who played this game at  least three times 41    First session Second session Third session  Average bet points (0 to 10) representing the  player's confidence (standard deviation) 8.05 (3.14)  8.90 (3.06)  9.15 (2.72)   Average watch time (standard deviation) 14.95 secon ds  (18.50)  7.22 seconds  (3.93)  5.88 seconds  (2.32)   Percentage of players, who declared that the model  is appropriate ("good"-judgements).  82.93 percent  90.24 percent  78.05 percent   Average confidence in "good"-judgement (standard  deviation) 8.53 (2.62)  9.32 (2.40)  9.38 (2.46)   Percentage of players, who declared that the model  is not  appropriate ("bad"-judgements) 17.07 percent  9.76 percent  21.95 percent   Average confidence in "bad" judgement (standard  deviation) 5.71 (4.50)  5.00 (5.77)  8.33 (3.54)    246     Judging Model pq_assign_a1_7   Associated program:  a = 3  b = a     Description: Variables are represented by con tainers containing cards. A manipulator arm of  container b takes copy of the card in container a.     Time: 9 seconds  Concreteness: 100 percent of names are used in  the model      Total number of first judgements 154   Average bet points (0 to 10) representing the playe r's  confidence (standard deviation) 8.64 (2.44)   Average watch time (standard deviation) 12.68 secon ds (11.56)   Number and percentage of players, who declared that   the model is appropriate ("good"-judgements).  125 players, 81.17 percent   Average confidence in "good"-judgement (standard  deviation) 8.76 (2.26)   Number and percentage of players, who declared that   the model is not  appropriate ("bad"-judgements) 29 players, 18.83 percent   Average confidence in "bad" judgement (standard  deviation) 8.10 (3.11)     Total number of persons, who played this game at  least three times 41    First session Second session Third session  Average bet points (0 to 10) representing the  player's confidence (standard deviation) 8.05 (3.14)  8.66 (2.74)  8.66 (3.17)   Average watch time (standard deviation) 12.95 secon ds  (12.34)  7.71 seconds  (5.28)  6.88 seconds  (2.56)   Percentage of players, who declared that the model  is appropriate ("good"-judgements).  80.49 percent  92.68 percent  85.37 percent   Average confidence in "good"-judgement (standard  deviation) 8.33 (2.70)  8.95 (2.37)  8.86 (2.99)   Percentage of players, who declared that the model  is not  appropriate ("bad"-judgements) 19.51 percent  7.32 percent  14.63 percent   Average confidence in "bad" judgement (standard  deviation) 6.88 (4.58)  5.00 (5.00)  7.50 (4.18)    247     Judging Model pq_assign_a1_6   Associated program:  a = 3  b = a     Description: Variables are represented by  containers containing cards. A copy of the  name sign a goes into container b    Time: 6 seconds  Concreteness: 100 percent of names are used  in the model      Total number of first judgements 154   Average bet points (0 to 10) representing the playe r's  confidence (standard deviation) 8.44 (2.94)   Average watch time (standard deviation) 10.50 secon ds (7.75)   Number and percentage of players, who declared that   the model is appropriate ("good"-judgements).  98 players, 63.64 percent   Average confidence in "good"-judgement (standard  deviation) 8.72 (2.41)   Number and percentage of players, who declared that   the model is not  appropriate ("bad"-judgements) 56 players, 36.36 percent   Average confidence in "bad" judgement (standard  deviation) 7.95 (3.67)     Total number of persons, who played this game at  least three times 41    First session Second session Third session  Average bet points (0 to 10) representing the  player's confidence (standard deviation) 8.17 (3.31)  8.29 (3.28)  8.41 (3.25)   Average watch time (standard deviation) 10.59 secon ds  (7.03)  7.20 seconds  (3.63)  6.37 seconds  (2.75)   Percentage of players, who declared that the model  is appropriate ("good"-judgements).  51.22 percent  41.46 percent  24.39 percent   Average confidence in "good"-judgement (standard  deviation) 8.81 (2.18)  7.94 (3.56)  9.00 (2.11)   Percentage of players, who declared that the model  is not  appropriate ("bad"-judgements) 48.78 percent  58.54 percent  75.61 percent   Average confidence in "bad" judgement (standard  deviation) 7.50 (4.14)  8.54 (3.12)  8.23 (3.55)  248     Judging Model pq_assign_a1_5   Associated program:  a = 3  b = a     Description: Variables are represented by  containers containing cards. A copy of the  card in a migrates to b.    Time: 6 seconds  Concreteness: 100 percent of names are used  in the model      Total number of first judgements 154   Average bet points (0 to 10) representing the playe r's  confidence (standard deviation) 8.77 (2.76)   Average watch time (standard deviation) 9.06 second s (7.39)   Number and percentage of players, who declared that   the model is appropriate ("good"-judgements).  133 players, 86.36 percent   Average confidence in "good"-judgement (standard  deviation) 9.02 (2.34)   Number and percentage of players, who declared that   the model is not  appropriate ("bad"-judgements) 21 players, 13.64 percent   Average confidence in "bad" judgement (standard  deviation) 7.14 (4.35)     Total number of persons, who played this game at  least three times 41    First session Second session Third session  Average bet points (0 to 10) representing the  player's confidence (standard deviation) 7.80 (3.88)  8.90 (2.62)  8.90 (3.06)   Average watch time (standard deviation) 7.71 second s  (6.10)  5.59 seconds  (1.99)  5.05 seconds  (2.10)   Percentage of players, who declared that the model  is appropriate ("good"-judgements).  80.49 percent  92.68 percent  95.12 percent   Average confidence in "good"-judgement (standard  deviation) 8.64 (3.13)  9.21 (2.18)  9.36 (2.35)   Percentage of players, who declared that the model  is not  appropriate ("bad"-judgements) 19.51 percent  7.32 percent  4.88 percent   Average confidence in "bad" judgement (standard  deviation) 4.38 (4.96)  5.00 (5.00)  0.00 (0.00)  249     Judging Model pq_assign_a1_4   Associated program:  a = 3  b = a     Description: Variables are represented by  containers containing cards. A card migrates  from a to b.    Time: 6 seconds  Concreteness: 100 percent of names are used  in the model      Total number of first judgements 154   Average bet points (0 to 10) representing the playe r's  confidence (standard deviation) 7.86 (3.56)   Average watch time (standard deviation) 12.02 secon ds (8.19)   Number and percentage of players, who declared that   the model is appropriate ("good"-judgements).  74 players, 48.05 percent   Average confidence in "good"-judgement (standard  deviation) 8.18 (3.37)   Number and percentage of players, who declared that   the model is not  appropriate ("bad"-judgements) 80 players, 51.95 percent   Average confidence in "bad" judgement (standard  deviation) 7.56 (3.73)     Total number of persons, who played this game at  least three times 41    First session Second session Third session  Average bet points (0 to 10) representing the  player's confidence (standard deviation) 6.83 (4.29)  8.41 (3.25)  8.05 (3.69)   Average watch time (standard deviation) 11.80 secon ds  (7.66)  7.66 seconds  (3.40)  7.12 seconds  (3.78)   Percentage of players, who declared that the model  is appropriate ("good"-judgements).  43.90 percent  17.07 percent  12.20 percent   Average confidence in "good"-judgement (standard  deviation) 7.50 (4.29)  6.43 (4.76)  5.00 (3.54)   Percentage of players, who declared that the model  is not  appropriate ("bad"-judgements) 56.10 percent  82.93 percent  87.80 percent   Average confidence in "bad" judgement (standard  deviation) 6.30 (4.32)  8.82 (2.77)  8.47 (3.55)    250     Judging Model pq_assign_a1_3   Associated program:  a = 3  b = a     Description: The value of a variable is repre sented by a rotating disk and secondly by an  abacus. Assignment is visualized by adjusting  the disk resp. abacus.    Time: 14 seconds  Concreteness: 100 percent of names are used  in the model      Total number of first judgements 154   Average bet points (0 to 10) representing the playe r's  confidence (standard deviation) 8.15 (3.18)   Average watch time (standard deviation) 15.92 secon ds (11.04)   Number and percentage of players, who declared that   the model is appropriate ("good"-judgements).  103 players, 66.88 percent   Average confidence in "good"-judgement (standard  deviation) 8.83 (2.54)   Number and percentage of players, who declared that   the model is not  appropriate ("bad"-judgements) 51 players, 33.12 percent   Average confidence in "bad" judgement (standard  deviation) 6.76 (3.85)     Total number of persons, who played this game at  least three times 41    First session Second session Third session  Average bet points (0 to 10) representing the  player's confidence (standard deviation) 8.05 (3.51)  8.78 (3.12)  8.90 (3.06)   Average watch time (standard deviation) 16.37 secon ds  (12.91)  8.88 seconds  (4.24)  6.90 seconds  (3.49)   Percentage of players, who declared that the model  is appropriate ("good"-judgements).  70.73 percent  82.93 percent  80.49 percent   Average confidence in "good"-judgement (standard  deviation) 8.62 (2.96)  9.12 (2.60)  9.85 (0.87)   Percentage of players, who declared that the model  is not  appropriate ("bad"-judgements) 29.27 percent  17.07 percent  19.51 percent   Average confidence in "bad" judgement (standard  deviation) 6.67 (4.44)  7.14 (4.88)  5.00 (5.35)  251     Judging Model pq_assign_a1_2   Associated program:  a = 3  b = a     Description: The value of a variable is repre sented by a rotating disk. Assignment is visual ized by adjusting the disk. Variable b adjusts  the disk of a.    Time: 14 seconds  Concreteness: 100 percent of names are used in  the model      Total number of first judgements 154   Average bet points (0 to 10) representing the playe r's  confidence (standard deviation) 8.38 (2.96)   Average watch time (standard deviation) 15.82 secon ds (10.79)   Number and percentage of players, who declared that   the model is appropriate ("good"-judgements).  108 players, 70.13 percent   Average confidence in "good"-judgement (standard  deviation) 8.80 (2.55)   Number and percentage of players, who declared that   the model is not  appropriate ("bad"-judgements) 46 players, 29.87 percent   Average confidence in "bad" judgement (standard  deviation) 7.39 (3.61)     First three judgements  Total number of persons, who played this game at  least three times 41    First session Second session Third session  Average bet points (0 to 10) representing the  player's confidence (standard deviation) 7.32 (3.72)  8.54 (2.79)  8.90 (2.85)   Average watch time (standard deviation) 16.10 secon ds  (9.13)  22.59 seconds  (62.44)  16.51 seconds  (47.26)   Percentage of players, who declared that the model  is appropriate ("good"-judgements).  60.98 percent  70.73 percent  70.73 percent   Average confidence in "good"-judgement (standard  deviation) 7.60 (3.57)  8.28 (3.07)  9.66 (1.86)   Percentage of players, who declared that the model  is not  appropriate ("bad"-judgements) 39.02 percent  29.27 percent  29.27 percent   Average confidence in "bad" judgement (standard  deviation) 6.88 (4.03)  9.17 (1.95)  7.08 (3.96)  252     Judging Model pq_assign_a1_1   Associated program:  a = 3  b = a     Description: The value of a variable is repre sented by a rotating disk. Assignment is visual ized by adjusting the disk.    Time: 14 seconds  Concreteness: 100 percent of names are used in  the model      Total number of first judgements 154   Average bet points (0 to 10) representing the playe r's  confidence (standard deviation) 7.82 (3.28)   Average watch time (standard deviation) 19.93 secon ds (10.96)   Number and percentage of players, who declared that   the model is appropriate ("good"-judgements).  100 players, 64.94 percent   Average confidence in "good"-judgement (standard  deviation) 8.30 (3.03)   Number and percentage of players, who declared that   the model is not appropriate ("bad"-judgements) 54 players, 35.06 percent   Average confidence in "bad" judgement (standard  deviation) 6.94 (3.56)     Total number of persons, who played this game at  least three times 41    First session Second session Third session  Average bet points (0 to 10) representing the  player's confidence (standard deviation) 6.83 (4.15)  9.15 (2.21)  9.15 (2.72)   Average watch time (standard deviation) 19.71 secon ds  (8.63)  12.41 seconds  (6.88)  9.10 seconds  (5.94)   Percentage of players, who declared that the model  is appropriate ("good"-judgements).  68.29 percent  92.68 percent  85.37 percent   Average confidence in "good"-judgement (standard  deviation) 7.50 (3.97)  9.21 (2.18)  9.86 (0.85)   Percentage of players, who declared that the model  is not  appropriate ("bad"-judgements) 31.71 percent  7.32 percent  14.63 percent   Average confidence in "bad" judgement (standard  deviation) 5.38 (4.31)  8.33 (2.89)  5.00 (5.48)  253     Judging Model pq_assign_a1_13   Associated program:  a = 3  b = a     Description: Shows a reversed pointer model  for variables. Two pointers point from a card  with number 3 to two names of the object 3 (a  and b)    Time: 5 seconds  Concreteness: 100 percent of names are used in  the model      Total number of first judgements 154   Average bet points (0 to 10) representing the playe r's  confidence (standard deviation) 7.60 (3.58)   Average watch time (standard deviation) 13.35 secon ds (13.77)   Number and percentage of players, who declared that   the model is appropriate ("good"-judgements).  70 players, 45.45 percent   Average confidence in "good"-judgement (standard  deviation) 7.21 (3.77)   Number and percentage of players, who declared that   the model is not  appropriate ("bad"-judgements) 84 players, 54.55 percent   Average confidence in "bad" judgement (standard  deviation) 7.92 (3.40)     Total number of persons, who played this game at  least three times 41    First session Second session Third session  Average bet points (0 to 10) representing the  player's confidence (standard deviation) 6.34 (4.33)  8.05 (3.69)  8.41 (3.61)   Average watch time (standard deviation) 18.10 secon ds  (18.67)  6.56 seconds  (3.29)  5.02 seconds  (4.85)   Percentage of players, who declared that the model  is appropriate ("good"-judgements).  56.10 percent  53.66 percent  29.27 percent   Average confidence in "good"-judgement (standard  deviation) 5.65 (4.60)  8.41 (3.58)  9.17 (2.89)   Percentage of players, who declared that the model  is not  appropriate ("bad"-judgements) 43.90 percent  46.34 percent  70.73 percent   Average confidence in "bad" judgement (standard  deviation) 7.22 (3.92)  7.63 (3.86)  8.10 (3.88)  254     Judging Model  pq_assign_a1_12   Associated program:  a = 3  b = a     Description: Variable a containing the value 3  is visualized by a pointer named a pointing to  number 3. A second pointer b points to the  origin of pointer a.    Time: 5 seconds  Concreteness: 100 percent of names are used in  the model      Total number of first judgements 154   Average bet points (0 to 10) representing the playe r's  confidence (standard deviation) 8.86 (2.46)   Average watch time (standard deviation) 12.07 secon ds (13.72)   Number and percentage of players, who declared that   the model is appropriate ("good"-judgements).  87 players, 56.49 percent   Average confidence in "good"-judgement (standard  deviation) 8.39 (2.80)   Number and percentage of players, who declared that   the model is not  appropriate ("bad"-judgements) 67 players, 43.51 percent   Average confidence in "bad" judgement (standard  deviation) 9.48 (1.77)     Total number of persons, who played this game at  least three times 41    First session Second session Third session  Average bet points (0 to 10) representing the  player's confidence (standard deviation) 8.90 (2.62)  8.66 (3.17)  8.54 (3.40)   Average watch time (standard deviation) 13.90 secon ds  (19.10)  5.00 seconds  (2.58)  4.76 seconds  (2.17)   Percentage of players, who declared that the model  is appropriate ("good"-judgements).  53.66 percent  14.63 percent  12.20 percent   Average confidence in "good"-judgement (standard  deviation) 8.18 (3.29)  6.67 (4.08)  9.00 (2.24)   Percentage of players, who declared that the model  is not  appropriate ("bad"-judgements) 46.34 percent  85.37 percent  87.80 percent   Average confidence in "bad" judgement (standard  deviation) 9.74 (1.15)  9.00 (2.92)  8.47 (3.55)  255     Judging Model pq_assign_a1_11   Associated program:  a = 3  b = a     Description: Variable a containing the value 3  is visualized by a pointer named a pointing to a  card with number 3. A second pointer b points  to the same card.    Time: 6 seconds  Concreteness: 100 percent of names are used in  the model      Total number of first judgements 154   Average bet points (0 to 10) representing the playe r's  confidence (standard deviation) 8.31 (2.98)   Average watch time (standard deviation) 13.36 secon ds (11.38)   Number and percentage of players, who declared that   the model is appropriate ("good"-judgements).  119 players, 77.27 percent   Average confidence in "good"-judgement (standard  deviation) 8.82 (2.50)   Number and percentage of players, who declared that   the model is not  appropriate ("bad"-judgements) 35 players, 22.73 percent   Average confidence in "bad" judgement (standard  deviation) 6.57 (3.79)     Total number of persons, who played this game at  least three times 41    First session Second session Third session  Average bet points (0 to 10) representing the  player's confidence (standard deviation) 7.80 (3.54)  9.27 (2.11)  8.41 (3.61)   Average watch time (standard deviation) 13.00 secon ds  (11.38)  6.17 seconds  (2.61)  5.12 seconds  (3.09)   Percentage of players, who declared that the model  is appropriate ("good"-judgements).  78.05 percent  87.80 percent  85.37 percent   Average confidence in "good"-judgement (standard  deviation) 8.75 (2.54)  9.31 (2.12)  9.29 (2.47)   Percentage of players, who declared that the model  is not  appropriate ("bad"-judgements) 21.95 percent  12.20 percent  14.63 percent   Average confidence in "bad" judgement (standard  deviation) 4.44 (4.64)  9.00 (2.24)  3.33 (5.16)  256     Judging Model pq_assign_a1_10   Associated program:  a = 3  b = a     Description: Variable a is visualized by a box  with a name sign a containing a card with  number 3. A second name sign b is attached  to this box.    Time: 6 seconds  Concreteness: 100 percent of names are used  in the model      Total number of first judgements 154   Average bet points (0 to 10) representing the playe r's  confidence (standard deviation) 7.76 (3.13)   Average watch time (standard deviation) 17.31 secon ds (18.40)   Number and percentage of players, who declared that   the model is appropriate ("good"-judgements).  103 players, 66.88 percent   Average confidence in "good"-judgement (standard  deviation) 7.96 (3.09)   Number and percentage of players, who declared that   the model is not  appropriate ("bad"-judgements) 51 players, 33.12 percent   Average confidence in "bad" judgement (standard  deviation) 7.35 (3.22)     Total number of persons, who played this game at  least three times 41    First session Second session Third session  Average bet points (0 to 10) representing the  player's confidence (standard deviation) 8.29 (3.08)  8.90 (2.10)  8.78 (3.12)   Average watch time (standard deviation) 19.56 secon ds  (25.27)  8.07 seconds  (3.45)  7.12 seconds  (5.38)   Percentage of players, who declared that the model  is appropriate ("good"-judgements).  60.98 percent  68.29 percent  60.98 percent   Average confidence in "good"-judgement (standard  deviation) 8.40 (2.78)  8.93 (2.09)  9.60 (1.38)   Percentage of players, who declared that the model  is not  appropriate ("bad"-judgements) 39.02 percent  31.71 percent  39.02 percent   Average confidence in "bad" judgement (standard  deviation) 8.12 (3.59)  8.85 (2.19)  7.50 (4.47)  257     Task 2  Judging Model pq_assign_a2_8   Associated program:  today = "Monday"  today = "Tuesday"  today = "Wednesday"     Description: A Variable is represented by a  pointer. Successive assignments are visual ized by accumulated pointers (fan) pointing  to several data objects    Time: 6 seconds  Concreteness: 100 percent of names are used  in the model       Total number of first judgements 154   Average bet points (0 to 10) representing the playe r's  confidence (standard deviation) 8.47 (3.10)   Average watch time (standard deviation) 11.38 secon ds (24.53)   Number and percentage of players, who declared that   the model is appropriate ("good"-judgements).  59 players, 38.31 percent   Average confidence in "good"-judgement (standard  deviation) 8.81 (2.84)   Number and percentage of players, who declared that   the model is not  appropriate ("bad"-judgements) 95 players, 61.69 percent   Average confidence in "bad" judgement (standard  deviation) 8.26 (3.24)     Total number of persons, who played this game at  least three times 41    First session Second session Third session  Average bet points (0 to 10) representing the  player's confidence (standard deviation) 7.56 (4.05)  8.88 (2.65)  8.54 (3.40)   Average watch time (standard deviation) 9.63 second s  (5.78)  5.05 seconds  (2.58)  3.73 seconds  (1.99)   Percentage of players, who declared that the model  is appropriate ("good"-judgements).  43.90 percent  19.51 percent  7.32 percent   Average confidence in "good"-judgement (standard  deviation) 7.78 (4.28)  7.50 (3.78)  6.67 (5.77)   Percentage of players, who declared that the model  is not  appropriate ("bad"-judgements) 56.10 percent  80.49 percent  92.68 percent   Average confidence in "bad" judgement (standard  deviation) 7.39 (3.95)  9.22 (2.24)  8.68 (3.22)  258     Judging Model pq_assign_a2_9   Associated program:  today = "Monday"  today = "Tuesday"  today = "Wednesday"     Description: A Variable is represented by a  pointer. Successive assignments are visual ized by one pointers pointing to appearing  cards    Time: 6 seconds  Concreteness: 100 percent of names are used  in the model       Total number of first judgements 154   Average bet points (0 to 10) representing the playe r's  confidence (standard deviation) 9.09 (2.32)   Average watch time (standard deviation) 7.77 second s (5.88)   Number and percentage of players, who declared that   the model is appropriate ("good"-judgements).  125 players, 81.17 percent   Average confidence in "good"-judgement (standard  deviation) 9.36 (1.79)   Number and percentage of players, who declared that   the model is not  appropriate ("bad"-judgements) 29 players, 18.83 percent   Average confidence in "bad" judgement (standard  deviation) 7.93 (3.66)     First three judgements  Total number of persons, who played this game at  least three times 41    First session Second session Third session  Average bet points (0 to 10) representing the  player's confidence (standard deviation) 8.29 (3.47)  9.00 (2.82)  8.66 (3.36)   Average watch time (standard deviation) 7.44 second s  (4.98)  5.80 seconds  (3.87)  4.44 seconds  (5.62)   Percentage of players, who declared that the model  is appropriate ("good"-judgements).  75.61 percent  90.24 percent  80.49 percent   Average confidence in "good"-judgement (standard  deviation) 9.03 (2.39)  9.19 (2.50)  9.55 (1.92)   Percentage of players, who declared that the model  is not  appropriate ("bad"-judgements) 24.39 percent  9.76 percent  19.51 percent   Average confidence in "bad" judgement (standard  deviation) 6.00 (5.16)  6.67 (5.77)  5.00 (5.35)  259     Judging Model pq_assign_a2_1   Associated program:  today = "Monday"  today = "Tuesday"  today = "Wednesday"     Description: A Variable is represented by a  container. To visualize 3 successive assign ments 3 cards move into the container with out destruction of former content.    Time: 6 seconds  Concreteness: 100 percent of names are used  in the model       Total number of first judgements 154   Average bet points (0 to 10) representing the playe r's  confidence (standard deviation) 8.86 (2.71)   Average watch time (standard deviation) 7.92 second s (4.65)   Number and percentage of players, who declared that   the model is appropriate ("good"-judgements).  54 players, 35.06 percent   Average confidence in "good"-judgement (standard  deviation) 8.70 (2.94)   Number and percentage of players, who declared that   the model is not  appropriate ("bad"-judgements) 100 players, 64.94 percent   Average confidence in "bad" judgement (standard  deviation) 8.95 (2.59)     Total number of persons, who played this game at  least three times 41    First session Second session Third session  Average bet points (0 to 10) representing the  player's confidence (standard deviation) 8.05 (3.51)  8.25 (3.50)  8.41 (3.61)   Average watch time (standard deviation) 8.15 second s  (5.14)  6.03 seconds  (3.77)  4.07 seconds  (2.07)   Percentage of players, who declared that the model  is appropriate ("good"-judgements).  36.59 percent  14.63 percent  7.32 percent   Average confidence in "good"-judgement (standard  deviation) 8.67 (2.97)  4.17 (4.92)  6.67 (5.77)   Percentage of players, who declared that the model  is not  appropriate ("bad"-judgements) 63.41 percent  85.37 percent  92.68 percent   Average confidence in "bad" judgement (standard  deviation) 7.69 (3.80)  8.97 (2.69)  8.55 (3.47)  260     Judging Model pq_assign_a2_2   Associated program:  today = "Monday"  today = "Tuesday"  today = "Wednesday"     Description: A Variable is represented by a  container. To visualize successive assign ments cards move into the container after  former content has moved out.    Time: 7 seconds  Concreteness: 100 percent of names are used  in the model       Total number of first judgements 154   Average bet points (0 to 10) representing the playe r's  confidence (standard deviation) 8.86 (2.83)   Average watch time (standard deviation) 9.45 second s (12.45)   Number and percentage of players, who declared that   the model is appropriate ("good"-judgements).  120 players, 77.92 percent   Average confidence in "good"-judgement (standard  deviation) 9.12 (2.40)   Number and percentage of players, who declared that   the model is not  appropriate ("bad"-judgements) 34 players, 22.08 percent   Average confidence in "bad" judgement (standard  deviation) 7.94 (3.92)     Total number of persons, who played this game at  least three times 41    First session Second session Third session  Average bet points (0 to 10) representing the  player's confidence (standard deviation) 8.29 (3.64)  9.25 (2.42)  8.66 (3.36)   Average watch time (standard deviation) 8.27 second s  (6.03)  5.53 seconds  (3.26)  3.98 seconds  (1.92)   Percentage of players, who declared that the model  is appropriate ("good"-judgements).  78.05 percent  90.24 percent  85.37 percent   Average confidence in "good"-judgement (standard  deviation) 9.06 (2.68)  9.46 (1.97)  9.57 (1.87)   Percentage of players, who declared that the model  is not  appropriate ("bad"-judgements) 21.95 percent  9.76 percent  14.63 percent   Average confidence in "bad" judgement (standard  deviation) 5.56 (5.27)  6.67 (5.77)  3.33 (5.16)  261     Judging Model pq_assign_a2_3   Associated program:  today = "Monday"  today = "Tuesday"  today = "Wednesday"     Description: A Variable is represented by a  container. To visualize successive assign ments cards move into it after former content  has been destroyed.    Time: 7 seconds  Concreteness: 100 percent of names are used  in the model       Total number of first judgements 154   Average bet points (0 to 10) representing the playe r's  confidence (standard deviation) 8.44 (3.00)   Average watch time (standard deviation) 10.14 secon ds (11.01)   Number and percentage of players, who declared that   the model is appropriate ("good"-judgements).  117 players, 75.97 percent   Average confidence in "good"-judgement (standard  deviation) 8.93 (2.53)   Number and percentage of players, who declared that   the model is not  appropriate ("bad"-judgements) 37 players, 24.03 percent   Average confidence in "bad" judgement (standard  deviation) 6.89 (3.79)     Total number of persons, who played this game at  least three times 41    First session Second session Third session  Average bet points (0 to 10) representing the  player's confidence (standard deviation) 7.68 (3.55)  8.62 (2.99)  8.29 (3.64)   Average watch time (standard deviation) 10.00 secon ds  (10.61)  5.92 seconds  (3.96)  4.10 seconds  (2.34)   Percentage of players, who declared that the model  is appropriate ("good"-judgements).  65.85 percent  82.93 percent  75.61 percent   Average confidence in "good"-judgement (standard  deviation) 9.26 (1.81)  8.68 (3.09)  9.19 (2.61)   Percentage of players, who declared that the model  is not  appropriate ("bad"-judgements) 34.15 percent  17.07 percent  24.39 percent   Average confidence in "bad" judgement (standard  deviation) 4.64 (4.14)  8.33 (2.58)  5.50 (4.97)  262     Judging Model pq_assign_a2_4   Associated program:  today = "Monday"  today = "Tuesday"  today = "Wednesday"     Description: A Variable is represented by a  sheet with title (representing the name). As signments are visualized through writing  words on it.    Time: 8 seconds  Concreteness: 100 percent of names are used  in the model       Total number of first judgements 154   Average bet points (0 to 10) representing the playe r's  confidence (standard deviation) 8.70 (2.96)   Average watch time (standard deviation) 10.67 secon ds (10.80)   Number and percentage of players, who declared that   the model is appropriate ("good"-judgements).  40 players, 25.97 percent   Average confidence in "good"-judgement (standard  deviation) 8.38 (3.08)   Number and percentage of players, who declared that   the model is not  appropriate ("bad"-judgements) 114 players, 74.03 percent   Average confidence in "bad" judgement (standard  deviation) 8.82 (2.92)     First three judgements  Total number of persons, who played this game at  least three times 41    First session Second session Third session  Average bet points (0 to 10) representing the  player's confidence (standard deviation) 7.68 (3.72)  8.62 (2.99)  8.90 (2.85)   Average watch time (standard deviation) 8.73 second s  (6.87)  5.45 seconds  (2.15)  4.44 seconds  (2.54)   Percentage of players, who declared that the model  is appropriate ("good"-judgements).  24.39 percent  24.39 percent  14.63 percent   Average confidence in "good"-judgement (standard  deviation) 5.50 (4.38)  6.00 (4.59)  10.00 (0.00)   Percentage of players, who declared that the model  is not  appropriate ("bad"-judgements) 75.61 percent  75.61 percent  85.37 percent   Average confidence in "bad" judgement (standard  deviation) 8.39 (3.26)  9.50 (1.53)  8.71 (3.05)  263     Judging Model pq_assign_a2_5   Associated program:  today = "Monday"  today = "Tuesday"  today = "Wednesday"     Description: A Variable is represented by a  sheet with title. Assignments are visualized  through writing words on it after crossing out  the former word.    Time: 8 seconds  Concreteness: 100 percent of names are used  in the model       Total number of first judgements 154   Average bet points (0 to 10) representing the playe r's  confidence (standard deviation) 8.93 (2.62)   Average watch time (standard deviation) 8.12 second s (6.71)   Number and percentage of players, who declared that   the model is appropriate ("good"-judgements).  102 players, 66.23 percent   Average confidence in "good"-judgement (standard  deviation) 9.17 (2.34)   Number and percentage of players, who declared that   the model is not  appropriate ("bad"-judgements) 52 players, 33.77 percent   Average confidence in "bad" judgement (standard  deviation) 8.46 (3.06)     Total number of persons, who played this game at  least three times 41    First session Second session Third session  Average bet points (0 to 10) representing the  player's confidence (standard deviation) 8.17 (3.31)  8.90 (2.37)  9.02 (3.00)   Average watch time (standard deviation) 8.90 second s  (8.45)  4.37 seconds  (1.89)  3.73 seconds  (2.37)   Percentage of players, who declared that the model  is appropriate ("good"-judgements).  75.61 percent  80.49 percent  75.61 percent   Average confidence in "good"-judgement (standard  deviation) 8.71 (2.88)  9.09 (2.32)  10.00 (0.00)   Percentage of players, who declared that the model  is not  appropriate ("bad"-judgements) 24.39 percent  19.51 percent  24.39 percent   Average confidence in "bad" judgement (standard  deviation) 6.50 (4.12)  8.12 (2.59)  6.00 (5.16)  264     Judging Model pq_assign_a2_6   Associated program:  today = "Monday"  today = "Tuesday"  today = "Wednesday"     Description: A variable is represented by a  sheet with title. Assignments are visualized  through writing words on it after having  erased the former word.    Time: 10 seconds  Concreteness: 100 percent of names are used  in the model       Total number of first judgements 154   Average bet points (0 to 10) representing the playe r's  confidence (standard deviation) 8.77 (2.70)   Average watch time (standard deviation) 9.28 second s (6.22)   Number and percentage of players, who declared that   the model is appropriate ("good"-judgements).  111 players, 72.08 percent   Average confidence in "good"-judgement (standard  deviation) 9.46 (1.56)   Number and percentage of players, who declared that   the model is not  appropriate ("bad"-judgements) 43 players, 27.92 percent   Average confidence in "bad" judgement (standard  deviation) 6.98 (3.96)     Total number of persons, who played this game at  least three times 41    First session Second session Third session  Average bet points (0 to 10) representing the  player's confidence (standard deviation) 8.05 (3.51)  8.62 (2.99)  8.66 (3.36)   Average watch time (standard deviation) 9.61 second s  (7.65)  5.83 seconds  (3.31)  3.49 seconds  (2.10)   Percentage of players, who declared that the model  is appropriate ("good"-judgements).  70.73 percent  85.37 percent  78.05 percent   Average confidence in "good"-judgement (standard  deviation) 9.48 (1.55)  9.14 (2.26)  9.84 (0.88)   Percentage of players, who declared that the model  is not  appropriate ("bad"-judgements) 29.27 percent  14.63 percent  21.95 percent   Average confidence in "bad" judgement (standard  deviation) 4.58 (4.50)  5.00 (5.00)  4.44 (5.27)  265     Judging Model pq_assign_a2_7   Associated program:  today = "Monday"  today = "Tuesday"  today = "Wednesday"     Description: A Variable is represented by a  sheet. An assignment is visualized through  writing a word on it after complete destruc tion of the former sheet.    Time: 10 seconds  Concreteness: 100 percent of names are used  in the model       Total number of first judgements 154   Average bet points (0 to 10) representing the playe r's  confidence (standard deviation) 8.05 (3.15)   Average watch time (standard deviation) 11.79 secon ds (10.68)   Number and percentage of players, who declared that   the model is appropriate ("good"-judgements).  96 players, 62.34 percent   Average confidence in "good"-judgement (standard  deviation) 8.44 (2.93)   Number and percentage of players, who declared that   the model is not  appropriate ("bad"-judgements) 58 players, 37.66 percent   Average confidence in "bad" judgement (standard  deviation) 7.41 (3.41)     First three judgements  Total number of persons, who played this game at  least three times 41    First session Second session Third session  Average bet points (0 to 10) representing the  player's confidence (standard deviation) 7.07 (3.70)  8.75 (2.94)  8.05 (3.69)   Average watch time (standard deviation) 9.39 second s  (6.30)  6.80 seconds  (4.91)  3.95 seconds  (2.86)   Percentage of players, who declared that the model  is appropriate ("good"-judgements).  60.98 percent  51.22 percent  29.27 percent   Average confidence in "good"-judgement (standard  deviation) 8.20 (3.19)  7.86 (3.73)  7.92 (3.96)   Percentage of players, who declared that the model  is not  appropriate ("bad"-judgements) 39.02 percent  48.78 percent  70.73 percent   Average confidence in "bad" judgement (standard  deviation) 5.31 (3.86)  9.74 (1.15)  8.10 (3.64)    266     Modeling messages in an object oriented program.  This game contains 5 tasks. I n each task the playe r has to judge several models, whether or not  they are appropriate to explain the execution of so me program statement.  Task 1  bottle = Container (0.7)  Task 2  bottle.fill(0.4)  Task 3  bottle.empty()  Task 4  bottle.fill(0.4)  Task 5  vase.fill(bottle.empty())      The following table provides some general informati on about the usage of this game (pq_objects).   Number of objective sessions   (not  taking into account that there are sometimes  two players working together) 28 sessions  Number of subjective sessions   (taking into account that there are sometimes two  players working together) 36 sessions  Number of subjective uncanceled sessions   (taking into account that there are sometimes two  players working together) 22 sessions  Number of subjective first uncanceled sessions   (taking into account that there are sometimes two  players working together and some people play this  game several times) 21 sessions  Number of persons, who played three times or more 0  persons    Some general information about the players of this category, who played the game at least once .   Professions 21 highschool students, 0 university students,   0 teachers, 0 professors and 0 others   Gender 4 female and 17 male persons  Hours a week spent on programming (standard de viation) 3.38 hours (2.69)  Roughly estimated experience in Python program ming(standard deviation) 126.00 days (112.73)  Age (standard deviation) 17.24 years (0.77)  Population of the town, where the workshop took  place Less than 100 000: 1, 100 000 to 500 000: 12, more  than 500 000: 8  Country Germany: 20 other country: 1    267     Task 1  Judging Model pq_objects_a1_6   Associated program:  bottle = Container (0.7)     Description: Visualization of instancing (a  bottle). A number (size) is replaced by a bot tle after a flash.    Time: 6 seconds  Concreteness: 100 percent of names are used  in the model      Total number of first judgements 21   Average bet points (0 to 10) representing the  player's confidence (standard deviation) 6.67 (3.98)   Average watch time (standard deviation) 16.62 secon ds (18.08)   Number and percentage of players, who declared  that the model is appropriate ("good"-judgements).  16 players, 76.19 percent   Average confidence in "good"-judgement (standard  deviation) 7.50 (3.65)   Number and percentage of players, who declared  that the model is not  appropriate ("bad"judgements) 5 players, 23.81 percent   Average confidence in "bad" judgement (standard  deviation) 4.00 (4.18)    268     Judging Model pq_objects_a1_5   Associated program:  bottle = Container (0.7)     Description: Unappropriate visualization of  instancing (a bottle).The class object receives  a number (size) and a string (name) and re turns a named object.    Time: 11 seconds  Concreteness: 100 percent of names are used  in the model      Total number of first judgements 21   Average bet points (0 to 10) representing the  player's confidence (standard deviation) 7.38 (3.75)   Average watch time (standard deviation) 20.52 secon ds (25.00)   Number and percentage of players, who declared  that the model is appropriate ("good"-judgements).  12 players, 57.14 percent   Average confidence in "good"-judgement (standard  deviation) 7.92 (3.34)   Number and percentage of players, who declared  that the model is not  appropriate ("bad"judgements) 9 players, 42.86 percent   Average confidence in "bad" judgement (standard  deviation) 6.67 (4.33)     Judging Model pq_objects_a1_4   Associated program:  bottle = Container (0.7)     Description: Unappropriate visualization of the  instantiation of an object (a bottle).    Time: 6 seconds  Concreteness: 100 percent of names are used in  the model   269     Total number of first judgements 21   Average bet points (0 to 10) representing the playe r's confidence (standard  deviation) 8.33 (2.42)   Average watch time (standard deviation) 11.76 secon ds (12.33)   Number and percentage of players, who declared that  the model is appropri ate ("good"-judgements).  16 players, 76.19 percent   Average confidence in "good"-judgement (standard de viation) 8.12 (2.50)   Number and percentage of players, who declared that  the model is not  ap propriate ("bad"-judgements) 5 players, 23.81 percent   Average confidence in "bad" judgement (standard dev iation) 9.00 (2.24)     Judging Model pq_objects_a1_3   Associated program:  bottle = Container (0.7)     Description: Visualization of the instantiation  of an object (a bottle). The class object is a  box which takes a number (size) and returns a  bottle.    Time: 12 seconds  Concreteness: 100 percent of names are used  in the model      Total number of first judgements 21   Average bet points (0 to 10) representing the playe r's  confidence (standard deviation) 8.10 (3.35)   Average watch time (standard deviation) 14.29 secon ds (10.22)   Number and percentage of players, who declared that   the model is appropriate ("good"-judgements).  17 players, 80.95 percent   Average confidence in "good"-judgement (standard  deviation) 7.94 (3.56)   Number and percentage of players, who declared that   the model is not  appropriate ("bad"-judgements) 4 players, 19.05 percent   Average confidence in "bad" judgement (standard  deviation) 8.75 (2.50)  270     Judging Model pq_objects_a1_ 2  Associated program:  bottle = Container (0.7)     Description: Visualization of the instantiation  of an object (a bottle). The class object has a  reservoire of bottles of different sizes and  chooses one.    Time: 6 seconds  Concreteness: 100 percent of names are used  in the model      Total number of first judgements 21   Average bet points (0 to 10) representing the  player's confidence (standard deviation) 6.67 (3.98)   Average watch time (standard deviation) 26.05 secon ds (29.00)   Number and percentage of players, who declared  that the model is appropriate ("good"-judgements).  16 players, 76.19 percent   Average confidence in "good"-judgement (standard  deviation) 7.19 (4.07)   Number and percentage of players, who declared  that the model is not  appropriate ("bad"judgements) 5 players, 23.81 percent   Average confidence in "bad" judgement (standard  deviation) 5.00 (3.54)     Judging Model pq_objects_a1_1   Associated program:  bottle = Container (0.7)     Description: Inappropriate visualization of  the instantiation of an object (a bottle). Dur ing the instantiation the class object has been  detroyed.    Time: 6 seconds  Concreteness: 100 percent of names are used  in the model   271       Total number of first judgements 21   Average bet points (0 to 10) representing the playe r's  confidence (standard deviation) 7.14 (2.99)   Average watch time (standard deviation) 21.67 secon ds (35.51)   Number and percentage of players, who declared that   the model is appropriate ("good"-judgements).  17 players, 80.95 percent   Average confidence in "good"-judgement (standard  deviation) 6.76 (3.03)   Number and percentage of players, who declared that   the model is not  appropriate ("bad"-judgements) 4 players, 19.05 percent   Average confidence in "bad" judgement (standard  deviation) 8.75 (2.50)     Task 2  Judging Model pq_objects_a2_1   Associated program:  bottle.fill(0.4)     Description: Visualization of the message  bottle.fill(0.4) using two entities for the  method and argument. The method is sent to  the bottle and the argument to a filling device.     Time: 14 seconds  Concreteness: 50 percent of names are used  in the model      Total number of first judgements 21   Average bet points (0 to 10) representing the playe r's  confidence (standard deviation) 8.57 (2.80)   Average watch time (standard deviation) 11.38 secon ds (7.77)   Number and percentage of players, who declared that   the model is appropriate ("good"-judgements).  14 players, 66.67 percent   Average confidence in "good"-judgement (standard  deviation) 9.64 (1.34)   Number and percentage of players, who declared that   the model is not  appropriate ("bad"-judgements) 7 players, 33.33 percent   Average confidence in "bad" judgement (standard  deviation) 6.43 (3.78)  272     Judging Model pq_objects_a2_2   Associated program:  bottle.fill(0.4)     Description: Visualization of the message  bottle.fill(0.4) using two entities for the  method and argument. Both are sent to a  bottle, which moves to a filling device.    Time: 13 seconds  Concreteness: 50 percent of names are used  in the model      Total number of first judgements 21   Average bet points (0 to 10) representing the  player's confidence (standard deviation) 7.62 (3.75)   Average watch time (standard deviation) 12.10 secon ds (8.99)   Number and percentage of players, who declared  that the model is appropriate ("good"-judgements).  18 players, 85.71 percent   Average confidence in "good"-judgement (standard  deviation) 8.89 (2.14)   Number and percentage of players, who declared  that the model is not  appropriate ("bad"judgements) 3 players, 14.29 percent   Average confidence in "bad" judgement (standard  deviation) 0.00 (0.00)     Judging Model pq_objects_a2_3   Associated program:  bottle.fill(0.4)     Description: Unappropriate visualization of  the message bottle.fill(0.4) by an oval moving  to a filling device which fills a bottle.    Time: 7 seconds  Concreteness: 100 percent of names are used  in the model   273       Total number of first judgements 21   Average bet points (0 to 10) representing the  player's confidence (standard deviation) 7.38 (3.75)   Average watch time (standard deviation) 9.43 second s (6.60)   Number and percentage of players, who declared  that the model is appropriate ("good"-judgements).  15 players, 71.43 percent   Average confidence in "good"-judgement (standard  deviation) 7.67 (3.20)   Number and percentage of players, who declared  that the model is not  appropriate ("bad"judgements) 6 players, 28.57 percent   Average confidence in "bad" judgement (standard  deviation) 6.67 (5.16)     Judging Model pq_objects_a2_4   Associated program:  bottle.fill(0.4)     Description: Visualization of the message  bottle.fill(0.4) by an oval moving to a bottle  which is filled in a magical way.    Time: 6 seconds  Concreteness: 100 percent of names are used  in the model      Total number of first judgements 21   Average bet points (0 to 10) representing the  player's confidence (standard deviation) 7.38 (3.75)   Average watch time (standard deviation) 11.33 secon ds (8.61)   Number and percentage of players, who declared  that the model is appropriate ("good"-judgements).  19 players, 90.48 percent   Average confidence in "good"-judgement (standard  deviation) 7.89 (3.46)   Number and percentage of players, who declared  that the model is not  appropriate ("bad"judgements) 2 players, 9.52 percent   Average confidence in "bad" judgement (standard  deviation) 2.50 (3.54)  274     Task 3  Judging Model pq_objects_a3_1   Associated program:  bottle.empty()     Description: Visualization of the message  bottle.empty() by an oval moving to a bottle  which pours out its content.    Time: 5 seconds  Concreteness: 100 percent of names are used  in the model      Total number of first judgements 21   Average bet points (0 to 10) representing the  player's confidence (standard deviation) 8.57 (2.80)   Average watch time (standard deviation) 5.67 second s (3.97)   Number and percentage of players, who declared  that the model is appropriate ("good"-judgements).  17 players, 80.95 percent   Average confidence in "good"-judgement (standard  deviation) 8.53 (2.94)   Number and percentage of players, who declared  that the model is not  appropriate ("bad"judgements) 4 players, 19.05 percent   Average confidence in "bad" judgement (standard  deviation) 8.75 (2.50)     Judging Model pq_objects_a3_3   Associated program:  bottle.empty()     Description: Unappropriate visualization of  the message bottle.empty() by an oval mov ing to a bottle. This oval is glued at the bottle.     Time: 4 seconds  Concreteness: 100 percent of names are used  in the model   275       Total number of first judgements 21   Average bet points (0 to 10) representing the playe r's  confidence (standard deviation) 9.52 (1.50)   Average watch time (standard deviation) 9.29 second s (7.36)   Number and percentage of players, who declared that   the model is appropriate ("good"-judgements).  5 players, 23.81 percent   Average confidence in "good"-judgement (standard  deviation) 10.00 (0.00)   Number and percentage of players, who declared that   the model is not  appropriate ("bad"-judgements) 16 players, 76.19 percent   Average confidence in "bad" judgement (standard  deviation) 9.38 (1.71)     Judging Model pq_objects_a3_2   Associated program:  bottle.empty()     Description: Visualization of the message bot tle.empty() by an oval moving to a bottle. This  oval has a mnipulator arm which grabs the bottle  and empties it.    Time: 5 seconds  Concreteness: 100 percent of names are used in  the model      Total number of first judgements 21   Average bet points (0 to 10) representing the playe r's  confidence (standard deviation) 7.14 (4.35)   Average watch time (standard deviation) 8.48 second s (6.85)   Number and percentage of players, who declared that   the model is appropriate ("good"-judgements).  17 players, 80.95 percent   Average confidence in "good"-judgement (standard  deviation) 8.53 (3.43)   Number and percentage of players, who declared that   the model is not  appropriate ("bad"-judgements) 4 players, 19.05 percent   Average confidence in "bad" judgement (standard  deviation) 1.25 (2.50)    276     Judging Model pq_objects_a3_5   Associated program:  bottle.empty()     Description: Visualization of the message  bottle.empty() by an oval moving to a bottle.  When it hits it, the bottle empties.    Time: 5 seconds  Concreteness: 100 percent of names are used  in the model      Total number of first judgements 21   Average bet points (0 to 10) representing the  player's confidence (standard deviation) 8.81 (3.12)   Average watch time (standard deviation) 6.10 second s (4.45)   Number and percentage of players, who declared  that the model is appropriate ("good"-judgements).  17 players, 80.95 percent   Average confidence in "good"-judgement (standard  deviation) 9.71 (1.21)   Number and percentage of players, who declared  that the model is not  appropriate ("bad"judgements) 4 players, 19.05 percent   Average confidence in "bad" judgement (standard  deviation) 5.00 (5.77)     Judging Model pq_objects_a3_4   Associated program:  bottle.empty()     Description: Unappropriate visualization of  the message bottle.empty() by an oval mov ing to a bottle. When it hits the bottle both  vanish.    Time: 5 seconds  Concreteness: 100 percent of names are used  in the model   277         Total number of first judgements 21   Average bet points (0 to 10) representing the playe r's  confidence (standard deviation) 9.05 (2.56)   Average watch time (standard deviation) 8.95 second s (7.63)   Number and percentage of players, who declared that   the model is appropriate ("good"-judgements).  4 players, 19.05 percent   Average confidence in "good"-judgement (standard  deviation) 10.00 (0.00)   Number and percentage of players, who declared that   the model is not  appropriate ("bad"-judgements) 17 players, 80.95 percent   Average confidence in "bad" judgement (standard  deviation) 8.82 (2.81)     Task 4  Judging Model pq_objects_a4_2   Associated program:  bottle.fill(0.4)     Description: An oval representing the mes sage bottle.fill(0.4) moves to a vase and then  to a bottle, triggering a flash and the filling of  the bottle with fluid.    Time: 8 seconds  Concreteness: 100 percent of names are used  in the model      Total number of first judgements 21   Average bet points (0 to 10) representing the playe r's  confidence (standard deviation) 6.90 (4.32)   Average watch time (standard deviation) 12.05 secon ds (12.84)   Number and percentage of players, who declared that   the model is appropriate ("good"-judgements).  15 players, 71.43 percent   Average confidence in "good"-judgement (standard  deviation) 9.00 (2.80)   Number and percentage of players, who declared that   the model is not  appropriate ("bad"-judgements) 6 players, 28.57 percent   Average confidence in "bad" judgement (standard  deviation) 1.67 (2.58)  278     Judging Model pq_objects_a4_3   Associated program:  bottle.fill(0.4)     Description: The transmission of the mes sage bottle.fill(0.4) is divied into two  phases. First a beam (blue line) to the  bottle appears, then the message glides  along the beam.    Time: 7 seconds  Concreteness: 100 percent of names are  used in the model      Total number of first judgements 21   Average bet points (0 to 10) representing the playe r's  confidence (standard deviation) 7.38 (3.75)   Average watch time (standard deviation) 11.62 secon ds (13.39)   Number and percentage of players, who declared that   the model is appropriate ("good"-judgements).  13 players, 61.90 percent   Average confidence in "good"-judgement (standard  deviation) 7.69 (3.30)   Number and percentage of players, who declared that   the model is not  appropriate ("bad"-judgements) 8 players, 38.10 percent   Average confidence in "bad" judgement (standard  deviation) 6.88 (4.58)     Judging Model pq_objects_a4_1   Associated program:  bottle.fill(0.4)     Description: Many ovals representing  the message bottle.fill(0.4) are mov ing over the scene. One hits the bottle  and the bottle is filled magically.    Time: 8 seconds  Concreteness: 100 percent of names  are used in the model   279     Total number of first judgements 21   Average bet points (0 to 10) representing the playe r's confidence  (standard deviation) 7.14 (3.73)   Average watch time (standard deviation) 9.43 second s (7.13)   Number and percentage of players, who declared that  the model is  appropriate ("good"-judgements).  7 players, 33.33 percent   Average confidence in "good"-judgement (standard de viation) 7.14 (3.93)   Number and percentage of players, who declared that  the model is  not  appropriate ("bad"-judgements) 14 players, 66.67 percent   Average confidence in "bad" judgement (standard dev iation) 7.14 (3.78)     Judging Model pq_objects_a4_4   Associated program:  bottle.fill(0.4)     Description: The message bottle.fill(0.4)  is not represented by an entity. Instead a  manipulator arm presses a button named  fill on the bottle-object and initiates the  filling.    Time: 7 seconds  Concreteness: 100 percent of names are  used in the model      Total number of first judgements 21   Average bet points (0 to 10) representing the playe r's  confidence (standard deviation) 6.67 (3.65)   Average watch time (standard deviation) 13.05 secon ds (11.19)   Number and percentage of players, who declared that   the model is appropriate ("good"-judgements).  17 players, 80.95 percent   Average confidence in "good"-judgement (standard  deviation) 7.65 (2.57)   Number and percentage of players, who declared that   the model is not  appropriate ("bad"-judgements) 4 players, 19.05 percent   Average confidence in "bad" judgement (standard  deviation) 2.50 (5.00)    280     Task 5  Judging Model pq_objects_a5_3   Associated program:  vase.fill(bottle.empty())     Description: The message  vase.fill(bottle.empty()) is represented by an  oval going to the vase. A message bot tle.empty() goes to the bottle which pours its  content into the vase.    Time: 7 seconds  Concreteness: 100 percent of names are used  in the model      Total number of first judgements 21   Average bet points (0 to 10) representing the playe r's  confidence (standard deviation) 6.67 (4.28)   Average watch time (standard deviation) 11.29 secon ds (10.27)   Number and percentage of players, who declared that   the model is appropriate ("good"-judgements).  11 players, 52.38 percent   Average confidence in "good"-judgement (standard  deviation) 7.27 (3.44)   Number and percentage of players, who declared that   the model is not  appropriate ("bad"-judgements) 10 players, 47.62 percent   Average confidence in "bad" judgement (standard  deviation) 6.00 (5.16)     Judging Model pq_objects_a5_2   Associated program:  vase.fill(bottle.empty())    Description: The nested message  vase.fill(bottle.empty()) is visualized  by two messages going to the bottle  and the vase. The bottle pours its  content into the vase.    Time: 7 seconds  Concreteness: 100 percent of names  are used in the model   281     Total number of first judgements 21   Average bet points (0 to 10) representing the playe r's confidence  (standard deviation) 7.14 (4.35)   Average watch time (standard deviation) 8.00 second s (6.96)   Number and percentage of players, who declared that  the model is  appropriate ("good"-judgements).  9 players, 42.86 percent   Average confidence in "good"-judgement (standard de viation) 8.89 (2.20)   Number and percentage of players, who declared that  the model is  not  appropriate ("bad"-judgements) 12 players, 57.14 percent   Average confidence in "bad" judgement (standard dev iation) 5.83 (5.15)     Judging Model pq_objects_a5_1   Associated program:  vase.fill(bottle.empty())     Description: Nested message  vase.fill(bottle.empty()) is visualized by  an empty()-message to bottle and a fill()message from bottle to vase    Time: 7 seconds  Concreteness: 50 percent of names are  used in the model      Total number of first judgements 21   Average bet points (0 to 10) representing the playe r's  confidence (standard deviation) 6.19 (4.72)   Average watch time (standard deviation) 9.86 second s (9.25)   Number and percentage of players, who declared that   the model is appropriate ("good"-judgements).  14 players, 66.67 percent   Average confidence in "good"-judgement (standard  deviation) 7.14 (4.26)   Number and percentage of players, who declared that   the model is not  appropriate ("bad"-judgements) 7 players, 33.33 percent   Average confidence in "bad" judgement (standard  deviation) 4.29 (5.35)    282     Judging Model pq_objects_a5_7   Associated program:  vase.fill(bottle.empty())     Description: The message  vase.fill(bottle.empty()) is represented by  a message that can send messages itself.    Time: 9 seconds  Concreteness: 50 percent of names are  used in the model      First Judgements   Total number of first judgements 21   Average bet points (0 to 10) representing the playe r's  confidence (standard deviation) 7.86 (3.73)   Average watch time (standard deviation) 10.10 secon ds (13.73)   Number and percentage of players, who declared that   the model is appropriate ("good"-judgements).  15 players, 71.43 percent   Average confidence in "good"-judgement (standard  deviation) 8.00 (3.68)   Number and percentage of players, who declared that   the model is not  appropriate ("bad"-judgements) 6 players, 28.57 percent   Average confidence in "bad" judgement (standard  deviation) 7.50 (4.18)     Judging Model pq_objects_a5_6   Associated program:  vase.fill(bottle.empty())    Description: The message  vase.fill(bottle.empty()) is repre sented by two messages: empty()  goes to the bottle, it returns 0.4, then  message fill(0.4) goes to the vase.    Time: 9 seconds  Concreteness: 50 percent of names  are used in the model   283     Total number of first judgements 21   Average bet points (0 to 10) representing the playe r's confidence  (standard deviation) 7.62 (3.75)   Average watch time (standard deviation) 9.14 second s (6.78)   Number and percentage of players, who declared that  the model is  appropriate ("good"-judgements).  14 players, 66.67 percent   Average confidence in "good"-judgement (standard de viation) 8.57 (3.06)   Number and percentage of players, who declared that  the model is  not  appropriate ("bad"-judgements) 7 players, 33.33 percent   Average confidence in "bad" judgement (standard dev iation) 5.71 (4.50)     Judging Model pq_objects_a5_5   Associated program:  vase.fill(bottle.empty())     Description: The message  vase.fill(bottle.empty()) is not represented  by an entity. A manipulator presses but tons on the objects and initiates the execu tion of methods.    Time: 10 seconds  Concreteness: 100 percent of names are  used in the model      Total number of first judgements 21   Average bet points (0 to 10) representing the playe r's  confidence (standard deviation) 7.38 (4.07)   Average watch time (standard deviation) 11.33 secon ds (11.46)   Number and percentage of players, who declared that   the model is appropriate ("good"-judgements).  17 players, 80.95 percent   Average confidence in "good"-judgement (standard  deviation) 8.53 (2.94)   Number and percentage of players, who declared that   the model is not  appropriate ("bad"-judgements) 4 players, 19.05 percent   Average confidence in "bad" judgement (standard  deviation) 2.50 (5.00)    284     Judging Model pq_objects_a5_4   Associated program:  vase.fill(bottle.empty())     Description: The message  vase.fill(bottle.empty()) is sent to the vase.  The vase grabs the bottle (using an ma nipulator) and pours its content into itself.     Time: 9 seconds  Concreteness: 100 percent of names are  used in the model      First Judgements   Total number of first judgements 21   Average bet points (0 to 10) representing the playe r's  confidence (standard deviation) 6.43 (4.23)   Average watch time (standard deviation) 35.57 secon ds (114.62)   Number and percentage of players, who declared that   the model is appropriate ("good"-judgements).  14 players, 66.67 percent   Average confidence in "good"-judgement (standard  deviation) 7.86 (3.23)   Number and percentage of players, who declared that   the model is not  appropriate ("bad"-judgements) 7 players, 33.33 percent   Average confidence in "bad" judgement (standard  deviation) 3.57 (4.76)    285       4 Ergänzungen zu Steuerungsmodellen  4.1 Verzweigungen in Datenfluss-Modellen  Datenfluss-orientierte visuelle Programmiersprachen  müssen bedingte Anweisungen durch relativ  aufwändige Konstrukte abbilden. Das System DRLP (An janeyulu & Anderson 1992) verwendet dazu  gesteuerte „Ventile“. Das Diagramm in Abb. 98 model liert eine Funktion, die ein Element an den An fang einer Liste setzt, sofern es noch nicht in der  Liste vorkommt. Es handelt sich um einen Graph mit   Knoten (Rechtecke, Trapez, Dreiecke) und gerichtete n Kanten (Richtung von oben nach unten). Die  oberen Rechtecke sind Eingänge für Daten, die unter en Ausgänge. Im oberen Dreieck (MEMBER)  wird geprüft, ob das Element (von links) in der Lis te (von rechts) enthalten ist. Das Ergebnis ist ein   boolescher Wert, aus dem in der trapezförmigen Einh eit ein Steuersignal erzeugt wird, das entweder  die rechte oder die linke Sperre (ENABLE) öffnet.     ENABLE ENABLENULL T FMEMBER CONSListe Element unver□ nderte  ListeListe mit neuem Element   Abb. 98: Ein datenflussorientiertes visuelles Progr amm mit DRLP nach Anjaneyulu & Anderson 1992, S. 58 9  Das Modell unterstützt zwei intuitive Modelle zum D atentransport.  Zum einen kann man sich vorstellen, dass über die D atenleitungen Entitäten wandern, die Daten  darstellen. In diesem Fall existieren aber von eine m Datum mehrere Kopien (für jeden Weg eine), die  von unterschiedlichen Einheiten verarbeitet werden oder ihr Ziel gar nicht erreichen, weil der Fluss  durch eine Sperre unterbrochen ist.  Zum zweiten kann ein Zustandsmodell für Daten verwe ndet werden. Wie bei elektronischen  Schaltkreisen befinden sich die Datenleitungen in e inem Zustand, der durch den Knoten am Anfang  der Kante determiniert ist und der die übertragenen  Daten repräsentiert.  4.2 Der Fetch-Execute-Zyklus als Beispiel einer Sch leife  Vom Benutzer wird die Eingabe eines Kommandos erwar tet. Wenn dieses Kommando keine Been digung des Dialogs signalisiert (quit), wird es aus geführt, ein neues Kommando abgefragt usw.   286     execute  commandget command command = ’quit’ ?nein ja   Abb. 99: Fetch-execute-Schleife eines interaktiven Systems. Nach Sommerville 1997, S. 287  Die Steuerungseinheit, die über die Wiederholung en tscheidet, muss sich an einer bestimmten Stel le der Sequenz befinden, nämlich vor dem Block execute command . Sie ist nicht einer holistischen zu  wiederholenden Aktion übergeordnet sondern „gleichr angiger“ Teil der Sequenz.  Der fetch-execute-Zyklus kann mit Python auf folgen de zwei Weisen implementiert werden. Erste  Variante:  while True:   c = raw_input()   if c == "Quit":          break       else:   execute(c)  Zweite Variante:  c = raw_input()  while c != "Quit":      execute(c)      c = raw_input()  Die erste Variante ist eine Implementierung des Sch leifenmodells, das im Flussdiagramm aus Abb.  99 wiedergegeben wird. Mit while True: …  wird im Prinzip eine Endlosschleife definiert, d.h . die  (von der Programmiersprachensyntax geforderte) whil e-Bedingung ist trivial und sorgt nicht für eine  Beendigung der Wiederholung. Der Ausstieg aus der S chleife erfolgt gegebenenfalls nach Prüfung der  Eingabe und wird durch die Anweisung break ausgelös t. Die Kontrolle des Schleifenausstiegs ist also  Element einer zyklischen Anweisungsfolge und nicht ihr übergeordnet.  In der zweiten Variante wird keine Programmverzweig ung sondern eine while-Bedingung verwen det, die die Anzahl der Wiederholungen steuert. Unt er dem Gesichtspunkt der Modellierung hat diese  Implementierung jedoch einen Nachteil. Die zusammen gehörige Folge von Eingabe und Auswertung  der Eingabe wird auseinander gebrochen. Der while-A nweisung ist eine einmalige EingabeAnweisung vorgeschaltet. Die wiederholte Anweisungs folge „Auswertung der Eingabe“ und „neue  Eingabe“ ist dagegen ist keine sinnvolle Gestalt. S ie kann nicht für sich stehen (d.h. sie ist nicht o hne  den Kontext der Wiederholung denkbar) da für die Au swertung im ersten Schritt eine Eingabe aus  dem letzen Durchgang verwendet wird.  Das Beispiel zeigt, dass manche Wiederholungen bess er mit dem Schleifenkonzept als mit dem  Konzept der kontrollierten Wiederholung einer holis tischen Aktivität modelliert werden. 287     4.3 Assoziierte Konzepte zur Rekursion  Levy & Lapidot (2000, 2001) beobachteten Schülerinn en und Schüler, die an einer Unterrichtsse quenz zur Rekursion („classification and discussion  learning activity“, CDA) mit folgender Struktur  teilnahmen:  1. Konfrontation mit rekursiven Phänomenen (z.B. Bi lder)  2. Gruppenarbeit: Klassifizierung der rekursiven Ph änomene  3. Präsentation der Klassifizierung, gefundenen Kat egorien und Kriterien  4. Diskussion im Plenum mit dem Ziel, gemeinsame Me rkmale von Rekursivität zu finden.  Auf Grund von Schüleräußerung identifizierten sie v erschiedene gedankliche Konzepte – sie spre chen von Präkonzepten (pre-conceptions) – , die bei  der Analyse rekursiver Phänomene ihrer Meinung  nach eine Schlüsselrolle einnehmen (Levy & Lapidot 2001). Beispiele (in Anführungsstrichen bei spielhafte Schüleräußerungen):  • Unendlich oder endlich. Hier geht es um den Abbruch  oder die unendliche Fortsetzung eines re kursiven Vorgangs.  • Regelmäßigkeit  • Gradualität („vom Kleinen zum Großen“ und umgekehrt )  • Periodizität  • Zurückkehren  • Sequentialität (z.B. „aufsteigende und absteigende Sequenzen“)  • Abhängigkeit  • Selbstbezug („Dinge, die sich selbst bauen“)  • Zirkularität  • Enthalten sein  Einige dieser Konzepte (unendlich/endlich, Zirkular ität, enthalten sein) tauchen bereits zu Beginn  der Auseinandersetzung mit Rekursivität auf. Manche  Werke der bildenden Kunst thematisieren gera dezu einen Aspekt von Rekursion. Ein Beispiel ist d as Bild von Escher, das zwei Hände darstellt, die  sich gegenseitig zeichnen (Drawing Hands, 1948). Si e zeigen das Paradox der wechselseitigen Abhän gigkeit zweier Objekte. Keines kann ohne das andere  existieren. In einer rekursiven Funktion verwen de ich dieselbe Funktion, die ich gerade definiere und die also noch gar nicht existiert.  Es gibt konkrete Phänomene, die jeweils einige dies er Konzepte in einer geschlossenen Gestalt rep räsentieren (Beispiele für „rekursive Phänomene“ fi ndet man in Levy und Lapidot, 2000). So sind in  den russian dolls die Konzepte Regelmäßigkeit , Gradualität  und enthalten sein verkörpert. Zwei ge genüber liegende parallele Spiegel eröffnen einen B lick in die Unendlichkeit, die durch rekursive  Funktionen ohne Abbruchbedingung erzeugt wird.   Man kann diese erlebbaren Phänomene als Repräsentat ionen intuitiver Modelle betrachten, die mit  Rekursion assoziiert werden, d.h. die bei der Inter pretation oder Generierung rekursiver Funktionen  verwendet werden. Diese Intuitionen sind jedoch – j ede für sich – keine vollständigen Modelle. Sie  sind fokussieren nur auf bestimmte Aspekte und könn en Teil eines Clusters von Intuitionen sein, das  bei der intellektuellen Auseinandersetzung mit eine r rekursiven Funktion verwendet wird.   Nach Wu, Dale & Bethel (1998) fördern „konkrete Mod elle“ der Rekursion (russian dolls, ProzessTracing, und Stack-Simulationen) unabhängig vom Ler ntyp besser der Lernprozess als „abstrakte Mo delle“ (Strukturschablonen, mathematische Induktion ). 288     4.4 Fehlerhafte Verwendung des Modells der Selbstau fforderung bei  eingebetteter Rekursion  Dicheva und Close (1996) haben Schüler befragt, wel che Bildschirmausgabe die Logo-Prozedur  aus Tab. 44 mit einem eingebetteten rekursiven Aufr uf liefert (initialer Aufruf: pattern3 "LEGO ).  Die Tabelle zeigt die korrekte und eine falsche Lös ung.    Logo-Programm Korrekte Lösung Falsche Lösung (Beisp iel)  to pattern3 :w     if empty? :w [stop]     print :w     pattern3 bf :w     print :w  end     LEGO  EGO  GO  O  O  GO  EGO  LEGO LEGO  EGO  GO  O  O    Tab. 44: Rekursive Logo-Prozedur mit einer korrekte n und zwei falschen Bildschirmausgaben   beim Aufruf von pattern3 "LEGO  Die richtige Lösung kann man nur finden, wenn man a nnimmt, dass beim rekursiven Aufruf ein  neuer Prozess (Akteur) entsteht, der eine Kopie des  Strings w ohne das letzte Zeichen einer (eigenen)  internen Variablen w zuordnet und verarbeitet (Dele gationsmodell, siehe nächster Abschnitt).  Auf die falsche Lösung (Tab. 44 rechts) kommt man, wenn man von der Annahme eines einzigen  Akteurs ausgeht. Das Tracing kann z.B. folgendermaß en erklärt werden:  Zuerst wird die Zeichenkette LEGO auf den Bildschir m geschrieben. Beim rekursiven Aufruf wird  die Ausführung der Aktionssequenz abgebrochen und v on neuem begonnen (gleicher Akteur). Aller dings wird diesmal die Zeichenkette ohne den ersten  Buchstaben ( bf :w ) verwendet. In der gleichen  Weise wird fortgefahren bis der String nur aus eine m Zeichen besteht. Dann wird der rekursive Aufruf  pattern3 bf :w  übersprungen (weil er nichts bewirkt) und die mit d er letzten print-Anweisung  die aktuelle Zeichenkette O nochmals ausgegeben.  Auch andere Fehlvorstellungen zur Rekursion, die Di cheva und Close identifiziert haben, basieren  auf der Vorstellung eines einzigen Akteurs (Dicheva  & Close, 1996; Close & Dicheva, 1997).   4.5 Anwendung des Delegationsmodells zur Visualisie rung der Ar beitsweise rekursiver Funktionen  Das Delegationsmodell wird in unterschiedlichen Vis ualisierungsansätzen verwendet. Sie unter scheiden sich vor allem in der Durchlässigkeit der Systemgrenze.   Im Boxmodell wird der Akteur (Prozess) als Kasten d argestellt, in dessen Inneren bei Funktions aufrufen weitere Kästen entstehen. In dieser Schach telung klingt das von Levy, Lapidot & Paz (2001)  beobachtete zur Rekursion assoziierte Konzept „enth alten sein“ an. Mit dem Boxmodell kann die Aus führung einer rekursiven Funktion durch ein System dargestellt werden, das nur über Einund Aus gänge Kontakt mit der Umgebung hat.  Eine zweite Variante des Delegationsmodells verwend et „Boxen mit Seitentüren“ und verzichtet  auf Schachtelung. Beim rekursiven Aufruf werden Dat en nicht durch den Ausgang (durch den nur das  Ergebnis nach außen darf) sondern gewissermaßen dur ch eine „Seitentür“ an einen anderen Akteur  übergeben. Dieser – und das ist das Entscheidende –  befindet sich außerhalb des aufrufenden Akteurs.  289     Delegationsmodelle ohne Schachtelung werden – etwas  versteckt – in verschiedenen Visualisie rungstechniken zur Darstellung der Arbeitsweise rek ursiver Funktionen verwendet:  • Im Stackmodell wandert die Repräsentation des warte nden Funktionsakteurs (der gerade eine  Aufgabe delegiert hat) – der Execution Frame – auf einen Stack. Wenn ein Akteur (aktiver Pro zess) seine Aufgabe abgeschlossen hat (der Prozess terminiert), übergibt er sein Ergebnis an den  Execution Frame, der zuoberst auf dem Stack liegt. Eine Besonderheit dieses Modells liegt darin,  dass immer nur ein Funktionsakteur aktiv sein kann und die anderen im Stack warten.  • Im Droid-Modell (Manis & Little, 1995) wird ein Fun ktionsaufruf durch eine grafische Repräsen tation dargestellt, die u.a. den Namen der Funktion , die übergebenen Argumente und einen Pfeil  zum aufrufenden Droid enthält. Auch hier gibt es ke ine Schachtelung.  • In der Veranschaulichung der Arbeitsweise einer rek ursiven Funktion, die eine komplexe Daten struktur bearbeitet (z.B. Sortieren einer Liste), k önnen Akteure durch Bezeichnung ihres Tätig keitsbereichs angedeutet werden. In dem Visualisier ungssytem von Stern & Naish (2002) für den  Quicksort-Algorithmus markieren Balken unterhalb ei ner Liste von Zahlen, welcher Prozess für  welchen Teilbereich zuständig ist. Jeder Balken rep räsentiert einen separaten Akteur.  Das Delegationsmodell (ohne Schachtelung mit statis chen Akteuren) kann in Rollenspielen veran schaulicht werden, indem mehrere Personen gemeinsam  einen rekursiven Algorithmus ausführen und  jeweils Teilaufgaben an andere Personen delegieren.  In dem folgenden Beispiel gehen wir davon aus,  dass eine genügend große Anzahl von Personen in ein er Reihe (zum Beispiel um einen Tisch herum)  sitzt. Der Versuchsleiter gibt einer Person eine Tü te mit verschiedenfarbigen Gummibärchen in die  Hand gegeben und fordert sie auf: „Iss rote Gummibä rchen“. Was unter dieser Aktivität zu verstehen  ist, wird in folgendem Algorithmus spezifiziert:   Algorithmus Iss rote Gummibärchen       Nimm die Tüte vom rechten Nachbarn in Empfang       Wenn die Tüte noch ein rotes Gummibärchen enth ält:             Entnimm der Tüte ein rotes Gummibärchen             Gib die Tüte dem linken Nachbarn mit der  Aufforderung             „Iss rote Gummibärchen“             Nimm die Tüte vom linken Nachbarn wieder  in Empfang        Gib die Tüte dem rechten Nachbarn zurück  4.6 Bevorzugung vollständiger Modelle zur Darstellu ng einer rekursi ven Funktion  In verschiedenen Python Visuals wurden Teilnehmer m it verschiedenen Animationen zur Erklä rung der Arbeitsweise rekursiver Funktionen konfron tiert (Berechnung der Fakultät und Spiegeln ei nes Wortes). Dabei gibt es zwei Varianten: In der l ängeren Version wird die Rekursion vollständig bis  zum Abbruch bei Erreichen des Elementarfalls darges tellt. In der kürzeren Variante wird nur der erste  rekursive Aufruf visualisiert. Abb. 100 zeigt Scree nshots jeweils aus den längeren Varianten.              Abb. 100: Visualisierung der Arbeitsweise rekursiver  Funktionen: Fakultät (Execution Frames und Termers etzungen)  und Spiegeln eines Wortes (nicht geschachtelte Akte ure, geschachtelte Execution Frames)  Die Spieler sollten u.a. angeben, welches Modell si e verwenden würden, wenn sie jemandem die  Arbeitsweise der rekursiven Funktion erklären müsst en. Tab. 45 zeigt die Verteilung der Wahlen. Die  letzte Spalte gibt das Signifkanzniveau des χ²-Tests bei Vergleich der beobachteten Wahlen mit e iner  Gleichverteilung wieder. 290      ein Schritt volle Rekursion p  Berechnung der Fakultät, Execution Frames 5 13 0,059 34645  Berechnung der Fakultät, Termersetzen 2 16 0,0009674 3  Wort spiegeln, nicht geschachtelt 3 12 0,02013675  Wort spiegeln, geschachtelt 4 11 0,07070116  Tab. 45: Ergebnisse von ersten Sessions zweier Pytho n Visuals. Die Zahlen in Spalte 2 und 3 geben an, wi e viele Perso nen das jeweilige Modell zur Erklärung der Arbeitswei se der Funktion verwenden würden. Erste und zweite Zei le: Rekursive  Berechnung der Fakultät. 36 Spieler, darunter 29 Sc hüler und 5 Studenten. 31 der Spieler haben an Work shops mit der PVS  teilgenommen. Dritte und vierte Zeile: Rekursives S piegeln eines Wortes. 30 Spieler, darunter 22 Schül er und 4 Studenten. 24  der Spieler haben an Workshops mit der PVS teilgeno mmen.  Die meisten Teilnehmer der PVS bevorzugten für Erkl ärungen die längeren und komplexeren A nimationen, die die Rekursion vollständig bis zum E lementarfall nachvollziehen.   5 Ergänzungen zu Verarbeitungsmodellen  5.1 Entstehungsprozesse im Alltag  Es gibt unterschiedliche Konzepte, um die  Entstehung  einer Sache zu beschreiben. Dazu gehören   1. die spontane Manifestation aus dem Nichts (z.B. Entstehung einer Wolke am Himmel) ohne expli ziten Produzenten,   2. Erschaffung einer Sache durch einen Produzenten (z.B. Nebel aus einer Nebelmaschine),   3. das Zusammensetzen eines Objekte aus vorhandenen  Teilen (z.B. Bau eines Autos) oder   4. die Auswahl eines Objektes aus einem Reservoir v orhandener Objekte (z.B. Würfeln einer Zu fallszahl).  Spontane Entstehung aus dem Nichts kommt in der mat eriellen Realwelt – zumindest bei den Vor gängen, die wir in unserem Alltag erleben – nicht w irklich vor. Das verbieten die Erhaltungssätze der  Naturwissenschaften (Energieerhaltungsgesetz, Masse nerhaltungsgesetz). In der Gedankenwelt der  Informatik ist dagegen spontane Entstehung ein zulä ssiges Konzept.   Bei einer Auswahl wird eine bereits existierende Sa che in einen neuen Zusammenhang gestellt und  mit neuen Qualitäten verbunden. Wer bei einer Multi ple-Choice-Aufgabe eine Möglichkeit ankreuzt,  hat ebenso eine Lösung hergestellt (obwohl der Antw orttext vorher schon existierte), wie jemand, mit  freiem Text antwortet. Ein Gegenstand, der in einem  Geschäft ausgewählt wurde, kann durch diesen  Akt zu einem Geburtstagsgeschenk (also einer neuen Entität) werden.  5.2 Vernichtungskonzepte im Alltag  Im Alltag gibt es eine Reihe von Vorgängen, bei den en Information vernichtet wird.  (1) Als ungültig markieren.  In einem Text kann man durch Einklammern oder Durc hstreichen Passagen  vernichten. Ein Pass kann durch einen entsprechende n Stempelaufdruck für ungültig erklärt werden.  Die Information bleibt aber immer noch lesbar.  (2) Vollständige Zerstörung ohne Möglichkeit der Rekons truktion.  Wenn man ein Schriftstück verbrennt,  ist die gespeicherte Information endgültig verloren  (sofern keine Kopien existieren).  (3) Verlust.  Daten werden von ihrem angestammten Platz an einen  unbekannten Ort verschoben (z.B. No tizzettel aus der Brieftasche herausnehmen und wegw erfen).  (4) Lösen von Bezügen.  Dazu zählt die Zerlegung eines informativen Aggreg ats in seine Teile (z.B. Blätter  eines Manuskriptes durcheinander bringen) als auch die Trennung eines Namens von der referierten In formationseinheit (z.B. Herausfallen eines Lesezeic hens aus einem Buch).   (5) Vergessen.  Vergessen ist die Vernichtung von Information ohne  besondere – mit der jeweiligen Infor mation zusammenhängende – Absicht. Information wird  vergessen, wenn sie lange nicht mehr ver wendet worden ist und der durch sie beanspruchte Sp eicherplatz für anderes benötigt wird.  291     (6) Entwerten.  Durch einfaches Lesen kann ein Geheimnis vernichte t werden. Eine geheime PIN-Nummer  ist nicht mehr geheim und verliert ihren Wert, wenn  sie jemand anderes liest.  Was das menschliche Gedächtnis betrifft, sind die V ernichtungsarten 1 und 5 relevant, nicht aber 2,  3 und 4. Wir können gespeicherte Information als fa lsch oder ungültig anotieren oder unwichtige Din ge mit der Zeit vergessen. Es ist uns aber nicht mö glich, einmal gespeicherte Inhalte gezielt zu zerst ö ren oder zu entfernen.  Für die Interpretation von Programmtexten sind vor allem die Vernichtungskonzepte 1 bis 4 von  Bedeutung. Das fünfte Konzept (Vergessen) kann zur Beschreibung einer Garbage Collection verwen det werden, wenn das Laufzeitsystem ein Objekt lösc ht (d.h. den für es reservierten Speicherplatz frei   gibt), für das keine Referenz mehr existiert und da s deshalb nicht mehr benötigt wird. Doch dieser  Mechanismus wird (üblicherweise) nicht vom Programm text kontrolliert. Das sechste Vernichtungs konzept (Entwerten) bezieht sich auf den pragmatisc hen Wert der Information, die durch Daten reprä sentiert wird, aber nicht auf die Daten selbst.  5.3 Totale Vernichtung bei Zuweisungen  Abb. 101 zeigt Screenshots aus einer Animation (Pyt hon Quiz assign Aufgabe 2), die sukzessive  Zuweisungen mit dem Notizzettelmodell folgendermaße n visualisiert: Vor einer erneuten Zuweisung  wird nicht allein der vorige Inhalt der Variablen v ernichtet sondern ebenfalls ihr Name. D.h. der ge samte Notizzettel verschwindet. Dann kommt ein neue r Zettel mit der Überschrift today (Variablen name) ins Bild, der dann mit dem neuen Wert beschri eben wird. Die meisten der in PVS-Workshops  beobachteten Schülerinnen und Schüler (96 von 154) akzeptierten dieses Modell. Dieses Ergebnis  zeigt, dass Anfänger häufig nicht deutlich zwischen  dem Namen und dem Wert einer Variablen diffe renzieren, sondern beides als eine Einheit sehen.      Abb. 101: Zuweisung mit totaler Vernichtung der Vari ablen  n = 154 Dauer der   Animation Entscheidungs zeit (Stdabw.) Als passend  beurteilt von  Konfidenz  (Stdabw.)  Notizzettel (pq_assign_a2_7) 10 s 11.79 s  (10.68) 96 (62.3%) 84.4% (29.3)  Tab. 46: Beurteilung eines Zuweisungsmodells mit tot aler Vernichtung der Variablen. Berücksichtigt wurde n die Antwor ten aus ersten Spieldurchgängen von 154 Schülerinne n und Schülern, die an Workshops mit der PVS teilge nommen haben.   Das Konzept der totalen Vernichtung ist sogar relat iv hartnäckig, wie die Lernkurve und Antilern kurve in Abb. 102 zeigen. Obwohl es bei dem Python Quiz Minuspunkte gab, wenn man dieses Mo dell als passend wertete, beurteilten es 29 % der V ielspieler (41 Schülerinnen und Schüler, die mindes 292     tens drei Mal gespielt haben) noch im dritten Durch gang positiv bei einer mittleren Konfidenz von  81%.   0,00% 20,00% 40,00% 60,00% 80,00% 100,00%  1 2 3als unpassend  beurteilt  Konfidenz  0,00% 20,00% 40,00% 60,00% 80,00% 100,00%  1 2 3als passend  beurteilt  Konfidenz        Abb. 102: Beurteilung eines Zuweisungsmodells mit to taler Vernichtung. Lernkurve (links) und Antilernku rve (rechts) bei  Vielspielern (n = 41)  Dieses Ergebnis zeigt, dass Anfänger häufig nicht d eutlich zwischen dem Namen und dem Wert  einer Variablen differenzieren, sondern beides als eine Einheit sehen. Es könnte sich auch um eine  spezifische Schwäche des Notizzettelmodells handeln . Im Alltag verwendet man Notizzettel häufig  nur einmal und wirft sie weg, wenn die gespeicherte  Information überholt ist. Leider wurde in der PVS  nicht geprüft, ob die Vorstellung einer totalen Ver nichtung beim Behältermodell oder Zeigermodell  seltener auftritt.  Eine zweite Erklärung ist eine übertriebene Betonun g des Zerstörungsaspektes bei sukzessiven  Zuweisungen. Dies könnte man als Halo-Effekt bezeic hnen, den man auch in anderen Zusammenhän gen beobachten kann. Der Vernichtungsgedanke „strah lt aus“ auf andere eigentlich nicht betroffene  Bereiche.  5.4 Beispiele für Datenumwandlungen   Abb. 103 zeigt eine Visualisierung der Anweisung (P ython)  result = result + 4      Abb. 103: „Verschmelzen“ von zwei Datenentitäten. Dr ei Screenshots aus einer Animation der PVS (Python Puzzle As sert First Steps)  Hier bewegt sich ein Zettel mit der Zahl 4 (Datenen tität) auf den mit result etikettierten Zettel zu.  Bei der Berührung ereignet sich die Umwandlung (vis ualisiert durch einen Blitz, der mit einem PlusZeichen beschriftet ist). Die Entitäten vereinigen sich – ähnlich wie bei einer chemischen Reaktion –  zu einer einzigen Entität mit der Summe. Sie leben gewissermaßen als Teil der Summe weiter. Offen sichtlicher ist diese „Kontinuität der Existenz“ no ch bei Visualisierungen, die die Konkatenation von  Sequenzen (Listen, Zeichenketten) darstellen (Abb. 104). 293        Abb. 104: Konkatenation von Listen. Drei Screenshots  aus einer Animation der PVS (Python Puzzle Multili sts)   Zerlegungen von Sequenzen (z.B. Listen oder Zeichen ketten) stellt man sich häufig so vor, dass ein  Materialstück – z.B. ein Papierstreifen – zerschnit ten wird (siehe Abb. 105). Begriffe aus dem Fach jargon oder sogar Funktionsund Methodenbezeichner  aus der Programmiersprachensyntax unterstüt zen diese Vorstellung (z.B. slicing für das Herausl ösen eines Stücks aus einer Sequenz). Die Beson derheit gegenüber dem Entfernen von Elementen aus e iner Sequenz ist, dass hier die Erhaltung der  Identität aufgegeben wird. Aus einer Entität entste hen mehrere neue Entitäten mit eigenen Identitäten.   Dennoch gibt es auch hier eine Kontinuität der Exis tenz, die man als „Erhaltung der Masse“ beschrei ben könnte. Bei Zerlegungen geht nichts verloren. D ie ursprüngliche Entität existiert in gewissem  Sinne in ihren Teilen weiter. Somit kann man Zerleg ungen guten Gewissens zu den Veränderungspro zessen zählen.    Abb. 105: Abstrakte Darstellung der Abspaltung eine s Pivot-Elementes aus einer unsortierten Liste im R ahmen des  Quicksort-Algorithmus. Drei Screenshots aus einer A nimation der PVS (Python Puzzle „Assert Quicksort“)   Abb. 106 zeigt eine Visualisierung, in der die Bere chnung der Wurzel durch die statische JavaMethode Math.sqrt()  als Zerlegung dargestellt wird. Der Schüler erklär te, er stelle sich die Me thode als Mechanik (symbolisiert durch die Zahnräde r) vor, die die Zahl 2 auseinander nimmt und  zwei gleiche Zahlen erzeugt, deren Produkt 2 ergibt.       Abb. 106: Illustration des 17-jährigen Schülers M. zur Visualisierung der statischen Methode (Java) Math.sqrt(2)   Programmiersprachen (z.B. C, Java, Python) enthalte n Konstrukte zur so genannten Typumwand lung (type conversion, cast). Bei Java und C z.B. w ird die Typumwandlungsoperation folgendermaßen  gebildet: Man schreibt den gewünschten Typ in Klamm ern – z.B. (byte)  – und setzt dahinter das  umzuwandelnde Objekt. Im folgenden Beispiel (Java) wird ein Objekt vom Typ  int  in ein Objekt  vom Typ float  „umgewandelt“: 294     int i = 1;  float f = (float) i;  Der Begriff Typumwandlung ist insofern missverständ lich als nicht der Typ modifiziert wird. Ein  Typ ist die Außenansicht einer Klasse (Balzert, 199 9, S.23). Wörtlich genommen würde die Umwand lung eines Typs bedeuten, dass eine Klasse (etwa di e Klasse der ganzen Zahlen) verändert wird. In der  Regel werden in Lehrbüchern Typumwandlungen sinngem äß so wie in der Wikipedia erklärt:   „Typumwandlung (engl. type conversion oder cast) be zeichnet in der Informatik die Umwandlung  eines Wertes eines Datentyps in einen Wert eines an deren Datentyps.“ 27   Es wird hier also das intuitive Modell einer Datenv eränderung verwendet. Programmtechnisch fin det aber bei einem Casting keine Veränderung statt,  sondern es wird ein neues Objekt einer anderen  Klasse generiert und das ursprüngliche Objekt bleib t erhalten.   Die Kontinuität der Existenz, die für Veränderungsp rozesse charakteristisch ist, kommt dadurch zu  Stande, dass das neue Objekt das gleiche Wissen rep räsentiert wie das gegebene Objekt. Im obigen  Beispiel repräsentiert das Objekt mit dem Namen i vom Typ int  die Zahl 1, also ein Stück mathe matischen Wissens. Das Objekt mit dem Namen f vom T yp float repräsentiert ebenfalls die Zahl 1. Bei  duck-typisierenden Sprachen wie Python wird der neu e Wert auch durch ein anderes Literal darge stellt. Das float-Objekt für das mathematische Obje kt 1 kann z.B. durch das Literal 1.0  beschrieben  werden (an Stelle von 1 für das int-Objekt).   Das Motiv für ein explizites Casting ist pragmatisc her Natur. Man möchte auf das Wissen-Objekt,  das durch das Datum repräsentiert wird, Operationen  anwenden, für die der ursprüngliche Datentyp  nicht geeignet war (in unserem Beispiel etwa Divisi onen oder Wurzelberechnungen).   5.5 Umbenennungen bei der der Ausführung von Funkti onen  Den Prozess, der beim Aufruf einer Funktion entsteh t, kann man als besonderen Bereich darstellen,  der von der Außenwelt abgetrennt ist. Man kann sich  vorstellen, dass eine Daten repräsentierende  Entität, die einen solchen Bereich betritt, einen n euen Namen annimmt. Er ist in der formalen Parame terliste spezifiziert und bringt (bei gutem Program mierstil) die Rolle des Objektes im neuen Kontext  zum Ausdruck.    Abb. 107: Umbenennungen bei der Ausführung einer Fu nktion. Sechs Screenshots aus einer Animation der P VS (Python  Puzzle Assert First Steps)                                                           27  Wikipedia, Stichwort „Typumwandlung“ www.wikipedia .de  Zugriff am 1.9.2006 295     Abb. 107 zeigt einige Screenshots aus einer Animati on, die die Ausführung der folgenden rekursi ven Funktion veranschaulicht (Python) und Umbenennu ngen an den Grenzen des Execution Frames  enthält :  def sum(n):     if n = 0: return 0     else:         result = n + sum(n-1)        return result  Aufgerufen wird sum(6) .  Der Ablauf ist folgender: Als erstes entsteht ein B rett mit der Aufschrift sum() , das einen Execu tion Frame der Funktion sum()  repräsentiert. Ein Zettel mit der Aufschrift 6 (Da tenentität ohne Na men) fliegt ins Bild (erstes Bild). Sobald er in de n Bereich des Execution Frames eintritt (zweites  Bild), erhält er das Label n (Name des formalen Par ameters). Beim rekursiven Aufruf verlässt ein Zet tel mit der Zahl 5 den Execution Frame und bewegt s ich zu einem neuen Execution Frame der Funkti on sum() (nicht im Bild). Der dritte Screenshot zei gt, wie ein Zettel mit dem Ergebnis des rekursiven  Aufrufs – nämlich die Zahl 15 – in den Execution Fr ame zurückkehrt. Er trägt ein Etikett mit der Auf schrift sum(5), also der Bezeichnung des Funktionsa ufrufs. Wie in Abschnitt 6.7.1 erläutert, kann man  Funktionsaufrufe als Namen für Daten auffassen. Bei  Berührung der beiden Datenentitäten (viertes  Bild) werden die Werte addiert und es entsteht ein neuer Zettel mit der Zahl 21, der entsprechend dem  Programmtext mit result etikettiert wird (fünftes B ild). Aus den beiden Namen n und sum(5)  ent steht in dieser Animation also ein neuer Name. Dies es Objekt wird zurückgegeben und erhält beim  Verlassen des Execution Frames (sechstes Bild) den neuen Namen sum(6) .   Der Name result macht nur innerhalb des Execution Frames der Funkti on Sinn. Außerhalb ist  er unbekannt.    5.6 Umbenennungen in Rechenprotokollen zur rekursiv en Berechnung  der Fakultät  Das folgende Python Skript definiert eine rekursive  Funktion zur Berechnung der Fakultät:  def fak(n):     if n <= 1: return 1     else: return n * fak(n-1)  In der PVS-Applikation Python Visual Factorial wurd en verschiedene Animationen, die die Ar beitsweise der Funktion fak()  veranschaulichen sollten, einander gegenüber geste llt. Zwei dieser  Animationen verwendeten das Modell der Execution Fr ames (siehe Abb. 108). In der ersten Variante  wird die Ausführung vollständig und in der zweiten Variante unvollständig bis zum ersten rekursiven  Aufruf dargestellt.    296        Abb. 108: Veranschaulichung der Arbeitsweise einer r ekursiven Funktion zur Berechnung der Fakultät unte r Verwen dung von Execution Frames. Screenshot aus der PVS ( Python Visual Factorial)  Zwei weitere Animationen verwenden ein Rechenprotok oll, bei dem Terme umgeformt werden.  Wiederum gibt die eine Variante die Ausführung in v oller Tiefe bis zum Erreichen des Elementarfalls  wieder, während die andere nach dem ersten rekursiv en Aufruf tiefer liegende Aufrufe überspringt.  Abb. 109 zeigt drei Screenshots aus einer dieser An imationen. Der Teil des Terms, der im nächsten  Schritt durch einen anderen ersetzt wird, ist durch  einen hellen Kasten markiert.     Abb. 109: Veranschaulichung der Arbeitsweise einer r ekursiven Funktion durch sukzessive Umbenennung. Dr ei Screens hots aus einer Animation der PVS (Python Visual Fac torial)  Die Spieler sollten am Ende einer Sitzung folgende Fragen beantworten:  • Welche Animation würden Sie verwenden, um jemandem zu erklären wie das Python-Skript funk tioniert?  • Welche Animation gibt die Idee einer rekursiven Fun ktion am besten wieder?  • Welche Animation war am schwierigsten nachzuvollzie hen?  Tab. 47 zeigt das Ergebnis der Sessions von 31 Teil nehmern verschiedener Workshops mit der  PVS. Die Angaben zur ersten und letzten Frage unter scheiden sich signifikant von einer Gleichvertei lung ( Chi-Quadrat-Test, p = 0.02 bzw. p = 0.04). 1 2 der 31 Teilnehmer gaben an, dass sie die Anima tion mit einer vollständigen sukzessiven Termumform ung verwenden würden, um jemandem die Ar beitsweise des Programms zu erklären. Nur sechs hie lten dieses Modell am für am schwierigsten  nachvollziehbar.     n = 31   Execution frames  (vollständig) Execution frames  (unvollständig) Rechenprotokoll  (vollständig) Rechenprotokoll  (unvollständig)  Erklären 12 5 12 2  Idee der Rekursion 10 7 11 3  Schwierig nachvoll ziehbar 2 11 6 12  Tab. 47: Wahl verschiedener Modelle zur Veranschaul ichung der Arbeitsweise einer rekursiven Funktion (F akultät). Er gebnisse von 31 ersten Sessions in Workshops mit de r PVS. Teilnehmer: 28 Schüler und 3 Studenten aus D eutschland, 6  weiblich und 25 männlich, sie beschäftigten sich im Schnitt 2.26 Stunden pro Woche mit Programmierung u nd hatten ein  Durchschnittsalter von 17.65 Jahren. 297     5.7 Datenbewegung bei Iterationen  Die PVS-Applikation Python Quiz List enthält einige  Animationen, in denen folgende Programm zeile (Python) aus einer Iteration visualisiert wir d:  for (n, a) in persons:  Dabei ist persons  eine Liste von Tupeln der Form (Name , Alter ), die eine Personengruppe  modelliert. Abb. 110 zeigt Screenshots aus Animatio nen, die das Durchlaufen der Liste (dargestellt als   Behälter mit drei Fächern) durch Zuweisungen modell iert. Die Modelle unterscheiden sich im Grad  der Naivität, mit der Materialbewegungen auf die Da rstellung von Zuweisungen angewendet werden:  (1) Im naiven Modell (pq_list_a2_6) werden keine Ko pien angefertigt und beim Überschreiben eines Va riableninhalts der vorige Inhalt nicht gelöscht. Au s dem Listenbehälter persons werden Karten ent nommen und in Behälter, die mit n und a etikettiert  sind, gesteckt. Das aktuelle Element befindet sich   immer vorne und ist somit eindeutig erkennbar. Ein solcher Ablauf kann mit realen Gegenständen  leicht nachgespielt werden.  (2) Im zweiten Modell (pq_list_a2_2) werden Element e aus dem Listenbehälter herausgenommen und  bewegen sich in die Behälter n und a, nachdem der v orige Inhalt mit einem Blitz verschwindet.  (3) Das dritte Modell (pq_list_a2_4) gibt Zuweisung en am realistischsten wieder, ist aber am weitesten   von der physischen Situation entfernt. Hier werden Kopien der Items aus der Liste angefertigt und in  die Behälter n und a bewegt, deren voriger Inhalt z erstört wird.            Abb. 110: Screenshots aus Animationen der PVS-Appli kation Python Quiz List: (1) Naive Bewegung, (2) Beweg ung ohne  Kopien, (3) Bewegung von Kopien  Tab. 48 zeigt die Ergebnisse der Beurteilung von 68  Schülerinnen und Schülern (12 w, 56 m,  Durchschnittsalter 17.15 Jahre). Die Mehrheit akzep tiert alle drei Modelle als geeignet, wobei das  dritte Modell gegenüber den anderen signifikant bev orzugt wird.  n = 68 Dauer der   Animation Entscheiungs zeit (Stdabw.) Als passend  beurteilt von  Konfidenz  (Stdabw.)  Naive Bewegung (pq_list_a2_6) 10 s 9.78 s  (5.97) 35 (51.7%) 75.7% (38.1%)  Bewegung ohne Kopien  (pq_list_a2_2) 10 s 8.81 s  (6.22) 40 (58.8%) 77.2% (38.1%)  Bewegung von Kopien (pq_list_a2_1) 10 s 11.18 s  (10.50) 49 (72.06%) 73.5% (39.7%)  Tab. 48: Beurteilung von Modellen zur Veranschaulic hung von Zuweisungen im Rahmen einer Iteration. Berü cksichtigt  wurden die Antworten aus ersten Spieldurchgängen von 68 Schülerinnen und Schülern, die an Workshops mit der PVS teil genommen haben.   Die beiden ersten Modelle können als Fehlvorstellun g interpretiert werden, weil im zugehörigen  Programm die Liste nicht verändert wird und in den Variablen a und n keine Daten gesammelt wer den. Es kann aber auch sein, dass einem Befürworter  dieser Modelle klar ist, welche Vereinfachungen  bzw. Abweichungen in ihnen stecken und dass sie gew issermaßen größeren Abstand zum Programm text haben. Die drei Modelle weisen in der oben dar gestellten Reihenfolge wachsende strukturelle 298     Komplexität (und damit sinkenden Gestaltcharakter) auf. Das Modell der naiven Bewegung ist struk turell am einfachsten und insofern das intuitivste.  Es kann denkökonomisch sein, ein solches Modell in   Kombination mit einschränkenden Vorstellungen (z.B.  „In Wirklichkeit verändert sich die Liste  nicht“) zu verwenden.  5.8 Namenbewegung bei Iterationen  In einigen Animationen der PVS-Applikation Python Q uiz List wird die Programmzeile  for (n, a) in persons:  durch Namenbewegungen veranschaulicht (siehe Abb. 1 11). Dabei werden Namen durch bewegliche  Etiketten (z.B. Klebezettel) oder Zeiger repräsenti ert.  (1) In der ersten Animation wird konsequent das Zei germodell für Namen verwendet. Zeiger mit den Na men n und a markieren die beiden Items des aktuelle n Tupels, das selbst ein Element der Liste persons  ist. Die Zeiger bewegen sich von Tupel zu Tupel.   (2) Das zweite Modell stellt die Liste durch eine V ariante eines Behältermodells dar (Brett mit grauen   Bereichen für die Elemente). Die Namen n und a werd en durch Klebezettel repräsentiert, die sich von  Wert zu Wert bewegen.  (3) Im dritten Modell sind ein Behältermodell für d ie Liste und Zeigermodelle für die Laufvariablen n und  a kombiniert.            Abb. 111: Modelle mit Namenbewegung zur Visualisierun g einer Iteration: Konsequentes Zeigermodell  (pq_assign_a1_9) Transport der Kopie eines Namens (pq _assign_a1_6 und Zeiger über Behälter (pq_assign_a1 _8)  Die Ergebnisse in Tab. 49 zeigen, dass alle drei Mo delle etwa von vier Fünftel der Schüler als pas send gewählt wurden bei etwa gleicher Konfidenz 28 . Es konnte keine Überlegenheit des einen oder  anderen Modells festgestellt werden.     n = 68 Dauer der   Animation Entscheidungs zeit (Stdabw.) Als passend  beurteilt von  Konfidenz  (Stdabw.)  Zeiger   (pq_list_a2_3) 4 s 19.4 s  (65.9) 57 (83.8%) 75.0 % (39.1%)  Zettel und Behälter (pq_assign_a1_7) 9 s 12.40 s  (17.74) 54 (79.4%) 73.5% (37.1%)  Zeiger und Behälter (pq_assign_a1_8) 7 s 10.20 s  (3.71) 54 (79.4%) 73.5% (37.1%)  Tab. 49: Beurteilung von Modellen zur Veranschaulic hung von Iterationen durch Namenbewegungen. Berücksic htigt  wurden die Antworten aus ersten Spieldurchgängen von 68 Schülerinnen und Schülern, die an Workshops mit der PVS teil genommen haben.                                                          28  Aufgrund der hohen Standardabweichungen, die auf e inige besonders lange Entscheidungszeiten hinweisen ,  lassen sich die mittleren Entscheidungszeiten nicht  vergleichen.  299     6 Ergänzungen zu intuitiven Modellen in der OOP  6.1 Klasse und Schema  Das intuitive Modell des Bauplans korrespondiert mi t dem Begriff des Schemas in der Kognitions psychologie. Nach Anderson (1996, S. 150) ist der p sychologische Begriff des Schemas an das Kon zept der Datenstrukturen angelehnt – stammt also ei gentlich aus der Informatik. Wie eine Klasse be schreibt auch ein Schema einen Typ von Objekten dur ch ein Set von Attributen (Slots), denen typische  Werte als Default zugeordnet sein können. Außerdem gibt es Attribute, die die Verbindung zu anderen  Schemata herstellen (z.B. Oberbegriff). Schemata we rden verwendet, um Objekte der Realwelt zu  identifizieren (Assimilation, Piaget) oder zu konst ruieren (Zeichnen, Bauen mit Bauklötzen etc.). Kinderzeichnungen aus verschiedenen Altersstufen illus trieren die zunehmende Verfeinerung der verwen deten Schemata. Die psychische Realität von Schemat a konnte in Erinnerungsexperimenten von Bre wer und Treyens (1981) nachgewiesen werden. Testper sonen sollten sich an Details der Einrichtung  eines Büros erinnern. Es stellte sich heraus, dass sie sich besonders gut an Gegenstände erinnern konn  ten, die typischerweise in einem Büro zu finden sin d, die also zum Schema eines Büros gehören.  6.2 Visualisierung von Klassen in Schülerzeichnunge n  Abb. 112 zeigt links eine Schülerzeichnung, in der die Java-Klasse Tier (Skript in Anhang 3.1)  durch ein Fabrikgebäude visualisiert wird. Eine Ins tanzierung eines Objektes wird durch einen Auftrag  ausgelöst, der variable Attributwerte enthält. Die zweite Abbildung enthält die Fabrik-Metapher in  abstrakterer Form, als Produzent beliebiger Objekte  des Typs ohne expliziten Auftrag.        Abb. 112: Schüler-Visualisierungen mit Fabrik-Metap hern  Abb. 113 zeigt eine Schülerzeichnung, die den Begri ff Klasse wörtlich nimmt und ihn als Klassen raum mit Tischen visualisiert. Jedes Element der Kl asse ist ein Tisch in einem Klassenraum.      Abb. 113: Modell einer Klasse als Menge von Objekten   Abb. 114 zeigt die Visualisierung einer Klassendefi nition, bei der die Prototyp-Metapher verwen det wurde. Die Klasse Tier  wird durch ein konkretes Exemplar – eine Kuh – rep räsentiert (die ersten  drei Bilder in der Klammer). Die Definition der Met hode gruesse()  wird als eine Art Schulung des  zunächst „dummen“ Prototypen dargestellt. Die Kuh l ernt, auf die Botschaft mit einem Gruß zu ant300     worten. Der Text des Grußes ist zunächst unbestimmt  und wird erst bei der Instanzierung eines Objek tes (letztes Bild) festgelegt.    Abb. 114: Illustration einer Klassendefinition und I nstanzierung eines Objektes (17-jährige Schülerin J .)  6.3 Klasse als Entität   Die Fabrikmetapher und die Toolbox-Metapher betrach ten eine Klasse (wie ein Objekt) als eigen ständige Entität in der Maschinerie eines laufenden  Programms. Dieses Bild wird durch einige Fea tures von Programmiersprachen unterstützt:  • Introspektive Klassenattribute enthalten Informatio n über eine Klasse wie z.B. Basisklassen, von  denen die Klasse abgeleitet ist (bei Python: __bases__ ), oder die verwendete method resolution  order d.h. die Reihenfolge, nach der in Oberklassen  nach Methoden gesucht wird (bei Python:  __mro__ ). Hier wird nicht ein Mengenkonzept verwendet (Kla ssenattribute als gemeinsame Ei genschaften aller Objekte) sondern die Klasse selbs t als Entität betrachtet.   • Eine statische Methode kann aufgerufen werden, inde m man eine Botschaft an die Klasse und  nicht an ein Objekt der Klasse sendet.  6.4 Prototyptheorien in der Kognitionspsychologie  In der kognitiven Psychologie unterscheidet man im Zusammenhang mit der gedanklichen Reprä sentation von Begriffen „Exemplartheorien“ und „Abs traktionstheorien“ (Anderson 1996, S. 160f.).  Abstraktionstheorien orientieren sich am aristoteli schen Kategorienkonzept, nach dem Objekte auf der  Basis gemeinsamer Merkmale zusammengefasst werden. Zum Beispiel gehören Lebewesen, die zwei  Beine, Flügel und einen Schnabel besitzen zur Kateg orie Vögel. Aristoteles ging von der Annahme  einer einzigen korrekten Taxonomie der Dinge aus. E r glaubte, es existierten universelle Regeln, nach  denen die Welt geordnet ist, und die der Philosoph nur noch zu entdecken braucht.   Dies wurde erstmals im 19. Jahrhundert von den brit ischen Philosophen Whewell und Jevons ange zweifelt. Sie betonten, dass Klassifizierung kein m echanischer Prozess ist, der sich an universellen  Regeln orientiert, sondern Kreativität erfordert (T aivalsaari 1997)  In seinen berühmten Philosophischen Untersuchungen (im Jahre 1953 erstmals veröffentlicht)  nannte Ludwig Wittgenstein Beispiele für Phänomene,  die man zwar durch einen Begriff aber nur  schwierig oder gar nicht durch gemeinsame Eigenscha ften charakterisieren kann. Ein viel zitiertes  Beispiel ist der Begriff „Spiel“. Höchst unterschie dliche Aktivitäten (die teilweise nichts Gemeinsa mes haben) werden als Spiel bezeichnet. Wittgenstei n definierte den Begriff Familienähnlichkeit. Da nach wird die Zugehörigkeit zu einer Kategorie nich t durch gemeinsame Eigenschaften, sondern durch  wechselseitige Ähnlichkeit bestimmt (Wittgenstein 1 982).  Mit Eleonor Rosch (1973, 1975) hielt diese Sichtwei se Einzug in die kognitive Psychologie. Sie  ließ Personen die Typikalität verschiedener Exempla re einer Kategorie durch Werte zwischen 1 (sehr  typisch) und 7 (sehr untypisch) einschätzen. Beispi elsweise für die Kategorie Gemüse erhielt Möhre  einen Wert von 1.1, wurde also als sehr typisch ang esehen, während Petersilie nur mit 3,8 bewertet  wurde (Rosch 1973). In den in der Folgezeit aufkomm enden Prototypoder Exemplartheorien (z.B.  Lakoff 1987) wird angenommen, dass Menschen sich zu  einem abstrakten Schema ein typisches Ex301     emplar als Prototyp merken. Wenn beurteilt werden s oll, ob ein Objekt zu dieser Kategorie gehört,  wird es mit diesem Prototyp verglichen und bei genü gend großer Ähnlichkeit der Kategorie zugeord net.  6.5 Prototyporientierte Programmiersprachen  Im Hinblick auf die Eignung als Werkzeug zur Modell ierung der Welt hat die OOP gewisse  Schwächen (Taivalsaari 1997, Lakoff 1987):  • Manche Konzepte und Phänomene lassen sich nicht auf  der Basis gemeinsamer Eigenschaften  modellieren.   • Es gibt in der Begriffsbildung graduelle Zugehörigk eiten zu Klassen und unscharfe Grenzen zwi schen Klassen.  • Kategorien sind nicht in einfachen Taxonomien aus O berund Unterbegriffen organisiert. Ent sprechend gibt es keine optimalen Klassenhierarchie n. Stattdessen ist in Programmierprojekten je de Klassenstruktur das Ergebnis eines sozialen Eini gungsprozesses („consensus-driven design“,  Taivalsaari 1997). Zudem müssen bei konkreter Softw are neben logischen Aspekten immer auch  technische Gesichtspunkte einbezogen werden. Eine k onzeptionell besonders „natürlich“ erschei nende Struktur wird manchmal abgelehnt, weil sie zu  einem System mit geringer Laufzeitund  Speicherplatzeffizienz führt.  Vor dem Hintergrund dieser Schwächen der klassische n OOP und der Erkenntnisse der kognitiven  Prototyptheorien sind prototyporientierte Programmi ersprachen entstanden, z.B. Self (Smith & Ungar  1995) und Kevo (Taivalsaari 1992). Sie verwenden ke ine Klassen, von denen Instanzen gebildet wer den (class-less programming). Stattdessen können ne ue Objekte durch Klonen aus vorhandenen Ob jekten gebildet werden. Bei Self können Eigenschaft en eines Prototypen (beliebiges anderes Objekt)  geerbt werden, indem man einem Objekt O eine Referenz zu einem Elternobjekt  P  zuordnet. Wenn in  einer Botschaft an O z.B. eine Methode vorkommt, die in der Spezifikati on von O nicht auftaucht,  sucht das System in den Spezifikationen von P und gegebenenfalls bei dessen Eltern weiter.   Ein Feature prototyporientierter Programmierung ist  das „Life Editing“ von Objekten (Smith &  Ungar 1995). Das heißt, bei einem Objekt können zu seiner Lebenszeit Attribute und Methodendefini tionen geändert oder hinzugefügt werden.   6.6 Implizite Verwendung des Prototypkonzepts bei d er Entwicklung  einer Klasse  Auch auf der Ebene des „Programmierens im Kleinen“ kann die Entwicklung einer Klasse mit ei ner objektorientierten Programmiersprache nahezu vö llig prototyporientiert sein. Anfänger, die in der  Syntax und Semantik einer Programmiersprache noch u nsicher sind, folgen häufig einer experimentel len Strategie, die dem Test Driven Development (TDD ) des Extreme Programming (Beck 2003) äh nelt. Mit Python, das diese Vorgehensweise unterstü tzt, geht das folgendermaßen. Als Beispiel neh men wir an, dass eine Schülerin namens Sandra die K lasse Geld aus dem vorigen Abschnitt  entwickeln möchte.  Als erstes schreibt sie ein Skript mit einer kleine n überschaubaren Klassendefinition und einigen  Programmzeilen zum Testen:  class Geld:        wechselkurs={'USD':0.84998,                   'GBP':1.39480,                   'EUR':1.0,                   'JPY':0.007168}            def __init__(self, waehrung, betrag):           self.waehrung=waehrung          self.betrag=float(betrag)   302     # Testen  if __name__ == "__main__":          #1      g = Geld("USD", 100)            #2      print g      print g.waehrung  Die Bedingung __name__ == "__main__"  (#1) ist dann erfüllt, wenn die Datei direkt gesta r tet wird. Nur in diesem Fall werden die Anweisungen  im eingerückten Block (ab #2) ausgeführt.  Wenn die Klasse – die später Teil eines größeren Pr ojektes sein kann – von einem anderen Modul aus  importiert wird, ist die Bedingung nicht erfüllt, u nd die Testanweisungen werden nicht ausgeführt.   Nach dem Edieren des Programmtextes startet Sandra die Datei und kontrolliert die Ausgabe der  Testanweisungen im Shell-Fenster. In diesem Fall si eht sie:  <__main__.Geld instance at 0x00D2C148>  USD  Falls die Ausgabe vom erwarteten Ergebnis abweicht oder Laufzeitfehler auftreten, enthält die  Klassendefinition logische Fehler. Der Programmtext  wird abgeändert und erneut getestet, solange bis  das Programm das gewünschte Ergebnis liefert. Im ob igen Beispiel ist das Programm korrekt. Die  erste Zeile der Ausgabe enthält eine interne Repräs entation des Objektes g.   Sandra beschließt, als nächstes dafür zu sorgen, da ss mit der print-Anweisung eine lesbare ObjektRepräsentation ausgegeben wird. Dazu ergänzt sie ei ne „magische Methode“ __str__()  , die in  einer print-Anweisung vom Laufzeitsystem aufgerufen  wird:  class Geld:        ...      def __str__(self):          return self.waehrung+' '+str(self.betrag)    # Testen  if __name__ == "__main__":          ...    Die Ausgabe im Shell-Fenster lautet nun wie erwarte t:  USD 100.0  USD  Auf diese Weise fährt Sandra fort und erweitert sch rittweise ihr Programm, bis es die gewünschte  Funktionalität hat. Das Entscheidende ist folgendes : Obwohl Sandra formal eine Klassendefinition  schreibt, modelliert sie doch in Gedanken einen Pro totypen. Alle kognitiven Aktivitäten drehen sich  um ein einzelnes Objekt, das die Klasse repräsentie rt. Dass es sich programmtechnisch um eine Klas sendefinition handelt, spielt nur ganz am Anfang ei ne Rolle, wenn sie die Klausel class Geld: notiert.   Beim eigentlichen Entwicklungsprozess hat sie immer  ein konkretes Objekt vor Augen.  6.7 Das Prototyp-Konzept bei der Nutzung von Grafik -Tools  Das Prototyp-Konzept wird auch bei der Arbeit mit v ektororientierten Grafikwerkzeugen ange wendet. Nehmen wir an, Tom will eine Abbildung mit vielen Gesichtern anfertigen. Dann zeichnet er  zunächst ein Gesicht und fügt die Elementarobjekte (Flächen und Linien) zu einer Gruppe zusammen.  Er hat damit einen Prototyp definiert. Von diesem m acht er viele Kopien und wandelt jede Kopie in  Details ab. Es entstehen viele Gesicht-Objekte, die  zwar Familienähnlichkeit im Sinne Wittgensteins  besitzen, aber nicht Exemplare einer Klasse im aris totelischen Sinne mit gemeinsamen Eigenschaften  sind.  Macromedia-Flash, ein System zur Definition visuell er Applikationen, ist zwar klassenorientiert  unterstützt aber auch und vor allem das Prototyp-Ko nzept. Ein Flash-Film kann aus verschiedenen  grafischen Objekten zusammengesetzt werden, indem m an sie aus einer Symbolbibliothek mit der  Maus auf die Arbeitsfläche holt. Technisch ist jede s Symbol eine Klasse und das „Auf-die-303     Arbeitsfläche-holen“ kein Kopieren sondern die Inst anzierung eines Objektes der Klasse. Jede Instanz  auf der Arbeitsfläche besitzt einen Instanznamen, d er z.B. von Bedeutung ist, wenn man an das Objekt  eine Botschaft schicken will. Eine nachträgliche Ve ränderung des Symbols (Klasse) wirkt sich auf alle  Instanzen aus. Bestimmte Merkmale einer Instanz (Gr öße, Helligkeit, Position auf der Arbeitsfläche)  können variieren und werden durch Attribute mit var iablen Werten repräsentiert. Wenn ein FlashEntwickler – nennen wir sie Sandra – ein Symbol (Kl asse) gestaltet, hat sie auf der Arbeitsfläche ein  konkretes Objekt – einen Prototypen – vor Augen.   6.8 Modelle für die Herstellung von Objekten  Instanzierung kann als Herstellung eines neuen Obje ktes aufgefasst werden, das vorher noch nicht  existiert hat. Je nachdem welches Modell einer Klas se man zu Grunde legt, gibt es unterschiedliche  Modellvarianten für den Herstellungsprozess. Die Fa brikmetapher impliziert, dass die Klasse ein Ak teur ist, der für den Herstellungsprozess zuständig  ist. Beim Aufruf des Konstruktors erhält die Klassenentität einen Auftrag, in dem Details des neuen Objektes spezifiziert sind. Sie führt den Auftrag a us  und generiert das neue Objekt. Stellt man sich eine  Klasse als Bauplan vor, geht bei der Instanzierung   die Aktivität von einer übergeordneten Entität aus (Laufzeitsystem), die das neue Objekt mit Hilfe der   Information aus dem Bauplan und der Argumente des K onstruktoraufrufs generiert. Eine Alltagsana logie für diesen Vorgang ist der Bau eines Hauses m it Hilfe eines Bauplans und unter Berücksichti gung bestimmter Sonderwünsche (Fassadenfarbe, Fenst ertyp, Haustür etc.), die nicht im Bauplan ver zeichnet sind. Eine ähnliche Intuition ergibt sich aus der Verwendung des Prototyp-Modells, bei dem  eine Klasse als unfertiges oder abwandelbares Objek t gesehen wird. Hier wird die Instanzierung zu  seinem Zusammenbau verschiedener Teile zu einem neu en und vollständigen Objekt. Die Klasse lie fert dabei sozusagen das Grundgerüst und die Konstr uktorargumente die Teile, die von Exemplar zu  Exemplar unterschiedlich sein können. Wie bei der R ealisierung eines Plans ist der Akteur eine über geordnete Entität. In dieser Sichtweise haben die A rgumente eines Konstruktoraufrufs eine etwas an dere Bedeutung als die Argumente eines normalen Met hodenoder Funktionsaufrufs. Methoden oder  Funktionen verbindet man in der Regel mit der Verar beitung von Daten, die als Argument übergeben  werden. Bei der Instanzierung eines Objektes stelle n die Argumente, die meist in Klammern hinter  dem Klassennamen angegeben werden, Teile (technisch : Attributwerte) dar, die in der Klassendefini tion nicht spezifiziert worden sind.   6.9 Modellierung verschachtelter Botschaften  In der letzten Aufgabe von Python Quiz „Objects“ we rden Visualisierungen der Anweisung  vase.fill(bottle.empty()) angeboten. Es geht also um die Frage, wie eine vers chachtelte  Botschaft (Botschaft, die eine andere Botschaft ent hält) aufgelöst wird. Hier gerät die Botschaftsmeta  pher an ihre Grenze. Wir unterscheiden drei Gruppen  intuitiver Modelle:  (1) Die Anweisung vase.fill(bottle.empty())  wird als eine einzige Botschaft interpre tiert. Dann muss es einen Adressaten geben, an den sie gesendet wird. In diesem Fall ist das das Ob jekt vase, da der Adressat immer zu Beginn der Bots chaft steht. Nun müsste also das Objekt vase das  Objekt bottle beauftragen, die Operation empty()  auszuführen. In zwei Modellen wird diese Sicht weise verwendet.   In der ersten Variante (pq_objects_a5_3) erhält die  Vase die komplexe Botschaft va se.fill(bottle.empty()) , dargestellt durch ein fliegendes Oval mit entspre chender Beschrif tung. Es entsteht eine neue Botschaft bottle.empty() , die sich zur Karaffe bewegt. Die Karaffe  empfängt die Botschaft, bewegt sich und schüttet ih ren Inhalt in die Vase (Abb. 115). Hier wird kon sequent das Konzept eigenaktiver Objekte, die Botsc haften verarbeiten, angewendet – freilich auf  unangemessene Weise, da gemäß der Semantik des Prog ramms das Objekt vase  keine Botschaften  verschickt. Von 23 beobachteten Personen hielten 12  dieses Modell für passend (mittlere Konfidenz  75%). 304        Abb. 115: Abspalten einer Botschaft aus einer versc hachtelten Botschaft (pq_objects_a5_3)  In der zweiten Variante (pq_objects_a5_4) wird kein e zweite Botschaft abgespalten sondern die  Vase ergreift mit einem Manipulatorarm die Karaffe und schüttet deren Inhalt in sich hinein. Hier wird   das Botschaftskonzept mit der Vorstellung passiver von außen manipulierter Objekte gemischt. Von  den 23 beobachteten Spielern hielten 16 dieses Mode ll für passend (mittlere Konfidenz 81%).    Abb. 116: Vermischen von passivem und aktivem Model l für Objekte (pq_objects_a5_3)    (2) In der zweiten Gruppe intuitiver Modelle wird d ie Programmzeile nicht als eine zusammenhän gende Botschaft sondern von vornherein als eine Fol ge zweier getrennter Botschaften interpretiert. Die   Auflösung der komplexen Botschaft erfolgt also durc h den Akteur, von dem die Botschaft stammt  (hier das Laufzeitsystem, der „oberste“ Akteur, der  für die Ausführung des gesamten Programms zu ständig ist). Einige Animationen der PVS greifen di ese Vorstellung auf. Im Modell pq_objects_a5_6  zum Beispiel schickt das Laufzeitsystem zuerst die Botschaft empty()  an die Karaffe, das Ergebnis  (Karte mit Aufschrift 0.4) wird zurück gesendet und  verschwindet aus dem Bild. Anschließend er scheint eine zweite Botschaft fill(0.4) , die an das Objekt vase geschickt wird und das Auffül len des Behälters auslöst (Abb. 117). Von den 23 be obachteten Spielern hielten 15 dieses Modell für  passend (mittlere Konfidenz 87%).       Abb. 117: Auflösung einer verschachtelten Botschaft  durch das Laufzeitsystem (pq_objects_a5_6)  Die soeben beschriebene Abfolge kann als plausibel betrachtet werden. Die PVS enthält aber zu  dieser Aufgabe auch eindeutig falsche Versionen mit  zwei einfachen Botschaften. In der Animation  (pq_objects_a5_1) wandert zunächst die Botschaft empty()  zur Karaffe. Daraufhin entleert sich 305     diese und sendet dann die Botschaft fill(0.4)  an die Vase. Diese füllt sich einem gewissen Volumen roter Flüssigkeit. Das Modell ist unpassend, we il das Objekt bottle definitiv keine Botschaft verschickt. Es wurde aber dennoch von 16 der 23 Spiele r mit einer durchschnittlichen Konfidenz von  75% akzeptiert. Die 7 ablehnenden Spieler hatten da gegen ein erheblich geringeres Vertrauen in ihre  Entscheidung (43%).    Abb. 118: Unplausibles Modell mit (pq_objects_a5_1)   (3) Eine dritte Möglichkeit schließlich besteht dar in, die Anweisung   vase.fill(bottle.empty())   als eigenen Akteur zu begreifen, als Botschaft mit noch unbestimmtem Parameter. Dieser Akteur sen det zunächst die Botschaft bottle.empty()  an die Karaffe, erhält einen Zahlenwert zurück und   wird damit zu einer vollständigen Botschaft, die zu m Objekt vase  wandert (). Von den beobachteten  23 Spielern hielten 17 dieses Modell für akzeptabel  (Konfidenz 82%) Abb. 119    Abb. 119: Verschachtelte Botschaft als eigener Akte ur, der Botschaften senden kann (pq_objects_a5_7)  6.9.1 Kontexte für die Verwendung von passiven   Objektmodellen   Im Rahmen realer Programmierprojekte gibt es Zusamm enhänge, in denen Objekte nicht als eigen aktive Entitäten gesehen werden, die Botschaften em pfangen. So können in allen OOProgrammiersprachen öffentliche Attribute direkt ge lesen oder verändert werden. Dabei bleibt das  Objekt passiv und muss die Manipulation von außen e rdulden. Häufig wird dies allerdings als schlech ter Programmierstil gesehen. In Standardwerken der OOP (z.B. Balzert 1999) wird häufig empfohlen,  den direkten Zugriff auf Attribute zu verbieten und  stattdessen spezielle öffentliche Methoden für das   Lesen und Schreiben zu definieren (setund get-Met hoden). Allerdings führt die Verwendung dieser  Zugriffsmethoden zu komplexeren (und deshalb wenige r intuitiven) mentalen Modellen. Mit Python  ist es möglich, für ein Objekt (einer „New-Style-Kl asse“) so genannte Properties zu spezifizieren (vgl .  Weigend 2006a). Dabei werden für Attribute, die von  außen erreichbar sein sollen, Zugriffsmethoden  definiert, die bei einem scheinbar direkten Zugriff  ausgeführt werden. Das heißt eine Zuweisung der  Form   objekt.attribut = neuerWert  306     wird vom Laufzeitsystem als Methodenaufruf uminterp retiert und bekommt damit den Charakter einer  Botschaft. Die Änderung selbst wird vom beauftragte n Objekt – gewissermaßen „in Eigenregie“ –  vollzogen.  Versetzen wir uns in die Situation eines Programmie rers der eine solche Zuweisung im Rahmen ei ner Problemlösung formuliert. Er oder sie verwendet  zwei intuitive Modelle gleichzeitig. Einerseits  denkt er an eine Zuweisung, also die unmittelbare V eränderung des Zustandes eines passiven Objek tes. Andererseits weiß er oder sie um den Mechanism us der Interpretation von Zugriffen auf Properties  und verwendet dabei die Intuition eines aktiven Obj ektes, das auf Botschaften reagiert. Dies ist die  typisches Beispiel für ein Modellcluster. Die gedan kliche Vorstellung passiver Objekte spielt auch  eine Rolle bei der Verwendung von Operatoren und Fu nktionen. So ist es vermutlich denkökonomi scher, eine Anweisung wie  c = a + b  als Verarbeitung zweier (passiver) Objekte zu betra chten. Der Plusoperator ist in dieser Sichtweise ei n  Akteur, der die Objekte a und b als Eingabe verwend et und ein neues Objekt (die Summe) generiert.  In einer Sichtweise, die dem objektorientierten Par adigma folgt, wird dagegen der Term a + b  als  Botschaft an das Objekt a interpretiert. Das Objekt  a erhält den Auftrag mit Objekt b in Interaktion z u  treten und ein neues Objekt zu generieren, das die Summe repräsentiert.  6.10 Indikatoren für die Validität der Ergebnisse   Das Python Quiz Objects enthält auch Animationen, d ie Vorgänge beschreiben, die objektiv im  Widerspruch zur Semantik des Bezugsprogrammtextes s tehen. Sie dienen in gewissem Maß als Kon trolle, inwieweit die PVS-Spieler überhaupt den Pro grammtext und die Bildersprache der visuellen  Modelle verstehen oder das Spiel ernst nehmen, und sind damit ein Indikator für die Validität der er hobenen Daten. Abb. 120 zeigt einige Screenshots au s falschen Modellen für die Anweisung bott le.empty() . Im ersten Modell (pq_objects_a3_4) verschwindet d ie Karaffe (Objekt bottle), sobald  die Botschaft (dargestellt als Oval) auf sie trifft . Es wurde nur von vier der 23 Spieler (17 %) akzep  tiert. Im zweiten Modell (pq_objects_a3_3) wird das  Oval, das die Botschaft repräsentieren soll, wie  ein Etikett an die Karaffe geheftet. Dieses Modell hielten fünf der 23 beobachteten Personen (22 %)  für passend.       Abb. 120: Modelle, die der Semantik der Anweisung bottle.empty()  widersprechen  7 Weitere Aspekte der intuitiven Modellierung  7.1 Intuitivität als messbare Größe  Der Begriffs „intuitiv“ wird in zwei Bedeutungsvari anten verwendet, die sich in einer Nuance un terscheiden. Häufig wird das Adjektiv „intuitiv“ in  einem idealistischen, nicht steigerungsfähigen Sin n  gebraucht. Eine Vorstellung ist intuitiv oder sie i st es nicht. Es gibt keinen Zwischenwert. Ich halte   eine gedankliche Vorstellung für richtig oder ich h abe Zweifel.   In der Praxis bewegen wir uns häufig an der Grenze zur Gewissheit. Insbesondere in kritischen Si tuationen (Entscheidungen und Handlungen, die schwe rwiegende Konsequenzen haben), vergewissert  man sich in Gedanken der Richtigkeit der gedanklich en Konzepte, die man z.B. für eine Problemlö sung verwendet. Dieses sich Vergewissern kann fast unmerklich quasi zeitgleich mit dem Auftreten  des Gedankens passieren, oder aber es erfordert grö ßere Anstrengung. 307     Wenn wir von der Intuitivität eines Modells reden, dann gebrauchen wir den Begriff „intuitiv“ in  einem steigerungsfähigen Sinn. Demnach kann ein Mod ell mehr oder weniger intuitiv sein. Der Hin tergrund ist, dass Intuitivität ein subjektives Gef ühl oder Erlebnis ist und von verschiedenen Begleit  umständen des Erlebens abhängt. Man kennt die Erfah rung, dass etwa eine Beweisidee in einem be stimmten Kontext (z.B. während eines Vortrags) einl euchtet aber das Gefühl der Gewissheit später  wieder verloren geht und erst durch eine gewisse Au seinandersetzung wieder hervorgerufen werden  kann. Messbare Aspekte von Intuitivität sind:  Akzeptanzzeit:  Die Zeit der Auseinandersetzung die benötigt wird um zu einem Gefühl der Ge wissheit zu kommen. Bei der Rezeption eines mathema tischen Beweises ist die Akzeptanzzeit die  Zeit, die ein Rezipient benötigt, um einen Beweissc hritt als richtig zu akzeptieren.  Evidenz:  Idealerweise ist eine Intuition selbstevident. Das  heißt man braucht keine weiteren Be gründungen für ihre Richtigkeit. „Sich einer Intuit ion vergewissern“ heißt, dass man zur Sicherheit  ihre Korrektheit mit Hilfe anderer Modelle (z.B. Ko ntrollmodelle) prüft. Das kann so schnell gehen,  dass man sich dessen gar nicht mehr bewusst ist ode r aber es wird zu einer bewussten subjektiv wahr nehmbaren – eventuell sogar (im Rahmen einer Erklär ung) externalisierten – gedanklichen Operation.   Gewissheit:  Wie schätze ich das Risiko ein, dass ich mit meine r Intuition falsch liege? Intuitionen  ändern sich im Laufe einer Biographie. Jeder hat be reits erlebt, dass sich etwas als falsch herausge stellt hat, das man vorher als sicher richtig einge schätzt hat. Auf Grund solcher Erlebnisse kann man  sich eigentlich niemals vollständig sicher sein.   7.2 Überstülpen des EVA-Modells als Beispiel für Üb erstrukturierung  Betrachten wir folgendes Programm:  a = "up"  b = "and down"  c = a + b  print c  Jesse (16 Jahre, Virginia, USA) hat dieses Programm  folgendermaßen durch eine Flash-Animation  visualisiert: Das Programm wurde durch eine Box dar gestellt. In diese Box wandern die beiden ersten  Zeilen des obigen Programmtextes hinein und als Aus gabe kommt die konkatenierte Zeichenkette  heraus. Jesse hat die ersten beiden Zuweisungen als  Eingabe interpretiert, was sie formal nicht sind.   Man kann dies insofern als Überstrukturierung deute n, als hier dem Programm die Struktur „Ein gabe-Verarbeitung-Ausgabe“ übergestülpt wurde. Das Verwechseln von Zuweisung und Eingabe  wurde von Samurcay (1989) beobachtet.        